[{"content":"1 2 3 4 5 6 7  # https://zhuanlan.zhihu.com/p/30670193 # pip install PySocks import socks import socket socks.set_default_proxy(socks.SOCKS5, \u0026#39;192.168.123.155\u0026#39;, 7891) socket.socket = socks.socksocket   ","description":"","id":0,"section":"moments","tags":null,"title":"Python设置全局代理","uri":"https://www.xunhs.cyou/moments/2021-07-03-python%E8%AE%BE%E7%BD%AE%E5%85%A8%E5%B1%80%E4%BB%A3%E7%90%86/"},{"content":"  \n 2021.7.1 建党百年：谁妄想欺负中国必将碰得头破血流！ 2021.7.2 心碎到太空 外星人拿来研究 发现只有你的名字 2021.7.3 一口气看完元龙第一季😂 2021.7.4 playground完成:Keras example-Text classification from scratch, my code: https://colab.research.google.com/drive/1HN6aPjVsoevc51eVYMQ_B2EKCYXzIx_R?usp=sharing 2021.7.5 “不务正业” 就爱瞎折腾啊啊🍳 2021.7.6 You\u0026rsquo;re a bright young man. This monkey business is in your blood, under your skin. You’re not getting out, you’re just getting in. I’ve every faith in you.  ","description":"","id":1,"section":"posts","tags":["Keras","建党百年","折腾"],"title":"2021-7","uri":"https://www.xunhs.cyou/posts/journals/2021-7/"},{"content":"\n听了很多遍的伤感文学。来源：https://mp.weixin.qq.com/s/UoNeEWS8xX3pik8WiHjLIQ\n 我知道我们的朋友不同，我们的城市不同，我们的处境不同人生的方向不同，但我努力开辟新的轨道以求走进你的世界，像是一棵树生拉硬扯改变生长的方向，想要去触碰围墙之外的飞鸟。 你若是喜欢花，就把它掐下来放在瓶子里养着；你要是喜欢树，也可以把它挖出来栽进自家院子去；但有的东西不行。不行就是不行。 ","description":"","id":3,"section":"moments","tags":null,"title":"Rolling Days","uri":"https://www.xunhs.cyou/moments/2021-06-28-rolling-days/"},{"content":"\n","description":"","id":4,"section":"moments","tags":null,"title":"阿拉斯加海湾","uri":"https://www.xunhs.cyou/moments/2021-06-26-%E9%98%BF%E6%8B%89%E6%96%AF%E5%8A%A0%E6%B5%B7%E6%B9%BE/"},{"content":"1 2 3 4  # jupyter  jupyter.xunhs.cyou # ssh ssh -p 21039 summer@43.249.192.204   ","description":"","id":5,"section":"moments","tags":null,"title":"远程","uri":"https://www.xunhs.cyou/moments/2021-06-21-%E8%BF%9C%E7%A8%8B/"},{"content":"\n","description":"","id":7,"section":"moments","tags":null,"title":"2021.6.19-A.I.N.Y","uri":"https://www.xunhs.cyou/moments/2021.6.19-a.i.n.y-%E9%82%93%E7%B4%AB%E6%A3%8B/"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import requests def tg_push(message, parse_mode=\u0026#39;HTML\u0026#39;): # https://blog.jialezi.net/?post=168 # https://core.telegram.org/bots/api#sendmessage proxy_pre_str = \u0026#39;https://thingproxy.freeboard.io/fetch/\u0026#39; # sendMessage（直接文本，支持MarkdownV2/HTML） req_body_str = \u0026#39;https://api.telegram.org/bot1790677966:AAH_jczd4hiHl159Yi5RkuRdhfju12hwA64/sendMessage\u0026#39; chat_id = 1753106187 req_data = { \u0026#39;chat_id\u0026#39;: chat_id, \u0026#39;text\u0026#39;: str(message), \u0026#39;parse_mode\u0026#39;: parse_mode } return requests.post(url=proxy_pre_str+req_body_str, data=req_data)   ","description":"","id":8,"section":"moments","tags":null,"title":"Telegram Bot","uri":"https://www.xunhs.cyou/moments/2021.6.17-telegram-bot/"},{"content":" SakuraFrp是一个非常好用的内网穿透工具，本文记录配置过程，包含ssh和http两类配置流程。\n 实例一：内网穿透openwrt ssh （树莓派3B+） 创建隧道  穿透节点：普通高防即可 隧道类型：TCP 本地地址：注意需填写真实ip地址，127.0.0.1此处不适用 本地端口：22  \n下载软件  uname -a查看内核：  返回：Linux OpenWrt 5.4.124 #0 SMP Fri Jun 11 17:57:31 2021 aarch64 GNU/Linux aarch64即arm64   前往https://www.natfrp.com/tunnel/download，选择Linux (arm64)，适用于树莓派3B+  树莓派端运行frpc  赋权：chmod 777 frpc_linux_arm64 运行： ./frpc_linux_arm64 -f 3ebb876549ee0ca6:1407145  客户端连接  验证：前往隧道列表查看隧道是否在线 运行：ssh -p 13694 root@cn-zz-bgp-1.natfrp.cloud  实例二：内网穿透jupyter notebook（win10） 此处仅配置内网穿透，假设系统已经配置好jupyter环境(192.168.123.87:10086)\n创建隧道  穿透节点：国外，可建站 隧道：HTTP 本地端口：10086 绑定域名：jupyter.xunhs.cyou  \n下载软件 本次环境为win10，下载win10版本即可\n运行frpc  win10环境下该软件一键安装，配置较为简单 根据日志提示，添加DNS记录，本例中使用的namesilo 等待至少15分钟（半天也是有可能的😂）生效  客户端连接  浏览器输入 http://jupyter.xunhs.cyou 即可访问  ","description":"","id":10,"section":"posts","tags":["札记","内网穿透","frp"],"title":"2021-06-15-SakuraFrp配置札记","uri":"https://www.xunhs.cyou/posts/notes/2021-06-15-sakurafrp%E9%85%8D%E7%BD%AE%E6%9C%AD%E8%AE%B0/"},{"content":"\n","description":"","id":11,"section":"moments","tags":null,"title":"2021.6.14-可不可以","uri":"https://www.xunhs.cyou/moments/2021.6.14-%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5/"},{"content":" 一些发表在“好期刊但很有意思”的论文\u0026quot;\n 2021-Staying at Home Is a Privilege: Evidence from Fine-Grained Mobile Phone Location Data in the United States during the COVID-19 Pandemic 2021-Sensing Mixed Urban Land-Use Patterns Using Municipal Water Consumption Time Series ","description":"","id":12,"section":"posts","tags":["札记"],"title":"2021-06-11-论文整理：一些发表在“好期刊但很有意思”的论文","uri":"https://www.xunhs.cyou/posts/notes/2021-06-11-%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86-%E4%B8%80%E4%BA%9B%E5%8F%91%E8%A1%A8%E5%9C%A8%E5%A5%BD%E6%9C%9F%E5%88%8A%E4%BD%86%E5%BE%88%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E8%AE%BA%E6%96%87/"},{"content":" 记录出租车数据处理基本流程及部分可视化分析。\n 数据准备及初始化 样例数据  来源: https://www.cs.rutgers.edu/~dz220/data.html 采集信息: 2013-10-22,深圳市 字段: Taxi ID, Time, Latitude, Longitude, Occupancy Status, Speed;(Occupancy Status: 1-with passengers \u0026amp; 0-with passengers;)  22223, 21:09:38, 114.116631, 22.582466, 19\n   初始化 1 2 3 4 5 6 7 8 9 10 11 12  import pandas as pd data_fp = \u0026#39;Taxidata.gz\u0026#39; data_df = pd.read_csv(data_fp, names=[\u0026#39;taxi_id\u0026#39;, \u0026#39;time\u0026#39;, \u0026#39;lat\u0026#39;, \u0026#39;lon\u0026#39;, \u0026#39;status\u0026#39;, \u0026#39;speed\u0026#39;]) data_df.head() # 数据清理 # 根据状态进行条件筛选，排除错误字段 # 按id、时间排序 data_df = data_df.query(\u0026#34;status in [0, 1]\u0026#34;)\\ .sort_values(by=[\u0026#39;taxi_id\u0026#39;, \u0026#39;time\u0026#39;])\\ .reset_index(drop=True)   提取OD 根据状态的变化确定上车点和下车点。主要参考：https://github.com/ni1o1/pygeo-tutorial/blob/master/1-taxigps_to_od.ipynb\n筛选，排除异常 1 2 3 4 5 6 7 8 9 10  #status用到的条件是： #1.后一位和前一位相等 #2.但是后一位与中间一位不等 #3.前一条数据，后一条数据的车牌相等 #4.中间一条数据，后一条数据的车牌相等 data_df = data_df[-((data_df[\u0026#39;status\u0026#39;].shift(-1) == data_df[\u0026#39;status\u0026#39;].shift())\u0026amp; (data_df[\u0026#39;status\u0026#39;].shift(-1) != data_df[\u0026#39;status\u0026#39;])\u0026amp; (data_df[\u0026#39;taxi_id\u0026#39;].shift(-1) == data_df[\u0026#39;taxi_id\u0026#39;].shift())\u0026amp; (data_df[\u0026#39;taxi_id\u0026#39;].shift(-1) == data_df[\u0026#39;taxi_id\u0026#39;]))]   乘客上下车的状态变化识别 1 2 3 4 5 6 7  data_df.loc[:,\u0026#39;status1\u0026#39;] = data_df[\u0026#39;status\u0026#39;].shift(-1) data_df.loc[:,\u0026#39;taxi_id1\u0026#39;] = data_df[\u0026#39;taxi_id\u0026#39;].shift(-1) data_df.loc[:,\u0026#39;lon1\u0026#39;] = data_df[\u0026#39;lon\u0026#39;].shift(-1) data_df.loc[:,\u0026#39;lat1\u0026#39;] = data_df[\u0026#39;lat\u0026#39;].shift(-1) data_df.loc[:,\u0026#39;time1\u0026#39;] = data_df[\u0026#39;time\u0026#39;].shift(-1) data_df.loc[:,\u0026#39;StatusChange\u0026#39;] = data_df[\u0026#39;status1\u0026#39;]-data_df[\u0026#39;status\u0026#39;]   将上下车状态整理为OD 1 2 3 4 5 6 7 8 9 10 11  data_df = data_df[((data_df[\u0026#39;StatusChange\u0026#39;] == 1)|(data_df[\u0026#39;StatusChange\u0026#39;] == -1)) \u0026amp;(data_df[\u0026#39;taxi_id\u0026#39;] == data_df[\u0026#39;taxi_id1\u0026#39;])] data_df = data_df[[\u0026#39;taxi_id\u0026#39;,\u0026#39;time\u0026#39;,\u0026#39;lon\u0026#39;,\u0026#39;lat\u0026#39;,\u0026#39;StatusChange\u0026#39;]] data_df = data_df.rename(columns = {\u0026#39;lon\u0026#39;:\u0026#39;o_lon\u0026#39;,\u0026#39;lat\u0026#39;:\u0026#39;o_lat\u0026#39;, \u0026#39;time\u0026#39;: \u0026#39;o_time\u0026#39;}) data_df[\u0026#39;d_lon\u0026#39;] = data_df[\u0026#39;o_lon\u0026#39;].shift(-1) data_df[\u0026#39;d_lat\u0026#39;] = data_df[\u0026#39;o_lat\u0026#39;].shift(-1) data_df[\u0026#39;d_time\u0026#39;] = data_df[\u0026#39;o_time\u0026#39;].shift(-1) data_df = data_df[data_df[\u0026#39;StatusChange\u0026#39;] == 1] data_df = data_df.drop(\u0026#39;StatusChange\u0026#39;,axis = 1).dropna().reset_index(drop=True)   计算trip时耗 pd.to_datetime好用但是太耗时了，直接用字符串解析吧\n1 2 3 4 5 6 7 8 9  # 计算耗时，order_time单位: s # 过滤掉小于 5min的订单 data_df[\u0026#39;order_time\u0026#39;] = data_df[\u0026#39;d_time\u0026#39;].str.slice(0,2).astype(\u0026#39;int\u0026#39;)*3600+\\ data_df[\u0026#39;d_time\u0026#39;].str.slice(3,5).astype(\u0026#39;int\u0026#39;)*60+\\ data_df[\u0026#39;d_time\u0026#39;].str.slice(6,8).astype(\u0026#39;int\u0026#39;)-\\ data_df[\u0026#39;o_time\u0026#39;].str.slice(0,2).astype(\u0026#39;int\u0026#39;)*3600-\\ data_df[\u0026#39;o_time\u0026#39;].str.slice(3,5).astype(\u0026#39;int\u0026#39;)*60-\\ data_df[\u0026#39;o_time\u0026#39;].str.slice(6,8).astype(\u0026#39;int\u0026#39;) data_df = data_df.query(\u0026#34;order_time \u0026gt; 300\u0026#34;)   持久化 1  data_df.to_csv(\u0026#39;trip_od.csv\u0026#39;, header=True, index=False)   可视化分析 列举部分可视化分析\ntrip上车时间(以每小时分组) 1 2 3 4 5 6 7 8 9  tirp_df[\u0026#39;o_hour\u0026#39;] = tirp_df.o_time.str.slice(0,2) hour_count_df = tirp_df.groupby([\u0026#39;o_hour\u0026#39;])[\u0026#39;taxi_id\u0026#39;].count().reset_index() fig = plt.figure(figsize=(8,6),dpi=300) #设置画布大小及分辨率 ax = fig.add_subplot(2,1,1) #创建一个2行1列的子图，绘制第1张子图 sns.barplot(x=\u0026#39;o_hour\u0026#39;, y=\u0026#39;taxi_id\u0026#39;, data=hour_count_df) ax.set_xlabel(\u0026#39;hour\u0026#39;) ax.set_ylabel(\u0026#39;trip count\u0026#39;)   trip持续时间(以每小时分组) 1 2 3 4 5 6  fig = plt.figure(figsize=(15,12),dpi=300) ax = fig.add_subplot(2,1,1) trip_df = trip_df.sort_values([\u0026#39;o_hour\u0026#39;]) ax = sns.boxplot(x=\u0026#34;o_hour\u0026#34;, y=\u0026#34;order_time\u0026#34;, data=trip_df) ax.set_xlabel(\u0026#39;hour\u0026#39;) ax.set_ylabel(\u0026#39;trip time(min)\u0026#39;)   ","description":"","id":13,"section":"posts","tags":["札记","出租车","数据处理","pandas"],"title":"2021-06-08-出租车数据处理札记","uri":"https://www.xunhs.cyou/posts/notes/2021-06-08-%E5%87%BA%E7%A7%9F%E8%BD%A6%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%9C%AD%E8%AE%B0/"},{"content":"\n","description":"","id":14,"section":"moments","tags":null,"title":"2021.5.31-嘉宾","uri":"https://www.xunhs.cyou/moments/2021.5.31-%E5%98%89%E5%AE%BE/"},{"content":" 命硬。\n \n 2021.6.1 睡不醒。 2021.6.2 喝完这么多酒会难受，为什么还要作呢，为什么不拒绝呢┓( ´∀` )┏ 2021.6.3 不要听见你真的说出口，再给我一点温柔 2021.6.4 国内投影坐标系: WGS 1984 UTM Zone 50N 2021.6.5 和方方姐出去约着吃了顿素菜，在宝通寺附近。说实话不太喜欢吃。方方姐开车约在武汉东站接的我，见面也没感觉生疏，可能是经常一起打游戏的缘故吧（或者直接就是我厚脸皮，哈哈）。回来的时候我开了一把，感觉别克俊朗就很不错啊，而且她说不到十万块就拿下了？驾驶感蛮不错的哎🤔 2021.6.6 突然想练腹肌。不知道这个想法能坚持多久 2021.6.7 yy也太狠了 给别人的学生打0分 给自己的学生打100分 真想看看100分的论文是什么亚子🤔 2021.6.8 无论“非升即走”这种制度有多糟糕，也不是杀人的理由。人生没有一劳永逸，慢慢的，很多曾经的铁饭碗职业也会消失。非升即走对我们国家高校的发展和进步意义很大，因为大批大批的高校教师还不如普通中小学教师付出的努力多，科研一方面水份大，另一方面经费和甜头都给有一些资源和权利的人把控着，很多高校一潭死水。内卷真的很卷，残酷是真的残酷。但是我们要改变高等教育现状，又不得不做出改变；mark一下：城市规划与设计学院赵鹏军教授课题组招聘博士后启事 2021.6.9 贵有恒，何必三更起五更勤;最无益，只怕一日曝十日寒。 2021.6.10 突然借到老妈的消息 他们决定把店面转让了 而且端午前就可以回家 觉得蛮意外的 以前怎么说都说不动 突然的消息让我觉得以后好像都不会去朱河那个地方 还是有点感情的😞 2021.6.11 哈哈 刚打电话问爸妈 店面没转出去 那个人临时反悔了 尴尬 不过总归是好事 我和父母在这方面达成共识 2021.6.12 mark: 1) momepy; 2)交通知识图谱应用 —— 公交出行场景挖掘 2021.6.13 [Aria2 + Rclone + OneDrive + Olaindex] Aria2 + Rclone 可以在下载之后自动上传到OneDrive 结合Olaindex展示播放 就很棒🤠 Refer:https://p3terx.com/archives/docker-aria2-pro.html 以前一分钱买的5T的OneDrive找到了 改了域名 不过以前的资料还在 正好可以用上 用作视频播放还不错哈 2021.6.14 每个人都会怀念一个夏天 2021.6.15 你是不是网上冲浪冲傻了 2021.6.16 15分钟社区生活圈 2021.6.17 小步迭代，再大的目标也能分解成大量小步骤，学会玩长期游戏 2021.6.18 回忆里的人 2021.6.19 节食太饿了😒😒 2021.6.20 毕业快乐 未来可期 2021.6.21 学校报销：1000元以上需要发票验证+学院盖章 2021.6.22 今天来北京 正好赶上建党百年庆典的烟花彩排 住的酒店也是不错的观景地点 我是什么眼神能够在窗帘缝里看到烟花 哈哈哈 2021.6.23 晚上与ZW约饭 多年未见 他因为胃病和近期的糟糕事情折磨的瘦骨如柴 听着他的经历十分遗憾 他的讲述、他的话非常痛苦 他在寻找一种解脱 世事无常 重在保持一颗良好的心态 又哪有这么容易呢 2021.6.24 返汉 在车上追绝命毒师到第五部 果然这里面没有一个人是好人 第四部末古斯就这么被炸死了 怀特老师有些让人又爱又恨 这个剧看的有些疲惫 第五季缓缓再看吧 2021.6.25 论文不想改😔 2021.6.26 我不想思考这么多，患得患失。我要给自己一个交代，也给别人一个交代，不留遗憾。 2021.6.27 定期的犒劳自己是有必要的 2021.6.28 控制不住自己😢 2021.6.29 江湖再见 2021.6.30 不想写论文的时候就来跑步吧  ","description":"","id":15,"section":"posts","tags":["投影坐标系","别克俊朗","青椒","别了朱河","交通知识图谱","王思聪梗","毕业季","报销","北京","绝命毒师","患得患失","跑步"],"title":"2021-6","uri":"https://www.xunhs.cyou/posts/journals/2021-06-01-2021-6/"},{"content":" Hugo中文帮助文档, 记录Hugo学习笔记。\n Hugo工作原理 基本概念  文章：md文件 页面：html文件，页面=文章+模板 模板：layouts目录下文件  content目录结构和URL的对应关系 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  └── content ├── _index.md // [home] \u0026lt;- https://example.com/ ** ├── about.md // [page] \u0026lt;- https://example.com/about/ ├── posts | ├── _index.md // [section] \u0026lt;- https://example.com/posts/ ** | ├── firstpost.md // [page] \u0026lt;- https://example.com/posts/firstpost/ | ├── happy | | ├── _index.md // [section] \u0026lt;- https://example.com/posts/happy/ ** | | └── ness.md // [page] \u0026lt;- https://example.com/posts/happy/ness/ | └── secondpost.md // [page] \u0026lt;- https://example.com/posts/secondpost/ └── quote ├── _index.md // [section] \u0026lt;- https://example.com/quote/ ** ├── first.md // [page] \u0026lt;- https://example.com/quote/first/ └── second.md // [page] \u0026lt;- https://example.com/quote/second/ // hugo默认生成的页面, 没有对应的markdown文章 分类列表页面 // [taxonomyTerm] \u0026lt;- https://example.com/categories/ ** 某个分类下的所有文章的列表 // [taxonomy] \u0026lt;- https://example.com/categories/one-category ** 标签列表页面 // [taxonomyTerm] \u0026lt;- https://example.com/tags/ ** 某个标签下的所有文章的列表 // [taxonomy] \u0026lt;- https://example.com/tags/one-tag **   页面和模板的对应关系  []中标注的是页面的kind属性，整体上分为两类：singe（单页面-page）和list（列表页-home,section,taxonomyTerm, taxonomy） site homepage(首页), section page(文章目录页), taxonomy list(某一分类的文章列表), taxonomy terms list(所有的分类) 列表页面可以有关联的content files, 即_index.md文件  content目录下的_index.md和首页相关 各个子目录下的_index.md和对应的section page相关 taxonomy list 和 taxonomy terms list需要在content目录下面创建特定名称的目录(tags或categories)并在里面添加_index.md文件   _index.html用来生成对应的列表页面，有无该文件均可生成。但有的话可根据文件中的FrontMatter的设置生成个性页面。  baseof.html baseof.html为基础模板页，任何页面都以它为模板。在基础模板页中使用block定义了一个占位符, 当模板页使用了一个基础模板页时, 模板页的解析后的内容会嵌入到基础模板页面中block的位置。参考：https://hugo.aiaide.com/post/%E5%9F%BA%E7%A1%80%E6%A8%A1%E6%9D%BF-baseof.html/\ngetCSV获取外援数据 参考：https://hugo.aiaide.com/post/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE-hugo%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93/\n","description":"","id":17,"section":"posts","tags":["Hugo","札记","博客"],"title":"2021-05-21-hugo学习札记","uri":"https://www.xunhs.cyou/posts/notes/2021-05-21-hugo%E5%AD%A6%E4%B9%A0%E6%9C%AD%E8%AE%B0/"},{"content":" Paper writing notes about urban functional regionalization.\n 札记 概念/定义  Regionalization  the task of partitioning a set of contiguous areas into spatial clusters or regions a type of clustering method that defines spatially contiguous and homogeneous groups, also known as regions. partition the geographic space into a set of homogeneous and geographically contiguous regions aptly described as ‘spatially constrained clustering algorithms’    2017-Creating multithemed ecological regions for macroscale ecology: Testing a flexible, repeatable, and accessible clustering method  Ecology and Evolution (中科院3-4区) 逻辑清晰，写作蛮好的，值得借鉴 regionalization的分析套路值得借鉴  Abstract  spatially constrained spectral clustering algorithm: a spatially constrained spectral clustering algorithm that balances geospatial homogeneity and region contiguity to create ecological regions using multiple terrestrial, climatic, and freshwater geospatial data Identify the most influential geospatial features: identified which of the geospatial features were most influential in creating the resulting regions capture regional variation: tested the ability of these ecological regions to capture regional variation in water nutrients and clarity for ~6,000 lakes  Introduction  Para. 1: 生态背景，看起来有点吃力  understand and predict ecosystem at broad spatial and temporal scales translating fine‐scaled understanding to macroscales is difficult spatial heterogeneity among ecosystems   Para. 2:（生态背景下的）区域化方法介绍  a regionalization framework that classifies the landscape into ecological regions under the assumption that ecosystems within regions are more similar (in properties and in responding to stressors) than those across regions   Para. 3:目前研究方法潜在地限制当前的应用  existing ecological regions have characteristics that potentially limit their general application. limitations in the availability of broad‐scale geospatial data subjectively using paper maps, leading to regions that cannot be reproduced or easily modified for new purposes   Para. 4: 这一段的逻辑还是蛮清晰的，讲区域化方法还是广泛应用滴，但是呢有A和B两个局限，但是这两点又很重要，怎么办呢，那当然是研究一个方法可以解决这两个问题啦。  historic regionalization frameworks are widely used there have been advances in statistical and computational approaches for delineating objective and reproducible ecological regions most of these newer methods have not been broadly disseminated(传播) to or available in a form easily adoptable by the ecological community. many of these methods are optimized to maximize landscape homogeneity, they do not always create contiguous regions Region contiguity is useful for two important reasons.  First, such regions help account for broad‐scale spatial autocorrelation that is common among ecosystems. Second, contiguous regions are useful for management because they allow managers to apply similar practices to nearby but unstudied ecosystems.   Therefore, we need methods that create contiguous and homogeneous regions, as well as dissemination of these approaches to the ecological community.   Para. 5: 这一段的写作逻辑真的太爱了！可以当写作模板！💛  一句话陈述，我们做了啥：  应用一个新的方法：apply a newly published computer science clustering algorithm that creates customized ecological regions 看它能不能用：test its use for macrosystems ecology research 人人可用：make it available in an online repository 拔高：help fill the need for adaptable and flexible methods for creating regions   关于空间限制算法的描述：a flexible method that allows users to impose restrictions on whether spatially adjacent points should be in the same region, thereby influencing the clustering process to create homogeneous regions that are also geographically connected (i.e., contiguous). 论文里讲到，空间限制的谱聚类算法不是这篇文章提出的，但是我们扩展了他的应用：  This method was developed and tested using terrestrial landscape data for three U.S. states and was found to outperform three other algorithms for delineating ecological regions we expand on this previous work to:  更大范围！—— create ecological regions with a wider range of nationally available data 谁更重要！—— examine which of the 52 geospatial features were most influential in creating these regions to determine how important individual geophysical features are for ecological region delineation 空间差异！—— test the ability of the resulting 100 ecological regions to capture regional variation in lake characteristics that were not used to develop the regions     人人可用：We make this algorithm freely available with an accessible user interface for other researchers to use and modify, including the ability to: create different numbers/sizes of regions; use a subset of themes or different combinations of measures of the terrestrial, atmospheric, and freshwater landscapes; and create regions for a different spatial extent (e.g., state, nation, and continent). 拔高：This objective and reproducible method and available code for creating ecological regions are designed to support a wide range of macroscale ecology applications.    Materials and Methods  研究单元——base geographic unit:  the U.S. Geological Survey 12‐digit hydrologic(水文的) unit (HU‐12), which is based on river basins There are 20,257 HU‐12s in the study extent, ranging in land area from 0.35 to 1,276 km2   单元特征——natural geographic variables:  52 grouped into three themes: terrestrial landscape features, climate features, and freshwater landscape features   LAGOS‐NE dataset:  includes lake‐specific water quality and chemistry data compiled from 54 individual datasets for a subset of ~10,000 lakes in the study extent for independently testing the ecological regions created in this study   Schematic illustrating the procedure for creating ecological regions:  预处理过程——Data preprocessing: remove HU‐12s that included spatially isolated landscape features (e.g., islands and peninsulas) fill in missing values in the geospatial database through interpolation remove egregious outliers PCA scores: 降维    two matrixs and joint similarity matrix:\n feature similarity matrix: a landscape feature similarity matrix that measures landscape homogeneity was computed using the Gaussian radial basis function spatial constraint matrix: a binary‐valued spatial constraint matrix was constructed based on HU‐12 contiguity (i.e., 1 if the HU‐12s share a border; 0 if the HU‐12s do not share a border). The spatial constraint matrix is used to guide the clustering process into finding spatially contiguous regions. Hadamard product:    spectral clustering algorithm:  two metrics for evaluating a regionalization framework: within-cluster sum-of-square error (SSW) to quantify the landscape homogeneity within the regions, A lower SSW implies higher homogeneity of landscape features within regions percentage of spatial constraints preserved by the clustering algorithm(PctML), a measure of cluster contiguity. This metric ranges from 0 to 1 and the higher the metric, the more spatially contiguous were the resulting regions. created nine sets of ecological regions:    number of regions:\n 聚类过程中确定聚类数的传统方法——standard approach to choose the optimal number of clusters  plot values of an internal cluster validity index such as SSW against the number of regions and identify the inflection point in the monotonically decreasing curve (识别单调递减曲线的拐点) 存在的不足：  this approach is subjective and the inflection point may not always be easily identified it does not consider the statistical significance of the regions compared to purely random clustering (i.e., no consideration of landscape homogeneity or region contiguity). Worse still, the monotonically decreasing relationship between SSW and number of regions is observed even for purely random clustering (i.e., no consideration of landscape homogeneity or region contiguity).     文中优化的方法：compared the SSW of the regions created with spatially constrained spectral clustering against the average SSW for 200 randomly created sets of regions to ensure that the improvement in SSW as the number of regions increases was statistically significant  computed the ratio of slopes for the two approaches as the number of regions increases If the constrained spectral clustering approach provides little improvement in SSW compared to the random clustering approach, then this ratio approaches 1 on plots of empirical curves and indicates an optimal number of regions. the number of regions increased from 5 to 1,000（with a step size of 5 from 5 to 600 clusters, a step size of 10 from 610 to 800 clusters, and a step size of 50 from 850 to 1,000 clusters）      Determining drivers of ecological regions: evaluated the relative importance of the 52 geospatial variables for region formation using a random forest algorithm The OOB error estimate Gini impurity criterion    Testing the ability of ecological regions to capture regional variation: examining SSW for the two lake characteristics examined the ratio of SSW:SSB in order to compare relative amounts of within‐ and among‐region heterogeneity across response variables and ecological regions      2020-Eﬃcient regionalization for spatially explicit neighborhood delineation  IJGIS: https://doi.org/10.1080/13658816.2020.1759806 生词多的我都觉得自己不是GIS 这个专业的了。  Abstract  Neighborhood delineation ➡️ identify the most appropriate spatial unit in urban social science reasearch the true number of neighborhoods (k parameter) Existing approaches  pre-speciﬁcation of a k-parameter either nonspatial or lead to noncontiguous or overlapping regions   In this paper  propose the use of max-p-regions for neighborhood delineation: the geographic space can be partitioned into a set of homogeneous and geographically contiguous neighborhoods computational challenges for large-scale neighborhood delineation    Introduction  Para. 1:  An increasingly important technique in the ﬁeld of GIScience: the identiﬁcation of distinct sub-regions or neighborhoods within a study area using unsupervised learning methods generally categorized as regionalization methods aim to partition the geographic space into a set of homogeneous and geographically contiguous regions regionalization algorithms might be more aptly described as ‘spatially constrained clustering algorithms’   Para. 2:  One important application of spatially constrained clustering the total number, spatial conﬁguration, and internal composition of neighborhoods are all unknown a priori （邻里的总数、空间结构和内部组成都是先验的）.   Para. 3:  The ﬁrst application: regionalization is leveraged method of data processing used to develop new primitive spatial units(基础的空间单元) that have better statistical reliability Spielman and Singleton (2015): social surveys (e.g. the census)   Para. 4:  The second application: regionalization is used to identify unique and discrete social neighborhoods according to their demographic composition Rey et al. (2011): geodemographic analysis, examine the dynamic footprint of social neighborhoods over time   Para. 5:  there is a clear need for exploration and development of novel approaches to regionalization that are scalable, eﬃcient, and able to ingest vast amounts of data in short cycles. max-p-regions proposed a new eﬃcient algorithm to address the computational challenges    2021-A quantitative comparison of regionalization methods  IJGIS: https://doi.org/10.1080/13658816.2021.1905819 分区方法比较全面的一套综述 这是我见过IJGIS最长的Introduction了  Abstract  Regionalization: the task of partitioning a set of contiguous areas into spatial clusters or regions yet few quantitative comparisons have been conducted the number of regions the simulated benchmark data set Model families are defined with respect to regions’ shapes, value-mixing between regions, and the number of underlying spatial clusters internal and external measures of regionalization quality investigate the computational efficiency implications on defining ecological regions  Introduction  Para. 1: 主要讲分区的意义和应用  Datadriven regions  public health  Applications:  spatial groups of disease incidence epidemiological analysis (流行病学分析)   Significances:  classifying disease prevalence delineate areas prone to a specific disease type     regions on social networks  defined based on the similarity of people’s interests to define communities   location-allocation problems  Applications  renewable source optimization to serve cities’ energy demands environmental planning   Significances  optimize energy consumption and data routing     regions for dynamic systems  delineate climate zones   define socio-economic regions ecological regions （生态分区） electoral and school districting     Para. 2: 分区问题的数学定义  solve a constrained optimization problem to maximize within-region similarity and between-region dissimilarity under spatially derived constraints n spatial units; vector xi with p variables; partition the data into k regions; distance measure the spatial constraint defined by geographical adjacency.   Para. 3: Regionalization方法分类  spatially implicit models  generally based on traditional and non-spatial clustering methods producing a first solution that is afterwards updated by enforcing the spatial constraints force the regions to be as homogeneous as possible, but the spatial contiguity is not always guaranteed an ad hoc post-processing step   spatially explicit models  models spatial constraints explicitly to ensure spatial contiguity within the resulting regions grouped as exact, heuristic, and mixed-heuristic models  Exact models search for the optimal regions among all possible regionalizations Heuristic models constrain the search space for the optimal solution to find regions efficiently mixed-heuristic models aim to combine heuristic models’ computational efficiency with exact models’ compactness   Others:  segmentation algorithms graph-based partitioning algorithms       Para. 4\u0026amp;5:一些其他的方法，本文不赘述  seeded region growing (SRG) algorithms automated zoning procedure (AZP) spatially explicit regionalization methods: finding underlying regions with constraints related to regions without the definition of a target number of regions Spatially implicit regionalization methods suffer from subjectivity due to the ad-hoc post processing required to ensure spatial contiguity   Para. 6:显式分区方法的缺陷  spatially explicit regionalization methods:  exact methods are computationally intensive heuristic models:  their solution’s optimality is not guaranteed constrained search space can result in heterogeneous regions where spatial units in the same region are significantly dissimilar       Para. 7\u0026amp;8\u0026amp;9: In this paper:  present a quantitative review expand and complement a recent paper conduct a rigorous statistical analysis of regionalization algorithms analyze the computational performance compare the performance of the state-of-the-art regionalization methods with SKATER evaluate algorithm performance quantitatively  degrees of separability between the spatial clusters number of underlying regions realizations for a given scenario   define data-driven ecoregions:  consider the utility of different regionalization algorithms on regionbuilding to define ecoregions compare our results to a widely known, expert-defined regionalization of ecoregions     Para. 10: Contributions  comparative performance of a large set of regionalization methods Demonstrate results from a large set of supervised and unsupervised regionalization quality metrics Perform sensitivity analysis to evaluate the algorithm performance for different scenarios Evaluate the performance of the different algorithms for an increasing number of spatial units Discuss the implications of performance disparities from the synthetic study    Methodology   unsupervised evaluation metrics:\n Calinski-Harabasz index  quantifies the value-based compactness (紧凑度) of k regions by comparing the average of within and between region sum of squares The Calinski-Harabasz index will be high for a region map containing distinct (dissimilar) regions that consist of similar spatial units.   Sum-Squared Errors:    SKATER\n it excels across most of our evaluation criteria when compared to the other regionalization techniques for cases where data do not possess well-defined regions, tree-based methodologies such as SKATER can define the regions with the most homogeneity.    2019-A regionalization method for clustering and partitioning based on trajectories from NLP perspective  IJGIS:https://doi.org/10.1080/13658816.2019.1643025 手机信令轨迹+Word2Vec 最开始看的，关于分区的几篇文章之一  Abstract  a novel regionalization method to cluster similar areal units and visualize the spatial structure by considering all trajectories in an area into a word embedding model. the result depicts the underlying socio-economic structure at multiple spatial scales evaluate its performance by predicting the next location of an individual’s trajectory  2019-Hierarchical community detection and functional area identification with OSM roads and complex graph theory  IJGIS: https://doi.org/10.1080/13658816.2019.1584806 关于社区检测，我的“入坑”读物  Abstract  urban road network structure ➡️ understanding the distribution of urban functional area communities of urban road roads Infomap commnity detection algorithm results:  the distribution of communities at different levels explored the functional area characteristics at the communities scale can be used as a basic unit    2021-Partitioning urban road network based on travel speed correlation  International Journal of Transportation Science and Technology: https://doi.org/10.1016/j.ijtst.2021.01.002 了解学习下交通领域背景 标准的abstract模板  Abstract  urban trafﬁc management urban road network partition existing study  the spatial relationship of road sections are introduced fails to capture the travel speed correlation between road sections with far distance   this paper  travel speed correlation between road sections fast unfolding method is used to divide urban road network into sub-partitions of densely correlated road sections A case study is conducted by using taxi GPS dataset in Shanghai   Results:  the travel speed will generate high correlation even if the road sections are not spatially connected or close divides the road network in Shanghai into 77 sub-partitions with strong intro-correlation of travel speed pattern Comparing the result with Ncut algorithm with different spatial constraints, generate evenly distributed and spatially compact sub-partitions.    Introduction  Para. 1: 交通分区的意义  increasingly serious problems in cities: urban congestion, extra gas emissions and low transportation efﬁciency Urban road network partitioning is a fundamental step in traffic management, control, simulation and policymaking.  the citywide management strategy is hierarchical and regionalized. ensuring that the road sections with a similar travel speed pattern are in the same sub-partition applying the same controlling strategy is the ﬁrst step to guarantee the effectiveness of the overall controlling system     Para. 2\u0026amp;3\u0026amp;4\u0026amp;5: 面临挑战——facing the following challenges  the ﬁrst challenge is how the partition method considers the urban trafﬁc characteristic the second challenge is how the partition method divides the road network so that a network partition can be spatially compact or continuous  the most existing road network partitioning approaches heavily depend on topological relationships of road segments when spatial constraints are imposed on the relationship between road sections, the relationship between non-spatial continuous or adjacent road sections will inevitably be ignored.   the travel speed of road sections highly related to each other   Para. 6:  A methodology framework: capture and quantitatively express the travel speed correlation the road network partition methodology proposed is based on trafﬁc ﬂow characteristics handle a citywide road network and generates the road network partition with a short computing time    Others:  potential control strategies to alleviate trafﬁc congestion should be designed based on the sub-partition of the urban road network  if a cluster contains subregions with signiﬁcantly different levels of congestion, the control strategies will be inefﬁcient road network partitioning is the ﬁrst step to space-parallel distributed transportation simulation   the principle of road network partitioning:  Non-overlapping Travel characteristic based Spatially compact balanced size   Framework:  ","description":"","id":19,"section":"posts","tags":["札记","Regionalization","Urban functions"],"title":"2021-05-09: Urban Functional Regionalization","uri":"https://www.xunhs.cyou/posts/notes/2021-05-09-urban-functional-regionalization/"},{"content":" Wedding.\n \n 2021.5.1 李奇才婚礼；象棋是王者的游戏，文明与杀戮并存。 2021.5.2 人生在世，你只要需要知道两件事：一、这个世界上绝对存在不需要读书也很聪明，不需要努力也过得很好，甚至不需要钱就过得很快乐的人。二、这个人绝对不是你。 2021.5.3 返汉。趁着三天小假期，追了一个奈非的小美剧-“后翼弃兵”，之后也看了些影评，十分感触。天才的背后，总有些不同寻常的际遇。从小被遗弃、镇定剂上瘾、酗酒以及心中斗争的“恶魔”。天才与疯子，一分之隔。幸亏在她迷茫时，仍有一群好友在帮她，找寻到自我，没有走到迷失的境地。看了知乎上一些天才，从小天赋惊人，但后期迷失自我，难以不让你惋惜。另一方面，女主对国际象棋的热爱，超乎了我对一件事物的理解。同样我也喜欢中国象棋，包括喜欢其他事物，但是我没有像她一般的热爱和执着。也许这就是热爱和消遣的区别吧。很羡慕哪些，可以找到自己一生热爱并愿付出一生去追寻理想的人，或者这是天才的“专利”吧 2021.5.4 只有人类才会失眠；我们今天所做的一切，无上光荣！——《建军大业》 2021.5.5 联通手机号更改为8元保号套餐，可能慢慢不用这个号码了吧、 2021.5.6 1）昨天喝完酒肚子还是不舒服，一早上啥都没干😑；2）大概是我走一程，回望一程，期待一程，落空一程。目之所及没有他，翻山越岭也没有他。可他分明在这世上，更在我心尖。\u0026ndash;《黄昏》 2021.5.7 中午睡醒冲杯咖啡很清醒，但是老闹肚子😟 嘴馋+bad肠胃 2021.5.8 尊重是相互的，你对我什么态度，So Do I. 2021.5.9 1）疑犯追踪，豆瓣搞笑评价：技术宅病娇和硬汉前特工的爱情故事；纽约活雷锋！；2）Urban functional Regionalization ➡️ what about the next CEUS 2021.5.10 1）GeoDa 现在做的，真的很好用呀 Cluster, Spatial Analysis etc. 应有尽有；2）所有人都想拯救世界，却没人帮妈妈洗碗😂；3）身为一个GIS专业的博士生，竟然还要Google检索“arcgis 投影转地理”这类问题。我服了我自己。啊awsl\u0026hellip;顺便贴出来解决方案：https://blog.csdn.net/weixin_44630029/article/details/104805195 2021.5.11 1）为一张脸去养一身伤；2）Geoda documentation: https://geodacenter.github.io/documentation.html 2021.5.12 发现自己真的会因为读到一篇逻辑严谨、写作巧妙的论文而高兴。 2021.5.13 突然好大雨。一把小伞连自己的遮不住 2021.5.14 1）如果你能让她降落；2）谈到未来（近三年）的发展，我没有一点头绪。是不是该好好考虑一下。 2021.5.15 1）突然发现好像只要忙起来就来不及去伤感那些有的没的的事情 我们有时可能会因为一些小事而烦恼 甚至会忧虑很久 但要知道 这很多时候都是因为我们太闲 因为闲下来才去有时间伤感 这伤感可能来源于某一首歌 某一件事亦或者某个人 可等过去一段时间我们再回想起来 好像当时我们所有忧虑的都不算什么 甚至有可能会更加怀念 所以那些对自己不再有意义的人不要接受 因为有些人的相遇确实是没有意义的 \u0026ndash;QQ音乐评论；2）今天老徐叫去他们老同学的一个局，师兄喝酒，我开车回来。七个人：有做科研的、有做行政的、有开公司的，听着他们分享生活、学习中的各种事情。当然吐槽比较多，毕竟他们比较熟络。不是那种凡尔赛宴会。从学校各种杂事谈到结婚生子，育儿等等。挺有意思的。本来晚上不善于开车，又加上些小雨，回来的路上非常谨慎。晚上开车确实会更累。心里有些话，但是不知道该怎么说。不知该如何表达。 2021.5.16 这两天把pytorch-lighting库熟悉了下、 2021.5.17 开始动笔、 2021.5.18 基于onedrive搭建olaindex，稍作部分修改，他的图床其实还可以上传其他东西，比如mp3啥的，理论上都能上传，方便，限制不超过4m、 2021.5.19 rm -R 一身轻松 2021.5.20 大概就是七月檐角的猫，误闯了十一月初冬的窗头，挠得心底痒痒的，世人将这种情感，称作喜欢? 2021.5.21 五月份的聚会：海底捞+ktv+江汉路小吃✌️ 2021.5.22 只愿君心似我心，定不负相思意-茶颜悦色的茶包很香~；推：北京外国语大学开源软件镜像站。conda源更新极快，不断包 2021.5.23 学校的相声社来新校区演出，演的很棒，蛮搞笑的🤡 2021.5.24 1）昨天晚上贪吃奥利奥饼干，今天一早起来刷牙牙疼，吃什么都牙疼，不能偷懒了，真的该约时间检查牙齿！2）从此无心爱良夜 任他明月下西楼 2021.5.25 1）终于把借款给还清了！2）去武大口腔检查为什么牙疼，查了半天也没查出牙齿什么问题，建议去牙周科挂个号检查一下；牙周科人太多了，饱满，无耐打算回学校；想着好不容易出来一趟，去做了一下盲人按摩，按按腰好舒服啊。然后路过光谷去看一下最近刚出的速度与激情9.差点包场了，不过觉得好无聊。只是能回忆起以前的一些事情。回学校跟老妈视频，说到牙疼的事情。结果我妈上来就说是上火啦。我一听，在一想前两天去吃海底捞，最近一直和红茶。感觉确实是这么回事，而且医生也没有查出牙齿有什么毛病呀🤔 先买点消炎药试试吧 反正预约挂号是在周五。牙疼两天也让自己张张记性，一直拖着去看牙、做洗牙不去。非等着难受才好！ 2021.5.26 果然是上火了。吃点消炎药和去火药好多了，哎😌 2021.5.27 田师傅香辣虾蟹-循礼门巷子 2021.5.28 主动 2021.5.29 蛮可爱的一个女孩子👧🏻 2021.5.30 天气炎热的一天 2021.5.31 燥热的夏天、  ","description":"","id":21,"section":"posts","tags":["美剧","闹肚子","疑犯追踪","GeoDa","未来规划","牙疼"],"title":"2021-5","uri":"https://www.xunhs.cyou/posts/journals/2021-05-02-2021-5/"},{"content":" Hi there, I\u0026rsquo;m Ethan (Sheng Hu, 胡胜).\n My Playlists Reading and Learning Frequently Listening Post-rock          'use strict'; var containerId = JSON.parse(\"\\\"2f5b0d23c785d92c\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  I\u0026rsquo;m a Student, GISer and Explorer!  I am a PhD student in the School of Geography and Information Engineering at China University of Geosciences, Wuhan. My research interest includes the geospatial data mining and modeling in urban areas through the application of innovative geographic information system (GIS) and GeoAI methods. I am an AI fan! I’m currently learning everything🤔 CV: zh; en  Connect with me  EMAIL: gishusheng@outlook.com QQ: 278738411  Publications An overview of my publications:\n Hu, Sheng, Song Gao, Liang Wu, Yongyang Xu, Ziwei Zhang, Haifu Cui, Xi Gong. “Urban function classification at road segment level using taxi trajectory data: A graph convolutional neural network approach”. Computers, Environment and Urban Systems 87 (2021): 101619. Hu, Sheng, Yongyang Xu, Liang Wu, Xincai Wu, Run Wang, Ziwei Zhang, Rujuan Lu, and Wei Mao. \u0026ldquo;A framework to detect and understand thematic places of a city using geospatial data.\u0026rdquo; Cities 109: 103012. Hu, Sheng, Zhanjun He, Liang Wu, Li Yin, Yongyang Xu, and Haifu Cui. \u0026ldquo;A framework for extracting urban functional regions based on multiprototype word embeddings using points-of-interest data.\u0026rdquo; Computers, Environment and Urban Systems 80 (2020): 101442. Wu, Liang, Sheng Hu, Li Yin, Yazhou Wang, Zhanlong Chen, Mingqiang Guo, Hao Chen, and Zhong Xie. \u0026ldquo;Optimizing cruising routes for taxi drivers using a spatio-temporal trajectory model.\u0026rdquo; ISPRS International Journal of Geo-Information 6, no. 11 (2017): 373. Cui, Haifu, Liang Wu, Sheng Hu, Rujuan Lu, and Shanlin Wang. \u0026ldquo;Recognition of Urban Functions and Mixed Use Based on Residents’ Movement and Topic Generation Model: The Case of Wuhan, China.\u0026rdquo; Remote Sensing 12, no. 18 (2020): 2889. Cui, Haifu, Liang Wu, Zhanjun He, Sheng Hu, Kai Ma, Li Yin, and Liufeng Tao. \u0026ldquo;Exploring Multidimensional Spatiotemporal Point Patterns Based on an Improved Affinity Propagation Algorithm.\u0026rdquo; International journal of environmental research and public health 16, no. 11 (2019): 1988. Wu, Liang, Fei Deng, Zhong Xie, Sheng Hu, Shu Shen, Junming Shi, and Dan Liu. \u0026ldquo;Spatial analysis of severe fever with thrombocytopenia syndrome virus in China using a geographically weighted logistic regression model.\u0026rdquo; International journal of environmental research and public health 13, no. 11 (2016): 1125.  Awards and Honors  Jun.2017 Outstanding Graduate Awards of China University of Geosciences, Wuhan Apr.2020 Outstanding Doctoral Innovation Fund of China University of Geosciences, Wuhan Jun.2020 Third prize in the final, Huawei Cloud Cup: Shenzhen Open Data Application Innovation Competition Nov.2020 High School GIS New Talent, awarded by National University GIS Forum Dec.2020 National Scholarship for Graduate Students  ","description":"","id":23,"section":"","tags":null,"title":"About Me","uri":"https://www.xunhs.cyou/about/"},{"content":" GIS操作——OSM路网化简，提取中心线。基本思路就是道路膨胀，然后提取中心线。\n 类似这种效果：路网处理 道路预处理，去除杂乱道路；提取主干道（可选）➡️ KowloonEdges.shp\n建立缓冲区（Buffer） 设置缓冲距离，建立缓冲区。(香港的路网较密集，实例中设置的15m) ➡️ KowloonEdgesBuffer.shp\n缓冲区距离根据实际效果设置。\n融合（Dissolve） 根据相同属性进行融合，这里使用的是街道名字。➡️ KEBDissolve.shp\n新建 (New)  新建线图层（KECenterline.shp），作为容器保存中心线。 新建raster.gdb，作为容器保存中间处理的栅格。（这里其实是软件bug的一个解决方案，在重分类的时候只能保存到gdb中，原因未知。）  面转栅格 (To Raster) cellsize可以调节。实例中设置的为0.0001 ➡️ dissolve2raster\n重分类（Reclassify） NoData设置为0（必须），其他均设置为1.结果如下： ➡️ reclassify\n提取中心线 操作参考：http://www.doc88.com/p-2307739648492.html\n 自定义-扩展模块-ArcScan (打钩) Editor-开始编辑-KECenterline.shp 显示ArcScan工具条 Vectorization设置Maximum Line Width。实例中使用的默认线宽，可根据情况调节。 区域生成中心线 手动调节部分细节  ","description":"","id":26,"section":"posts","tags":["GIS","osm","中心线","路网"],"title":"GIS操作——OSM路网化简，提取中心线","uri":"https://www.xunhs.cyou/2021/04/07/567/"},{"content":" papers about understanding urban physical environment using street view images. From Fan Zhang\u0026rsquo;s Researchgate project.\n 术语  街景影像 street view imagery 评估建成环境 audit various built environments 评估\u0026hellip;的适应性和直接影响 assess their suitability for physical activity as well as their directly effect on public health evaluate the walkability of the urban physical environment 经验证据 empirical evidence 关系关联  explore the association between walkability and older adults' depression explore the linkage between A and B    基于街景图像的城市环境评价研究综述  地球信息科学-张丽英，裴韬 城市街景图像具有如下优势：  街景图像以行人的视角详细系统地记录了城市街道级别的景象，图像中包含的城市基础设施信息丰富，提供了街道层级的人造景观和自然景观，能够直观准确地反映城市的立面信息； 街景图像覆盖范围广、数据量大。谷歌街景覆盖了 114 个国家和地区的城市，百度街景覆盖了中国 372 座城市，这为不同国家之间或者同一国家的不同城市之间的环境评价研究提供了坚实的数据源； 数据收集效率高，成本低。地图商提供 API 开发接口，可以免费下载街景图像，通过街景图像进行数据收集成本低，流程逻辑简单，同时便于监督和质量控制，并能解决一些现场采集数据的干扰性以及与实地调查高犯罪率街区的人员安全问题的担忧。   基于街景图像的城市环境评价  A review of urban physical environment sensing using street view imagery in public health studies  ANNALS OF GIS-Yuhao Kang Applications of street view imagery for health research  Physiological-related applications  walkable environment-walkability cycling behaviours obesity and food environment physical injury   psychological-related applications  mental health perception and sentiment (how people think about their surroundings)     comparison between street view imagery and remote sensing imagery  \n","description":"","id":28,"section":"posts","tags":["street view images","urban physical environment"],"title":"Papers Reading-Understanding urban physical environment using street view images","uri":"https://www.xunhs.cyou/2021/04/02/551/"},{"content":" Hope\n \n 2021.4.1 工欲善其事，必先利其器 2021.4.2 Mark Fan Zhang: Understanding urban physical environment using street view images; People who said that. 2021.4.3 牢记感恩，希望以后变成什么样子，都可以永远记住这点。? 2021.4.4 学术帽子 2021.4.5 超从上海过来办事 晚上一起组了个局 还要浩子 繁 都有各自的烦恼 大家的方向也不同 但是大家都在努力 繁繁年底就能就能报上孩子了 超也说年底回武汉 结婚 浩子和女朋友相处的很好 不得不提到自己 反正他们聊天 我吃的蛮香的 哈哈 我也不知道自己到底想要什么 过两天答辩加油鸭 争取不做炮灰? 2021.4.6 踏踏实实 自然心态 2021.4.7 难以取舍 2021.4.8 我也会因为一个人好看或有趣而喜欢上对方，但真正能够持续吸引我的，不是普世价值中表现出来的东西，是那些只有我能看见的那部分，是那些理智外壳中躲着的疯狂，温柔之下的阴戾，坚强背后的敏感和脆弱，夜晚时的沉默不语，以及这些光芒背后的那些仅对我可见的可爱与天真。-摘自朋友圈 2021.4.9 答辩结束好累 2021.4.10 一周一次羽毛球~? 2021.4.11 Mark ArcGIS RS Tutorial: https://introduction-to-remote-sensing-learngis.hub.arcgis.com/ 了解RS及ARCGIS Pro很棒的教程 2021.4.12 不要总是做出怀才不遇的样子，你真的有才华，想释放才华，就低头学习别人的优点，保持谨慎谦虚 2021.4.13 Windows shortcuts on macOS: https://ke-complex-modifications.pqrs.org/#windows_shortcuts_on_macos; 研究生标兵没选上? 2021.4.14 faiss导入时报错，尝试解决方案:https://zhuanlan.zhihu.com/p/346728479; Siamese Network——小样本学习 2021.4.15 四月过半 静候美签消息; 目光比月色寂寞 2021.4.16 你穿的比女生还好看？？？这种夸人方式真独特 2021.4.17 ??——向日葵发芽了 2021.4.18 脑回路新奇; Markdown编辑器规范：添加块代码要加Tab，不然会出现缩进问题！ 2021.4.19 校园广播里放到好几首自己喜欢的歌，心情就很好啊😭；博客的Emoji被吃了，全都成问号了? 2021.4.20 把闲置的树莓派3B刷了OpenWrt软路由，配置了一番,作为主路由器（小米路由器4千兆）的旁路由。体验还不错哈。参考教程：https://rongtianjie.me/archives/207 2021.4.21 Mark-图之典: http://www.tuzhidian.com/ 作者介绍：致力于介绍可视化图表及其应用场景。我们对常见图表进行了整理归类，并详细总结了图表的正确用法，如数据类型、适用场景、不适用场景等。同时，我们还搜集了许多有趣的图表设计作品和图表教程，帮助大家制作出高效、美观的可视化。 2021.4.22 抵杭。 2021.4.23 听费腾老师讲的很经典的一句：一开始我也不知道我做的（研究）有什么意义，一边做一边找寻[大体意思是这样子]。 2021.4.24 今天姚尧老师作报告，在Embedding那一块还特意提了一句我，真心非常感激[收买人心很成功]。见了张修远博士，要了联系方式，非常开心. 2021.4.25 返汉。 2021.4.26 如果生命没有遗憾没有波澜 你会不会永远没有说再见的一天 可能年少的心太柔软 经不起风经不起浪 2021.4.27 ArcGIS Desktop 10.7 安装包不大 破解方便 不用繁琐的破解过程 直接替换一个文件就可以了 2021.4.28 hugo迁移; 划水的一天🤷🏻‍♀️ 2021.4.29 🏸 2021.4.30 life as a feather, stiff as a board.  ","description":"","id":29,"section":"posts","tags":["杭州","清明","研究生标兵评选","路由器"],"title":"2021-4","uri":"https://www.xunhs.cyou/posts/journals/2021-04-01-2021-4/"},{"content":" 图卷积神经网络学习笔记。记录常用数据集、任务及网络架构。\n 主要参考链接：\n Paper Study with DGL Official DGL Examples and Modules DGL用户指南 OGB Dataset 图基准数据集(OGB)  常用数据 引文网络（Cora、PubMed、Citeseer） Cora为例：\nCora数据集由机器学习论文组成，是近年来图深度学习很喜欢使用的数据集。在数据集中，论文分为以下七类之一:基于案例、遗传算法、神经网络、概率方法、强化学习、规则学习、理论。论文的选择方式是，在最终语料库中，每篇论文引用或被至少一篇其他论文引用。整个语料库中有2708篇论文。在词干堵塞和去除词尾后，只剩下1433个独特的单词。文档频率小于10的所有单词都被删除。cora数据集包含1433个独特单词，所以特征是1433维。0和1描述的是每个单词在paper中是否存在。\n数据集划分：Cora数据含有2708个样本，划分为labeled data, test data and unlabeled data.文件列表  ind.dataset_str.x =\u0026gt; 训练实例的特征向量，是scipy.sparse.csr.csr_matrix类对象，shape:(140, 1433)；140个样本，每类随机选择20个样本，一共包含7个类别，因此训练集含有140个样本（即labeled 样本）；  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  with open(\u0026#34;data/ind.cora.x\u0026#34;, \u0026#39;rb\u0026#39;) as f: data = pkl.load(f, encoding=\u0026#39;latin1\u0026#39;) print(type(data)) #\u0026amp;lt;class \u0026#39;scipy.sparse.csr.csr_matrix\u0026#39;\u0026amp;gt; print(data.shape) #(140, 1433)-ind.cora.x是140行，1433列的 print(data[1]) nonzero=data.nonzero() print(nonzero) print(data.toarray()) ------- # print(data[1]) # 变量data是个scipy.sparse.csr.csr_matrix，类似稀疏矩阵，输出得到的是矩阵中非0的行列坐标及值 # (0, 19) 1.0 # (0, 88) 1.0 # (0, 149) 1.0 # (0, 212) 1.0 # (0, 233) 1.0 # (0, 332) 1.0 # (0, 336) 1.0 # (0, 359) 1.0 # (0, 472) 1.0 # (0, 507) 1.0 # (0, 548) 1.0 # ... ------- # print(nonzero) # 输出非零元素对应的行坐标和列坐标, nonzero是个tuple # (array([ 0, 0, 0, ..., 139, 139, 139], dtype=int32), array([ 19, 81, 146, ..., 1263, 1274, 1393], dtype=int32)) ------- # print(data.toarray()) # [[0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # ... # [0. 0. 0. ... 0. 1. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 1. 0. ... 0. 0. 0.]]    ind.dataset_str.tx =\u0026gt; 测试实例的特征向量,shape:(1000, 1433)；随机选取1000个样本（即test 样本）； ind.dataset_str.allx =\u0026gt; 有标签的+无标签训练实例的特征向量，是ind.dataset_str.x的超集，shape:(1708, 1433)；排除测试样本中选取的1000个样本，选取的剩余样本（即labeled + unlabeled 样本）。 ind.dataset_str.y =\u0026gt; 训练实例的标签，独热编码，numpy.ndarray类的实例，是numpy.ndarray对象，shape：(140, 7)  1 2 3 4 5  with open(\u0026#34;data/ind.cora.y\u0026#34;, \u0026#39;rb\u0026#39;) as f: data = pkl.load(f, encoding=\u0026#39;latin1\u0026#39;) print(type(data)) # \u0026amp;lt;class \u0026#39;numpy.ndarray\u0026#39;\u0026amp;gt; print(data.shape) # (140, 7) print(data[1]) # [0 0 0 0 1 0 0]    ind.dataset_str.ty =\u0026gt; 测试实例的标签，独热编码，numpy.ndarray类的实例,shape:(1000, 7) ind.dataset_str.ally =\u0026gt; 对应于ind.dataset_str.allx的标签，独热编码,shape:(1708, 7) ind.dataset_str.graph =\u0026gt; 图数据，collections.defaultdict类的实例，格式为 {index：[index_of_neighbor_nodes]}  1 2 3 4 5 6 7 8 9 10 11 12 13 14  with open(\u0026#34;data/ind.cora.graph\u0026#34;, \u0026#34;rb\u0026#34;) as f: data = pkl.load(f, encoding=\u0026#34;latin1\u0026#34;) print(type(data)) # \u0026amp;lt;class \u0026#39;collections.defaultdict\u0026#39;\u0026amp;gt; print(data) ------ # { # 0: [633, 1862, 2582], # 1: [2, 652, 654], # 2: [1986, 332, 1666, 1, 1454], # ..., # 2706: [165, 2707, 1473, 169], # 2707: [598, 165, 1473, 2706], # }    ind.dataset_str.test.index =\u0026gt; 测试实例的id，1000行(1708-2707)  节点分类任务中，一直迷惑的mask的index    idx_test = test_idx_range.tolist() #1708-2707，共1000个 = 计算测试acc   idx_train = range(len(y)) #0-139，共140个 = 训练过程计算loss，用于反向传播   idx_val = range(len(y), len(y)+500)#140-539，共500个 = 训练过程计算acc    生物化学结构（PPI、NCI-1、NCI-109、MUTAG、QM9、Tox21）   参考：   数据描述：https://www.jianshu.com/p/67137451b67f；https://my.oschina.net/chengsen/blog/4545191   TUDataset：https://chrsmrrs.github.io/datasets/docs/datasets/     常用网络 MLP Linear + BatchNorm1d\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  class MLP(nn.Module): \u0026#34;\u0026#34;\u0026#34;MLP with linear output\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_layers, input_dim, hidden_dim, output_dim): \u0026#34;\u0026#34;\u0026#34;MLP layers construction Paramters --------- num_layers: int The number of linear layers input_dim: int The dimensionality of input features hidden_dim: int The dimensionality of hidden units at ALL layers output_dim: int The number of classes for prediction \u0026#34;\u0026#34;\u0026#34; super(MLP, self).__init__() self.linear_or_not = True # default is linear model self.num_layers = num_layers self.output_dim = output_dim if num_layers \u0026amp;lt; 1: raise ValueError(\u0026#34;number of layers should be positive!\u0026#34;) elif num_layers == 1: # Linear model self.linear = nn.Linear(input_dim, output_dim) else: # Multi-layer model self.linear_or_not = False self.linears = torch.nn.ModuleList() self.batch_norms = torch.nn.ModuleList() self.linears.append(nn.Linear(input_dim, hidden_dim)) for layer in range(num_layers - 2): self.linears.append(nn.Linear(hidden_dim, hidden_dim)) self.linears.append(nn.Linear(hidden_dim, output_dim)) for layer in range(num_layers - 1): self.batch_norms.append(nn.BatchNorm1d((hidden_dim))) def forward(self, x): if self.linear_or_not: # If linear model return self.linear(x) else: # If MLP h = x for i in range(self.num_layers - 1): h = F.relu(self.batch_norms[i](self.linears[i](h))) return self.linears[-1](h)   GCN GraphSAGE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  import torch import torch.nn as nn import torch.nn.functional as F from dgl.nn.pytorch.conv import SAGEConv class GraphSAGE(nn.Module): def __init__( self, in_feats, n_hidden, n_layers, out_feats, activation, dropout, aggregator_type, ): super(GraphSAGE, self).__init__() self.layers = nn.ModuleList() self.dropout = nn.Dropout(dropout) self.activation = activation # input layer self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type)) # hidden layers for i in range(n_layers - 1): self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type)) # output layer self.layers.append(SAGEConv(n_hidden, out_feats, aggregator_type)) def forward(self, graph, inputs): h = self.dropout(inputs) for l, layer in enumerate(self.layers): h = layer(graph, h) if l != len(self.layers) - 1: h = self.activation(h) h = self.dropout(h) return h model = GraphSAGE( in_feats=dataset.dim_nfeats, n_hidden=32, n_layers=2, out_feats=dataset.gclasses, activation=F.relu, dropout=0.5, aggregator_type=\u0026#34;gcn\u0026#34;, )   GIN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  \u0026#34;\u0026#34;\u0026#34; How Powerful are Graph Neural Networks https:\u0026amp;#47;\u0026amp;#47;arxiv.org/abs/1810.00826 https://openreview.net/forum?id=ryGs6iA5Km Author\u0026#39;s implementation: https://github.com/weihua916/powerful-gnns \u0026#34;\u0026#34;\u0026#34; from dgl.nn.pytorch.conv import GINConv from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling class ApplyNodeFunc(nn.Module): \u0026#34;\u0026#34;\u0026#34;Update the node feature hv with MLP, BN and ReLU.\u0026#34;\u0026#34;\u0026#34; def __init__(self, mlp): super(ApplyNodeFunc, self).__init__() self.mlp = mlp self.bn = nn.BatchNorm1d(self.mlp.output_dim) def forward(self, h): h = self.mlp(h) h = self.bn(h) h = F.relu(h) return h class MLP(nn.Module): \u0026#34;\u0026#34;\u0026#34;MLP with linear output\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_layers, input_dim, hidden_dim, output_dim): \u0026#34;\u0026#34;\u0026#34;MLP layers construction Paramters --------- num_layers: int The number of linear layers input_dim: int The dimensionality of input features hidden_dim: int The dimensionality of hidden units at ALL layers output_dim: int The number of classes for prediction \u0026#34;\u0026#34;\u0026#34; super(MLP, self).__init__() self.linear_or_not = True # default is linear model self.num_layers = num_layers self.output_dim = output_dim if num_layers \u0026amp;lt; 1: raise ValueError(\u0026#34;number of layers should be positive!\u0026#34;) elif num_layers == 1: # Linear model self.linear = nn.Linear(input_dim, output_dim) else: # Multi-layer model self.linear_or_not = False self.linears = torch.nn.ModuleList() self.batch_norms = torch.nn.ModuleList() self.linears.append(nn.Linear(input_dim, hidden_dim)) for layer in range(num_layers - 2): self.linears.append(nn.Linear(hidden_dim, hidden_dim)) self.linears.append(nn.Linear(hidden_dim, output_dim)) for layer in range(num_layers - 1): self.batch_norms.append(nn.BatchNorm1d((hidden_dim))) def forward(self, x): if self.linear_or_not: # If linear model return self.linear(x) else: # If MLP h = x for i in range(self.num_layers - 1): h = F.relu(self.batch_norms[i](self.linears[i](h))) return self.linears[-1](h) class GIN(nn.Module): \u0026#34;\u0026#34;\u0026#34;GIN model\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_layers, num_mlp_layers, input_dim, hidden_dim, output_dim, final_dropout, learn_eps, graph_pooling_type, neighbor_pooling_type): \u0026#34;\u0026#34;\u0026#34;model parameters setting Paramters --------- num_layers: int The number of linear layers in the neural network num_mlp_layers: int The number of linear layers in mlps input_dim: int The dimensionality of input features hidden_dim: int The dimensionality of hidden units at ALL layers output_dim: int The number of classes for prediction final_dropout: float dropout ratio on the final linear layer learn_eps: boolean If True, learn epsilon to distinguish center nodes from neighbors If False, aggregate neighbors and center nodes altogether. neighbor_pooling_type: str how to aggregate neighbors (sum, mean, or max) graph_pooling_type: str how to aggregate entire nodes in a graph (sum, mean or max) \u0026#34;\u0026#34;\u0026#34; super(GIN, self).__init__() self.num_layers = num_layers self.learn_eps = learn_eps # List of MLPs self.ginlayers = torch.nn.ModuleList() self.batch_norms = torch.nn.ModuleList() for layer in range(self.num_layers - 1): if layer == 0: mlp = MLP(num_mlp_layers, input_dim, hidden_dim, hidden_dim) else: mlp = MLP(num_mlp_layers, hidden_dim, hidden_dim, hidden_dim) self.ginlayers.append( GINConv(ApplyNodeFunc(mlp), neighbor_pooling_type, 0, self.learn_eps)) self.batch_norms.append(nn.BatchNorm1d(hidden_dim)) # Linear function for graph poolings of output of each layer # which maps the output of different layers into a prediction score self.linears_prediction = torch.nn.ModuleList() for layer in range(num_layers): if layer == 0: self.linears_prediction.append( nn.Linear(input_dim, output_dim)) else: self.linears_prediction.append( nn.Linear(hidden_dim, output_dim)) self.drop = nn.Dropout(final_dropout) if graph_pooling_type == \u0026#39;sum\u0026#39;: self.pool = SumPooling() elif graph_pooling_type == \u0026#39;mean\u0026#39;: self.pool = AvgPooling() elif graph_pooling_type == \u0026#39;max\u0026#39;: self.pool = MaxPooling() else: raise NotImplementedError def forward(self, g, h): # list of hidden representation at each layer (including input) hidden_rep = [h] for i in range(self.num_layers - 1): h = self.ginlayers[i](g, h) h = self.batch_norms[i](h) h = F.relu(h) hidden_rep.append(h) score_over_layer = 0 # perform pooling over all nodes in each graph in every layer for i, h in enumerate(hidden_rep): pooled_h = self.pool(g, h) score_over_layer += self.drop(self.linears_prediction[i](pooled_h)) return score_over_layer model = GIN( args.num_layers, args.num_mlp_layers, dataset.dim_nfeats, args.hidden_dim, dataset.gclasses, args.final_dropout, args.learn_eps, args.graph_pooling_type, args.neighbor_pooling_type, ).to(args.device)   任务 节点分类 对于图神经网络来说，最常见和被广泛使用的任务之一就是节点分类。 图数据中的训练、验证和测试集中的每个节点都具有从一组预定义的类别中分配的一个类别，即正确的标注。 节点回归任务也类似，训练、验证和测试集中的每个节点都被标注了一个正确的数字。为了对节点进行分类，图神经网络执行了消息传递机制，利用节点自身的特征和其邻节点及边的特征来计算节点的隐藏表示。 消息传递可以重复多轮，以利用更大范围的邻居信息。\ncora数据集上节点分类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202  \u0026#34;\u0026#34;\u0026#34; Inductive Representation Learning on Large Graphs Paper: http://papers.nips.cc/paper/6703-inductive-representation-learning-on-large-graphs.pdf Code: https://github.com/williamleif/graphsage-simple Simple reference implementation of GraphSAGE. \u0026#34;\u0026#34;\u0026#34; import argparse import time import dgl import networkx as nx import numpy as np import torch import torch.nn as nn import torch.nn.functional as F from dgl import DGLGraph from dgl.data import load_data, register_data_args from dgl.nn.pytorch.conv import SAGEConv class GraphSAGE(nn.Module): def __init__( self, in_feats, n_hidden, n_classes, n_layers, activation, dropout, aggregator_type, ): super(GraphSAGE, self).__init__() self.layers = nn.ModuleList() self.dropout = nn.Dropout(dropout) self.activation = activation # input layer self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type)) # hidden layers for i in range(n_layers - 1): self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type)) # output layer self.layers.append( SAGEConv(n_hidden, n_classes, aggregator_type) ) # activation None def forward(self, graph, inputs): h = self.dropout(inputs) for l, layer in enumerate(self.layers): h = layer(graph, h) if l != len(self.layers) - 1: h = self.activation(h) h = self.dropout(h) return h def evaluate(model, graph, features, labels, nid): model.eval() with torch.no_grad(): logits = model(graph, features) logits = logits[nid] labels = labels[nid] _, indices = torch.max(logits, dim=1) correct = torch.sum(indices == labels) return correct.item() * 1.0 / len(labels) def main(args): # load and preprocess dataset data = load_data(args) g = data[0] features = g.ndata[\u0026#34;feat\u0026#34;] labels = g.ndata[\u0026#34;label\u0026#34;] train_mask = g.ndata[\u0026#34;train_mask\u0026#34;] val_mask = g.ndata[\u0026#34;val_mask\u0026#34;] test_mask = g.ndata[\u0026#34;test_mask\u0026#34;] in_feats = features.shape[1] n_classes = data.num_classes n_edges = data.graph.number_of_edges() print( \u0026#34;\u0026#34;\u0026#34;----Data statistics------\u0026#39; #Edges %d#Classes %d#Train samples %d#Val samples %d#Test samples %d\u0026#34;\u0026#34;\u0026#34; % ( n_edges, n_classes, train_mask.int().sum().item(), val_mask.int().sum().item(), test_mask.int().sum().item(), ) ) if args.gpu \u0026amp;lt; 0: cuda = False else: cuda = True torch.cuda.set_device(args.gpu) features = features.cuda() labels = labels.cuda() train_mask = train_mask.cuda() val_mask = val_mask.cuda() test_mask = test_mask.cuda() print(\u0026#34;use cuda:\u0026#34;, args.gpu) train_nid = train_mask.nonzero().squeeze() val_nid = val_mask.nonzero().squeeze() test_nid = test_mask.nonzero().squeeze() # graph preprocess and calculate normalization factor g = dgl.remove_self_loop(g) n_edges = g.number_of_edges() if cuda: g = g.int().to(args.gpu) # create GraphSAGE model model = GraphSAGE( in_feats, args.n_hidden, n_classes, args.n_layers, F.relu, args.dropout, args.aggregator_type, ) if cuda: model.cuda() # use optimizer optimizer = torch.optim.Adam( model.parameters(), lr=args.lr, weight_decay=args.weight_decay ) # initialize graph dur = [] for epoch in range(args.n_epochs): model.train() if epoch \u0026amp;gt;= 3: t0 = time.time() # forward logits = model(g, features) loss = F.cross_entropy(logits[train_nid], labels[train_nid]) optimizer.zero_grad() loss.backward() optimizer.step() if epoch \u0026amp;gt;= 3: dur.append(time.time() - t0) acc = evaluate(model, g, features, labels, val_nid) print( \u0026#34;Epoch {:05d}| Time(s) {:.4f}| Loss {:.4f}| Accuracy {:.4f}| \u0026#34; \u0026#34;ETputs(KTEPS) {:.2f}\u0026#34;.format( epoch, np.mean(dur), loss.item(), acc, n_edges / np.mean(dur) / 1000 ) ) print() acc = evaluate(model, g, features, labels, test_nid) print(\u0026#34;Test Accuracy {:.4f}\u0026#34;.format(acc)) parser = argparse.ArgumentParser(description=\u0026#34;GraphSAGE\u0026#34;) register_data_args(parser) parser.add_argument(\u0026#34;--dropout\u0026#34;, type=float, default=0.5, help=\u0026#34;dropout probability\u0026#34;) parser.add_argument(\u0026#34;--gpu\u0026#34;, type=int, default=-1, help=\u0026#34;gpu\u0026#34;) parser.add_argument(\u0026#34;--lr\u0026#34;, type=float, default=1e-2, help=\u0026#34;learning rate\u0026#34;) parser.add_argument( \u0026#34;--n-epochs\u0026#34;, type=int, default=200, help=\u0026#34;number of training epochs\u0026#34; ) parser.add_argument( \u0026#34;--n-hidden\u0026#34;, type=int, default=16, help=\u0026#34;number of hidden gcn units\u0026#34; ) parser.add_argument( \u0026#34;--n-layers\u0026#34;, type=int, default=1, help=\u0026#34;number of hidden gcn layers\u0026#34; ) parser.add_argument( \u0026#34;--weight-decay\u0026#34;, type=float, default=5e-4, help=\u0026#34;Weight for L2 loss\u0026#34; ) parser.add_argument( \u0026#34;--aggregator-type\u0026#34;, type=str, default=\u0026#34;gcn\u0026#34;, help=\u0026#34;Aggregator type: mean/gcn/pool/lstm\u0026#34;, ) # 设置参数 args = parser.parse_args(args=[\u0026#34;--dataset\u0026#34;, \u0026#34;cora\u0026#34;, \u0026#34;--gpu\u0026#34;, \u0026#34;0\u0026#34;]) print(args) main(args) ------ # output Epoch 00000 | Time(s) nan | Loss 1.9592 | Accuracy 0.0580 | ETputs(KTEPS) nan Epoch 00001 | Time(s) nan | Loss 1.9487 | Accuracy 0.0580 | ETputs(KTEPS) nan ... Epoch 00198 | Time(s) 0.0105 | Loss 0.3375 | Accuracy 0.7980 | ETputs(KTEPS) 1006.57 Epoch 00199 | Time(s) 0.0105 | Loss 0.3457 | Accuracy 0.7960 | ETputs(KTEPS) 1006.80 Test Accuracy 0.8220   边分类/回归 有时用户希望预测图中边的属性值，这种情况下，用户需要构建一个边分类/回归的模型。多层GNN同样也可以被用于计算任何节点的隐藏表示， 并从边的两个端点的表示，通过计算得出对边属性的预测。对一条边计算预测值最常见的情况是将预测表示为一个函数，函数的输入为两个端点的表示， 输入还可以包括边自身的特征。\n与节点分类在模型实现上的差别 节点分类模型中计算了节点的表示，那么用户只需要再编写一个apply_edges()方法计算边预测的组件即可进行边分类/回归任务。例如，对于边回归任务，如果用户想为每条边计算一个分数，可按下面的代码对每一条边计算它的两端节点隐藏表示的点积来作为分数。\n1 2 3 4 5 6 7 8  import dgl.function as fn class DotProductPredictor(nn.Module): def forward(self, graph, h): # h是从5.1节的GNN模型中计算出的节点表示 with graph.local_scope(): graph.ndata[\u0026#39;h\u0026#39;] = h graph.apply_edges(fn.u_dot_v(\u0026#39;h\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;score\u0026#39;)) return graph.edata[\u0026#39;score\u0026#39;]   用户也可以使用MLP(多层感知机)对每条边生成一个向量表示(例如，作为一个未经过归一化的类别的分布)， 并在下游任务中使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class MLPPredictor(nn.Module): def __init__(self, in_features, out_classes): super().__init__() self.W = nn.Linear(in_features * 2, out_classes) def apply_edges(self, edges): h_u = edges.src[\u0026#39;h\u0026#39;] h_v = edges.dst[\u0026#39;h\u0026#39;] score = self.W(torch.cat([h_u, h_v], 1)) return {\u0026#39;score\u0026#39;: score} def forward(self, graph, h): # h是从5.1节的GNN模型中计算出的节点表示 with graph.local_scope(): graph.ndata[\u0026#39;h\u0026#39;] = h graph.apply_edges(self.apply_edges) return graph.edata[\u0026#39;score\u0026#39;]   构建给定计算节点和边上表示的模型。\n1 2 3 4 5 6 7 8  class Model(nn.Module): def __init__(self, in_features, hidden_features, out_features): super().__init__() self.sage = SAGE(in_features, hidden_features, out_features) self.pred = DotProductPredictor() def forward(self, g, x): h = self.sage(g, x) return self.pred(g, h)   链路预测 在某些场景中，用户可能希望预测给定节点之间是否存在边，这样的任务称作链路预测（或链接预测） 任务。部分理论基础见DGL-用户指南5.3链路预测。\n链路预测是一种定义在边上的任务，给定两个节点vi和vj,链路预测的目标是判断这两个节点之间是否有连接eij或它们之间的连接属于什么类别。链路预测和工业界联系十分紧密，很多推荐系统是基于链路预测的，知识图谱补全中对实体关系的预测也被认为是一种链路预测的问题。\n参考资料：\n 基础知识 评价指标：R1，R2  cora数据集上链路预测 Refer: https://docs.dgl.ai/en/latest/new-tutorial/4_link_predict.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233  import itertools import dgl import numpy as np import scipy.sparse as sp import torch import torch.nn as nn import torch.nn.functional as F from dgl.nn.pytorch.conv import SAGEConv from sklearn.metrics import roc_auc_score \u0026#39;\u0026#39;\u0026#39; ### Overview of LinkPrediction on Cora #### Task: predicting whether a citation relationship, either citing or being cited, between two papers exists in a citation network. #### Idea: formulates the link prediction problem as a binary classification problem #### Steps: - Treat the edges in the graph as positive examples. - Sample a number of non-existent edges (i.e. node pairs with no edges between them) as negative examples. - Divide the positive examples and negative examples into a training set and a test set. - Evaluate the model with any binary classification metric such as Area Under Curve (AUC). \u0026#39;\u0026#39;\u0026#39; import dgl.data dataset = dgl.data.CoraGraphDataset() g = dataset[0] \u0026#39;\u0026#39;\u0026#39; ### Prepare training and testing sets randomly picks 10% of the edges for positive examples in the test set, and leave the rest for the training set. It then samples the same number of edges for negative examples in both sets. \u0026#39;\u0026#39;\u0026#39; # Split edge set for training and testing u, v = g.edges() # source nodes and destination nodes eids = np.arange(g.number_of_edges()) # edge ids eids = np.random.permutation(eids) # randomly shuffle the arrange test_size = int(len(eids) * 0.1) # the number of test sets train_size = g.number_of_edges() - test_size # . test_pos_u, test_pos_v = ( u[eids[:test_size]], v[eids[:test_size]], ) # recording the position of test sets train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]] # 1. Find all negative edges and 2. split them for training and testing adj = sp.coo_matrix( (np.ones(len(u)), (u.numpy(), v.numpy())) ) # construct a coordinate matrix, coo_matrix((data, (row indices, col indices))) adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes()) neg_u, neg_v = np.where(adj_neg != 0) neg_eids = np.random.choice(len(neg_u), g.number_of_edges() // 2) test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]] train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]] # When training, you will need to remove the edges in the test set from the original graph. train_g = dgl.remove_edges(g, eids[:test_size]) # constructs the positive graph and the negative graph for the training set and the test set respectively train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes()) train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes()) test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes()) test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes()) # building models # produces a scalar score on each edge by concatenating the incident nodes’ features and passing it to an MLP class MLPPredictor(nn.Module): def __init__(self, h_feats): super().__init__() self.W1 = nn.Linear(h_feats * 2, h_feats) self.W2 = nn.Linear(h_feats, 1) def apply_edges(self, edges): \u0026#34;\u0026#34;\u0026#34; Computes a scalar score for each edge of the given graph. Parameters ---------- edges : Has three members ``src``, ``dst`` and ``data``, each of which is a dictionary representing the features of the source nodes, the destination nodes, and the edges themselves. Returns ------- dict A dictionary of new edge features. \u0026#34;\u0026#34;\u0026#34; h = torch.cat([edges.src[\u0026#34;h\u0026#34;], edges.dst[\u0026#34;h\u0026#34;]], 1) return {\u0026#34;score\u0026#34;: self.W2(F.relu(self.W1(h))).squeeze(1)} def forward(self, g, h): with g.local_scope(): g.ndata[\u0026#34;h\u0026#34;] = h g.apply_edges(self.apply_edges) return g.edata[\u0026#34;score\u0026#34;] # builds a model consisting of two GraphSAGE layers, each computes new node representations by aggregating neighbor information class GraphSAGE(nn.Module): def __init__( self, in_feats, n_hidden, n_layers, activation, dropout, aggregator_type, ): super(GraphSAGE, self).__init__() self.layers = nn.ModuleList() self.dropout = nn.Dropout(dropout) self.activation = activation # input layer self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type)) # hidden layers for i in range(n_layers - 1): self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type)) def forward(self, graph, inputs): h = self.dropout(inputs) for l, layer in enumerate(self.layers): h = layer(graph, h) if l != len(self.layers) - 1: h = self.activation(h) h = self.dropout(h) return h model = GraphSAGE( in_feats=train_g.ndata[\u0026#34;feat\u0026#34;].shape[1], n_hidden=32, n_layers=2, activation=F.relu, dropout=0.5, aggregator_type=\u0026#34;gcn\u0026#34;, ) pred = MLPPredictor(32) def compute_loss(pos_score, neg_score): scores = torch.cat([pos_score, neg_score]) labels = torch.cat( [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])] ) return F.binary_cross_entropy_with_logits(scores, labels) def compute_auc(pos_score, neg_score): scores = torch.cat([pos_score, neg_score]).numpy() labels = torch.cat( [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])] ).numpy() return roc_auc_score(labels, scores) # calcuate hits@k - accuracy # refer: # 1. https://github.com/snap-stanford/ogb/blob/master/ogb/linkproppred/evaluate.py # 2. https://github.com/snap-stanford/ogb/issues/105 def eval_hits(y_pred_pos, y_pred_neg, type_info=\u0026#34;torch\u0026#34;, K=100): \u0026#34;\u0026#34;\u0026#34; compute Hits@K For each positive target node, the negative target nodes are the same. y_pred_neg is an array. rank y_pred_pos[i] against y_pred_neg for each i \u0026#34;\u0026#34;\u0026#34; if len(y_pred_neg) \u0026amp;lt; K: return {\u0026#34;hits@{}\u0026#34;.format(K): 1.0} if type_info == \u0026#34;torch\u0026#34;: kth_score_in_negative_edges = torch.topk(y_pred_neg, K)[0][-1] hitsK = float(torch.sum(y_pred_pos \u0026amp;gt; kth_score_in_negative_edges).cpu()) / len( y_pred_pos ) # type_info is numpy else: kth_score_in_negative_edges = np.sort(y_pred_neg)[-K] hitsK = float(np.sum(y_pred_pos \u0026amp;gt; kth_score_in_negative_edges)) / len( y_pred_pos ) return hitsK optimizer = torch.optim.Adam( itertools.chain(model.parameters(), pred.parameters()), lr=0.01 ) # training loooooooooooop for e in range(301): # forward h = model(train_g, train_g.ndata[\u0026#34;feat\u0026#34;]) pos_score = pred(train_pos_g, h) neg_score = pred(train_neg_g, h) loss = compute_loss(pos_score, neg_score) # backward optimizer.zero_grad() loss.backward() optimizer.step() with torch.no_grad(): pos_score = pred(test_pos_g, h) neg_score = pred(test_neg_g, h) auc = compute_auc(pos_score, neg_score) test_hits = eval_hits(pos_score, neg_score) if e % 5 == 0: print( \u0026#34;In epoch {}, train loss: {}, test auc: {}, hits@100: {}\u0026#34;.format( e, loss, auc, test_hits, ) )   整图分类 许多场景中的图数据是由多个图组成，而不是单个的大图数据。例如不同类型的人群社区。 通过用图刻画同一社区里人与人间的友谊，可以得到多张用于分类的图。 在这个场景里，整图分类模型可以识别社区的类型，即根据结构和整体信息对图进行分类。整图分类与节点分类或链接预测的主要区别是：预测结果刻画了整个输入图的属性。 与之前的任务类似，用户还是在节点或边上进行消息传递。但不同的是，整图分类任务还需要得到整个图的表示。GIN数据集整图分类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467  import sys import numpy as np from tqdm import tqdm import torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F import argparse from dgl.data import GINDataset class Parser: def __init__(self, description, args_list=[]): \u0026#34;\u0026#34;\u0026#34; arguments parser \u0026#34;\u0026#34;\u0026#34; self.parser = argparse.ArgumentParser(description=description) self.args = None self._parse(args_list) def _parse(self, args_list): # dataset self.parser.add_argument( \u0026#34;--dataset\u0026#34;, type=str, default=\u0026#34;MUTAG\u0026#34;, choices=[\u0026#34;MUTAG\u0026#34;, \u0026#34;COLLAB\u0026#34;, \u0026#34;IMDBBINARY\u0026#34;, \u0026#34;IMDBMULTI\u0026#34;], help=\u0026#34;name of dataset (default: MUTAG)\u0026#34;, ) self.parser.add_argument( \u0026#34;--batch_size\u0026#34;, type=int, default=32, help=\u0026#34;batch size for training and validation (default: 32)\u0026#34;, ) self.parser.add_argument( \u0026#34;--fold_idx\u0026#34;, type=int, default=0, help=\u0026#34;the index(\u0026amp;lt;10) of fold in 10-fold validation.\u0026#34;, ) self.parser.add_argument(\u0026#34;--filename\u0026#34;, type=str, default=\u0026#34;\u0026#34;, help=\u0026#34;output file\u0026#34;) # device self.parser.add_argument( \u0026#34;--disable-cuda\u0026#34;, action=\u0026#34;store_true\u0026#34;, help=\u0026#34;Disable CUDA\u0026#34; ) self.parser.add_argument( \u0026#34;--device\u0026#34;, type=int, default=0, help=\u0026#34;which gpu device to use (default: 0)\u0026#34; ) # net self.parser.add_argument( \u0026#34;--num_layers\u0026#34;, type=int, default=5, help=\u0026#34;number of layers (default: 5)\u0026#34; ) self.parser.add_argument( \u0026#34;--num_mlp_layers\u0026#34;, type=int, default=2, help=\u0026#34;number of MLP layers(default: 2). 1 means linear model.\u0026#34;, ) self.parser.add_argument( \u0026#34;--hidden_dim\u0026#34;, type=int, default=64, help=\u0026#34;number of hidden units (default: 64)\u0026#34;, ) # graph self.parser.add_argument( \u0026#34;--graph_pooling_type\u0026#34;, type=str, default=\u0026#34;sum\u0026#34;, choices=[\u0026#34;sum\u0026#34;, \u0026#34;mean\u0026#34;, \u0026#34;max\u0026#34;], help=\u0026#34;type of graph pooling: sum, mean or max\u0026#34;, ) self.parser.add_argument( \u0026#34;--neighbor_pooling_type\u0026#34;, type=str, default=\u0026#34;sum\u0026#34;, choices=[\u0026#34;sum\u0026#34;, \u0026#34;mean\u0026#34;, \u0026#34;max\u0026#34;], help=\u0026#34;type of neighboring pooling: sum, mean or max\u0026#34;, ) self.parser.add_argument( \u0026#34;--learn_eps\u0026#34;, action=\u0026#34;store_true\u0026#34;, help=\u0026#34;learn the epsilon weighting\u0026#34; ) # learning self.parser.add_argument( \u0026#34;--seed\u0026#34;, type=int, default=0, help=\u0026#34;random seed (default: 0)\u0026#34; ) self.parser.add_argument( \u0026#34;--epochs\u0026#34;, type=int, default=350, help=\u0026#34;number of epochs to train (default: 350)\u0026#34;, ) self.parser.add_argument( \u0026#34;--lr\u0026#34;, type=float, default=0.01, help=\u0026#34;learning rate (default: 0.01)\u0026#34; ) self.parser.add_argument( \u0026#34;--final_dropout\u0026#34;, type=float, default=0.5, help=\u0026#34;final layer dropout (default: 0.5)\u0026#34;, ) # done self.args = self.parser.parse_args(args_list) # default args args = Parser(description=\u0026#34;GIN\u0026#34;, args_list=[]).args print(args) # set up seeds, args.seed supported torch.manual_seed(seed=args.seed) np.random.seed(seed=args.seed) is_cuda = not args.disable_cuda and torch.cuda.is_available() if is_cuda: args.device = torch.device(\u0026#34;cuda:\u0026#34; + str(args.device)) torch.cuda.manual_seed_all(seed=args.seed) else: args.device = torch.device(\u0026#34;cpu\u0026#34;) import math from torch.utils.data.sampler import SubsetRandomSampler from sklearn.model_selection import StratifiedKFold import dgl from dgl.dataloading import GraphDataLoader class GINDataLoader(): def __init__(self, dataset, batch_size, device, collate_fn=None, seed=0, shuffle=True, split_name=\u0026#39;fold10\u0026#39;, fold_idx=0, split_ratio=0.7): self.shuffle = shuffle self.seed = seed self.kwargs = {\u0026#39;pin_memory\u0026#39;: True} if \u0026#39;cuda\u0026#39; in device.type else {} labels = [l for _, l in dataset] if split_name == \u0026#39;fold10\u0026#39;: train_idx, valid_idx = self._split_fold10( labels, fold_idx, seed, shuffle) elif split_name == \u0026#39;rand\u0026#39;: train_idx, valid_idx = self._split_rand( labels, split_ratio, seed, shuffle) else: raise NotImplementedError() train_sampler = SubsetRandomSampler(train_idx) valid_sampler = SubsetRandomSampler(valid_idx) self.train_loader = GraphDataLoader( dataset, sampler=train_sampler, batch_size=batch_size, collate_fn=collate_fn, **self.kwargs) self.valid_loader = GraphDataLoader( dataset, sampler=valid_sampler, batch_size=batch_size, collate_fn=collate_fn, **self.kwargs) def train_valid_loader(self): return self.train_loader, self.valid_loader def _split_fold10(self, labels, fold_idx=0, seed=0, shuffle=True): \u0026#39;\u0026#39;\u0026#39; 10 flod \u0026#39;\u0026#39;\u0026#39; assert 0 \u0026amp;lt;= fold_idx and fold_idx \u0026amp;lt; 10, print( \u0026#34;fold_idx must be from 0 to 9.\u0026#34;) skf = StratifiedKFold(n_splits=10, shuffle=shuffle, random_state=seed) idx_list = [] for idx in skf.split(np.zeros(len(labels)), labels): # split(x, y) idx_list.append(idx) train_idx, valid_idx = idx_list[fold_idx] print( \u0026#34;train_set : test_set = %d: %d\u0026#34;, len(train_idx), len(valid_idx)) return train_idx, valid_idx def _split_rand(self, labels, split_ratio=0.7, seed=0, shuffle=True): num_entries = len(labels) indices = list(range(num_entries)) np.random.seed(seed) np.random.shuffle(indices) split = int(math.floor(split_ratio * num_entries)) train_idx, valid_idx = indices[:split], indices[split:] print( \u0026#34;train_set : test_set = %d: %d\u0026#34;, len(train_idx), len(valid_idx)) return train_idx, valid_idx \u0026#34;\u0026#34;\u0026#34; How Powerful are Graph Neural Networks https:\u0026amp;#47;\u0026amp;#47;arxiv.org/abs/1810.00826 https://openreview.net/forum?id=ryGs6iA5Km Author\u0026#39;s implementation: https://github.com/weihua916/powerful-gnns \u0026#34;\u0026#34;\u0026#34; from dgl.nn.pytorch.conv import GINConv from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling class ApplyNodeFunc(nn.Module): \u0026#34;\u0026#34;\u0026#34;Update the node feature hv with MLP, BN and ReLU.\u0026#34;\u0026#34;\u0026#34; def __init__(self, mlp): super(ApplyNodeFunc, self).__init__() self.mlp = mlp self.bn = nn.BatchNorm1d(self.mlp.output_dim) def forward(self, h): h = self.mlp(h) h = self.bn(h) h = F.relu(h) return h class MLP(nn.Module): \u0026#34;\u0026#34;\u0026#34;MLP with linear output\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_layers, input_dim, hidden_dim, output_dim): \u0026#34;\u0026#34;\u0026#34;MLP layers construction Paramters --------- num_layers: int The number of linear layers input_dim: int The dimensionality of input features hidden_dim: int The dimensionality of hidden units at ALL layers output_dim: int The number of classes for prediction \u0026#34;\u0026#34;\u0026#34; super(MLP, self).__init__() self.linear_or_not = True # default is linear model self.num_layers = num_layers self.output_dim = output_dim if num_layers \u0026amp;lt; 1: raise ValueError(\u0026#34;number of layers should be positive!\u0026#34;) elif num_layers == 1: # Linear model self.linear = nn.Linear(input_dim, output_dim) else: # Multi-layer model self.linear_or_not = False self.linears = torch.nn.ModuleList() self.batch_norms = torch.nn.ModuleList() self.linears.append(nn.Linear(input_dim, hidden_dim)) for layer in range(num_layers - 2): self.linears.append(nn.Linear(hidden_dim, hidden_dim)) self.linears.append(nn.Linear(hidden_dim, output_dim)) for layer in range(num_layers - 1): self.batch_norms.append(nn.BatchNorm1d((hidden_dim))) def forward(self, x): if self.linear_or_not: # If linear model return self.linear(x) else: # If MLP h = x for i in range(self.num_layers - 1): h = F.relu(self.batch_norms[i](self.linears[i](h))) return self.linears[-1](h) class GIN(nn.Module): \u0026#34;\u0026#34;\u0026#34;GIN model\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_layers, num_mlp_layers, input_dim, hidden_dim, output_dim, final_dropout, learn_eps, graph_pooling_type, neighbor_pooling_type): \u0026#34;\u0026#34;\u0026#34;model parameters setting Paramters --------- num_layers: int The number of linear layers in the neural network num_mlp_layers: int The number of linear layers in mlps input_dim: int The dimensionality of input features hidden_dim: int The dimensionality of hidden units at ALL layers output_dim: int The number of classes for prediction final_dropout: float dropout ratio on the final linear layer learn_eps: boolean If True, learn epsilon to distinguish center nodes from neighbors If False, aggregate neighbors and center nodes altogether. neighbor_pooling_type: str how to aggregate neighbors (sum, mean, or max) graph_pooling_type: str how to aggregate entire nodes in a graph (sum, mean or max) \u0026#34;\u0026#34;\u0026#34; super(GIN, self).__init__() self.num_layers = num_layers self.learn_eps = learn_eps # List of MLPs self.ginlayers = torch.nn.ModuleList() self.batch_norms = torch.nn.ModuleList() for layer in range(self.num_layers - 1): if layer == 0: mlp = MLP(num_mlp_layers, input_dim, hidden_dim, hidden_dim) else: mlp = MLP(num_mlp_layers, hidden_dim, hidden_dim, hidden_dim) self.ginlayers.append( GINConv(ApplyNodeFunc(mlp), neighbor_pooling_type, 0, self.learn_eps)) self.batch_norms.append(nn.BatchNorm1d(hidden_dim)) # Linear function for graph poolings of output of each layer # which maps the output of different layers into a prediction score self.linears_prediction = torch.nn.ModuleList() for layer in range(num_layers): if layer == 0: self.linears_prediction.append( nn.Linear(input_dim, output_dim)) else: self.linears_prediction.append( nn.Linear(hidden_dim, output_dim)) self.drop = nn.Dropout(final_dropout) if graph_pooling_type == \u0026#39;sum\u0026#39;: self.pool = SumPooling() elif graph_pooling_type == \u0026#39;mean\u0026#39;: self.pool = AvgPooling() elif graph_pooling_type == \u0026#39;max\u0026#39;: self.pool = MaxPooling() else: raise NotImplementedError def forward(self, g, h): # list of hidden representation at each layer (including input) hidden_rep = [h] for i in range(self.num_layers - 1): h = self.ginlayers[i](g, h) h = self.batch_norms[i](h) h = F.relu(h) hidden_rep.append(h) score_over_layer = 0 # perform pooling over all nodes in each graph in every layer for i, h in enumerate(hidden_rep): pooled_h = self.pool(g, h) score_over_layer += self.drop(self.linears_prediction[i](pooled_h)) return score_over_layer dataset = GINDataset(args.dataset, not args.learn_eps) trainloader, validloader = GINDataLoader( dataset, batch_size=args.batch_size, device=args.device, seed=args.seed, shuffle=True, split_name=\u0026#34;fold10\u0026#34;, fold_idx=args.fold_idx, ).train_valid_loader() # or split_name=\u0026#39;rand\u0026#39;, split_ratio=0.7 model = GIN( args.num_layers, args.num_mlp_layers, dataset.dim_nfeats, args.hidden_dim, dataset.gclasses, args.final_dropout, args.learn_eps, args.graph_pooling_type, args.neighbor_pooling_type, ).to(args.device) criterion = nn.CrossEntropyLoss() # defaul reduce is true optimizer = optim.Adam(model.parameters(), lr=args.lr) scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5) def train(args, net, trainloader, optimizer, criterion, epoch): net.train() running_loss = 0 total_iters = len(trainloader) for graphs, labels in trainloader: # batch graphs will be shipped to device in forward part of model labels = labels.to(args.device) graphs = graphs.to(args.device) feat = graphs.ndata.pop(\u0026#39;attr\u0026#39;) outputs = net(graphs, feat) loss = criterion(outputs, labels) running_loss += loss.item() # backprop optimizer.zero_grad() loss.backward() optimizer.step() # the final batch will be aligned running_loss = running_loss / total_iters return running_loss def eval_net(args, net, dataloader, criterion): net.eval() total = 0 total_loss = 0 total_correct = 0 for data in dataloader: graphs, labels = data graphs = graphs.to(args.device) labels = labels.to(args.device) feat = graphs.ndata.pop(\u0026#39;attr\u0026#39;) total += len(labels) outputs = net(graphs, feat) _, predicted = torch.max(outputs.data, 1) total_correct += (predicted == labels.data).sum().item() loss = criterion(outputs, labels) # crossentropy(reduce=True) for default total_loss += loss.item() * len(labels) loss, acc = 1.0*total_loss / total, 1.0*total_correct / total net.train() return loss, acc for epoch in range(args.epochs): train(args, model, trainloader, optimizer, criterion, epoch) scheduler.step() train_loss, train_acc = eval_net(args, model, trainloader, criterion) valid_loss, valid_acc = eval_net(args, model, validloader, criterion) print( \u0026#34;Epoch: {}, train set - average loss: {:.4f}, accuracy: {:.0f}%, valid set - average loss: {:.4f}, accuracy: {:.0f}%\u0026#34;.format( epoch, train_loss, 100.0 * train_acc, valid_loss, 100.0 * valid_acc ) )   ","description":"","id":31,"section":"posts","tags":null,"title":"GNN-学习札记","uri":"https://www.xunhs.cyou/posts/notes/2021-03-24-gnn-%E5%AD%A6%E4%B9%A0%E6%9C%AD%E8%AE%B0/"},{"content":" 深圳\n \n 2021.3.1 Using Pytorch to implement GCNN: PyTorch Geometric； nni：机器学习AutoML模型参数搜索，特征工程工具 2021.3.2 深圳 VS CSC 哈哈；崩溃了，跑的神经网络没有传统的机器学习的模型好，简直就是差远了。 2021.3.3 Mac自带词典转换：工具DictUnifier; 字典源 2021.3.4 Clash for Window: 兼顾Profiles更新和自定义规则; 移动轨迹分析库: scikit-mobility，以后出租车轨迹分析用它试试。 2021.3.5 namesoil添加子域名，直接在域名解析里面添加子域名即可，并指向服务器地址。等待15分钟左右生效；人生难测 命途多舛? 2021.3.6 精神世界丰富，感性且无趣 2021.3.7 WSL2 内存设置：https://mourinaruto.github.io/2020/11/01/reduce-the-memory-usage-of-wsl2/; 样本量少 还是老老实实用ml吧? 2021.3.8 你很在乎朋友对你的看法吗？其实你也知道是在开玩笑、准备明天开题 2021.3.9 顺利开题? 晚饭和老板们吃饭 国窖1573呐 这酒原价三千呢 老师们半开玩笑的讲了很多人生忠告 非常值得深思 加油吧 骚年 哈哈 2021.3.10 重逢 2021.3.11 等待 2021.3.12 约定 2021.3.13 再感性的冲动一次 权当去散散心 记住不要被自己感动 2021.3.14 抵深 2021.3.15 向往已久的深大进不去，只能在周边转悠。再访深圳湾公园，这次以骑行代步，天气更加晴朗，十分惬意；静若处子，动若脱兔? 2021.3.16 福田-景田-益田-盐田，深圳的“田”字系列? 2021.3.17 返汉，各自好好努力，未来可期? 2021.3.18 Mark一下无监督对比学习：https://zhuanlan.zhihu.com/p/334732028 2021.3.19 青城山下白素贞 2021.3.20 无趣。无趣啊 2021.3.21 鲁巷广场听说倒闭了，今天过去好多人在清仓。好久没见过光谷这么多人的场景了。忘记了鲁巷7楼的电影院叫什么名字，总觉得很熟悉，蛮怀念以前的在南望山读研的日子。半秋山的牛排还是蛮好吃的。 2021.3.22 台大姜成翰助教讲的GNN蛮好的，知识点很仔细。但是能感觉到，下面的同学有些听不懂，或者与助教交互有点少，助教略微有些失望吧。 2021.3.23 哪有那么容易做到完美? 2021.3.24 GNN很有探索的空间啊，模型众多，应用广泛。先从dgl链路预测问题开始，跑跑banchmark 2021.3.25 今天打了新冠疫苗? 2021.3.26 找链路预测的demo，OGB的例子都跑不动，要不是内存溢出就是跑几个小时没进度。下午在dgl的英文文档复现了基于cora的小demo，还算不错，基本理解了。 2021.3.27 针不戳? 2021.3.28 Predicting spatial interaction using gnn + poi tfidf features 半天拖拖拉拉 做好了训练数据集 2021.3.29 Mark 自监督学习列表； 取悦自己，是终身浪漫的开始 2021.3.30 机器学习结果可视化sklearn-evaluation 2021.3.31 3月在慌忙整理申请材料中结束。  ","description":"","id":35,"section":"posts","tags":["GNN","海","深圳","疫苗"],"title":"2021-3","uri":"https://www.xunhs.cyou/posts/journals/2021-03-01-2021-3/"},{"content":" 使用ArcGIS Pro栅格切割工具做分块裁剪，并使用切割好的分块做Image Embeddings。记录操作过程及注意事项。\n Raster Split 数据准备  北京市城区栅格数据（From 水经注：Google Maps） 北京市五环矢量数据（研究范围）\n  分块裁剪  生成外包矩形：使用北京市五环矢量数据生成外包矩形\n 掩膜提取：使用外包矩形切割栅格影像\n 分块裁剪\n设置分块大小，自动裁剪影像；格式选择tif格式\n 注意：ArcGIS Pro进行此操作时存在Bug（异常错误（或者已完成，无结果）），在环境变量中设置并行参数为0即可 ArcGIS Pro更新后没有出现该问题\n 生成文件如下：\n    后处理及获取中心坐标  获取中心坐标，便于后续空间关联操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  from osgeo import gdal import geopandas as gpd import pandas as pd from pathlib import Path import os from tqdm import tqdm patch_size = 256 split_raster_dir = Path(\u0026#39;/workspace\u0026#39;, \u0026#39;ImagePatchEmbedding\u0026#39;, \u0026#39;SplitingPatch\u0026#39;, \u0026#39;BJR5_256\u0026#39;) all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif_path in tqdm(all_tif): ds = gdal.Open(str(tif_path)) width = ds.RasterXSize height = ds.RasterYSize ds = None if width != patch_size or height != patch_size: # delete path_stem = tif_path.stem path_parent = tif_path.parent _l = [\u0026#39;.tfw\u0026#39;, \u0026#39;.TIF\u0026#39;, \u0026#39;.TIF.aux.xml\u0026#39;, \u0026#39;.TIF.ovr\u0026#39;] for _ in _l: d_fp = Path(path_parent, f\u0026#39;{path_stem}{_}\u0026#39;) os.remove(d_fp) _dict = { \u0026#39;rs_stem\u0026#39;: [], \u0026#39;centralx\u0026#39;: [], \u0026#39;centraly\u0026#39;: [], } all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif_path in tqdm(all_tif): path_stem = tif_path.stem ds = gdal.Open(str(tif_path)) width = ds.RasterXSize height = ds.RasterYSize gt = ds.GetGeoTransform() minx = gt[0] miny = gt[3] + width*gt[4] + height*gt[5] maxx = gt[0] + width*gt[1] + height*gt[2] maxy = gt[3] centralx = (minx + maxx) / 2 centraly = (miny + maxy) / 2 _dict[\u0026#39;rs_stem\u0026#39;].append(path_stem) _dict[\u0026#39;centralx\u0026#39;].append(centralx) _dict[\u0026#39;centraly\u0026#39;].append(centraly) bj_rs_split_df = pd.DataFrame(_dict) bj_rs_split_df.head() bj_arial_image_split_fp = Path(split_raster_dir.parent, \u0026#39;BJR5_256_patch_location.txt\u0026#39;) bj_rs_split_df.to_csv(bj_arial_image_split_fp, header=True, index=False)   导入ArcGIS：\n GeoTiff转rgb（JPG图片）\n使用一些方式（rasterio等）转换为jpg格式后，转换后的jpg图片一片漆黑，参考解释。需进行rgb转换，参考方法：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  # -*- coding: UTF-8 -*- import numpy as np import os from PIL import Image from osgeo import gdal from pathlib import Path from tqdm import tqdm def readTif(imgPath, bandsOrder=[1,2,3]): \u0026#34;\u0026#34;\u0026#34; 读取GEO tif影像的前三个波段值，并按照R.G.B顺序存储到形状为【原长*原宽*3】的数组中 :param imgPath: 图像存储全路径 :param bandsOrder: RGB对应的波段顺序，如高分二号多光谱包含蓝，绿，红，近红外四个波段，RGB对应的波段为3，2，1 :return: R.G.B三维数组 \u0026#34;\u0026#34;\u0026#34; dataset = gdal.Open(imgPath, gdal.GA_ReadOnly) cols = dataset.RasterXSize rows = dataset.RasterYSize data = np.empty([rows, cols, 3], dtype=float) for i in range(3): band = dataset.GetRasterBand(bandsOrder[i]) oneband_data = band.ReadAsArray() data[:, :, i] = oneband_data return data def stretchImg(imgPath, resultPath, lower_percent=0.5, higher_percent=99.5): \u0026#34;\u0026#34;\u0026#34; #将光谱DN值映射至0-255，并保存 :param imgPath: 需要转换的tif影像路径（***.tif） :param resultPath: 转换后的文件存储路径(***.jpg) :param lower_percent: 低值拉伸比率 :param higher_percent: 高值拉伸比率 :return: 无返回参数，直接输出图片 \u0026#34;\u0026#34;\u0026#34; RGB_Array=readTif(imgPath) band_Num = RGB_Array.shape[2] JPG_Array = np.zeros_like(RGB_Array, dtype=np.uint8) for i in range(band_Num): minValue = 0 maxValue = 255 #获取数组RGB_Array某个百分比分位上的值 low_value = np.percentile(RGB_Array[:, :,i], lower_percent) high_value = np.percentile(RGB_Array[:, :,i], higher_percent) temp_value = minValue + (RGB_Array[:, :,i] - low_value) * (maxValue - minValue) / (high_value - low_value) temp_value[temp_value \u0026lt; minValue] = minValue temp_value[temp_value \u0026gt; maxValue] = maxValue JPG_Array[:, :, i] = temp_value outputImg = Image.fromarray(np.uint8(JPG_Array)) outputImg.save(resultPath) def Batch_Convert_tif_to_jpg(imgdir, savedir): #获取文件夹下所有tif文件名称，并存入列表 all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif in tqdm(all_tif): stretchImg(str(tif), str(tif.with_suffix(\u0026#39;.jpg\u0026#39;))) print(\u0026#34;完成所有图片转换!\u0026#34;) Batch_Convert_tif_to_jpg(split_raster_dir, split_raster_dir)    删除多余文件  1 2 3 4 5 6  # del extra files, only keep jpg _del = [\u0026#39;.tfw\u0026#39;, \u0026#39;.TIF\u0026#39;, \u0026#39;.TIF.aux.xml\u0026#39;, \u0026#39;.TIF.ovr\u0026#39;] all_jpg = [_ for _ in split_raster_dir.glob(\u0026#39;*.jpg\u0026#39;)] for jpg in tqdm(all_jpg): for _p in _del: os.remove(jpg.with_suffix(_p))   Image Embeddings Image Embedding初衷是使用Embedding的方式对图像进行表示，后续可应用于图片检索等应用。此处参考(https://github.com/rom1504/image_embeddings)实现该功能。在本机配置环境的过程中，faiss这个包始终报错，且网上并无解决方案。故使用Google Calab在线Jupyter Notebook的平台进行操作。\n数据准备  压缩数据并上传至Google 云端硬盘 将作者分享的using_the_lib.ipynb保存至自己的Google云端硬盘 安装repo: !pip install -U image_embeddings 挂在Google云端硬盘 1 2  from google.colab import drive drive.mount(\u0026#39;/content/drive\u0026#39;)    解压：!unzip \u0026quot;/content/drive/MyDrive/DataUploads/ImageEmbeddings/RasterSplitJPG.zip\u0026quot; -d \u0026quot;/content/drive/MyDrive/DataUploads/ImageEmbeddings/\u0026quot; 载入repo及路径： 1 2 3 4 5 6 7  # Let\u0026#39;s define some paths where to save images, tfrecords and embeddings from pathlib import Path import image_embeddings home = Path(\u0026#34;/content/drive/MyDrive/\u0026#34;) path_images = str(Path(home, \u0026#34;DataUploads/ImageEmbeddings/RasterSplitJPG/\u0026#34;)) path_tfrecords = str(Path(home, \u0026#34;Colab Notebooks/ImageEmbeddings/tfrecords\u0026#34;)) path_embeddings = str(Path(home, \u0026#34;Colab Notebooks/ImageEmbeddings/embeddings\u0026#34;))    重命名*.JPG(原作者代码中操作的是*.jpeg格式，JPG可以读取，但是在后续图片显示操作中会提示路径错误) 1 2 3 4 5 6  # rename *.JPG with *,jpeg import os root_path = Path(\u0026#34;/content/drive/MyDrive/DataUploads/ImageEmbeddings/RasterSplitJPG\u0026#34;) for fp in root_path.glob(\u0026#34;*.JPG\u0026#34;): stem = fp.stem os.rename(fp, Path(root_path, f\u0026#34;{stem}.jpeg\u0026#34;))      Build embeddings  Transform image to tf records：Tf record is an efficient format to store image, it\u0026rsquo;s better to use than raw image file for inference 1  image_embeddings.inference.write_tfrecord(image_folder=path_images, output_folder=path_tfrecords, num_shards=10)    Build embeddings：Here, efficientnet is used, but the code is particularly simple, and any other model could be used. The input is tfrecords and the output is embeddings 1 2  # 如出现内存溢出错误，可适当降低batch size image_embeddings.inference.run_inference(tfrecords_folder=path_tfrecords, output_folder=path_embeddings, batch_size=500)      Image Search  Read the embeddings and build an index with it. The knn index is built using faiss which makes it possible to search embeddings in log(N) with lot of options to reduce memory footprint 1 2  [id_to_name, name_to_id, embeddings] = image_embeddings.knn.read_embeddings(path_embeddings) index = image_embeddings.knn.build_index(embeddings)    Search in the index  example 1 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_189\u0026#39;] # 工业区 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 7440 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=7440 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114254.png)  example 2 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_636\u0026#39;] # 绿地 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 5553 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=5553 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114532.png)  example 3 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_1423\u0026#39;] # 居住区 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 3818 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=3818 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114703.png)  效果还是蛮好的   Combination of images：Any vector in the same space can be used as query For example I could have 2 image and want to find some example that are closeby to the 2, Let\u0026rsquo;s just average them and see that happens ! 1 2 3 4 5 6 7 8  p1 = 7440 p2 = 5553 image1 = id_to_name[p1] image2 = id_to_name[p2] image_embeddings.knn.display_picture(path_images, image1) image_embeddings.knn.display_picture(path_images, image2) results = image_embeddings.knn.search(index, id_to_name, (embeddings[p1] + embeddings[p2])/2, 7) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114940.png) 可以检索出混合工业区和绿地的区域  Normalize embedding: We get mostly one of the picture. One thing that can be done to improve this is to normalize the embeddings to get a better mix  Normalize 1 2 3 4 5 6 7  import numpy as np def normalized(a, axis=-1, order=2): l2 = np.atleast_1d(np.linalg.norm(a, order, axis)) l2[l2==0] = 1 return a / np.expand_dims(l2, axis) normalized_embeddings = normalized(embeddings, 1) index_normalized = image_embeddings.knn.build_index(normalized_embeddings)    Normalize Index 1 2 3 4 5 6 7 8  p1 = 7440 p2 = 5553 image1 = id_to_name[p1] image2 = id_to_name[p2] image_embeddings.knn.display_picture(path_images, image1) image_embeddings.knn.display_picture(path_images, image2) results = image_embeddings.knn.search(index_normalized, id_to_name, (normalized_embeddings[p1] + normalized_embeddings[p2])/2, 7) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228115412.png) 作者说正则化（normalize）embeddings后可以提高混合检索的精度，在一定程度上确实有所提高    Exporting the embeddings to numpy 1 2 3  from image_embeddings.knn import embeddings_to_numpy path_embeddings_numpy = f\u0026#34;{home}/{dataset}/embeddings_numpy\u0026#34; embeddings_to_numpy(path_embeddings, path_embeddings_numpy)      ","description":"","id":36,"section":"posts","tags":["Embedding","GIS"],"title":"ArcGIS Pro栅格切割及应用于Image Embeddings札记","uri":"https://www.xunhs.cyou/2021/02/27/414/"},{"content":" 本文对POI-type Embedding的构建流程进行整理。\n POI数据准备  高德地图兴趣点2018-POI（Point of Interest）数据，数据共享地址：https://opendata.pku.edu.cn/dataset.xhtml?persistentId=doi:10.18170/DVN/WSXCNM 数据入库（这里使用的是ES，方便快速查询及可视化）（参考之前写的ES操作的文章）  构建语料库  生成随机点\n 构建随机点语料库  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  # Building K-NN Corpus # 根据随机点以及指定距离，寻找附近POI点，构建“语料库” # 此处POI type选择的是高德地图的type3 # %% import geopandas as gpd from tqdm import tqdm import os, joblib from elasticsearch import Elasticsearch from elasticsearch_dsl import Search client = Elasticsearch(hosts=\u0026#34;192.168.123.87:9200\u0026#34;) # %% random_points_fp = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;RandomPoints.shp\u0026#39;) random_points_gdf = gpd.read_file(random_points_fp) random_points_gdf.head() # %% def get_neighbors(client, index, geo_point, distance, geo_unit=\u0026#34;m\u0026#34;): s = Search(using=client, index=index) s = s.filter( \u0026#34;geo_distance\u0026#34;, distance=f\u0026#34;{distance}{geo_unit}\u0026#34;, wgs_location=geo_point ) _sort_json = { \u0026#34;_geo_distance\u0026#34;: { \u0026#34;wgs_location\u0026#34;: geo_point, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34;, \u0026#34;unit\u0026#34;: geo_unit, \u0026#34;mode\u0026#34;: \u0026#34;min\u0026#34;, \u0026#34;distance_type\u0026#34;: \u0026#34;arc\u0026#34;, } } s = s.sort(_sort_json) total = s.count() s = s[0:total] response = s.execute() return total, response # %% index = \u0026#34;北京市\u0026#34; distance = 500 geo_unit = \u0026#34;m\u0026#34; corpus_dict = {} for (point_id, lat, lon) in tqdm(zip(random_points_gdf[\u0026#39;PointID\u0026#39;], random_points_gdf[\u0026#39;lat\u0026#39;], random_points_gdf[\u0026#39;lon\u0026#39;])): geo_point = {\u0026#34;lat\u0026#34;: lat, \u0026#34;lon\u0026#34;: lon} total, neighbors = get_neighbors(client, index, geo_point, distance, geo_unit) if total \u0026gt; 10: # 至少10个点 corpus_dict[point_id] = [] for p in neighbors.hits.hits: distance = p.sort[0] corpus_dict[point_id].append(p._source.type_3) # %% # 保存变量 corpus_fp = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;EmbeddingCorpus.dat\u0026#39;) joblib.dump(value=corpus_dict, filename=corpus_fp) # # 载入变量 # corpus_fp = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;EmbeddingCorpus.dat\u0026#39;) # corpus_dict = joblib.load(corpus_fp)   使用gensim进行POI-type embedding的训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  import os, joblib from gensim.models.word2vec import Word2Vec import logging import json # 载入变量 corpus_fp = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;EmbeddingCorpus.dat\u0026#39;) corpus_dict = joblib.load(corpus_fp) _corpora = corpus_dict.values() \u0026#39;\u0026#39;\u0026#39; 语料库模板如下 _corpora= [ [type1, type2, ...,], [], ... ] \u0026#39;\u0026#39;\u0026#39; # %% #获取日志信息 logging.basicConfig( format=\u0026#39;%(asctime)s: %(levelname)s: %(message)s\u0026#39;, level=logging.INFO) def func(corpora, path_name, model_size=100): model = Word2Vec(corpora, size=model_size, # 特征向量的维度 min_count=1, # 需要计算词向量的最小词频 window=5, # 词向量上下文最大距离 sample = 1e-3, # 高频词汇的随机降采样的配置阈值 sg=1, # 0: CBOW; 1: Skip-Gram hs = 1, #为 1 用hierarchical softmax 0 negative sampling iter=100, # 随机梯度下降法中迭代的最大次数 workers=8 # 开启线程个数 ) model.save(r\u0026#39;Embedding{}.word2vec\u0026#39;.format(path_name)) # 保存向量 words = [] for c in corpora: words.extend(c) words = list(set(words)) print(\u0026#39;总共{}个单词\u0026#39;.format(len(words))) with open(r\u0026#39;Embedding{}.json\u0026#39;.format(path_name), \u0026#39;w+\u0026#39;, encoding=\u0026#39;utf8\u0026#39;) as fp: save_json = {} for w in words: save_json[w] = [float(_) for _ in model.wv[w]] json.dump(save_json, fp) model_size = 128 # 词向量的维度 func(_corpora, \u0026#39;POI\u0026#39;, model_size)   向量查询检索 1 2 3 4 5 6 7 8 9 10 11  from gensim.models import KeyedVectors from gensim.models.word2vec import Word2Vec # 载入预训练 # 方式一：载入已训练模型 w2v_model = Word2Vec.load(\u0026#39;Embedding128.word2vec\u0026#39;) # 方式二：载入已训练向量（如OpenNE导出的向量） with open(\u0026#39;/workspace/UrbanFunctionalRegionalization/result/openne/deepwalk_sz_ep10.txt\u0026#39;, \u0026#39;r\u0026#39;) as fp: w2v_wv = KeyedVectors.load_word2vec_format(fp, binary=False) # w2v_wv为KeyedVectors格式，即等同于w2v_model.wv    获取单词列表：word_list = w2v_model.wv.index2word 或 word_list = w2v_wv.index2word 获取单词向量：w2v_model.wv.get_vector('机场相关') w2v_wv.get_vector('机场相关') 查询两个词的相似度：  1 2 3  s_word_1 = \u0026#34;机场相关\u0026#34; s_word_2 = \u0026#34;脑科医院\u0026#34; f_word_sim = w2v_model.similarity(s_word_1, s_word_2)    查询单词最相似的单词（默认前10）：w2v_model.most_similar(\u0026quot;脑科医院\u0026quot;)  POI-type Embedding案例：应用于城市功能区分类  POI数据与区块数据（如交通分析小区TAZ，空间格网等）进行空间关联（spatial join）  POI空间关联结果：POIJoinTaz.shp 交通分析小区（with functions）：eulucJoinTaz.shp   计算doc embedding，这里使用简单使用的mean embedding  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  from gensim.models.word2vec import Word2Vec import geopandas as gpd import pandas as pd import numpy as np import os w2v_model = Word2Vec.load(\u0026#39;Embedding128.word2vec\u0026#39;) root_dir = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;OriginalPublicData\u0026#39;) POI_gdf = gpd.read_file(os.path.join(root_dir, \u0026#39;POIJoinTaz.shp\u0026#39;)) taz_gdf = gpd.read_file(os.path.join(root_dir, \u0026#39;eulucJoinTaz.shp\u0026#39;)) # %% taz_group = POI_gdf.groupby(by=[\u0026#39;TAZ_FID\u0026#39;]) # 计算mean embedding mean_feature_dict = {} vector_list = [] for (taz_FID, taz_sub_gdf) in taz_group: type_list = taz_sub_gdf[\u0026#39;type_3\u0026#39;] for t in type_list: try: v = w2v_model.wv.get_vector(t) except: pass vector_list.append(v) mean_feature_dict[taz_FID] = np.mean(np.array(vector_list), axis=0) # %% # mean_feature_dict 转为 DataFrame 保存 _dict = {} _dict[\u0026#39;taz_fid\u0026#39;] = [] for i in range(128): feature_name = f\u0026#39;feature_{i}\u0026#39; _dict[feature_name] = [] for _fid, mean_feature in mean_feature_dict.items(): _dict[\u0026#39;taz_fid\u0026#39;].append(_fid) for i, f in enumerate(list(mean_feature)): feature_name = f\u0026#39;feature_{i}\u0026#39; _dict[feature_name].append(f) mean_feature_df = pd.DataFrame(_dict) mean_feature_path = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;TAZDocEmbedding.txt\u0026#39;) mean_feature_df.to_csv(mean_feature_path, header=True, index=False)    构建分类器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152  # 分类 import geopandas as gpd import pandas as pd import os from sklearn import preprocessing from sklearn.model_selection import StratifiedKFold from sklearn.model_selection import cross_val_score from sklearn.linear_model import Ridge from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.discriminant_analysis import LinearDiscriminantAnalysis from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC from sklearn.ensemble import AdaBoostClassifier from sklearn.ensemble import GradientBoostingClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import ExtraTreesClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report, confusion_matrix # %% taz_doc_embedding_path = os.path.join(\u0026#39;.\u0026#39;, \u0026#39;TAZDocEmbedding.txt\u0026#39;) taz_doc_embedding_df = pd.read_csv(taz_doc_embedding_path, header=0) root_dir = os.path.join(\u0026#39;..\u0026#39;, \u0026#39;OriginalPublicData\u0026#39;) taz_gdf = gpd.read_file(os.path.join(root_dir, \u0026#39;eulucJoinTaz.shp\u0026#39;)) classifier_df = pd.merge(taz_doc_embedding_df, taz_gdf[[\u0026#39;TAZ_FID\u0026#39;, \u0026#39;Level1\u0026#39;, \u0026#39;Level2\u0026#39;]], left_on= \u0026#39;taz_fid\u0026#39;, right_on=\u0026#39;TAZ_FID\u0026#39;, how=\u0026#39;inner\u0026#39;) # %% # 构建训练数据集 # 样本不平衡问题，增加小样本的样本量 sample_1 = classifier_df.query(\u0026#39;Level1 == 1\u0026#39;).sample(n=500, random_state=2021) sample_2 = classifier_df.query(\u0026#39;Level1 == 5\u0026#39;).sample(n=500, random_state=2021) sample_3 = classifier_df.query(\u0026#39;Level1 == 2\u0026#39;) sample_4 = classifier_df.query(\u0026#39;Level1 == 3\u0026#39;) concat_list = [sample_1, sample_2] + [sample_3] * 2 + [sample_4] * 4 classifier_df = pd.concat(concat_list, axis=0) feature_names = list(taz_doc_embedding_df.columns)[1:] x = classifier_df[feature_names] scaler = preprocessing.StandardScaler().fit(x) x = scaler.transform(x) y = classifier_df[\u0026#39;Level1\u0026#39;] train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=2021) # %% # 模型选择 models = [ (\u0026#39;LR\u0026#39; , LogisticRegression()), # (\u0026#39;LDA\u0026#39; , LinearDiscriminantAnalysis()), # (\u0026#39;KNN\u0026#39; , KNeighborsClassifier()), # (\u0026#39;CART\u0026#39; , DecisionTreeClassifier()), # (\u0026#39;NB\u0026#39; , GaussianNB()), (\u0026#39;SVM\u0026#39; , SVC(probability=True)), # (\u0026#39;AB\u0026#39; , AdaBoostClassifier()), # (\u0026#39;GBM\u0026#39; , GradientBoostingClassifier()), (\u0026#39;RF\u0026#39; , RandomForestClassifier()), # (\u0026#39;ET\u0026#39; , ExtraTreesClassifier()) ] def run_models(x, y, models): num_folds = 10 scoring = \u0026#39;accuracy\u0026#39; results = [] names = [] for name, model in models: kfold = StratifiedKFold(n_splits=num_folds, random_state=2021) cv_results = cross_val_score(model, x, y, cv=kfold, scoring=scoring) results.append(cv_results) names.append(name) msg = \u0026#34;%s: %f(%f)\u0026#34; % (name, cv_results.mean(), cv_results.std()) print(msg) return names, results names, results = run_models(x, y, models) \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Results: LR: 0.356372 (0.070240) SVM: 0.333471 (0.061519) RF: 0.649130 (0.022192) \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; # %% # 分类报告 model = RandomForestClassifier() model.fit(train_x, train_y) pred_test_y = model.predict(test_x) # 获取混淆矩阵 m = confusion_matrix(test_y, pred_test_y) print(\u0026#39;混淆矩阵：\u0026#39;, m, sep=\u0026#39;\\n\u0026#39;) # 获取分类报告 r = classification_report(test_y, pred_test_y) print(\u0026#39;分类报告：\u0026#39;, r, sep=\u0026#39;\\n\u0026#39;) \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Results: 混淆矩阵： [[59 24 12 52] [12 97 0 14] [ 0 0 66 0] [49 28 13 59]] 分类报告： precision recall f1-score support 1 0.49 0.40 0.44 147 2 0.65 0.79 0.71 123 3 0.73 1.00 0.84 66 5 0.47 0.40 0.43 149 accuracy 0.58 485 macro avg 0.58 0.65 0.61 485 weighted avg 0.56 0.58 0.56 485 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; # %% # 尝试模型融合 ensemble.stacking from sklearn.datasets import load_iris from sklearn.svm import LinearSVC from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import StandardScaler from sklearn.pipeline import make_pipeline from sklearn.ensemble import StackingClassifier from sklearn.model_selection import train_test_split estimators = [ (\u0026#39;rf\u0026#39;, RandomForestClassifier(n_estimators=10, random_state=42)), (\u0026#39;SVM\u0026#39; , SVC(probability=True)) ] model = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression() ) model.fit(train_x, train_y) pred_test_y = model.predict(test_x) # 获取混淆矩阵 m = confusion_matrix(test_y, pred_test_y) print(\u0026#39;混淆矩阵：\u0026#39;, m, sep=\u0026#39;\\n\u0026#39;) # 获取分类报告 r = classification_report(test_y, pred_test_y) print(\u0026#39;分类报告：\u0026#39;, r, sep=\u0026#39;\\n\u0026#39;) \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; Results: 混淆矩阵： [[61 22 8 56] [16 93 0 14] [ 0 0 64 2] [61 22 9 57]] 分类报告： precision recall f1-score support 1 0.44 0.41 0.43 147 2 0.68 0.76 0.72 123 3 0.79 0.97 0.87 66 5 0.44 0.38 0.41 149 accuracy 0.57 485 macro avg 0.59 0.63 0.61 485 weighted avg 0.55 0.57 0.56 485 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;   ","description":"","id":37,"section":"posts","tags":["Embedding","Gensim","POIs","Python","城市功能区","札记"],"title":"POI-type Embedding构建流程札记","uri":"https://www.xunhs.cyou/posts/notes/2021-02-24-gensim-embedding%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"},{"content":" 使用ArcGIS Pro栅格切割工具做分块裁剪，并使用切割好的分块做Image Embeddings。记录操作过程及注意事项。\n Raster Split 数据准备  北京市城区栅格数据（From 水经注：Google Maps） 北京市五环矢量数据（研究范围）\n  分块裁剪  生成外包矩形：使用北京市五环矢量数据生成外包矩形\n 掩膜提取：使用外包矩形切割栅格影像\n 分块裁剪\n设置分块大小，自动裁剪影像；格式选择tif格式\n 注意：ArcGIS Pro进行此操作时存在Bug（异常错误（或者已完成，无结果）），在环境变量中设置并行参数为0即可 ArcGIS Pro更新后没有出现该问题\n 生成文件如下：\n    后处理及获取中心坐标  获取中心坐标，便于后续空间关联操作  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  from osgeo import gdal import geopandas as gpd import pandas as pd from pathlib import Path import os from tqdm import tqdm patch_size = 256 split_raster_dir = Path(\u0026#39;/workspace\u0026#39;, \u0026#39;ImagePatchEmbedding\u0026#39;, \u0026#39;SplitingPatch\u0026#39;, \u0026#39;BJR5_256\u0026#39;) all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif_path in tqdm(all_tif): ds = gdal.Open(str(tif_path)) width = ds.RasterXSize height = ds.RasterYSize ds = None if width != patch_size or height != patch_size: # delete path_stem = tif_path.stem path_parent = tif_path.parent _l = [\u0026#39;.tfw\u0026#39;, \u0026#39;.TIF\u0026#39;, \u0026#39;.TIF.aux.xml\u0026#39;, \u0026#39;.TIF.ovr\u0026#39;] for _ in _l: d_fp = Path(path_parent, f\u0026#39;{path_stem}{_}\u0026#39;) os.remove(d_fp) _dict = { \u0026#39;rs_stem\u0026#39;: [], \u0026#39;centralx\u0026#39;: [], \u0026#39;centraly\u0026#39;: [], } all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif_path in tqdm(all_tif): path_stem = tif_path.stem ds = gdal.Open(str(tif_path)) width = ds.RasterXSize height = ds.RasterYSize gt = ds.GetGeoTransform() minx = gt[0] miny = gt[3] + width*gt[4] + height*gt[5] maxx = gt[0] + width*gt[1] + height*gt[2] maxy = gt[3] centralx = (minx + maxx) / 2 centraly = (miny + maxy) / 2 _dict[\u0026#39;rs_stem\u0026#39;].append(path_stem) _dict[\u0026#39;centralx\u0026#39;].append(centralx) _dict[\u0026#39;centraly\u0026#39;].append(centraly) bj_rs_split_df = pd.DataFrame(_dict) bj_rs_split_df.head() bj_arial_image_split_fp = Path(split_raster_dir.parent, \u0026#39;BJR5_256_patch_location.txt\u0026#39;) bj_rs_split_df.to_csv(bj_arial_image_split_fp, header=True, index=False)   导入ArcGIS：\n GeoTiff转rgb（JPG图片）\n使用一些方式（rasterio等）转换为jpg格式后，转换后的jpg图片一片漆黑，参考解释。需进行rgb转换，参考方法：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  # -*- coding: UTF-8 -*- import numpy as np import os from PIL import Image from osgeo import gdal from pathlib import Path from tqdm import tqdm def readTif(imgPath, bandsOrder=[1,2,3]): \u0026#34;\u0026#34;\u0026#34; 读取GEO tif影像的前三个波段值，并按照R.G.B顺序存储到形状为【原长*原宽*3】的数组中 :param imgPath: 图像存储全路径 :param bandsOrder: RGB对应的波段顺序，如高分二号多光谱包含蓝，绿，红，近红外四个波段，RGB对应的波段为3，2，1 :return: R.G.B三维数组 \u0026#34;\u0026#34;\u0026#34; dataset = gdal.Open(imgPath, gdal.GA_ReadOnly) cols = dataset.RasterXSize rows = dataset.RasterYSize data = np.empty([rows, cols, 3], dtype=float) for i in range(3): band = dataset.GetRasterBand(bandsOrder[i]) oneband_data = band.ReadAsArray() data[:, :, i] = oneband_data return data def stretchImg(imgPath, resultPath, lower_percent=0.5, higher_percent=99.5): \u0026#34;\u0026#34;\u0026#34; #将光谱DN值映射至0-255，并保存 :param imgPath: 需要转换的tif影像路径（***.tif） :param resultPath: 转换后的文件存储路径(***.jpg) :param lower_percent: 低值拉伸比率 :param higher_percent: 高值拉伸比率 :return: 无返回参数，直接输出图片 \u0026#34;\u0026#34;\u0026#34; RGB_Array=readTif(imgPath) band_Num = RGB_Array.shape[2] JPG_Array = np.zeros_like(RGB_Array, dtype=np.uint8) for i in range(band_Num): minValue = 0 maxValue = 255 #获取数组RGB_Array某个百分比分位上的值 low_value = np.percentile(RGB_Array[:, :,i], lower_percent) high_value = np.percentile(RGB_Array[:, :,i], higher_percent) temp_value = minValue + (RGB_Array[:, :,i] - low_value) * (maxValue - minValue) / (high_value - low_value) temp_value[temp_value \u0026lt; minValue] = minValue temp_value[temp_value \u0026gt; maxValue] = maxValue JPG_Array[:, :, i] = temp_value outputImg = Image.fromarray(np.uint8(JPG_Array)) outputImg.save(resultPath) def Batch_Convert_tif_to_jpg(imgdir, savedir): #获取文件夹下所有tif文件名称，并存入列表 all_tif = [_ for _ in split_raster_dir.glob(\u0026#39;*.TIF\u0026#39;)] for tif in tqdm(all_tif): stretchImg(str(tif), str(tif.with_suffix(\u0026#39;.jpg\u0026#39;))) print(\u0026#34;完成所有图片转换!\u0026#34;) Batch_Convert_tif_to_jpg(split_raster_dir, split_raster_dir)    删除多余文件  1 2 3 4 5 6  # del extra files, only keep jpg _del = [\u0026#39;.tfw\u0026#39;, \u0026#39;.TIF\u0026#39;, \u0026#39;.TIF.aux.xml\u0026#39;, \u0026#39;.TIF.ovr\u0026#39;] all_jpg = [_ for _ in split_raster_dir.glob(\u0026#39;*.jpg\u0026#39;)] for jpg in tqdm(all_jpg): for _p in _del: os.remove(jpg.with_suffix(_p))   Image Embeddings Image Embedding初衷是使用Embedding的方式对图像进行表示，后续可应用于图片检索等应用。此处参考(https://github.com/rom1504/image_embeddings)实现该功能。在本机配置环境的过程中，faiss这个包始终报错，且网上并无解决方案。故使用Google Calab在线Jupyter Notebook的平台进行操作。\n数据准备  压缩数据并上传至Google 云端硬盘 将作者分享的using_the_lib.ipynb保存至自己的Google云端硬盘 安装repo: !pip install -U image_embeddings 挂在Google云端硬盘 1 2  from google.colab import drive drive.mount(\u0026#39;/content/drive\u0026#39;)    解压：!unzip \u0026quot;/content/drive/MyDrive/DataUploads/ImageEmbeddings/RasterSplitJPG.zip\u0026quot; -d \u0026quot;/content/drive/MyDrive/DataUploads/ImageEmbeddings/\u0026quot; 载入repo及路径： 1 2 3 4 5 6 7  # Let\u0026#39;s define some paths where to save images, tfrecords and embeddings from pathlib import Path import image_embeddings home = Path(\u0026#34;/content/drive/MyDrive/\u0026#34;) path_images = str(Path(home, \u0026#34;DataUploads/ImageEmbeddings/RasterSplitJPG/\u0026#34;)) path_tfrecords = str(Path(home, \u0026#34;Colab Notebooks/ImageEmbeddings/tfrecords\u0026#34;)) path_embeddings = str(Path(home, \u0026#34;Colab Notebooks/ImageEmbeddings/embeddings\u0026#34;))    重命名*.JPG(原作者代码中操作的是*.jpeg格式，JPG可以读取，但是在后续图片显示操作中会提示路径错误) 1 2 3 4 5 6  # rename *.JPG with *,jpeg import os root_path = Path(\u0026#34;/content/drive/MyDrive/DataUploads/ImageEmbeddings/RasterSplitJPG\u0026#34;) for fp in root_path.glob(\u0026#34;*.JPG\u0026#34;): stem = fp.stem os.rename(fp, Path(root_path, f\u0026#34;{stem}.jpeg\u0026#34;))      Build embeddings  Transform image to tf records：Tf record is an efficient format to store image, it\u0026rsquo;s better to use than raw image file for inference 1  image_embeddings.inference.write_tfrecord(image_folder=path_images, output_folder=path_tfrecords, num_shards=10)    Build embeddings：Here, efficientnet is used, but the code is particularly simple, and any other model could be used. The input is tfrecords and the output is embeddings 1 2  # 如出现内存溢出错误，可适当降低batch size image_embeddings.inference.run_inference(tfrecords_folder=path_tfrecords, output_folder=path_embeddings, batch_size=500)      Image Search  Read the embeddings and build an index with it. The knn index is built using faiss which makes it possible to search embeddings in log(N) with lot of options to reduce memory footprint 1 2  [id_to_name, name_to_id, embeddings] = image_embeddings.knn.read_embeddings(path_embeddings) index = image_embeddings.knn.build_index(embeddings)    Search in the index  example 1 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_189\u0026#39;] # 工业区 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 7440 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=7440 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114254.png)  example 2 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_636\u0026#39;] # 绿地 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 5553 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=5553 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114532.png)  example 3 1 2 3 4 5 6 7 8 9  name_to_id[\u0026#39;BJ_5R_AI_1423\u0026#39;] # 居住区 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 3818 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; p=3818 print(id_to_name[p]) image_embeddings.knn.display_picture(path_images, id_to_name[p]) results = image_embeddings.knn.search(index, id_to_name, embeddings[p]) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114703.png)  效果还是蛮好的   Combination of images：Any vector in the same space can be used as query For example I could have 2 image and want to find some example that are closeby to the 2, Let\u0026rsquo;s just average them and see that happens ! 1 2 3 4 5 6 7 8  p1 = 7440 p2 = 5553 image1 = id_to_name[p1] image2 = id_to_name[p2] image_embeddings.knn.display_picture(path_images, image1) image_embeddings.knn.display_picture(path_images, image2) results = image_embeddings.knn.search(index, id_to_name, (embeddings[p1] + embeddings[p2])/2, 7) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228114940.png) 可以检索出混合工业区和绿地的区域  Normalize embedding: We get mostly one of the picture. One thing that can be done to improve this is to normalize the embeddings to get a better mix  Normalize 1 2 3 4 5 6 7  import numpy as np def normalized(a, axis=-1, order=2): l2 = np.atleast_1d(np.linalg.norm(a, order, axis)) l2[l2==0] = 1 return a / np.expand_dims(l2, axis) normalized_embeddings = normalized(embeddings, 1) index_normalized = image_embeddings.knn.build_index(normalized_embeddings)    Normalize Index 1 2 3 4 5 6 7 8  p1 = 7440 p2 = 5553 image1 = id_to_name[p1] image2 = id_to_name[p2] image_embeddings.knn.display_picture(path_images, image1) image_embeddings.knn.display_picture(path_images, image2) results = image_embeddings.knn.search(index_normalized, id_to_name, (normalized_embeddings[p1] + normalized_embeddings[p2])/2, 7) image_embeddings.knn.display_results(path_images, results)    ![](https://cdn.jsdelivr.net/gh/xunhs/image_host@master/PicX/20210228115412.png) 作者说正则化（normalize）embeddings后可以提高混合检索的精度，在一定程度上确实有所提高    Exporting the embeddings to numpy 1 2 3  from image_embeddings.knn import embeddings_to_numpy path_embeddings_numpy = f\u0026#34;{home}/{dataset}/embeddings_numpy\u0026#34; embeddings_to_numpy(path_embeddings, path_embeddings_numpy)      ","description":"","id":38,"section":"posts","tags":["Elasticsearch","POIs","Python","兴趣点"],"title":"POI数据Elasticsearch存储及查询操作札记","uri":"https://www.xunhs.cyou/2021/02/23/368/"},{"content":" Another month in home.\n \n 2021.2.1 重新拾起塞尔达传说：荒野之息。游戏是好游戏，以前没有好好玩~ 2021.2.2 二月春风似剪刀 2021.2.3 ArcGIS Pro异常错误（或者已完成，无结果），可以尝试在环境变量中将并行参数设置为0，例如在分割栅格工具中出现的错误。 2021.2.4 玩游戏玩的头疼、眼睛疼? 2021.2.5 塞尔达确实有很多奇奇怪怪的脑洞、这就是他的好玩之处吧；A:“推荐一个好玩的爬山游戏吧、”B:“塞尔达传说-荒野之息”\u0026hellip; 2021.2.6 铁球开道\u0026hellip;这脑洞真的是服了 哈哈哈 2021.2.7 毛毛回来了 啊哈 今年过年和舅舅家一起过、 2021.2.8 打完飞鸟boss 开完全图 想休息一下了 2021.2.9 CEUS的稿子直接小修了 而且只有一个无关紧要的意见 我挺意外的; 今天难得和老妈出来溜达溜达 2021.2.10 说实话 很感激高老师逐字逐句帮我修改论文 而且大多数仅仅是一些语法问题 很感激老师的耐心 我自己对师弟师妹都做不到这行的细心和耐心 高老师更加严苛 可能年轻老师都这样吧 总之 非常感激 也很期待 2021.2.11 愿新年胜旧年 愿将来胜过往 新年快乐 2021.2.12 愿佳人相伴 多欢喜 长安宁 2021.2.13 开双闪的时候打转向能看见吗 2021.2.14 今天回店里了 2021.2.15 window10 的更新策略真的是 搞了半天没弄好 2021.2.16 凡心所向，素履以往，生如逆旅，一苇以航；去年买的阿里云的域名，竟然卖出去了 哈 2021.2.17 “上次你请我 这次我请你。” “那你要请我什么呢？” “请你务必喜欢我。” 2021.2.18 window10 + wsl2 + nvidia-docker + ml-workspace-gpu终于配置好了 断断续续搞了好久的事情 前几天因为window10更新问题搁置了 今天突发奇想：可以从网上下载21286版本的镜像。遂解决更新问题。后顺利安装nvidia-docker。目前感觉很棒~在此基础上，配置好了ohmyzsh，以及一键配置代理的脚本，window暴露wsl2端口的脚本等issues。感觉很棒~终于在win配置好了~wsl2大法好！ 2021.2.19 flask和vue，快速开发常用应用; 使用Vue3+Vite+Tailwindcss+Pug爽快的开发前端页面 2021.2.20 下了一天的棋 脑壳疼 2021.2.21 返校 2021.2.22 尝试新发型：钢夹烫 2021.2.23 Elasticsearch Search挖了一天坑 2021.2.24 mark一个稠密向量检索工具Faiss-教程；签到脚本入魔了? 2021.2.25 签到脚本优化了下，把js和py的两个签到库整合到一个库。 2021.2.26 元宵节：潮汕牛肉火锅 + 电影《人潮汹涌》+江滩夜景；拿到worldview2数据不知道怎么用 2021.2.27 睡不着 老想着最后一局棋的败招；文章见刊 2021.2.28 学校食堂新开的拌面蛮好吃的  ","description":"","id":40,"section":"posts","tags":null,"title":"2021-2","uri":"https://www.xunhs.cyou/2021/02/02/322/"},{"content":" 大禾象棋视频整理\n 先手 列炮  列炮走，教你弃子攻杀 正谱中炮  仙人指路  对过宫炮: 残棋炮回家，进可攻，退可守 转屏风马 仙人指路飞象局、对卒底炮  后手 顺炮  【象棋顺炮】21回合速胜 对五八炮  卒底炮  卒底炮对抗仙人指路：演变为顺炮对五六炮  正着-屏风马  对过宫炮 对顺跑  ","description":"","id":43,"section":"posts","tags":null,"title":"大禾象棋-札记","uri":"https://www.xunhs.cyou/2021/01/21/295/"},{"content":" New year.\n \n 2021.1.1 GEE遥感大数据分析平台: GEE入门[3] | 相关学习网站；Macbook Pro到了 配好了日常环境 早买早享受~ 2021.1.2 海底捞 + 拆弹专家2 2021.1.3 年终总结组会；畅快的聚餐，好久没有喝这么多了 2021.1.4 何去何从 2021.1.5 博士论文想写好真的好难啊?? 2021.1.6 不是吧 阿sir 2021.1.7 神经病? 有些人就很气 2021.1.8 同一个星球 同一段时光 是我的荣幸～ 谢谢你们的礼物 2021.1.9 Mark一下，Mac生态做的很??。随航功能一键联动Pad和Mac 爱了爱了 2021.1.10 象棋布局 实操很难啊 2021.1.11 晚上出发 即刻回家 2021.1.12 在家第一天 2021.1.13 吃了睡 睡了吃? 2021.1.14 闹腾\u0026hellip;过去的事为什么要挖出来 2021.1.15 双马饮泉 2021.1.16 中国机长 2021.1.17 纸短情长 2021.1.18 当时只道是寻常 2021.1.19 不要想太多，放手去做~不做永远不会有结果 2021.1.20 寻找问题 解决问题? 2021.1.21 21世纪，第21年的第21天，在第21时想见你。 2021.1.22 想改派。去哪里呀。人啊 为什么总是纠结的个体 2021.1.23 五月雨让一整个下午都变得伤感 2021.1.24 Mark一下，VR游戏-节奏光剑 2021.1.25 长颈鹿是一头因为好奇而伸长脖子的马 衣服上有很多扣子是因为它想当钢琴 河流总在给大海写一封很长的信 奇妙事物属于眼睛 - 长颈鹿去动物园看长颈鹿 2021.1.26 我曾觉得只要努力就一定会得到想要的，可是你看看，你若是喜欢花，就把它掐下来放在瓶子里养着；你要是喜欢树，也可以把它挖出来栽进自家院子去；但有的东西不行。不行就是不行。- 夜听·地大|Rolling days 2021.1.27 按照教程成功配置了一个DNF70版本单机的台服游戏，上手简单玩了玩、对于这个游戏，算是一种情结吧、从高中到大学，承载的太多。还记得高中的时候，走在路上模仿游戏里技能的动作，想起来就傻乎乎的、第一次通宵去打游戏，与当时的朋友一见面就聊游戏、回家后挤时间刷会图。。。现在都时常去关注这个游戏。 2021.1.28 每天都在刮胡子和懒得刮胡子之间犹豫不决 2021.1.29 what should love be 2021.1.30 保持热情 奔赴山海 2021.1.31 类别不平衡分类问题一月，休息结束~  ","description":"","id":44,"section":"posts","tags":null,"title":"2021-1","uri":"https://www.xunhs.cyou/posts/journals/2021-01-01-2021-1/"},{"content":" 阅读深圳大学乐阳老师公众号（乐知半点）-专题“城市分析-概念辨析”札记。\n 识别城市地域-概念篇  如何定义“城市”是开展城市研究的一个起点性基础问题，现有研究：  吴志强院士团队  链接 总结城镇群发展的时空规律 根据遥感影像识别全球上万个城市40年城市建成区的空间变化   清华大学地学系(宫鹏)  链接 以可持续发展为目标 基于遥感数据提取了多时相人造不透水层提取全球城市边界（urban boundary）   北京城市实验室（BCL）  链接 以定义中国城市体系为目标 利用POI数据识别城市形态(urban form) 利用滴滴乘车记录、公交线路和人口密度等识别全国城市功能性城市区域（Functional Urban Area） 利用道路交叉口密度结合POI和点评数据等识别中国城市2009-2014年的变化     在城市地理学中，一般从行政地域、实体地域以及功能地域三个维度定义城市：  行政地域（city）就是法律规定的行政区划范围。使用行政地域区分城乡的主要问题是较难准确描述城市化进程，因为很多行政区划除了城市市区，还包括辖县等城市化程度不高的区域。 **实地地域（urbanized area）**一般理解为城市建成区（built-up area），是城市设施的集中地，又称景观地域。 **功能地域（metropolitan area）**是一日通勤、休闲等活动紧密联系的区域，通常是对实地地域核心区域的拓展。    识别城市实体地域  在实际情况中，城市的实体地域很少和行政辖区完全一致；针对城市的研究，更多是针对城市的实体地域，而非行政地域。所以，准确识别城市实体地域成为一个问题。 经典方法/手段-利用遥感影像数据识别不透水层（impervious surface）  不透水层一般指建筑物、道路等阻止水渗入土壤的地表覆盖物，不透水层也与城市热岛效应直接相关，因此是建成区一个比较直观的表征。 可识别不透水层的遥感数据主要包括光学影像，如MODIS,、Landsat、QuickBird和DMSP-OLS夜间灯光数据，以及雷达数据、LiDAR等。   利用遥感数据难以识别“鬼城”（人类活动不显著的地域）=\u0026gt; 人类活动数据成为近年识别城市建成区的一个主要数据源，如POI数据、手机位置数据、水电数据等。  识别城市功能地域  如果识别出的区域超过了一个城市的行政边界，涉及两个或更多的地区，这样的区域则可以被称为（大）都市区（Metropolitan Area或Metropolitan District）、都市连绵区（Metropolitan Interlocking Region）或都市带（Megalopolis）等。而连绵成片的城市实体地域如果与周边地区有日常通勤等较紧密的联系，那么这个大的区域在国际上常被认为是一个有意义的经济统计单元，即“城市功能地域”(FUA, Functional Urban Area) 。 FUA  为了便于统计和进行基础设施、交通、住房、教育等事务间的协调管理 简单讲，指一日活动，尤其是通勤，所覆盖的范围 经合组织：densely populated municipalities (urban cores) and adjacent municipalities with high levels of commuting towards the densely populated urban cores (hinterland) 与城市群的区别 城市实体地域而言，城市功能地域是一个更准确和完整的经济单元，所以也有从经济单元的角度定义FUA：Functional urban areas are economic units characterised by a city (or core) and a commuting zone that is functionally interconnected to the city 有助于理解城市发展模式   识别方法  城市实体地域和城市功能地域都是以人为中心而定义的，因此，如果有人类活动相关的数据则可以代替遥感和建筑物这类相对间接的数据，结果可以更准确。识别城市功能地域，除了行政边界数据外，按国际现行标准还需要人口和通勤这两类数据。 OECD已提供识别城市功能区的算法流程。    关于“城市功能分区”  “城市功能分区”（urban functional zones/ regions）  相对于“山水林田湖草”各类非建设用地，城市用地类型通常指居住用地、工业用地、商业用地等，是城市规划中一个非常重要的命题。 城市建设用地按功能可分为居住用地、工业用地、公共管理与公共服务设施用地、绿地与广场用地、交通用地等，包括“留白用地”共9大类（2020年8月20日自然资源部国土空间规划局发布的《市级国土空间总体规划编制指南（试行）》（征求意见稿）》） 遥感领域对土地利用和覆盖变化（LUCC, Land-Useand Land-CoverChanges）已经有几十年的基础，其基本原理是根据不同地物的波谱特征建立判别函数，获得图像中每个像元对应的地物类型。   柯布西耶-光辉城市 分析土地混合利用或均质性是研究社区（比如15分钟生活圈）和城市的合理结构和布局（size, scale）(Batty, 2008) 等问题的核心。  城市空间结构  城市研究的一个核心关注点是城市形态和社会过程之间的相互关系。城市空间结构主要指城市要素的空间分布和相互作用的内在机制，其研究框架和内容体系可从三个层面展开  形式研究：分析城市各要素的空间分布格局和相互作用关系 过程研究：分析城市空间结构的动态变化特征与规律，如西方的“郊区化”、“多核心”等空间结构的演变规律 机制研究：解释城市形态和城市内部要素空间分布的变化原因以及这些要素之间相互作用的内在机制，如可达性、集聚机制、资本的作用等   城市空间结构的形成和演化建立在社会过程的空间属性基础上，涉及到城市社会空间（urban social space）层面的问题，不是单纯的物质空间土地利用和功能分区问题。  同心圆模型（concentric zone model）、扇形模式（Sector model）和多核心模式（Multiple nuclei model）   哈佛大学经济系开设的（网红）新课-Using Big Data Solve Economic and Social Problems：https://opportunityinsights.org/course/ 物质空间、社会空间、意向空间（人们对周围环境的直接或间接经验认识的主观空间）  ","description":"","id":45,"section":"posts","tags":["城市功能区","学习笔记","阅读笔记"],"title":"识别城市地域-札记","uri":"https://www.xunhs.cyou/2020/12/30/243/"},{"content":" 城市混合土地利用文献阅读。\n 2019-用地混合使用的国际经验 ：模式、测度方法和效果  清华大学中国新型城镇化研究院开放基金项目 国际城市规划 http://tucsu.tsinghua.edu.cn/info/research_kfkt/3322  摘要  对用地混合使用模式、测度方法和效果的探讨相对缺乏 梳理国外用地混合使用的概念内涵、类型、测度方法和效果实证  引言  多样化功能的有机混合可以增加区域吸引力和活力， 创造成功的社区 国家城市空间发展形势：增量规划=\u0026gt;存量规划 然而，我国相关研究主要侧重于规划实践中对于用地混合使用的政策引导， 对用地混合使用模式、 测度方法和效果的探讨相对缺乏。 本文介绍用地混合使用的实践和研究进展  用地混合使用的内涵和模式  用地混合使用定义 概念定义的模糊性  用地功能的内涵不统一 用地混合的空间条件难以界定 用地混合的空间尺度和类型较为丰富    概念内涵  关于用地功能的分类：多样，国际标准，国内标准 功能联系：多层次  同一类用地功能用途多样性的混合，例如不同住房形式或不同使用权的混合 相兼容用地功能的混合， 如居住与商业功能的混合 不相兼容用地功能的混合    用地混合的空间条件  用地混合使用本质上是城市功能组织的一种形式，强调功能的集聚和协同， 需要与城市空间结构相互作用 美国城市土地学会：用地混合使用在空间上和功能上需整合形成高密度、 高强度的土地利用模式， 同时包含连续的步行通道 保障用地混合使用的重要空间条件：肌理（grain）、 密度（density）、 渗透性（permeability） 和交织（interweaving）  肌理是指街区的规模和划分形式， 强调用地功能的尺度 密度也与用地混合使用有着密不可分的关系， 因为用地混合使用需要一定的功能和人口密度 渗透性指步行穿过区域可选择的通道数量， 即步行可达性， 较大的步行穿越可能性有利于促进不同功能之间的联系， 鼓励人们采用慢行交通 交织即一定范围内功能的分散程度    用地混合的类型和空间尺度  用地混合使用类型：共享式混合、 水平方向上的混合、垂直方向上的混合和时间维度的混合等不同类型 用地混合使用尺度：建筑尺度、栅格单元、 街区尺度、 调查小区 和城市局部区域等不同空间尺度 街区是由建筑群体和公共空间共同组成的， 是用地混合使用的核心研究尺度  测度方法  定量化测度混合程度 熵值法（entropy）  最常用 熵值法并非严格测量我们认知的混合程度， 它不考虑混合成分的数量， 只测度混合成分的占比是否均衡 熵值法不考虑不同组成成分和不同混合方式的不同影响 用地功能种类的选取和测量区域的面积都会显著影响熵值的计算   分异度指数  通过测度一个栅格内用地功能与周边 8 个栅格用地功能分布的相似程度， 反映该栅格的混合程度。 相比熵值法， 分异度指数可以测度更精细尺度的用地混合使用程度， 强调用地功能组合的差异性而非均衡性。 缺陷 ： 一方面其也不考虑不同混合功能和不同混合方式的不同影响 ； 另一方面测算结果受栅格划分的影响较大， 不能反映研究区域与周边区域功能组成相同的混合   基于目的地的用地混合使用测度法  测量研究区域（ 主要是居住地） 到各功能的最近距离， 或一定范围内各功能的密度或数量， 反映研究区域的混合程度。 人们慢行交通出行意愿，有助于分析用地混合使用对于交通出行的影响效用 只考虑某个特殊功能又难以反映混合程度   代用指标法（proxies）  不是基于用地功能的数量， 而是通过测算某些被认为与用地混合使用具有显著联系的指标来反映混合程度 例如职住比、 住房的年龄、 地块的大小、 慢行交通通勤的占比等 它们并不是混合程度的直接反映   其他指标：功能占比、 平衡指数（balance index）、 赫芬达尔 - 赫希曼指数（Herfindahl-Hirschman index）、 阿特金森指数（Atkinson index）、 基尼系数（Gini index） 和混合指数（mixed-use index） 等方法 特定条件下最适宜的用地混合使用测度方法  用地混合的效果验证  用地混合使用将不同功能聚集在一起，可在较小的范围内满足人们的不同需求， 增加了区域多样性的同时减少了出行距离 随着区域多样性的增加， 用地混合使用满足了人们不同时间的不同需求， 既增加了区域吸引力又增加了区域活力， 最终营造了安全而又具有经济活力的区域  对慢行交通出行的促进  用地混合使用缩短了机动车出行距离和出行时间 用地混合使用可以促进使用慢行交通进行娱乐休闲等活动的出行频率， 增加公共交通的使用时间，但距离是一个较为重要的因素 用地混合使用可以提高慢行交通的分担率 实证研究证明了用地混合使用对于慢行交通出行具有积极作用  对居民健康活动的促进  用地混合使用对于体育活动有积极作用， 可以增加活动时间和运动量 减轻空气污染， 可以降低氮氧化物、 挥发性有机化合物等有害气体的排放 等等  对城市安全性的提高  用地混合使用与城市安全关系 缺乏高质量的实证研究  其他效果  关于城市活力  将商店、 餐饮等设施与居住、 工作等产生大量人流的主要用地功能混合， 可以营造不同时间段具有稳定人流的社区 由于数据所限， 高密度和混合功能对城市活力的影响很难被实证   关于经济活动  人们愿意为用地混合使用区域的住宅负担更多的费用， 与公园和商业用地功能混合可以显著提高房价   ","description":"","id":46,"section":"posts","tags":["城市功能区","混合土地利用","论文阅读","阅读笔记"],"title":"Papers Reading: Urban Mixed Land Use","uri":"https://www.xunhs.cyou/2020/12/18/128/"},{"content":"  \n 2020.12.1 入手steam第一款游戏——城市天际线。打折后还是蛮便宜 2020.12.2 从现在开始建造一个社畜养殖圈 2020.12.3 论文见刊啦；一食堂三楼的烧烤蛮好吃的呀 2020.12.4 Be the type of person you want to meet. 2020.12.5 为什么爱情里面，总要有人受伤、 2020.12.6 遇到贵人先立业，遇到良人先成家，遇到富婆成家立业? 2020.12.7 中百罗森的虾仁味饭团很好吃呀、我都想自己做小饭团;和弦图绘制-Chord diagram with Bokeh;看别人论文里面的方法的最大感触是：我去，还可以这样玩？ 2020.12.8 每次穿这条灯芯绒的裤子，仿佛都在提醒我腰真的很宽;5km+1🏃 2020.12.9 花园的纯牛奶好喝呀 2020.12.10 看到Reviewer的意见之后就也很平静了啊。 2020.12.11 玉置浩二“专辑” 2020.12.12 Recording. 2020.12.13 妖风与初雪相遇 2020.12.14 来到北京，没有想象中冷、仍是那么陌生。 2020.12.15 匆匆从北京回到武汉，明明可以多留一天第二天再走，而且晚上回学校也不方面，但是仍要离开。不晓得为何以前那么喜欢出差，喜欢各处跑的自己，现在如此不愿留在这里。 2020.12.16 不只是上火，还有各种火气、easy easy！😩 2020.12.17 买了一个ucloud服务器，三年的，配了一个域名，我又迁到wordpress啦。正在做迁移工作、 2020.12.18 嗯 一点都不紧张 就连名字都没介绍 2020.12.19 没那么在乎 是不紧张的最好办法吧 2020.12.20 岂曰无衣？与子同袍。王于兴师，修我戈矛。与子同仇。- 《大秦赋》；Mark一下，可视化方案及实现，可以放在论文里面(https://github.com/CNFeffery/FefferyViz)。 2020.12.21 人们总是希望寻求他人的理解，却从来不会主动换位思考，理解他人、不对，不是其他人，是你。 2020.12.22 心安理得 2020.12.23 忍别离 不忍却又别离；ceus大修提交。 2020.12.24 PrettyErrors =\u0026gt; 使Python报错信息更加可读；最终博客方案：WordPress(Theme: Argon) + Ucloud云服务器 + namesilo购买域名（国内域名要备案，可惜了我花了将近100块买的两个域名） 2020.12.25 想开启个wsl2支持Docker的最新版本，感慨Window 10的设置真是“sao”，一环扣着一环。 2020.12.26 团队工作总结 2020.12.27 西装革领  ","description":"","id":48,"section":"posts","tags":null,"title":"2020-12","uri":"https://www.xunhs.cyou/posts/journals/2020-12-01-2020-12/"},{"content":" 原文来源：相机操作入门指南(索尼篇)。本文为阅读原文指南札记。\n 目录 摄影基础知识 摄影的核心—曝光  曝光：通俗的理解为：“相机每一次照片的拍摄就是一次让光线涌入相机，并进行记录的过程” 三个要素：光圈、快门速度、感光值ISO 基础模型 光圈  盒子上的孔径大小可以改变，而光圈就是开孔孔径的控制 孔径越大，进光量越大，画面越亮：孔径越小，进光量越小，画面越暗 对应到数值上就是1.2 1.4 1.8 2.8 5.6 甚至到64等，数值越大意味着光圈越小 光圈对于画面除了明暗的影响，还有一个非常重要的作用：控制景深。也就是我们常见的虚化程度 详解参考：了解光圈 这一篇就够了\n   快门速度  盒子中纸片这个小孔本来是被盖住的，但是当你使用的时候，小孔前面的盖子是会打开。而，打开的时间长短也就是快门速度 打开的时间越久，进来的光就越多，画面就会越亮。打开的时间越短，进来的光越少，画面越暗。 快门的速度范围一般都是从1/8000到30秒 除了画面的明暗，快门速度还对画面有另一个影响：快门速度越快意味着能够凝固短暂的瞬间，快门速度越慢意味着会记录下物体运动的轨迹   感光值ISO  描述盒子里那个记录光的神奇纸片对光的敏感程度 量化到数值，一般都是100，200，400，甚至到6400或更高。 数值越高，也就意味着对光越敏感，反映到这一张照片就是其他参数相同的时候，感光值越高画面越亮。 感光值越高画面的质量会下降，噪点增多所以，在光线充足情况下感光值越低越好   总述：除了控制亮度，这些参数还有着一个对画面内容产生重要影响的因素，例如光圈的景深，快门的画面捕捉瞬间长短等。所以，不能一味的提高某一个数值，要按照不同的拍摄主题，进行不同的调节和相互制约。 夜晚拍照，照片很容易模糊，而且画质很差：夜晚由于光线不足，相机为了获得更多的光线，要让快门速度更长，这样你只要有一定的晃动，画面就会模糊。与此同时，相机还要提高ISO值，提高对光的敏感程度，于是就会出现噪点导致画质下降。 安全快门  相机的曝光—测光  引子  在以前，相机最开始的时候，一切都是手动的。当我们看到一个场景的时候，摄影师需要通过各种方式，判断出画面所需要的曝光量，然后设置好参数。 数码时代最大的便利就是相机可以很快的计算出一个当前画面所需要的曝光量，但是，这曝光量里三个数值的关系如何是需要我们自己进行调节的 问题：相机是如何进行测光的？世间万物亮度不同，他是怎么选择参考的？ 标杆/参考值  18%灰 相机会按照画面中所有物体反射的光线，计算一个加权平均值 加权计算方式 测光点 常见问题  拍摄大逆光的时候，例如夕阳，人物往往都是曝光不足的是为什么  由于夕阳太亮了，导致它在刚才的计算权重算式中占据了上风，于是相机就按照他来进行曝光。因此，人物就不足了。 那如何解决呢，这个时候我们就可以通过降低夕阳的权重，使用点测光，让测光点（一般是画面中心）对在人物身上，增加人物在测光中的权重，这个时候就可以让人物亮起来。   为什么在雪地里，我们拍摄人物照片的时候，人物肤色往往比较灰暗  画面中大部分雪，而雪是最亮的，所以亮占据了主导，最终曝光画面也就变得灰暗。   曝光补偿        相机的对焦  景深  假设我们的照片是二维坐标的XY，所以当我们看到一张画面中有清晰，有模糊的时候我们会觉得，清晰和模糊是在XY中进行选择。但其实，照片清晰和模糊的范围是在Z轴上进行选择 景深是一个清晰的范围，这个清晰范围越短，我们就叫浅景深，那么背景的模糊（也就是虚化）越明显。那么这样回答了，为什么大光圈拍人像，会有背景虚化？因为，光圈越大，景深也就越浅，也就是越容易虚化。   影响景深范围（即L的长短）有哪些因素呢  光圈，光圈越大，景深越小；光圈越小，景深越大。 焦距，焦距越长，景深越小；焦距越短，景深越大。这也为是为什么85mm，70-200mm等焦距适合人像的原因，因为虚化好。这也是为什么，手机不能虚化的原因，因为手机的等效焦距是20mm以下。（双镜头的虚化是算法，不是光学） 对焦距离，在其他条件相同情况下，对焦越近，景深越小。 相机画幅，画幅越大，景深越小。这也是为什么，全画幅好于残幅的一个原因。 如何能够在拍摄人像的时候更好的虚化？=\u0026gt; 使用尽可能的大光圈，使用尽可能长的焦距，尽可能的走近模特，以及使用全画幅相机   如何控制这个清晰范围？也就是，如果进行清晰和模糊的调整？  相机圈定对焦区域的方式 我们可以圈定一个范围，这个范围有面积的大小，例如是一个点，还是一个区域还是全局（广域） 这些区域可以进行移动，例如点可以在画面中间，也可以在画面边缘。区域可以在画面中间，也可以在画面边缘。 对于所有相机，并不是在任何地方都可以对焦的。这也是在相机购买中，对焦点参数的意义。 并不是你选择的某一个区域，这个区域是清晰的，区域外是模糊的。而只是相机在区域内进行选择主体，只要是你选择区域里主体焦平面上的，都会清晰的。   对焦方式主要是针对动态，静态，以及极限环境下的手动对焦  针对初学者，我直接给出使用建议。单点自动对焦，例如拍摄“听话”的人，这个很重要哈，这个听话是可以听摄影师指挥，保持不动的。我们使用“AF-S”，也就自动单点锁定对焦，选定一个对焦后，移动相机对焦点不更改。 先对焦，再构图：具体操作为，使用单点中间对焦，半按快门锁定对焦，再移动相机（平行于焦平面，也就是左右移动，不要前后移动）进行构图，再按下快门进行拍摄。 针对运动物体，以及“不听话”的人，或者你不能指挥的人（活动，婚礼），建议使用连续自动对焦，也就是AF-C。这个对焦方式，是说相机会跟随画面中移动的主体进行移动，然后进行拍摄。 那么针对一些极限环境，例如对焦精度要求极高，以及弱光环境，我们就需要手动对焦。手动对焦的方式是，首先选择到相机的手动对焦，然后选择你想要的对焦区域，再通过显示屏放大画面（索尼相机可以设置自动放大），然后转动镜头调焦环，直到清晰。如果是，拍摄极限风景，如夜景星空，只要拧到无穷远处，稍微回一点（经验），即可。    相机的白平衡  白平衡的调节就是调节画面的冷暖调，最重要的影响就是色彩的发色。 你只要知道他们的递进关系，或者拍摄时挨个尝试找到自己喜欢的就好了。 索尼黄  总结  在拍摄一张照片的时候，人和相机都是怎么工作的：首先，摄影师对焦在物体上，然后半按快门，这个时候相机进行对焦和测光，完成后相机会提示，通过提示音或者画面上提示光点。接下来，平行画面移动构图（幅度不要大，不要前后移动），然后不要松手完全按下快门，拍摄结束。拍摄过程中，尤其是快门速度不快时要保持稳定。  机身和电池 电池  购买两块电池。购买可以有两个选择，一个是原厂的电池，另一个是副厂，例如品胜等 购买电池座充，一方面提高充电效率，另一方面直连相机充电有各种顾虑。  显示器和取景器  取景器  刷新频率 屈光度   显示器  机身CMOS  相当于传统相机的胶片 微单相机卸下镜头时，CMOS是直接裸露在外面的。 更换镜头过程中，CMOS很容易进灰，会在照片上留下脏点。 更换镜头要迅速，更换过程中要CMOS向下。  不要在室外更换镜头 不要在潮湿环境更换 在室内外温差大的时候，千万不要轻易取出相机。例如从寒冷屋内，到温暖室内，立刻取出相机，由于相机温度低，空气中的水遇冷凝结，会对镜头和机身产生非常严重的损坏！一定要先在相机包内放置一段时间，温度稳定时再取出。   清洁  不要使用任何物品擦拭，一定会造成不可逆的损伤。 使用气吹（可通过淘吧购买相机清洗套装获得），轻轻的吹走即可。千万不要用嘴吹！    相机的镜头  **mm：焦距 F**：光圈是指这个镜头的最大光圈 镜头分类 镜头其实对于拍摄的内容有着非常关键的作用 对于镜头而言，什么都能拍，就意味着什么都不能拍好 说好镜头加差机身好于好机身加差镜头 相机和镜头的组合是要看卡口的，也就是说是要配对的。全画幅的镜头可以给残幅，但是残幅基本上不可以给全画幅用 镜头的保养  UV镜值不值得买。如果你的镜头很贵，四五千以上的，买一个保护很有必要，而且几十几百的都不行，要买顶级的。要是几百几千的镜头，就算了，没必要，自己注意就好了 使用气吹清洁。使用气吹吹灰尘，不要用嘴吹在这里一样适用。更多的清洁防范 可以使用纯棉，划重点，一定是纯棉的擦拭镜头的水分污渍等。千万不要使用纸巾！因为会刮花镜头的涂层。    相机的存储  SD卡  容量：基本上16GB足够，32G够好，64顶配 速度：Class 10以上   RAW与JPEG：  RAW优势：更大的后期空间；无损调节；更利于前期拍摄 RAW格式适用于你希望真正意义上的进行摄影创作，而不是简单的社交分享，比如吃个饭发朋友圈，对于不精通后期，只是分享生活的JPG足够。    相机的指挥中心—模式转盘  模式转盘：决定相机在拍摄中的操作逻辑  M A S P是指挥曝光  M：手动模式，所有参数分别由自己调节。默认情况下，滚轮调节光圈，转动拨轮调节快门速度，按右键转动拨动调节感光值。 P：全自动模式，全听相机的，三个参数都是相机定。可以通过，转动拨轮增加和减少曝光。 A：光圈优先模式，自己决定光圈，其他相机决定。调节滚轮调节光圈大小，转动拨轮调节曝光补偿。 S：快门优先模式，自己决定快门速度，其他相机决定。调节滚轮调节快门速度，转动拨轮调节曝光补偿。 一长条是全景模式 SCN是场景模式，会针对不同情况进行参数调节。例如人像模式会使用最大光圈，风景就使用小光圈，夜景就尽可能保证快门素等。其实看起来很智能，但是说实话不实用 P挡不推荐使用，M档高手进阶使用。A档最为常用，S档想要拍摄特定场景可以使用，例如就是想希望告诉相机快门高速或者慢速快门实现特殊的拍摄效果。一个A一个S足够大家使用。 绝大多数，相机的自动测光已经满足我们的实际场景，稍微的明暗都可以后期调节，而且拍摄发现不满意，也可以通过调节曝光补偿的方式进行快速纠正。所以使用A档，配合曝光补偿，就已经满足绝大多数的拍摄需求。      索尼相机按键  AF/MF和AEL拨杆：自动对焦/手动对焦快捷切换。将拨杆调整在AF/MF上，然后按住拨杆中间的按键，就可以手动调焦。相反的，如果你目前是手动对焦模式，这个时候按住按键就可以切换为自动对焦。 AEL：曝光锁定。当你拍摄某一场景的照片的时候，找到合适的曝光组合以后，按住拨杆中间的按键，这个时候，相机的曝光值就会保持不变。 Fn 拨盘  上键DISP是调整不同的显示界面，每种界面都包含不同的信息内容侧重点。 左键是拍摄方式，拍摄分三个类型，每一种类型以及使用经验  单张拍摄，最常见的拍摄方式，按一次快门拍摄一张。 连拍，拍摄运动物体和抓拍最常用的，按一次快门拍很多张。连拍速度分为几个档次，分别是Hi高速，Mid中速以及Lo低速连拍。 定时拍摄，按下快门后等一段时间进行拍摄。可以时间为2s 10s等，用于自拍或者是避免按快门造成的机身抖动（在慢速快门时使用）   右键是ISO调节 按键下，是曝光补偿调整，但是曝光补偿调节其实在拍摄界面直接左右转动也可以完成。   C1和C2自定义功能键  对焦操作的流畅，因此我的C1设置为对焦区域，C2设置为对焦方式。这样我就可以快速调整我的相机对焦    索尼相机菜单功能 索尼相机视频功能 ","description":"","id":49,"section":"posts","tags":["相机","索尼"],"title":"相机操作入门指南-索尼","uri":"https://www.xunhs.cyou/2020/11/30/108/"},{"content":" 续 博士论文阅读札记-2\n  区域尺度城市土地遥感监测关键技术研究 轨迹数据挖掘关键技术研究 基于地理场景的城市功能区建模与分析方法研究  区域尺度城市土地遥感监测关键技术研究 王润-2018-中国地质大学（武汉）\n摘要  背景：  城市➡️城市化➡️城市建设用地不断增加 ➡️ 城市的扩张 造成问题：  改变局部地区的土地覆被构成 影响区域乃至全球的生态系统   意义：我国的城市化率还在持续增长中，及时、准确地掌握城市土地利用变化能够防范与遏制城市盲目扩张，为宏观决策制定提供科学依据   城市土地监测及其相关研究  逐渐从针对单个城市的分析转向区域和更宏观尺度的探讨 利用遥感技术开展区域城市土地监测 国内外学者取得了丰硕的研究成果，但在区域尺度下仍存在一些问题  在数据方面，低空间分辨率遥感数据中存在大量的混合像元，城市像元的“同物异谱”和“异物同谱”现象易导致城市土地的低估或高估情况 ➡️ 如何在区域尺度下发挥各种遥感数据的优势还需进一步研究。 在方法方面，区域尺度的城市制图是典型的不平衡分类问题，非城市像元数量远大于城市像元数量。➡️ 还需从方法入手，发展针对于特定类别的城市提取方法，在少量样本的前提下获取准确的城市区域。     针对现有区域尺度城市土地遥感监测中存在的问题，本文:  研究对象：区域尺度下的“城市” 数据支撑：三类常用的区域尺度城市土地遥感监测数据（夜间灯光影像 DMSP/OLS NTL 与 NPP-VIIRS DNB，MODIS 数据产品 MOD09A1 与MOD13A1，以及包含城市类别的全球土地覆被数据集 MCD12Q1 与 GlobeLand30） 针对单目标的方法：即基于知识驱动的指数模型法与基于数据驱动的一类分类法   主要研究内容与结论：  在数据方面，本文分析了三种遥感数据的数据结构与数据质量，并给出了原始数据的处理策略  夜间灯光数据 NPP-VIIRS DNB 去噪与极大值过滤，MOD09A1 影像筛选与质量控制，MOD13A1 NDVI 最大值合成以及基于 GLC30-2010 人造地表类型的城市区域提取 结果表明：数据的结合准确性高；贡献程度更高；更好的微光探测能力   基于知识驱动的指数模型法  居民地指数 LHSI 实验结果表明：更有效；准确性高；更丰富的城市内部细节信息   基于数据驱动的一类分类法  一类分类方法 PUL 实验结果表明：准确度更高；更清晰的城市边界；鲁棒性   2012 年中国大陆城市区域专题图  本文结果与地表情况更接近，准确性更高。 验证试验表明：在像素级别；在城市级别上     技术路线：  轨迹数据挖掘关键技术研究 吴睿智-2020-电子科技大学\n摘要  背景：定位技术与位置社交网络高速发展➡️轨迹数据呈爆炸式增长 意义：  移动对象的时空特征和移动行为信息 挖掘海量轨迹数据背后所蕴藏的丰富信息，既有理论研究价值也是紧迫的现实需求 未来城市服务的主要研究方向，广泛应用   轨迹数据挖掘在实际应用场景中仍面临一些问题  由于轨迹数据语义缺失，人们无法理解轨迹数据中隐含的语义特征 轨迹点序列式的表征方式无法适应于广泛的数据挖掘模型 现有的位置预测模型的预测精度较低   关键技术: 轨迹语义推断、轨迹表征学习、位置预测性能提升 主要内容+研究成果  针对轨迹语义缺失的问题，论文提出一种基于图卷积神经网络的位置语义推断模型 (SI­-GCN)  利用网络表征学习算法和变分自编码器分别学习位置的空间向量表征和时间向量表征，构成位置的时空特征 用户-位置访问二部图 图卷积神经网络学习 引入自注意力机制 结果表明：SI-GCN 的语义推断性能优于现有方法   针对轨迹表征困难的问题，论文提出融合时空结构的轨迹数据表征学习算法 (STAR)  传统轨迹点序列表征方式割裂轨迹数据的时空耦合关系（❓），且不适应于广泛的数据挖掘模型 STAR 建立统一框架学习（❓）轨迹中的空间和时间信息：地理上下文、轨迹上下文、语义上下文 利用自适应霍克斯过程建模用户出行时间信息（下一个访问位置和时间） 结果表明：STAR 在相似性检索、相似度度量、异常检测等数据挖掘任务优于现有方法   针对个人出行数据随机性高、数据稀疏，导致现有位置预测模型精度较低的问题，论文提出基于偏好社交互动的位置预测算法 (PSI)  群组出行模式 度量用户轨迹相似度构建用户群组 利用关联规则挖掘算法提取群组出行模式 建立个人偏好模型 通过岭回归学习个人偏好与群组出行模式对位置预测的贡献，预测用户出行位置 结果表明：与现有方法相比，位置预测性能优于现有预测算法   针对用户签到行为的成因与动态机制缺乏深入研究的问题（👍），论文提出地理感知的用户行为动态模型 (DGPS)  用户签到行为的动态机制（❓） 地理感知的位置特征（包括语义特征、潜在特征和动态特征）➡️ 学习用户个人偏好 用户行为的强度函数 同时预测用户签到活动的位置与时间 结果表明：多个真实数据集上的实验结果表明 DGPS 预测性能优于现有方法     技术路线：  绪论 研究工作的背景与意义  轨迹数据  GPS 轨迹数据  交通工具产生的轨迹，飞机、船舶、汽车上配备 GPS 设备 人类活动轨迹，智能手环、穿戴设备、智能手机的健康应用程序会记录用户的位置信息 自然界其他移动对象轨迹，如动物迁徙数据，飓风的移动数据   签到 (check­in) 轨迹数据  基于位置服务的社交网络 (Location­Based Social Networks, LBSNs) 应用如 Foursquare、Gowalla、微博、微信等移动社交网络 智能设备到达不同位置时接入网络设备的位置信息（Wi­Fi，通信基站）   这些移动对象由于空间位置移动而产生的移动数据，按照时间先后顺序构成的数据都属于轨迹数据   轨迹数据挖掘意义  轨迹数据挖掘是数据挖掘的一个新兴分支，拓展了传统数据挖掘的研究方法和应用领域，成为当前研究热点  KDD、ICDE、ICDM 等国际知名学术会议 TKDE、TKDD、TIST 等国际学术杂志   研究轨迹数据挖掘相关技术也具有广泛的应用价值  对人类轨迹数据的挖掘：更好的理解人类行为动力学特征；有利于探索理解人类社会活动特性 对城市交通的轨迹数据的挖掘 对船舶、飞机的轨迹数据挖掘 从动物迁徙数据分析动物迁徙规律 从飓风的移动数据分析出飓风的形成位置和移动规律，提前预警气象灾害   城市计算、智慧城市等城市未来发展研究，核心均是群体感知与移动位置的感知计算   现有工作：轨迹预处理、轨迹相似度度量、轨迹检索、模式挖掘、轨迹聚类和异常检测等 存在一些潜在问题：  轨迹语义缺失 轨迹表征困难 位置预测精度低   总结：轨迹数据挖掘有深刻的理论研究价值和广泛的应用前景，论文围绕上述三个问题，开展理论算法与关键技术研究。  轨迹数据挖掘相关理论基础 轨迹数据语义研究相关理论 轨迹数据中的语义信息（按语义层次）   简单语义信息\n 轨迹的起点、终点、停留点、兴趣点都属于轨迹中的特殊位置信息，蕴含着简单的语义信息 简单语义信息能够反映用户轨迹中用户出行的空间特征或运动状态，但简单语义信息不含有任何语言类的语义解释，缺乏更深层次的语义理解    地理语义信息\n 利用地标建筑物标注、地图匹配算法、位置语义推断算法赋予轨迹数据高层次的语义解释信息 签到位置属于不同语义类别，医院、酒吧、公司、商店等 地图匹配算法将轨迹数据映射至城市路网中，利用路网的辅助语义信息，如十字路口、道路信息刻画用户在城市中的出行行为。 常见的地理语义信息还包括地理数据（植被、河流、行政划分等）、地标建筑物、可获取兴趣点（大众点评等网站提供）等 地理语义信息含有人类活动中的可理解语义信息，不仅能够反映用户运动状态，还包含用户出行含义，从哪里来、到哪去、活动目的等。    描述性语义信息\n  签到活动时分享自己的感受，发布图片或视频等多媒体信息\n  描述性语义信息表达了用户在签到位置所做的具体事情，甚至包括更高层的用户情绪，政治倾向等\n  通过文本或多媒体信息推断位置语义、为位置添加特定的标签（如“文青聚集地”的标签），利用照片分享或短视频传播等社交传播方式加速地理位置影响力的传播\n    当前轨迹数据语义研究  轨迹语义推断  粗轨迹信息提取语义 ➡️ 分析用户在地理空间中的运动状态 利用地图匹配或地理信息推断语义，通过增加额外的地理空间信息，如路网或地标建筑等，采用相关算法匹配轨迹，赋予轨迹数据可理解的语义信息。 语义补全   轨迹语义模式挖掘：利用轨迹中的语义特征执行数据挖掘任务，如轨迹语义压缩、轨迹语义分段、生活模式挖掘等 基于语义分析的事件检测  轨迹表征研究相关理论   第一段：绪言\n  轨迹是轨迹点按照时间先后顺序组成的序列，序列点的表征方式是轨迹主要表示方式。\n  轨迹点组成序列的方式直观、简单，但也存在信息冗余，直接适用的数据挖掘和机器学习模型少等不足，同时序列点表征没有将轨迹的时空信息融合在一起，无法体现轨迹数据的时空耦合性\n  为了能从轨迹数据中发现更多的新知识，将轨迹原始数据转化或学习新的轨迹表征成为一种重要的研究思路。\n    第二段：轨迹数据表征基本方法：关键点、子轨迹、轨迹物理特征\n 轨迹中的轨迹点重要性不尽相同，其中部分轨迹点代表轨迹数据中的关键信息 利用轨迹中的关键点作为轨迹数据的表征，能够减少轨迹数据量提高表征质量 关键点分类  在人类出行轨迹中，对人类活动有特殊意义的关键位置点  用户在连续较近的地理位置长时间停留的停留点 根据轨迹点密度或用户偏好得到的兴趣点   对轨迹形状有影响的关键点，如拐点或轨迹压缩中的保留点   子轨迹段是研究轨迹局部性质的重要表征方式 轨迹物理特征：关键点表征与子轨迹段表征是基于轨迹形状的表征方式，另有一些研究人员通过提取轨迹速度、起始点、方向、加速度等特征，用可解释的物理特征向量表示轨迹或子轨迹。 总结：关键点、子轨迹、轨迹物理特征提取三种轨迹表征方式是研究轨迹数据的基本方法，简单直观利于理解，是轨迹数据表征基础方法。    第三段：将轨迹数据转化为图表征\n 关键：如何准确将轨迹数据表征为图里的点和边 路网 自由空间：郑宇：首先通过密度聚类算法识别轨迹中的关键点，然后根据密度构建一个层次化的树状结构进一步提取高价值位置，树中的节点作为顶点，所有用户共享顶点集，用户根据自己的轨迹历史数据构建自己的轨迹数据图。至此，度量两个用户轨迹相似度转化为度量两个图的相似度，将图挖掘算法应用至轨迹数据挖掘中    第四段：将轨迹数据转化为矩阵表征 ➡️ 位置推荐和用户潜在兴趣挖掘\n  第五段：表征学习：将轨迹数据转化为特征空间中的向量表征\n 轨迹数据表征学习  目的：自动提取轨迹数据特征，并用特征向量表征轨迹数据 关键：学习轨迹数据的空间和时间信息 轨迹相似度：利用欧式距离度量两条轨迹特征向量的距离，无需设计复杂度较高的距离函数 目前的轨迹数据表征学习研究往往从单一侧面展开，割裂时间和空间之间的紧密偶合关联，对轨迹数据时空耦合分析还很欠缺      位置预测研究相关理论 以后感兴趣再细看吧\n  第一段：绪言\n  轨迹数据中的预测问题：主要的研究方向为交通流的预测和位置或行为预测\n  人类活动在时空维度上有很大的复杂性，但是也表现出了一定的统计规律特性\n  位置预测主要研究预判用户未来会到达的具体位置，位置推荐是通过分析用户偏好模型，为用户推荐感兴趣的地点\n  分类：\n 位置预测根据预测方法不同分为八类 根据个体模型或群组模型分为三类 轨迹数据有位置社交网络的签到数据(check­in) 与 GPS 出行数据两种      第三章 基于图卷积神经网络的位置语义推断 引言  位置社交网络中用户签到活动 ➡️ 签到位置的语义:揭示用户活动的目的和用户偏好 ➡️ 位置语义推断 已有研究表明  用户的签到活动与位置语义存在某种潜在关系  表明用户签到偏好与位置语义之间存在联系 例如，经常访问图书馆、书店、学校等类似地点的用户很少访问夜店、酒吧等地。   相似空间结构与相似的时间模式的地点具有相近的语义  表明在城市规划建设时，具有相同职能的位置建设规划相似 例如，居民区附近普遍有超市、医院、市场等配套   现有位置语义推断算法  通过度量用户出行行为间相似度转化为位置特征，进而推断相似签到位置的语义 提取用户签到活动的出行模式，从中提取位置特征，推断位置语义 但度量用户签到行为相似度，手工提取位置特征或提取长效有价值的签到活动出行模式是一项有挑战性的工作   本研究  为了解决现有方法通过手工提取特征或出行模式的不足，同时充分利用签到活动中的高阶信息 基于图卷积神经网络的位置语义推断算法框架（SI-­GCN）  无监督地提取用户、位置的时空特征  node2vec学习位置的空间结构特征 变分自编码器学习时间信息的特征   构建用户­-位置访问二部图，利用图卷积神经网络获取用户签到活动中的高阶信息用以推断位置语义 引入注意力机制区分二部图中邻居节点的不同影响     贡献  利用无监督方式提取用户、位置的时空特征 利用图卷积神经网络获取用户签到活动中的高阶信息用以推断位置语义 良好的语义推断性能      SI-GCN框架 三部分   时空特征提取\n  用户-位置访问二部图\n  位置语义推断\n  位置时空特征提取   位置空间特征提取\t 手工提取特征 ➡️ 无监督方法提取 Step 1. 用户映射至地理空间  除去用户家以外，选取用户访问频率最高的 3 个访问位置代表用户常去的地理空间活动范围 使用 3 个位置的平均经度、纬度作为用户 u 的地理坐标   Step 2. 构造地理空间网络  将用户、地理位置看作节点，通过计算节点间距离 若距离小于 δ 时，两节点相连构成边，否则不构成边   Step 3. 空间特征提取算法  采用 node2vec 算法无监督学习用户、地理位置的空间特征表达 目标是在地理空间网络中的节点与邻居节点共同出现的概率最大 ➡️ 最大化邻居节点的出现概率      位置时间特征提取 目标是学习用户访问的时间模式以及地理位置的被访问的时间模式 Step 1. 建立 7 × 24 的时间矩阵，计算用户访问时间、位置的被访问时间得到时间矩阵  例如，用户 A 在周一上午 9 点10 点访问位置 B，则时间矩阵相应元素加 1 位置的时间矩阵与用户的时间矩阵计算方法一致   Step 2. 采用变分自编码器无监督学习时间矩阵的特征向量 Step 3. 完成网络学习后，提取变分自编码器的隐层输出得到用户、地理位置的时间特征    将用户、地理位置的空间特征、时间特征直接相连，构成时空特征\n  图卷积神经网络推断模型  用户­-位置访问二部图：反映用户与地理位置之间的访问关系与拓扑结构 利用图卷积神经网络将用户-­位置访问二部图的拓扑关系、用户和地理位置的时空特征相结合探索位置的语义  实验与分析   实验\n 数据集：FourSquare 提供的纽约市 (NYC) 和东京市 (Tokyo)签到数据集 实验中移除了访问次数少于 10 次的位置 设置两种语义标签策略  所有的标签归为 10 大类 签到次数排序前 20 的位置语义标签     选择了三种基准位置语义推断算法作为对比 参数：空间特征维度为 200，时间特征维度为 16，因此用户、位置时空特征为 216 维 为了充分评估模型性能，完成提取位置时空特征后，训练图卷积神经网络时，分别采用 80%，70%，60%，50% 的训练数据训练模型，对应 20%，30%，40%，50% 的测试数据测试模型。    结果与分析\n 数据类别分布不平衡对模型性能影响明显 在纽约市数据集的结果好于东京市数据集的结果 ➡️ 纽约市每名用户访问过更多位置，使模型能够获得更多信息 不同训练数据比例的实验结果表明，SI­-GCN 语义推断性能稳定，实验结果没有显著降低。 不同特征对 SI­GCN 模型语义推断性能的影响 ➡️ 缺失任何一种特征对模型都会产生较大影响，所有评价指标都有下降 自注意力机制使节点能够捕捉数据内部的相关性，减少其他信息的干扰。  移除自注意力机制后，模型整体性能有显著下滑，但部分实验结果优于移除特定特征模型的结果，说明位置的时空特征对 SI­GCN 模型性能有更重要影响。 自注意力机制对模型性能提升是正面的，自注意力机制加权处理邻居节点信息，有效提高模型性能。   SI­GCN 结果明显优于三种基准算法的位置语义推断性能    第四章 融合时空结构的轨迹数据表征学习 引言  不同定位设备采集，不同采样率与轨迹长度 ➡️ 轨迹数据表征困难 现有大多数轨迹表征研究割裂时间与空间之间的紧密耦合，仅从单一维度（通常是空间维度）表征轨迹数据：（1）以往关注轨迹数据空间结构表征，忽略轨迹的时间信息；（2）以往表征方式不适用于普遍的机器学习与数据挖掘模型；（3）欠缺语义信息嵌入 本文提出一种统一的框架——融合时空结构的轨迹表征学习算法框架（Space-Time Architecture for semantic trajectory Representation, STAR）  上下文信息+词向量表征学习算法学习轨迹空间结构信息 自适应霍克斯过程建模轨迹时间信息 轨迹向量表征作为桥梁连接融合轨迹时空信息 通过预测用户位置和时间的过程自动学习轨迹表征 主成分分析（PCA） ➡️ 检测异常轨迹   贡献  融合时空信息 语义嵌入 在轨迹表征向量基础上提出轨迹异常检测算法    框架概述  三部分：空间表征、轨迹时间建模、时空融合  轨迹表征学习模型 轨迹空间信息向量表征 三种上下文的提出还是蛮有意义的\n  词向量表征学习介绍 + word2vec + CBOW\n  类比思想：将用户轨迹中的用户兴趣点类比于自然语言领域文本中的单词，将用户轨迹类比于文本中的句子\n  轨迹与文本两者之间的上下文信息有所差别，因为兴趣点语义信息相近，并不一定在地理上相邻 ➡️ 需要重新定义给定兴趣点的上下文信息 地理上下文 轨迹上下文 语义上下文：  1­阶熵：1­阶熵是给定兴趣点与其 1­阶邻居连接强度的分布熵 2­阶熵和聚类系数：2­阶熵进一步获取了连接强度 2­阶邻居范围内的整体分布 聚类系数：考虑连通密度，计算聚类系数      根据上述兴趣点的上下文邻域，通过 CBOW 模型学习兴趣点和轨迹的向量表征\n  时间信息建模 没看懂\n  点过程\n  条件强度函数：在给定历史数据的条件下，新事件在单位时刻内发生的瞬时率\n  霍克斯过程：泊松过程的一个扩展\n  霍克斯过程比传统泊松过程更能够模拟过去事件对未来事件发生的影响，特别是过去事件对未来事件的正面激励影响\n基于轨迹表征的异常检测   现有的轨迹异常检测算法主要利用轨迹距离度量、轨迹密度、子轨迹片段划分等空间形状，或轨迹异常模式检测异常轨迹\n  本文：分析轨迹数据表征中数据的主要成分信息，检测偏离主要成分信息的轨迹\n  异常分数表示轨迹异常程度，即异常轨迹与轨迹数据主成分的偏离程度，选择一个阈值来区分异常轨迹\n  实验与分析  数据 兴趣点提取：为了有效分析轨迹中的重要信息，实验提取轨迹数据集中的兴趣点，减少无效信息有助于分析轨迹表征学习算法的性能。将研究区域划分为 n × n 的网格（实验中设置 n = 100）。计算落在网格中 GPS 点的经纬度的平均值和时间信息，计算单元网格地理距离的相似度矩阵，最后使用 K­means 聚类方法提取 K 个兴趣点 (POIs)，本章实验中设置所有数据集K = 1000 语义标签标注：将兴趣点语义类别分为八种，包括风景区、公园、村庄、社区、交通、商务区、医院和教育。  第五章 基于偏好社交互动的位置预测算法 引言  位置预测是轨迹分析中的一项重要任务，位置预测的目标是分析人类的出行轨迹数据，从历史数据中学习人们的出行模式预测未来人们到访的位置 个体的出行行为并不完全是规律的，且会受到外部因素的影响而发生变化 人类行为主要受自身偏好与外部社交两方面影响 本文提出——基于偏好社交互动的位置预测算法（Preferences and Social Interactions for location prediction, PSI）：  首先量化外部互动对个人出行行为的影响，利用聚类技术确定个人所属的关联群组 然后采用关联规则挖掘方法，提取反映外部互动影响的群组频繁出行模式 最后，利用岭回归整合群组移动模式与个人出行模式，预测用户位置   贡献：  双层聚类的兴趣点：热点兴趣点和普通兴趣点 基于偏好社交互动的位置预测算法 采用北京行人出行数据集和波尔图市的出租车数据集对 PSI 进行实验分析    基于地理场景的城市功能区建模与分析方法研究  张修远-2019-北京大学，师从杜世宏  札记  写作用词套路：提出了-应用于-能够-实现了  摘要   第一段：背景-问题-本文目的\n 全球城市化发展-城市问题 响应我国城市可持续发展的重大战略规划➡️需要获取高时效、 高精度、大范围的城市功能分区数据 已有研究通常使用城市规划图表征功能分区信息  规划图仅反映某一时间区间内对功能区建设的预期目标，不能反映当前时刻城市功能分区的真实状态 规划图以街区为基本单元， 忽视了街区内部功能类型的异质性， 进而无法在更精细的尺度上分析功能分区情况   因此，本文致力于  发展一种自动化城市功能区制图的解决方案 重点解决功能区的空间单元提取、 结构格局表达和功能类别智能识别等关键问题      第二段：从遥感数据角度分析，背景-阐述难点-本文目的\n 基于高分辨率遥感影像的高时效、大范围功能区制图 城市功能区作为一种地理综合体：综合性、异质性以及尺度不确定性  综合性：城市功能区的空间单元是由多种地物要素按照一定空间分布规律聚合而成， 而其语义类别是概括这些地物的利用类型通过而获得的， 因此功能区在空间组成上和语义类别上具有综合性。 异质性： 城市中不同类型的功能区（如商业区、居民区、工业区）在空间上分布不均匀， 且每个功能区内部地物组成和空间结构多变， 是不同类型社会经济活动共同作用的结果。 尺度不确定性： 城市功能区的分析结果在不同尺度上有不同表现， 本质上城市功能和地物要素在不同的尺度上耦合关联， 不同的分析尺度有助于分析调查不同粒度的地物结构以及功能类别。   难点：三个特性互相关联， 导致功能区建模与分析的难度远大于地物识别与分析的难度， 因此已有的遥感影像分析方法无法准确地提取功能区的空间单元、 结构格局和语义类别。 为解决此问题（他的用词很有讲究吧）  原创性地提出了基于地理场景的遥感影像分析方法   应用于*城市功能区自动分割提取、特征表达和智能识别   能够准确提取和表达功能区空间单元、 结构格局和语义类别 实现功能区的自动化制图。      第三-六段：论文研究成果概述\n 功能区空间单元分割及提取  已有分割算法没有考虑城市功能区综合性和异质性的影响， 不能从遥感影像中分割提取功能区空间单元  提出了基于多要素聚合的多尺度地理场景分割方法 解决了功能区的异质性度量以及自动聚合等难题 实现了在不同尺度上分割提取功能区单元 以满足不同粒度城市调查和规划的需求   功能区的尺度不确定性对分割结果和效率造成不利影响  进一步提出了自适应分割尺度学习方法 通过局部尺度评估方法， 自动确定每个功能区的最佳分割尺度，进而优化分割结果，提高功能区提取的精度和效率。     功能区空间单元表达  功能区的异质性极大减弱了现有影像特征对功能区的表达能力  提出了空间语义共生模型 度量功能区中不同地物要素在空间和语义上的依赖关系，表达功能区的空间格局 并在数学上证明了该特征的鲁棒性   受功能区综合性的影响，单一特征无法全面表达功能区  进一步提出了层次语义认知模型 对多源特征（包括视觉特征、语义特征、空间共生特征） 进行分层组织 并建模了不同特征间的层次依赖概率，用于功能区多源特征及其层次关联结构表达。     结构格局和语义类别  功能区综合性、异质性和尺度不确定性， 导致功能区样本选择、 分类识别困难  基于主动学习， 提出了启发式样本学习方法 兼顾纯净样本和混淆样本， 能够自动获取代表性样本用于功能区监督分类   功能区分类  建立了连续多项式分布模型， 表达功能区之间的空间依赖性 优化提高了功能区分类制图精度        第七段：\n 研究思路  图像特征➡️土地覆盖➡️空间结构➡️功能分区 对现有遥感影像分类范式的有效拓展   提出了一套基于地理场景的城市功能区分析理论和方法体系  应用于功能区分割提取、 特征表达和分类识别 能够准确地提取功能区的空间单元、 结构格局和语义类别 实现了自动化的城市功能分区制图   论文研究方法和结果  可为城市规划、城市可持续发展评估提供详细尺度、高精度、 时效性强的城市功能分区数据 对城市可持续发展规划与建设具有重要的推动作用      第一章 绪论 论文研究背景与意义  第一段  全球城市化建设进程-我国城市化建设 城市化的高速发展-许多自然和社会问题-城市可持续发展 城市化-功能区作为城市化建设的基本地理单元，是研究和调查城市化进程的关键 城市功能区制图   第二段：城市功能区的概念及发展  源于区域经济学  首次提出：同类经济活动集中的连片地区 引入环境科学领域 城市景观生态分析   功能区在城市问题分析中扮演着重要的角色  区域经济学中城市功能区这一概念比较模糊， 无法体现功能区的构成要素、形成机理 Tyler and Ward 从城市规划的角度给出了一个新的定义：城市功能区指由不同地表要素构成的地理综合体， 每个功能区内部具有相对一致的建成环境和人类社会经济活动。(Tyler, N., \u0026amp; Ward, R. M. (2011). Planning and community development: A guide for the 21st century. WW Norton.)     第三段，功能区分析中的难点问题  在地理表现上，呈现出（1） 综合性和（2） 异质性  城市功能区的综合性：多种地物要素组成、具有一定建成环境或景观格局、在规划建设和历史因素作用下这些地物要素的空间分布、 排列呈现出一定规律 综合性是功能区分析的基础  这一特性明确了功能区内部地物的分布特点，可以作为提取功能区的依据 综合性还是功能区在地理表现上的最基本特性，它也直接导致了功能区的异质性和尺度不确定性   城市功能区的异质性  每个城市包含不同的功能区（如商业区、工业区、居民区、学校、公园） 且这些功能区在空间上交错且不均匀地分布 功能区在内部组成和结构上表现异质（这一点以前确实没有理解到），例如居民区中包含了建筑物、植被、裸土、道路，这些土地覆盖要素又具有不同的空间结构。 功能区的异质性是由人类不同的社会经济活动作用形成的     在分析中存在（3）尺度不确定性\n-功能区分析结果随分析尺度的变化而变化， 本质上是城市功能和地物要素可以在不同的尺度上耦合关联， 不同的分析尺度可以用于调查不同粒度的地物结构以及功能类型  例如在较大的尺度上才能分析调查学校功能区，而在较小的尺度上学校则被划分为了宿舍居民区、教学区甚至还包含了商业区和公园（这个例子举得很经典）?   三个基本特性是基于遥感影像功能区分析中的难点， 这三个特性增大了提取功能区空间单元和语义类别的难度 综上所述：城市功能区在地理表现上的三个基本特性导致功能区建模与分析异常困难， 使其难度远大于传统的地物识别与分析的难度，因此在城市功能区分析中需要考虑和解决上述三个难点。   第四段  传统的城市功能区调查与分析基于历史规划数据进行  在城市规划与建设中，规划人员以土地覆盖现状和社会经济属性为基础， 以城市发展为导向， 设计城市规划图实现对功能区的划分和表达， 其最详细到街区尺度最粗略到城市群尺度 城市规划图不足：  本质是针对某段时间区间内城市建设的指导方案， 并无法反映当前或某一个时间节点上城市功能区的真实情况 规划图以街区作为最详细尺度忽略了街区内部功能类型混淆的情况， 因此无法准确地表达功能区的空间范围   基于城市规划图的功能区建模与分析是不准确的   基于地理大数据的功能区调查方法逐渐兴起 ➡️ 城市功能区的动态检测 本文：  基于高分遥感影像结合街道、兴趣点等多源地理数据提出了地理场景的建模与分析方法，将其应用于城市功能区制图与分析 解决了功能区分析中三个难点问题，实现了功能区的自动提取、 综合表达与智能识别 在技术上，创新性地提出了地理场景场景分割、自适应尺度优化、空间语义特征提取、 多源特征组织与表达、功能区样本学习、 功能分类等关键技术难点      基于地理场景的功能区分析中基本概念 本质上，是利用影像中地理场景对城市功能区进行建模提取， 在此基础上提取功能区的描述特征， 进而实现对功能区的分类识别。\n城市功能区相关概念及分类体系  城市功能区的空间约束条件是城市范围  什么是城市  在经济学中 在城市规划学中 在地理学中（本文中参考）：城市是指交通网络密集，人群和房屋的密集的结合体     概念对比：城市功能区与土地利用  土地利用是指人类根据一定的社会经济目的对土地覆盖进行长期性或周期性的经营管理和治理改造（Anderson, 1976） 相同点：土地利用和功能区的基本组成单元都是土地覆盖，都涉及到社会经济活动 不同的是：功能区在定义中强调了区域的空间范围，而土地利用则没有对空间范围进行约束 一个土地利用要素可以是由一个土地覆盖要素构成的利用类型，也可以是由多个土地覆盖要素组成的利用分区；而功能区一定是由多个不同的土地覆盖要素组成的。 功能区可视为土地利用的子集   城市功能区分类体系  参考：我国《城市用地分类与规划建设用地标准》 (Code for classification of urban land use and planning standard of development land, GB 50137-2011) 将我国城市划分为商业区、工业区、居民区、 城中村、 教育用地（一般指学校）、 公共开放区（如公园）（后续可以参考文中对每一类功能区的解释，这里拷贝过来了） 商业区（图 1.3 a）。商业区是指零售商业聚集、交易频繁的地区以及大型写字楼办公区（详见《城市用地分类与规划建设用地标准》）。商业区在地理空间上多分布于城市中心和经济开发区，常位于交通路口、繁华街道两侧、大型公共设施周围。 商业区中建筑物一般较为高大且建筑结构复杂。在大城市或特大城市中商业区又常被划分为中央、区和街等不同层次、规模的商业区， 在本论文所研究的商业区为具有一定规模且商业活动聚集区域， 因此居民区内部规模较小的商业服务设施属于居民区， 不属于本论文中商业区范畴。 工业区（图 1.3 b）。 工业区包括制造生产资料或大型器械的重工业区以及生产日常消耗用品的轻工业区。 在城市中， 工业区多由加工工业企业群组成，一般情况下，其内部结构比较协调，并有紧密的生产联系。由于城市的整体职能不同，城市中工业区的地理表现也不同。例如，工业城市与旅游城市的工业区大小、形态以及空间分布都有差异，但是一般来说城市工业区在空间上集群分布，多位于城市郊区或城乡结合带。工业厂房房顶的材质和颜色与城市中其它建筑物有很大差别。 本论文所涉及的工业区包括重工业区以及大规模的轻工业区，而混杂在其它功能区中的小型加工厂、手工作坊不属于本论文工业区范畴。 居民区（图 1.3 c）。 **居民区泛指城市常住人口居住的社区， 包含其配套设施。**居住区是城市中主要的用地组成部分， 散布在城市的各个区域。 根据居民区中居住环境、 配套设施， 可以将居民区分为一级居民区（高档居民区）、 二级居民区（普通居民区） 和三级居民区（老旧居民区）。 一级居民区一般由别墅、新式高层建筑组成，常配套有健身房、绿地等生活设施；二级居民区一般是由不高于 9 层的中层居民楼构成，分布规则排列有序，周边有一定的配套设施，如小超市、餐馆等，该类型居民区分布最为广泛，遍布城区； 三级居民区是由不高于 4 层的老式居民楼构成， 周边配套设施较少，该类居民区常出现在老城区。 论文中的居民区包括以上三种居民区。 城中村（图 1.3 d）。**城中村是城市中一种特殊的功能区类型，是城镇化建设过程中未开发建设但周围都已形成城市结构的区域。**该区域仍保留乡村的建筑结构（低矮的房屋、密集的建筑分布）和老式的社区形态， 拥有较少的、规模较小的配套服务设施。 但是由于位于城市建成区内部， 城中村中居住人口、基础设施等又与乡村相比具有明显差异。 学校（图 1.3 e）。 **学校包括幼儿园、小学、中学以及高校。**此功能区内部组成一般比较复杂，包含了宿舍、超市、教学楼、办公楼、操场等。 论文中所研究的学校包括具有一定规模的小学、 中学和高校， 而居民区配套的幼儿园以及小规模的小学属于居民区， 而不属于学校范畴。 公园（图 1.3 f）。**公园是指政府修建并经营的作为自然观赏区和供公众的休息游玩的公共开放区域， 一般是由政府规划建设或历史因素形成的。**根据上述定义， 由地产开放商建设的居民区、 商业区内的观赏和休闲区不属于论文中公园的范畴， 此外，有学校经营和管理的观赏休闲区也不属于公园的研究范畴。      地理场景相关概念  场景  在计算机视觉领域， 场景常被用于形容一幅图片所包含的内容，例如“海岸”、“高山”、“森林”、“乡村”、“街道”和“建筑物”。 ➡️ 几乎任何一幅图片都可以被视为一个场景。 计算机视觉中图片场景缺乏一个明确的定义。 场景被用于描述高分遥感影像  最著名的遥感影像场景数据库是 UC Merced Land Use（http://vision.ucmerced.edu/datasets/landuse.html） 遥感影像场景分类   现状/问题：无论是图片场景还是遥感影像场景对其含义、 构成要素、 形成规则都缺乏明确的定义， 因此无法给出相应的数学形式化建模方法。  上述场景都是基于人的主观认知使用规则栅格划分提取的， 而这些栅格本身是缺乏地理含义的， 因为栅格划分无法表达地理要素的空间单元， 进而难以准确地表达地理要素的语义类别。   结论：故已有的图片场景和遥感影像场景不适用于建模分析城市功能区这种地理综合体。   地理场景  地理场景是由多种土地覆盖对象组成的图像块， 每个地理场景内同类型的土地覆盖对象具有相似的个体特征和空间分布特征。 例如图 1.6（c）中建筑物具有相似的颜色、形状、朝向，形成整齐的排列方式，其他土地覆盖具有类似的规律，因此将这样的一个图像区域称为地理场景。 数学形式化表达 是一种地理分异单元。具有明显的地理含义 地理场景不同于传统的图像单元  像素是传感器成像的基本物理单元，是图像上最小的可区分单元 对象是图像中颜色纹理均质且连续的区域   对象与场景的区别    研究现状与存在问题 引言  该领域研究方法   基于社交媒体定位数据的功能区分析， 社交媒体定位数据是指社交媒体平台上产生的具有位置信息和语义信息的有价值数据 基于感兴趣点（Point of interests, POI）数据的功能区分析， POI 数据泛指一切人类感兴趣的位置点数据，通常 POI 数据用于导航包含点的位置、 属性和利用信息 基于遥感影像数据的城市功能区分析   论文以遥感影像为本底数据，结合 POI 信息对城市功能区进行建模和分析，其主要研究思路包括功能区分割提取、特征表达和分类识别  基于遥感影像的城市功能区建模与分析中共存在六个关键问题  城市功能区分割提取的研究现状和存在问题  问题一，功能区分割方法问题：传统分割算法都是为了提取视觉特征均质的图像对象，而城市功能区包含多种土地覆盖要素（如水体、植被、建筑物等）， 因此功能区在视觉上是不连续的， 即功能区表现出很强异质性。 这使得传统的图像分割方法无法提取城市功能区。 问题二，功能区分割尺度问题：功能区在分割提取时具有尺度不确定性，而现有的尺度选择方法无法解决功能区分割提取中尺度不确定性问题  城市功能区特征表达的研究现状和存在问题  问题三，功能区空间格局特征表达问题：如何提取鲁棒的空间格局特征是功能区特征表达中亟待解决的问题  功能区的常用特征主要包括三类：视觉特征、抽象特征、 语义特征 视觉特征：直接从图像中提取的用于描述图像单元的量化指标， 这些指标是基于人类视觉感知经验定义的。视觉特征可进一步分为两类： 图像对象特征、视觉描述子。  图像对象特征：目标对象光谱、纹理、 形状、大小等 视觉描述子：梯度方向直方图（Histogram of oriented gradients, HOG） 和尺度不变特征变换（Scale-invariant feature transform, SIFT）   抽象特征：在视觉特征的基础上，利用一些机器学习或者统计学习方法将视觉特征进行抽象和变换从而获得更有意义的特征。  主题语义模型 ➡️ 潜在主题特征   对象库（object bank）：每个功能区内部对象语义类别的频率分布   视觉特征的对功能区的表达分析能力较差； 抽象特征可解释性不强； 语义特征能够有效提高功能区的抽象表达能力也具有很强的可解释性， 但是忽略了空间信息；而功能区内部地物的空间格局是表达功能区的关键。   问题四，功能区特征层次依赖问题：在组合多源特征对功能区进行表达时需要考虑不同特征之间的层次依赖关系， 而现有的特征组合方式忽略了特征之间的层次依赖关系  单一特征难以全面地、准确地表达城市功能区➡️组合不同特征（视觉特征、抽象特征、 语义特征和空间格局特征）来提高特征对功能区的表达能力  常见的特征组合方法是首先将上述所有特征展为多个一维向量， 然后把不同特征首尾串联获得一个超高维的特征向量  特征维度大 这些特征属于多源异构特征，即特征的含义、单位和数量级都是不同的 这些高维特征间具有很强的相关性， 因此简单的线性特征组合表达对于功能区分类识别造成不利的影响   视觉特征、抽象特征、语义特征和空间格局特征之间具有显著的自下而上的层次依赖特性      城市功能区分类识别的研究现状和存在问题  问题五，功能区样本获取问题：如何准确地选取和标注功能区样本是功能区分类识别中的难点问题 问题六，功能区空间相关性问题：仅考虑功能区内部特征难以准确分类识别功能区类型， 因此需要建模功能区的空间相关性以优化分类结果  功能区作为一种地理综合体具有地理特性：地理空间上越靠近的事物相似度越高 空间上邻近的功能区具有很强的相关性：例如一个功能区可能属于城中村也可能属于居民区， 如果这个功能区与工业区邻接，那么它大概率属于城中村。因此在分类识别功能区时需要考虑功能区的空间相关信息，但已有分类方法无法建模和表达功能区的空间相关性（这个例子举的很好）    研究目标与内容  论文致力于实现基于遥感影像的城市功能区分割提取、特征表达以及分类识别，但是受功能区综合性、异质性和尺度不确定性的影响， 引发了六个难点问题。 论文将结合地理学、景观生态学以及计算机视觉等领域的知识， 提取一套基于地理场景的城市功能区建模与分析方法体系， 考虑了功能区的基本特性， 解决了上述难点问题， 并将该方法应用于城市功能区制图和城市功能结构分析等方面。 技术路线 研究内容遵循功能区提取➡️表达➡️识别的前后逻辑关系 章节安排  第二章 多尺度地理场景分割：功能区分割提取 引言 功能区分割提取的研究背景  第一段  城市功能区是城市规划和管理的基本空间单元➡️ 获取这些功能区的空间边界信息是进行功能区分析的前提➡️ 功能区内部组成和结构异质且功能区边界范围模糊、易混淆，因此传统的面向均质对象的分割方法难以从遥感影像中提取城市功能区➡️ 本章将解决功能区分割方法问题， 致力于自动化、多尺度提取功能区的空间单元   第二段  研究历史悠久且近年来也是研究热点 基于高分影像城市功能区分析主要包括三个步骤：功能区分割、 特征表达以及功能分类  功能区分割是指将高分遥感影像在空间上分割成不同的区域，使得每个区域代表一个功能区。 其次，特征表达是利用量化特征对每个功能区中的内容进行描述和表达。 最后，功能语义分类是基于功能区的特征表达对每个功能区进行分类以及功能语义标注，实现功能区分类制图。   已有的功能区分析方法中大部分集中于特征表达和功能分类， 但是忽略了功能区分割。 功能区分割的重要性(最初始、最基础的一步) ➡️ 首先应解决功能区分割的问题➡️ 由于综合性和异质性，已有的图像分割方法都无法解决功能区分割提取问题➡️ 使用街区分割提取城市功能区（道路分割）的不足：  欠分割 时间差异导致分割结果不准确 街区分割结果不适合多粒度或多尺度分析   需要提出新的方法实现基于高分影像的城市功能区分割提取   第三段  功能区分割中需要考虑四方面内容：  分割依据（功能区异质性表达）：图像特征及其异质性表达是图像分割的主要依据。  低层特征  光谱、几何和纹理图像特征 能有效表达相对同质的对象， 而不能有效表达由不同对象组成的异质的功能区   中层特征  对象语义和视觉词袋 缺乏明确的语义信息，忽略了对象的空间上下文信息，导致分割结果不准确   高层特征  卷积神经网络提取高层次深度特征 1）深度特征是基于像素窗口提取的， 能够度量像素的上下文信息，而不能表达地物要素在空间和语义方面的依赖关系，因此在度量不规则功能区时表现较差。2）此外，深度特征缺乏地理意义，可解释性较弱。 ➡️ 抛出问题：如何定义空间模式特征并应用于功能区分割     分割方法（基于功能区异质性度量的对象聚合）  基于分割依据按照一定规则将图像分割成不同的斑块 基于区域增长的和基于边缘方法 均无法提取功能区， 原因在于他们都为分割提取同质对象而设计的，对象方法侧重低层特征的连续性和同质性；使用区域分割方法，功能区会被分割成破碎的对象，而不是一个整体。 抛出问题：如何设计功能区分割方法   分割尺度（功能区异质性阈值）  尺度一个重要的分割参数， 指功能区内部异质性的的最大值。分割尺度的大小将决定分割结果中不同功能区的大小。 现有分割尺度设置方法主要是手工选择一个全局的尺度参数。 抛出问题：为不同功能区选择局部最优的尺度参数   分割结果评价（功能区分割精度计算）  需要定量评估功能区分割结果的准确性，验证分割方法的有效性 1）监督评价法需要人工标注功能区边界，人工勾画边界将耗费大量人力物力，不是最佳选择；2）非监督评价假设分割对象内是相似的而分割对象间是有差异的。 但是功能区内部通常是异质的，因此上述假设不适用于功能区分割结果评价。 抛出问题：需要针对功能区特点研究新的分割评价方法       第四段：总结  本文致力于解决上述四个问题， 自动分割提取功能区的空间单元。 功能区在地理空间上由不同地物要素按一定空间格局组织聚合而成的区域 基本思路为影像特征➡️地物类别➡️功能分区 首先影像特征提取地物类别（使用传统的面向对象分割和分类方法） 研究地物聚合算法分割提取功能区边界（本章研究重点）      地理场景： 功能区的影像建模方法  第一段：强调图像模型  难点/根本原因：缺乏一种可数学形式化表达的、可用于建模表达城市功能区的图像模型   第二段：  不同社会经济活动导致不同功能区具有不同的结构或格局➡️（疑问?️：结构或格局=？建成环境/景观格局） 相同城市功能区内建成环境具有相似性，而不同功能区间的建成环境具有差异性➡️ 功能区的分割提取问题本质上是建成环境的分割问题 需要提出一种能够表达不同建成环境的图像模型对建成环境以及功能区进行建模 建成环境的特征体现在不同地物要素（如建筑物、水体、植被等地物） 的个体特征及其空间分布模式   第三段：  地理场景定义为遥感影像上连续且不重叠的区域， 在每个地理场景内，同类型地物应该具有相似的个体特征和空间分布规律。 数学上表达：\u0026hellip;   第四段：地理场景和功能区之间的关系  几何属性：均表现为不规则多边形 内部组分：均表现异质性 组成机理：地理场景概念中定义了对象的空间分布格局可表达功能区内部的景观格局或建成环境 分析尺度：均受分析尺度参数的影响 总结：地理场景作为一种图像模型在几何属性、 内部组成、构成机理以及分析尺度四个方面与城市功能区高度相关， 因此地理场景能够有效地建模和分析城市功能区。   第五段：再次总结：  已有的图像分割研究不适用于功能区的分割提取 本章（有一种虎头蛇尾的感jio?）  通过定义空间分布特征解决分割依据的问题 通过定义地理场景这一新的图像模型以及提出多尺度地理场景分割解决分割方法和尺度表达两个问题 利用感兴趣点数据对分割结果进行评价      多尺度地理场景分割  基础  地理场景由多种土地覆盖要素联合分布构成 每类土地覆盖要素的个体特征及空间特征之间的相似性   基本思路：根据土地覆盖类型逐类别进行分层聚合，进而将不同层的聚合结果叠加组合生成地理场景 首先， 定义土地覆盖对象的个体特征以及空间分布特征， 其中空间分布特征需要考虑对象与不同类别之间的距离和方向的信息； 然后，基于上述特征的相似度， 逐类别聚合土地覆盖对象形成每类对象的对象簇； 最后， 对不同类别对象生成的对象簇进行空间叠加形成最终的地理场景分割结果。    空间分布特征  对象特征  光谱、几何、纹理等特征 从视觉的角度表达对象的个体属性，被广泛应用于土地覆盖分类中 缺乏对空间分布特征的描述   空间分布特征  指对象的空间关系、结构和格局等 是探究和发现土地覆盖对象空间分布规律的关键 从空间邻接和空间分离两个角度定义和研究空间分布特征  空间邻接  已有研究采用对象间的公共边长度信息来表达对象的邻接关系 它忽略了周围对象的序列和特征信息，而这些信息对于表征空间分布非常重要 对象邻接关系的三种信息： 邻接对象特征、邻接顺序和邻接边长   空间分离  空间分离特征度量每个对象与不相邻的各类对象的空间关系 由每个对象到每个类别的最小距离、平均距离和主要方向组成        地理场景分割  聚合：基于这些关系图聚合每类对象形成对象簇，在聚合过程中考虑它们在对象个体特征以及空间分布特征上的相似性。  每个地理场景中的同类对象在个体特征和空间模式上应该相似 基于关系图进行空间聚合  对象被表达为节点，它们的关系由无向边来表示，只有链接在一起的对象才可以被聚合 链接定义：如果两个对象属于同一类别且?2与?1的重心距离小于20 ?，则这两个对象存在边链接。 聚合算法是基于分形网络演化理论 阈值-地理场景分割尺度   通过聚合，每类土地覆盖对象可以生成许多对象簇， 而这些对象簇空间上是分离的。   扩张：聚合形成的对象簇空间上不连续，将对这些对象簇在空间上进行扩张形成空间上连续的、以某一类对象为主的地理场景。  聚合生成对象簇在空间上不连续，因为每个类别的对象簇中间有其他类别的对象。地理场景在空间上应该是连续的， 因此提出使用扩张的方法来解决对象簇空间不连续的问题 吸引力模型   空间叠加：多层不同类型的地理场景进行空间叠加， 它们的公共部分作为地理场景分割结果  地理场景不是按土地覆盖类别分层表达的，而是包含所有类型的对象 消除、合并破碎的地理场景 考虑其在空间分布特征上的相似性，可以将较小的地理场景合并至相邻的场景中    多尺度分割  现实中城市功能区的大小和异质度可能都不同➡️多尺度 较小尺度生成面积较小且详细的地理场景用于表达相对均质的功能区， 如公园和居民区； 而大尺度生成面积较大且粗略的地理场景用于表达具有高度异质性的城市功能区， 如学校、商业区。 多尺度分割结果组织方式 层次结构 非层次结构   为了实现层次多尺度分割，最小尺度的地理场景是通过地理场景分割直接生成的，而其他尺度的地理场景是通过聚合小尺度场景生成生成的。 层次结构对于生成多尺度地理场景分割结果效率更高， 而且层次关系对于分析功能区也很重要  分割结果评价  基于兴趣点的功能区分割评价方法：假设每个城市功能区内的 POI 集中于 1-2 类别。因此， POI 类别单一纯净的功能区分割结果的精度高， 相反如果一个功能区包含许多类 POI，说明分割结果较差精度偏低。 使用每平方米 POI 信息熵的倒数来定义 POI 的纯净度。（很有道理，但是又觉得哪里不对，或者哪里不严谨?） ??代表分割结果的整体精度  实验分析 实验数据 多尺度功能区分割提取结果  面向对象分析中常用的对象特征 流程  多尺度分割（MRS）➡️对象 对每个对象提取视觉特征 手工标注训练样本，SVM对象分类 提取对象空间模式特征，尺度缩放至（0，255）   地理场景分割尺度：70、 90、 110、 130 和 150 这五个尺度 子区域分析  分割尺度在功能区分割提取中扮演着重要的角色，不同类型的功能区应使用不同的尺度进行划分。➡️有必要选择一个最佳尺度来生成最终的功能区分割结果 130尺度    空间模式特征在功能区分割中重要性评价  本实验旨在评估空间格局特征在功能区分割中的重要性，回答空间格局是否比对象个体特征更重要的问题。（话术） 结论：  空间模式在功能区分割中比对象个体特征更重要，但不能忽略对象个体特征的在功能区分割中的贡献。（话术） 对于整个研究区使用 130 尺度和??? =0.7 可以生成最精确的功能区分割结果    功能区分割提取结果  提取生成了 386 个功能区单元 选取了五个子区域进行目视判读   讨论 本章方法与传统的功能区分析对比  城市功能区分析属于景观生态学、 城市规划学和人文地理研究的范畴，具有广泛的应用前景， 但是还存在许多技术问题 功能区通常具有不同的形状和大小，应该在不同的尺度上进行分析 三个方面与现有的功能区分析有所不同  首先，本研究使用多尺度地理场景作为功能区分析的空间单元，而其它研究则使用图像瓦片。地理场景可以表达任意形状的功能区，既能保持地物对象的完整性，又能保证功能区之间的独立性。 第二， 地理场景的分割尺度指的是地理场景内部同类对象的异质度，而图瓦片的尺度则是直接测量其大小。在实际应用中，多尺度地理场景比多分辨率图像瓦片更适用于多粒度表达和分析城市功能区。 第三，除了空间单元和分析尺度之外，使用的特征也不同。    面向地理场景分析与面向对象分析对比  本研究所提出的基于地理场景的的影像分析（Geoscene-based image analysis,GEOSBIA）旨在通过聚合地理对象（Geographic-object-based image analysis, GEOBIA）来分析功能区。 GEOSBIA 与 GEOBIA 存在显著差异，但它们也有着密切的关系。  本章小结 瞧瞧别人的总结能力\n 本章节的研究成果可以概述为以下四个方面：  提出了表达地物空间格局的特征，并将其用于功能区划分 首次提出了一种多尺度功能区分割提取的方法 讨论了尺度和空间格局权重两个参数对提取城市功能区的影响 利用所提出的方法对北京地区的功能区进行了多尺度提取。   方法应用于北京地区的功能区分割提取获得了以下四个结论：  首先， 地理场景分割可以在不同尺度上提取不同的城市功能区。 其次，在提取功能区时，空间模式特征比对象的个体特征更重要。 第三， 本章研究方法不同于以往的城市功能区分析， 体现在所使用的空间单元、特征和分析尺度。 第四， 本章提出的地理场景不同于传统单元（如像素和对象），基于地理场景的图像分析是对传统的基于像素和对象分析的有益补充，对于高分数据分析而言有重要意义。    第三章 自适应尺度学习：功能区分割尺度优化 引言  第二章实验发现：功能区具有尺度不确定性 ➡️ 抛出问题：如何自动确定和计算每个功能区的局部最优分割尺度以提高功能区提取精度？ 已有的分割尺度评价方法都是从全局的角度选取一个分割精度最高的尺度作为最优尺度， 但是受功能区异质性的影响，不同功能区的最佳分割尺度通常是不同，因此最优分割尺度应该是一个局部变量。 本章提出了一种局部自适应的分割尺度学习方法 三类分割现象：欠分割、过分割、正确分割（最优分割） 每个功能区的最优分割尺度受到三个因素影响： 功能区类型、 内部异质性、 与相邻功能区的差异性 根据所使用的尺度，现有的分割方法可以分为三类  固定尺度分割  包括：基于边缘的、 基于区域的和基于图的分割 全局的、固定的分割尺度对图像进行分割 用户手工指定 ➡️ 分割结果是不准确，很难满足城市功能区提取的要求   多尺度分割  考虑了不同类别的功能区， 认为功能区类别是决定分割尺度的关键因素，即每类功能区对于一个最佳分割尺度 （第二章） 多尺度分割只能为每个类别选择一个尺度，忽略了功能区个体之间的差异 多尺度分割效率很低，因为需要大量人力和计算资源来手动地为不同类别选择最佳的分割尺度 不同的功能区产生于不同的尺度层， 这对于制图和拓扑分析而言是非常不利的   变尺度分割  通常使用卷积窗口度量窗口内局部对比度并估计局部分割尺度 忽略了功能区的分类体系；计算局部对比度的窗口大小仍然是全局固定的，手动设置的； 变尺度分割仍然不能做到局部自适应，不能获得准确的分割结果     综上所述，已有的分割方法主要使用固定尺度、多尺度和可变尺度， 这些尺度没有充分的考虑和建模影响分割尺度的三个因素， 无法实现局部自适应尺度分割， 因此它们获得的分割结果不够准确无法满足功能区制图应用需求。本章节希望自动地学习局部自适应分割尺度，并使用自适应尺度优化多尺度地理场景分割结果，准确提取城市功能区。  自适应尺度功能区分割 自适应分割尺度学习  基本思路：利用特征重要性度量尺度重要性， 基于尺度重要性选择局部最优分割尺度  首先，在不同的尺度层上分别提取特征； 然后， 使用特征重要性评价方法计算每个特征的局部重要性； 最后， 归算每个尺度层上的特征重要性获得对应尺度的局部重要性，选取重要性最大的尺度作为局部自适应分割尺度。 该研究思路中最重要的是构建局部特征重要性评价方法 ➡️ 改进随机森林的特征重要性评价方法    自适应尺度约束下功能区分割  采用层次结构组织存储多尺度功能区分割结果 大尺度功能区与小尺度功能区具有一对多的层次映射关系 最大尺度的功能区分割结果是欠分割的；而最小尺度的分割结果通常是过分割的；最佳的功能区分割尺度应该位于若干个中间尺度层上。 将中间尺度内的多尺度分割结果根据自适应尺度学习结果进行重新的排列组合， 形成新的分割结果，最终用于表达自适应分割尺度的功能区提取结果。 自适应分割尺度是逐像素计算的， 即每个像素都被标记了一个自适应尺度。 进而利用最大尺度功能区作为统计单元， 统计每个功能区内的自适应尺度的频率分布， 认为出现频率最高的尺度就是该区域功能区分割的最佳尺度。  实验分析 自适应分割尺度学习结果  本节选取了 90、110 和 130 三个尺度的分割结果（图 3.6 b-d） 进行自适应尺度学习，利用层次结构组织和存储这三个尺度的分割结果，对分割结果进行重构。 特征构建：对每个分割结果提取视觉特征以及景观特征  视觉特征使用对象视觉特征的频率分布来表示（80维） 景观特征是通过景观格局指数进行度量， 景观格局指数适用于描述景观空间结构的特征， 包括景观破碎度、分离度、 多样性、 分维数和聚集度等（5维度） 而对于每个像素而言，它对应三个多尺度分割块，因此每个像素可以被85 × 3 = 255维特征所描述   学习局部个性尺度本质上就是利用随机森林分类器计算这 255 维特征对于分类该像素的重要性 尺度重要性的空间分布和功能区的局部自适应分割尺度分布结果： 每类功能区中各种自适应尺度所占比例结果：  自适应尺度分割结果  最终自适应尺度分割结果是组合了三个不同尺度的分割结果 基于POI的分割精度评价 子区域多尺度分割与自适应分割结果对比  讨论  自适应尺度学习方法的优势：  首先， 自适应尺度学习仅依赖少量的训练样本， 就可以从多尺度分割结果中学习到局部自适应的尺度，学习过程是数据驱动的，而监督样本是知识驱动的。 其次，自适应尺度是一个局部变量，能够根据局部建筑环境的变化进行自动调整。 第三，自适应尺度学习过程中充分考虑了多尺度特征信息。 第四， 除了功能区分割制图以外，自适应尺度还有可能应用于其它领域， 比如城市调查（温度、污染、人口、犯罪和经济的空间分布）。这些调查都需要在合适的尺度上进行， 已有的城市调查方法常常是基于街区等固定尺度来进行的，因此忽略了调查变量的尺度效应以及空间非平稳性， 这使得调查结果不可靠。因此， 在城市调查中需要使用自适应尺度。例如， 在调查城市地表温度时， 应使用自适应尺度分割结果作为空间单元进行地表温度反演。    本章小结（Conclusion模板） [这里也体现了Conclusion和Abstract的不同]\n 问题：尺度不确定性 已有的分割尺度分析方法：全局角度 本文（本章）：旨在提出一种自适应尺度分割方法 重要结论：  首先， 不同功能区的最佳分割尺度是不同的， 其受功能区类别、与周围环境对比度以及内部异质度的影响。 其次，自适应尺度分割解决了城市功能区分割提取中跨尺度的问题，其结果优于多尺度分割结果。   重要贡献：  提出了自适应分割尺度学习方法， 该方法充分建模分析了影响分割尺度的三个因素; 提出了自适应尺度约束下的分割优化算法， 并将该方法用于分割提取北京地区的功能区。   贡献总结：根据已有工作检索结果发现本章首次实现了高分影像的自适应尺度学习及分割优化方法， 解决了地物分割提取中跨尺度的问题，推动了高分影像分割技术的发展。 尽管自适应尺度在功能区分割中表现良好，但仍有一些问题有待进一步研究。  第四章 空间语义共生概率模型：功能区空间格局特征表达  特征度量与表达是功能区分析的基础，因此如何提取有效的功能区特征是本章研究的重点。 传统的图像视觉特征难以充分表达城市功能区， 而空间格局特征是表达功能区的关键。空间格局特征的提取和计算结果不稳定， 易受仿射变换影响。 充分考虑功能区的综合性和异质性，研究并提取更加鲁棒的空间格局特征对城市功能区进行表达。  引言  从计算机视觉的角度来看，遥感影像中的城市功能区可以通过不同的特征进行表达， 如视觉特征、抽象特征、语义特征  视觉特征 抽象特征 语义特征   上述这些特征不适用于表达功能区的本质原因是，这些特征都是从计算机视觉角度定义的、 用于表达图像场景的， 但是图像场景和功能区影像是有明显差异的： 功能区是有明确的地理学、景观生态学含义的，其影像能够体现出不同的建成环境， 而图像场景是缺乏明确定义的，一般来说任何一个图像块都可以成为图像场景 作为城市功能区的基本组成部分，对象及其空间格局是功能区分析的基础 对象的空间关系包括不同对象之间的距离关系和方向关系。度量对象的空间关系常受三个问题的影响，包括各向异性、尺度依赖性和语义依赖性。对象的空间关系度量可能受三个因素的影响： 方向、距离、对象语义， 因此在度量空间关系时应充分考虑这三个因素 综上所述（学习叙事逻辑）  已有的关于城市功能区特征表达的研究工作大多忽略了对象的空间格局信息，因此难以获得准确的表达功能区和获取高精度的功能区分析结果； 近期一些研究已经注意到对象空间信息对于功能区影像分析的重要性， 但是它们忽略了对象空间信息度量中存在的三个重要问题（即各向异性、尺度依赖性和语义依赖性）。 本研究考虑了这三个特性，并通过度量对象在空间上和语义上的共生关系来表达功能区的空间格局进而对城市功能区进行特征表达。 为实现这个目标， 需要回答两个问题： 第一， 如何度量对象的空间格局？ 第二， 如何利用空间格局对城市功能区进行分类？ 因此， 本章提出了一种新的功能区空间语义特征用于表达功能区内部地物的空间格局，然后将其与分类器结合实现城市功能区分类识别。    地理对象的空间语义共生分析  基本思路是以对象类别语义为基础，度量不同对象之间在不同方向和不同距离上的共生概率，然后对不同方向和距离上的共生概率做二次卷积获得空间语义共生概率密度函数。  实验分析 先使用公共数据集进行场景分类，再使用北京的数据进行功能区分类\n第一部分：使用公共数据集，将本章所提出的空间语义特征与其它场景特征进行对比  公共数据集：UC Merced Land Use Dataset。 包括 21 个土地利用类型，每类有 100幅图像（256× 256 像素）。 主要实验步骤：对象识别和土地利用场景分类 对象识别：首先利用 multiresolution segmentation（MRS; Baatz 和 Schäpe, 2000） 分割方法将每个图像根据颜色分割成不同的对象。然后，提取图像对象特征包括光谱特征、纹理特征和几何特征（表 2.1）。最后，利用支持向量机分类器（Suykens 和Vandewalle, 1999）将这些对象分为阴影、水体、 植被、土壤、建筑物、道路、船舶、车辆、飞机等 9 类。 功能区分类：提取 SSCP 作为空间语义特征对每个图像场景进行数字化表达，在特征表达的基础上使用 semi-latent Dirichlet allocation（S-LDA; Wang, Sabzmeydani 和 Mori, 2007）监督分类器对 21 类图像场景进行分类，其中随机选择 80%图像场景作为训练样本，而另外 20%则用作测试样本。此实验使用五次交叉验证方法对分类结果进行评价（表 4.1），并使用平均生产者精度（每类正确分类个数与测试样本数的比值）来衡量每个类别的分类精度。➡️ 精度高达97.6% 与前人方法比较    第二部分：北京地区功能区表达与识别  分类：商业区、 居民区、工业区、学校、公园、城中村。 为了对表达和识别这些功能区，本实验分为以下四个步骤： 首先用道路网数据将高分遥感影像分割成不同的功能区。结果，生成 254 个具有不同形状和大小的功能区单元。然后，用 MRS对每个功能区中的对象进行分割，并用支持向量机对这些对象进行土地覆盖分类，共提取了七类土地覆盖对象，包括阴影、植被、土壤、水体、建筑物、工厂和道路。接着，提出的空间语义共生分析方法对每个功能区提取了 SSCP 特征。最后，使用 S-LDA 算法对城市功能区进行分类。  根据城市规划图和实地调查结果，人工选取了** 63 个功能区作为训练样本**。这些样本用于训练 S-LDA 分类器， 进而将其他 191 个未标注样本划分为不同的类别。为了定量地评价此分类结果， 基于百度地图以及高德地图对分类中的 **191 个功能区进行人工分类和手动标注**。 这里将人工识别结果作为测试样本，对功能区分类结果进行精度评估。  讨论  哪些对象的空间关系在表达功能区中更为有效：Relief 算法 SSCP 的三个重要的特性 SSCP 与其它空间特征的对比 SSCP 特征的优缺点  本章小结 第五章 层次语义认知模型： 功能区多源特征层次依赖性表达  单一特征难以全面地、 充分地表达功能区，因此需要组合多源特征对功能区进行表达 在组合这些多源异构特征时，发现这些特征之间具有很强的层次依赖关系： 视觉特征是获取对象语义特征的基础，而对象语义特征是获取空间格局特征的基础。 本章研究层次语义认知模型， 在多个层次上（纵向上） 对城市功能区进行特征表达，并且建模多源特征之间的层次依赖关系。  \n\n","description":"","id":50,"section":"posts","tags":["博士论文","阅读笔记"],"title":"博士论文阅读札记-3","uri":"https://www.xunhs.cyou/2020/11/17/106/"},{"content":" 出差，地理大数据开发，月末完完整整的是ppt汇报人\u0026hellip;\n \n 2020.11.1 团队聚餐 + 尽情ktv 竟然还有唱日语歌的小师弟 惊艳到了 2020.11.2 按计划来说我仍将飞往月球，亲爱的人，书架上的东西如果无端掉落，就是我要回来的信号。 2020.11.3 今日份被嫌弃。\u0026ldquo;你看我穿这件衣服会不会太成熟了啊\u0026rdquo; \u0026ldquo;你都快三十的人了。不应该这样穿吗\u0026rdquo;； 月亮不会奔向你，但我会，不远万里的那种 2020.11.4 再也不喝凉咖啡了 还是隔夜的? 2020.11.5 广州见 2020.11.6 一座城市，一些新鲜感 2020.11.7 我也有了第一个“帽子”；MapGIS中年ktv之夜：专家教授们都玩开了 2020.11.8 老爸生日快乐!；为了这次相遇，我连见面时的呼吸都曾反复练习。很开心能见到你，畅聊一下午，虽然后来都忘记我们聊了啥，能够与你漫步这么久已经非常开心👫 2020.11.9 果然到了武汉天气就冷了下来，晚上又换上了卫衣、怀念南方的天气。收拾好心情再出发 2020.11.10 论文找不到创新点时，以“某某缺乏深入研究的问题”作为论述，把自己逗乐了 2020.11.11  人间的苦\n比如 寒冬刺骨 老病孤独 痛失或别离\n只是一场 流转和经过\n浮出水面 又扎进泥里\n呼啸而来 又呼啸而去\n殷勤面对就好了 何必沉溺 人间的甜\n比如 春日的逍遥 恰时的少年 亲爱的你\n只是阳光洒在肩上 夏冰含在嘴里 薄荷刚好新绿\n心生欢喜就好了 何必沉溺   2020.11.12 西安见；小燕子-大悦城凑凑火锅-大雁塔南广场-大唐不夜城 2020.11.13 参加长安大学举办的测绘博士论文，疫情期间还是蛮多人来酒店参会的；感觉长大准备的蛮好，组委会很热心，本来说没有的午餐和晚餐也提供了，酒店住宿也很舒服，可以说已经非常周到了。虽然研究主题相关度不是很大（话说我的专业就是测绘科学与技术），这次参加收获还是有的。学习大佬们的报告，学习他们的故事，学习他们基金本子怎么来的，怎么讲故事。晚上甄博士的姐姐请我们吃饭，挑的一家西安特色的店-遇见长安，菜品都蛮有特色的，其实之前打卡过这些菜品，什么毛笔酥呀、酱猪蹄等，味道还是蛮不错的。 2020.11.14 今天和小燕子开车去诗经里玩。兜兜转转、散步谈心，回来开车是我开回来的，路上蛮堵的，一个小时的路程硬是开了两个小时，还有晚上开车，我确实还不适应。晚上去一家酒馆-三巡酒肆吃饭，味道还是蛮不错的。高处看西安的夜景确实很美。特色的清酒也很不错 2020.11.15 疲惫的返程。现在超级不喜欢做高铁。目前是这样的；晚上和阿伟聊天，感觉某些方面像极了自己以前的样子，但他比当时的自己更有能力、也更有思想，在我看来，他不过是暂时的情感迷惑吧，希望他尽快走出来。 2020.11.16 “所以结论是：人其实是一种很无趣的动物。”-“那是你。”；校级科报会答辩，终于做好了ppt。其实内容没大变，把ppt精修了下，再就是好好准备吧，月底就要答辩了，其实五分钟答辩挺难的；晚上把长摘要好好改了改，基本内容够了吧。再就是精修一下就可以发出去了；地理大数据的拖到现在，项目组终于开始催了。接下来要好好测试了，别人都有测试通过的了。 2020.11.17 男士洗面奶推荐：smzdm 2020.11.18 这两天看到比较多的一个词：chaos 2020.11.19 最后还是把那套大地色的西服给退掉了、哎 2020.11.20 I love three things in this world. Sun, Moon and You. Sun for morning, Moon for night, and You forever. 2020.11.21 He understands you better than yourself👊 2020.11.22 由于几天前左眼有一点小小肿胀(借口)，所以给自己放了几天假。今天甚至顶着寒风出去逛街，买了几件衣服(西服+呢子大衣+针织开衫)，花的蛮通透。 2020.11.23 三旬尚远浓烟散，一如年少迟夏归 2020.11.24 博士新生分享会 2020.11.25 一如年少模样 2020.11.26 身体和思想，总有一个在路上 2020.11.27 总归是自己哪里做的不够好吧 这次科报会还是学习到很多的 2020.11.28 晚上一觉睡得是真的舒服 2020.11.29 Sony α6400 小心翼翼打开心爱的玩具盒 2020.11.30 买的时候犹豫，其实这是一件很提升幸福感的事。  ","description":"","id":51,"section":"posts","tags":null,"title":"2020-11","uri":"https://www.xunhs.cyou/posts/journals/2020-11-01-2020-11/"},{"content":" 与地理知识发现相关的文本挖掘论文阅读总结\n 2017 - Extracting and analyzing semantic relatedness between cities using news articles   Yingjie Hu\n  International Journal of Geographical Information Science\n  https://www.tandfonline.com/doi/abs/10.1080/13658816.2017.1367797?journalCode=tgis20\n  札记  Abstract短小精悍，逻辑性很强 Introduction部分写的蛮好，advantages 和 potential applications 部分做撰写参考 创新点在于这个 computational framework；其框架里的方法我觉得还是蛮容易理解的  Abstract  news articles reflect socioeconomic activities + public concerns that exist only in the perceptions of people cities are frequently mentioned in news articles, and two or more cities may co-occur (共现) in the same article. co-occurrence =\u0026gt; relatedness between cities =\u0026gt; be under different topics semantic relatedness: the relatedness under different topics By reading news articles, one can grasp the general semantic relatedness between cities given hundreds of thousands of news articles, it is very difficult for anyone to manually read them. proposes a computational framework:  extract the semantic relatedness between cities based on a natural language processing model and employs a machine learning process to identify the main topics more than 500,000 news articles covering the top 100 US cities spanning a 10-year period. perform exploratory visualizations of the extracted semantic relatedness under different topics and over multiple years analyze the impact of geographic distance on semantic relatedness and find varied distance decay effects    Introduction  news articles  rich information timely published online =\u0026gt; becomes useful data resource for answering scientific questions   cities in news articles  cities are frequently mentioned in news articles. =\u0026gt; relatedness Cities can be related under a variety of topics. =\u0026gt; similarity / dissimilarity cities are interrelated into a network, in which the nodes are cities and the edges can have different semantics By reading news articles, one can grasp the general semantic relatedness between cities given hundreds of thousands of news articles, it is very difficult for anyone to manually read them.   the notion - semantic relatedness  semantic relatedness in NLP  the words cat and mouse most people would consider them as related there exist films, books, and personal stories that link these two words together   =\u0026gt; the semantic relatedness between cities   advantages in using news articles for extracting semantic relatedness between cities  accessed relatively easily capture diverse city relations enables a temporal exploration discover the intangible (抽象的，无形的) city relatedness perceived by people   potential applications  In city planning and policy-making In geographic information retrieval (GIR) integrated with existing research on place-based GIS There also exist other possible applications   contributions  a computational framework varied distance decay effects of the semantic relatedness perform exploratory visualizations on the multiple city networks；explore the temporal variations of the semantic relatedness between cities over years    Method and Results  其实我理解就三个过程(Orz)：提取topic+建立语义关联+时空分析   4,950-by-17 matrix  each row representing one city pair each column representing one IPTC topic cell containing the relatedness value of a city pair under a topic   two exploratory visualizations  based on the topics =\u0026gt; construct 17 city networks based on the 17 IPTC topics based on the years =\u0026gt; obtain 10 matrices, each of which is 4,950 by 17 and contains the semantic relatedness in each year   the extracted semantic relatedness also opens the door to many other research questions, which can be grouped from spatial, temporal, and thematic perspectives.  distance decay analysis    ","description":"","id":52,"section":"posts","tags":["文本挖掘","论文阅读"],"title":"Papers Reading-文本挖掘","uri":"https://www.xunhs.cyou/2020/10/28/104/"},{"content":" 文献阅读：城市功能区划分与城市土地利用分类相关。主题为遥感数据与社交型大数据融合方法。\n 2016 - Mapping Urban Land Use by Using Landsat Images and Open Social Data  remote sensing https://doi.org/10.3390/rs8020151  札记  Introduction 讲的城市化进程和land use、land cover的差异写的不错，值得借鉴参考 Introduction 他一直在讲 relatively large spatial scale Introduction 还是从遥感的角度来讲的，open social data的戏份不多；而且有种虎头蛇尾的感觉 Two-steps classification: 先区分建成区和非建成区，在此基础上两类分类  标签  RS + POI  Abstract  high-resolution urban land use maps have important applications the availability of these maps is low in countries such as China using satellite images and open social data  used 10 features derived from Points of Interest (POI) data and two indices obtained from Landsat 8 Operational Land Imager(OLI) images   classify parcels into eight Level I classes and sixteen Level II classes of land use (两级分类) tested in Beijing, China  Introduction  城市化的背景（可以借鉴参考）：Urbanization in China =\u0026gt; Large-scale urbanization has had a dramatic impact =\u0026gt; Studies that assess this process and its impacts are important =\u0026gt; To achieve these goals, detailed urban land cover/use maps are required [land use和land cover的差异] Currently, land cover information is a primary data source =\u0026gt; detailed information on urban land use is needed  land use is a cultural concept that describes human activities and their use of land whereas land cover is a physical description of land surface land cover can be used to infer land use, but the two concepts are not entirely interchangeable.   然而，  问题1：high-resolution urban land use maps covering large spatial extents are relatively rare 原因-发展中国家认知和技术不行：local knowledge and the techniques necessary for developing these types of maps are often not available, particularly for developing regions 问题2：outdated maps 原因：urban land use maps are normally produced by interpreting aerial photographs, field survey results, and auxiliary materials, such as appraisal records or statistical data 因此：As a result, to obtain land use maps that capture the pace of urban development in a timely and accurate manner at a relatively large spatial scale is a critical challenge in urban studies, both in China and in other countries facing similar situations.   Satellite-based remote sensing holds certain advantages  large spatial coverage, high time resolution, and wide availability pixel-based image classification methods: using spectral and/or textural properties per-field and object-based classification methods medium-resolution satellite images difficult to extract socioeconomic features of urban areas cannot provide sufficient separation among urban functional zones high spatial and spectral resolution satellite images provide more detailed information on urban structures 贵: prohibitively expensive in general   emergence of open social data =\u0026gt; mapping urban land uses at high-resolution containing spatiotemporal patterns of human activities the existing studies were often implemented over relatively small areas or specific land use types using data sets that were subjective or proprietary(主观) the physical attributes of urban functional parcels were seldom included integrating social knowledge with remotely sensed data  physical features extracted from satellite data socioeconomic features retrieved from open social data One type of open social data that is particularly promising for this purpose are Points of Interest (POI) data. [就当时而言吧] As far as we know, there are no reports on using POI data and satellite data jointly to produce detailed land use maps. 我们的工作: developed a protocol that utilizes medium-resolution satellite images and POI data to map urban land uses.    数据和方法  Method 两步划分 [先划分为建成区和非建成区] differentiate the built-up and non-built-up areas based on classified impervious surface(不透水面) areas the classified built-up and non-built-up regions were merged into a final land use map   Classification System - 分类系统  built-up area as places dominated by artificial buildings and structures non-built-up area as places mainly occupied by cultivated land, forests, grassland, water and water conservancy facilities two-level classes    2017 - Classifying urban land use by integrating remote sensing and social media data  International Journal of Geographical Information Science https://doi.org/10.1080/13658816.2017.1324976  札记  groud truth是通过人工目视解译打的标签 工作流还需要很多手工调参的地方，比如kmeans等 使用的基础特征，如low-level的visual features和frequent features 没有充分利用数据带来的特征。  标签  RS与多源社交媒体融合 融合方法：土地利用词典  Abstract  accurate classification of urban functional zones urban land use classification by considering features that are extracted from either high spatial resolution (HSR) remote sensing images or social media data, but few studies consider both features due to the lack of available models. Proposed: a novel scene classification framework to identify dominant urban land use type at the level of traffic analysis zone by integrating probabilistic topic models and support vector machine A land use word dictionary fusing:  natural–physical features from HSR images socioeconomic semantic features from multisource social media data   comparing with manual interpretation (人工目视解译) data  Introduction  背景论述: Land use and land cover (LULC) information =\u0026gt; urban functional zones which reflect in urban land use patterns =\u0026gt; the effective detection of urban land use patterns High spatial resolution (HSR) remote sensing images  computation-based urban land use detection three types of spatial units  units of pixels and objects are usually employed to evaluate land cover, whereas scenes are commonly used to identify urban functional zones and accurate urban land use patterns   object-oriented classification(OOC) models  physical features (such as spectral, shape, and texture features) of ground components 缺陷: often overlook the spatial distribution and semantic features of ground components because they were\nonly designed to mine the low-level semantic land cover information of ground components     Semantic Gap  low-level semantic features indicate ‘information’ that comes with the data directly high-level semantic features refer to ‘knowledge’ specific for each user and application semantic gap refers to the disparity (不一致) of features identified between these two levels   To bridge the ‘Semantic Gap’ between LULC, recent studies have introduced the concept of ‘scene classification’ into HSR image classification to label a scene with a single category  Current studies: apply the bag-ofwords (BoW) modeling approach and fuse physical features of ground scenes via\nprobabilistic topic models (PTMs) However, extracting features from remote sensing images can only represent the external (外部的) natural–physical properties of ground components, whereas regional land use types often have a strong correlation with indoor human socioeconomic activities, which are difficult to extract from HSR images.   To solve this problem, recent studies have proposed the concepts of ‘social sensing’ and ‘urban computing’  Multisource social media data =\u0026gt; monitor residential activities and urban land use dynamics   However, these methods utilize only one type of data rather than fusing geospatial information from HSR images and social media data into the detection of land use types.  假设-同类区域同特征: Regions with similar types of urban land use tend to have similar external natural–physical properties and indoor human socioeconomic activity patterns   本文工作:  aims to build a dominant urban land use sensing framework by combining several machine learning and natural language processing (NLP) models to fuse the geospatial latent semantic information extracted from HSR images (remote sensing information) and multisource social media data (social sensing information) as patterns to classify the urban land use and evaluate the accuracies and reliabilities of classification models by manual interpretation Haizhu district in Guangzhou    数据及方法   遥感数据\n high spatial resolution (HSR) Worldview-2 image 2014，grid size of 34,263 × 14,382 and a spatial resolution of 0.5 m Taz换分为 593 land patches 手工目视解译打的标签，包含七类: public management services land (M), industrial land (I), green land (G), commercial land(C), residential land (R), park land (P), and urban villages (U).    社交媒体数据\n OpenStreetMap (OSM) road networks Gaode POIs (说是用API获取的，没说时间) real-time Tencent user density (RTUD)：spatial resolution of 25 m    Method\n K-Means需要手工定义参数；使用low-level的visual features； 一股脑都当做单词了    2017-Hierarchical semantic cognition for urban functional zones with VHR satellite images and POI data  ISPRS Journal of Photogrammetry and Remote Sensing http://dx.doi.org/10.1016/j.isprsjprs.2017.09.007 张修远  札记 标签 Abstract  [功能区划图不好拿]functional-zone maps are hardly available in most cities [急需(半)自动化的方法]an automatic/semi-automatic method for mapping urban functional zones is highly required [继承性语义识别]Hierarchical semantic cognition (HSC) relies on geographic cognition and considers four semantic layers with a very-highresolution (VHR) satellite image and point-of-interest (POI) data result: overall accuracy of 90.8%; the contributions of diverse semantic layers are quantified  2018 - Integrating Aerial and Street View Images for Urban Land Use Classification  remote sensing https://doi.org/10.3390/rs10101553  札记  街景空间对齐的方式 feature maps stacking 实验明明做出来是遥感影像语义分割的结果呀~感觉是套上Urban land use的壳，做着语义分割的活 特征自对比；没有与其他方法/baseline的对比  标签  Aerial and Street View Images Pixel-level land use classification SegNet based Encoder-Decoder 端到端  Abstract \u0026amp; Introduction  Urban land use rely heavily on domain experts in this paper  deep neural network-based approaches label urban land use at pixel level using high-resolution aerial images and ground-level street view images   specifically  extract semantic features from sparsely distributed street view images interpolate(插值) them in the spatial domain to match the spatial resolution of the aerial images fused together through a deep neural network for classifying land use categories tested on a large publicly available aerial and street view images dataset of New York City   Results  using aerial images alone can achieve relatively high classification accuracy the ground-level street view images contain useful information for urban land use classification fusing street image features with aerial images can improve classification accuracy street view images add more values when the resolutions of the aerial images are lower   Contributions  presents a novel method to fuse extracted ground-level features from street view images with high-resolution aerial images to enhance pixel-level urban land use classification accuracy; two sources of images collected from totally different views (i.e., overhead and ground-level views) examines the impact of aerial image resolution changes on classification accuracy; investigate into the contribution\nthat street view images make to the improvement of the classification results explore deep neural network methods for pixel-level urban land use classification =\u0026gt; enriches the remote sensing applications    Method  Ground Feature Map Construction （怎样特征空间对齐的） semantic feature extraction  pretrained Places-CNN (without the last fully connection layer) =\u0026gt; extract a 512-dimensional feature vector for each image concatenate the extracted four feature vectors into a 2048-dimensional feature vector for each location principal component analysis (PCA) is used to compress semantic information and reduce the dimension of the feature vector to 50   spatial interpolation  起因：places with street view images are sparsely distributed along roads in the spatial domain street view images capture the scenes of nearby visual areas instead of single dots in the space [街景捕捉周边的场景] 因此，project the semantic information of street view images to their covered areas from top-down viewpoint 策略：  use spatial interpolation method - Nadaraya-Watson kernel regression estimate the impact of nearby street view images on a pixel - Gaussian kernel to calculate weights       Data Fusion (怎样融合训练的) two encoders: feature maps stacking the output feature map is fed to a Softmax layer to make pixel-level predictions    2019-Beyond Word2vec: An approach for urban functional region extraction and identification by combining Place2vec and POIs 2019 - Model Fusion for Building Type Classification from Aerial and Street View Images  remote sensing [半个月就接收了！不可思议，我的小修文章半个月还在编辑手里呢 Orz] https://doi.org/10.3390/rs11111259  札记  主要是做的用Google影像+街景识别建筑物功能，重点讲的在模型融合方面 研究现状讲的是urban land use with DL 做了一个summerized的表格 还行 写现状的时候可以回过来参考 结论是结论层的融合（虽然简单）比特征层的融合效果好，并简单分析了下原因  标签  Aerial and Street View Images Building Type Classification 融合策略：decision-level fusion vs feature-level fusion 端到端  Abstract  mapping building functions jointly using both aerial and street view images via deep learning techniques a data fusion strategy =\u0026gt; cope with heterogeneous image modalities (形态) geometric combinations of the features (图像的特征的几何组合) of such two types of images, especially in an early stage of the convolutional layers, often lead to a destructive effect (破坏性的效果) due to the spatial misalignment of the features (特征的空间错位). proposed a decision-level fusion of a diverse ensemble of models (compared to the common multi-stream end-to-end fusion approaches) sophisticated classification schemes =\u0026gt; highly compact classification scheme with four classes, commercial, residential, public, and industrial  Introduction  compared two model fusion strategies (two-stream end-to-end fusion network)  a geometric-level model fusion decision-level model fusion   A summary of the models and fusion strategies  Data and Method   Data\n we extracted geolocation and the attributions of building function annotated by volunteers from OSM. Then, the associated street view images and the overhead remote sensing images of each building instance were retrieved via BingMap API and Google Street View API using its geolocation    Building Classification Scheme/System\n  extracted the class of each building from the volunteered building tag from OSM\n  selected the 16 most frequently occurring building tags in our raw dataset and aggregated them into four cluster classes\n  follow a very basic but widely accepted classification scheme with four classes: commercial, industrial, public, and residential  Data Volume: 56,259 buildings with four images for each building (区域党？？为什么要分区域划分数据集呢？)\n the images from the state of Wisconsin and Wyoming were used as validation samples (1943 buildings) Washington and West Virginia were used as test samples (2212 buildings) remaining 47 areas were used as training samples (52,104 buildings)      Method\n existing deep neural networks pre-trained on very large datasets: Places365 and ImageNet two-stream end-to-end fusing networks decision-level fusion  combines the softmax probabilities or the classification labels directly model blending and model stacking   他的Experiments and Discussion（包含训练参数和训练过程）可以参考下，以后训练的经验    Conclusion  a decision-level fusion of street view and overhead images often outperforms a feature-level fusion, despite its simplicity we employed decision-level fusion strategies to achieve great performance without significantly altering the current network architecture  2020 - Deep learning-based remote and social sensing data fusion for urban region function recognition  ISPRS Journal of Photogrammetry and Remote Sensing https://doi.org/10.1016/j.isprsjprs.2020.02.014  札记  Introduction写的确实好，感觉没有一句废话。开头的背景介绍和方法、最后的文章总结都可以用作模板。 很好的方法类论文模板  标签  多模态：RS + 时间序列数据 端到端 改进损失函数  Abstract  Urban region function recognition effectively integrating the multi-source and multi-modal remote(多模态) and social sensing data remains technically challenging end-to-end deep learningbased remote and social sensing data fusion model two data sources are asynchronous (异步的) simultaneously optimizing three costs classification cost cross-modal feature consistency (CMFC) cost cross-modal triplet (CMT) cost conducted on publicly available datasets: 百度AI-城市区域功能分类; 飞桨官方基线 The results show that the seemingly unrelated physically sensed image data and social activities sensed signatures can indeed complement each other to help enhance the accuracy of urban region function recognition  Introduction  背景 - [从城市区域有限，城市人口膨胀角度论述背景，可参考] it is of great importance to monitor and manage the limited urban areas for such a huge population 研究问题 - urban region function recognition VS land use and land cover (LULC) classification (各有各的说法吧)  LULC stresses on physical characteristics of the earth surface urban region function recognition focuses purely on socioeconomic functional attributes of urban regions region function recognition using remote sensing images alone is not sufficient   数据 - [这一段写的蛮好，逻辑性也很强]  social sensing big data  by-products of human daily life; contain rich socioeconomic attributes   When these data meet with remote sensing, the promising trend is to fuse them to recognize urban functions, since the two kinds of data are complementary to each other (这句感觉写的蛮好) [问题来了] remote and social sensing data are significantly different in terms of sources and modalities [关键在于解决这个问题] The key challenge is to alleviate the modality gap and heterogeneity between them   方法 - deep learning  powerful abilities to automatically learn high-level features from large amount of data   本文工作及贡献  [设计模型] end-to-end deep multi-modal fusion method [两种处理网络] two effective neural networks to extract temporal signature features automatically [两个costs] two auxiliary losses =\u0026gt; address the data asynchronous problem [设计实验并分析] conducted extensive experiments on open available datasets; analyze and discuss the results thoroughly to give insights into fusing the two multi-modal data   相关工作部分一些总结  Remote and social sensing data are of significantly different sources and modalities, they possess different information about urban land surface and are complementary to each other Most existing works use handcrafted features (手工特征), which require human experts and are laborious.    方法和数据  Framework image encoder =\u0026gt; extract time-dependent features from time-series signature data temporal signature (TS) encoder Fusion methods: concatenation, element-wise sum, and element-wise max pooling. the fused feature is then fed into fully connected layers and softmax layer to make the final prediction. Loss functions  the major loss: cross entropy loss the auxiliary loss:  [两类特征尽量相似(cos相似性)] cross-modal feature consistency (CMFC) loss: Analogous to document alignment, since both the image and signature data are indicative of (象征) the same urban function properties of the same region, there ought to be correlation between them in spite of different modalities. The CMFC loss enforces the features of image and signature to be consistent and similar with regard to vector orientation. [三元组triplet损失函数] cross-modal triplet (CMT) loss: further utilizes the category information and tries to draw cross-modal features of the same class nearer, while push features of different classes far away        2020 - Recognizing urban functional zones by a hierarchical fusion method considering landscape features and human activities  Transactions in GIS https://doi.org/10.1111/tgis.12642  札记  Introduction套路有点熟，而且写得感觉有一点乱 所以方法的最后一步Recognizing到底是怎么做的呢？就是普通的叠加产生复杂区么？ 创新的地方个人感觉满牵强 能写出来也不容易  标签  RS + POI + Taxi GPS Trajectories hierarchical fusion method  Abstract  functional zones two basic factors  urban landscape environment: provides the basic space for human activity and influences urban land use at a coarse scale human activities: indicates the differentiation of functions in local urban areas   In previous studies, the hierarchical correspondence and interaction (层次对应关系和相互作用) between urban landscape and human activities have not been given full consideration in the cognition of urban functional zones, which would influence the accuracy and interpretability of the results. a hierarchical fusion method  a land use classification based on urban landscape features from remote sensing images fine‐grained functional semantics of local urban areas are recognized based on human activity patterns extracted from crowdsourced data (i.e., points of interest and taxi trajectories) the above results at different scales are fused with hierarchical constraints   Results  Wuhan, China overall accuracy of the proposed method is 82.51% (accuracies of the mixed functional zones and single functional zones are 77.93 and 87.96%, respectively) compared with state‐of‐the‐art methods, the proposed method performed better for the recognition of mixed functional zones    Introduction  第一段  urban functional zone定义 concept of functional zones与两个因素密切相关：  urban landscape: determines the basic type of urban land use at a coarse\nscale (such as water, forest, built-up areas) human activities: indicate the differentiation of functions in finegrained urban regions (e.g. the built-up area at a coarse scale may consist of residential, commercial, industrial, or mixed land use zones)   urban functional zone maps的重要性 =\u0026gt; the functional zone maps are still hardly available in many cities The recognition of urban functional zones的意义 Numerous methods have been developed to cognize the functional zones based on remote sensing images and crowdsourced data  Remote sensing images  one of the commonly used data sources to detect urban land cover objects and land use classification forming the basis of semantic cognition of urban functional zones       第二段  many studies based on remote sensing images most of these methods are based on the physical properties (such as spectral and textural features) of the objects, which makes it difficult to disclose the functional attributes of the urban areas  例子: buildings in different urban areas may have different functions, such as residential, educational, and commercial buildings, which are hard to differentiate based only on the physical properties from remote sensing images   引出多源数据：it is essential to work with multiple data sources for the recognition of urban functional zones, especially the crowdsourced data related to human activities   第三段  crowdsourced data Since different kinds of data can reflect different characteristics of urban functional zones, it is essential to integrate multi-source data to improve the accuracy of recognition of functional zones   第四段  仍有提升的空间 Although many methods have been proposed for discovering urban functional zones, there is still space for improvement. From the perspective of urban morphology=\u0026gt; the formation of urban functional zones =\u0026gt; both the underlying landscape environment and human activities in urban space Most of the existing studies only focus on one aspect and neglect the integration of landscape and humanity in this paper =\u0026gt; a hierarchical fusion approach  a new area-weighted proportion of POIs introduced information entropy =\u0026gt; the combinational diversity of mixed functions comprehensive: integrating the underlying landscape features, spatial pattern of ground objects, and human activity patterns      方法和数据  数据  land patches: divided the area into 915 zones using the road network and the morphological partition algorithm of Yuan et al. (2012) Landsat-8 images downloaded from the Geospatial Data Cloud (http://www.gscloud.cn/sources) POIs: Gaode map taxi GPS trajectories: 8,141 taxies on May 8–14, 2017, with a total of 1.65 million trajectories   Methodology  三部分：urban landscape classification, functional semantic feature extraction, and functional zone recognition  urban landscape classification  Remote sensing images  reflect the real state of the urban land cover, forming the basis of urban land use classify the urban landscape into different land use categories =\u0026gt; “woodland,” “farmland,” “water,” and “built-up” areas spectral, texture, and spatial features  spectral descriptor: Mean, standard deviation, minimum, and maximum values of spectral features in a moving window (25 × 25 pixels) for each band of the image texture features: The gray-level co-occurrence matrix (GLCM) texture descriptor: four Haralick texture measures, including contrast, sum average, variance, and entropy in a moving window spatial descriptor: The area, compactness, and convexity measures       human activity features extraction  land use functional semantics extraction using a vote-based model  aggregated these POI types into six basic functional categories according to the Standard for Urban Land Classification and Land Use Planning for Construction (GB50137-2011) 【这个图蛮好看的，以后可以参考】 vote-based model to POIs  area-weighted proportion (AWP) of POIs 【POI不是点么，有面积么】 Shannon\u0026rsquo;s information entropy =\u0026gt; measure the mixed degree of functional categories 阈值区分单一类型和复杂功能区     Human mobility patterns detection and function inference  POI =\u0026gt; only reveal the static semantic information of human activities Taxi GPS trajectory =\u0026gt; dynamic human mobility patterns origin–destination (OD) flows =\u0026gt; 24-dimensional feature vector (F)  divided a day into 12 time periods F={O, D} normalized volumes   the fast nearest-neighbor (NN) classification model  the Pearson correlation coefficient is used to measure the similarity of feature vectors (F) of two urban zones manually labeled the functional categories of 915 urban zones       Functional zone recognition by hierarchical semantic fusion【图参考】 Evaluation of results  the overall accuracy (OA) kappa coefficient      Results 2020-Mapping essential urban land use categories in China (EULUC-China):preliminary results for 2018  宫鹏 Science Bulletin Short Communication https://doi.org/10.1016/j.scib.2019.12.007  札记  preliminary/initial results：作者强调初步的分类结果，意思你懂吧（我的结果、精度可能不好，但是我是第一个做大尺度的） 分类体系：Essential(基本) Urban Land Use Categories, EULUC （可以参考） 分类结果共享了，在这里：http://data.ess.tsinghua.edu.cn/  标签  urban land use map for entire China  内容  第一段  Land use =\u0026gt; Urban land use =\u0026gt; widespread effects 目前难题：  maps, pattern and composition of various land use types in urban areas, are limited to city level The mapping standard on data sources, methods, land use classification schemes varies from city to city 挑战：various national and global environmental challenges caused by urbanization   =\u0026gt;急需方案：urban land uses at the national and global scales that are derived from the same or consistent data sources with the same or compatible classification systems and mapping methods 然而，现状是：  a number of urban-extent maps exist at global scales, more detailed urban land use maps do not exist at the same scale consistent land use mapping efforts are rare     第二段  城市土地利扩展 =\u0026gt; 城市不透水面 再次强调难题：However, we do not have a complete knowledge about the distribution, pattern and composition of more detailed land use types in urban China 现有工作：more and more efforts have been made to map individual cities using a combination of remotely sensed data and open social data   第三段，本文工作：=\u0026gt; a new urban land use map for entire China  input features: 10-m satellite images, OpenStreetMap, nighttime lights, POI and Tencent social big data all in 2018 A two-level classification system: Essential Urban Land Use Categories, EULUC Training and validation samples are separately collected through a crowdsourcing approach present the initial results for producing EULUC of China   第四段，步骤简述，Four major procedures： parcel generation with OSM road network and impervious boundaries feature extraction from multisource geospatial big data crowdsourcing collection of training and validation samples mapping and accuracy assessment of EULUC-China   第五段，polygon-based parcels， 交通分析小区的生成细节  represents a relatively homogeneous socioeconomic function(相对同质) polygons bounded by road networks backbone: buffered major roads and minor roads overlaying the parcel map with the impervious boundaries and the water layer =\u0026gt; 440,798 urban parcels   第六段，Four types of features，输入特征的细节（数据：特征）  10-m Sentinel-2A/B images: mean and standard deviations of blue, green, red, and near-infrared bands, normalized difference vegetation index, and normalized water index Tencent mobilephone locating-request (MPL) data: 8-h mean trajectories of the active population during weekdays and weekends 130-m Luojia-1 nighttime light images: mean value of digital number Gaode POI data: total number of all POIs, and total number and proportion of each type of POIs within each parcel   第七段，crowdsourcing campaign for collecting training and validation samples，做标签，训练集、验证集  21 research groups in 27 selected representative cities training sample collection  The selected training parcels are required to be typical and stable with low mixing of land uses   validation sample collection  randomly generate around 50 parcels in each city on-site survey: geolocations, Level I and II categories, landmark buildings and facilities, and mixed land use situation and their estimated proportions   1795 training sample parcels and 869 validation sample parcels in total with a high confidence   第八段，模型训练 produce a parcel-level mapping of EULUC-China with the random forest (RF) classifier transportation lands样本量太少，评价的时候排除 第九段，结果简述  R, C, P =\u0026gt; clustered in urban cores I =\u0026gt; distributed in suburban areas each city has its respective characteristics Statistically (参考分析结果)  within the 166,338 km2 impervious area of China in 2018 residual lands account for 25.0%(41,576 km2) commercial lands account for 4.4% (7317 km2) industrial lands account for 40.6% (67,588 km2) transportation lands account for 11.2% (18,576 km2) public management and service lands account for 18.8% (31,281 km2)     第十段，全局精度评价  independent validation sample is 61.2% for Level I and 57.5% for Level II overall accuracy varies from 40.4% to 82.9% for Level I, and from 34.0% to 80.0% for Level II complexity of parcel-level land use, land use mixture =\u0026gt; an impact on the performance of the validation process RETIO: Residential, Entertainment, Transportation, Industrial, and Office   第十一段， the contribution of different types of features, 特征贡献率  Compared with the use of POIs only: remotely sensed data and social big data help further improve the overall classification accuracy (~7%) quantify the variable importance in random forest model in terms of mean decrease of accuracy and mean decrease of Gini coefficient =\u0026gt; POI has the greatest contribution, followed by Sentinel-2 multispectral features, Luojia-1 and Tencent features   第十二段，综合评价及展望  mark the beginning of a new way of collaborative urban land use mapping over large areas weakness of crowdsourcing  斑块划分方式改进，quality improvement of parcels: finer division of existing parcels with the help of more detailed road networks and image segmentation techniques has good potential =\u0026gt; 更加精细的斑块划分 更为系统的采样、特征及算法，systematic testing of samples, features, and algorithms: Knowledge about the impact of sample size and feature combinations on classification performance 软分类策略，hard and soft classification strategies: expand classification from the current dominant-class only to multiple-class per-parcel classification      2020-DFCNN-Based Semantic Recognition of Urban Functional Zones by Integrating Remote Sensing Data and POI Data  Remote Sensing https://www.mdpi.com/2072-4292/12/7/1088  2020-Understanding Place Characteristics in Geographic Contexts through Graph Convolutional Neural Networks   Refer: Annals of the American Association of Geographers\n  AAAAA\n  Place Characteristics; Geographic Contexts; Graph convolutional neural networks (GCNNs)\n  Abstract:\n both its observed attributes and the characteristics of the places to which it is connected spatial prediction task: predict the unobserved place characteristics based on the observed properties and specific place connections GCNNs capture the knowledge of the relevant geographic context A series of comparative experiments formalizing places for geographic knowledge representation and reasoning    Introduction\n place characteristics places are not isolated but are connecthsed ti each other the contextual information for a place (i.e., its connection to other places) is crucial to understand its characteristics place conncetions =\u0026gt; the measures between places (distance, adjacency and spatial interactions) [为什么会提到地理空间层次的上下文呢？我理解，正如作者所言，对位置地点属性的预测，不仅仅依赖于该地点的观测变量，同时还由该地点周边/相连接的地点的观测属性决定。这里的周边/相连接，对应着作者论述的地理空间上下文]geographic contexts =\u0026gt; The prediction of a place’s unknown characteristic relies on both the place’s observed characteristics and the characteristics of the places to which it is connected. [这里引入了GCNN,提到几个关键词:aggregation,neighbors,contextual infformation]process the connection information: GCNNs generally follow an aggregation scheme where each node aggregates characteristics of its neighbors to learn a deep representation of the contextual information each place is represented as a node, place characteristics are the node features to be computed, and place connections are represented as the graph edges Introduction部分可以说短小精悍了,内容不多但是论点阐述的很清楚。  第一段通过place引入place characteristic的概念，为后面做铺垫； 第二段说place不是孤立的而是相连的，引入了place connection的概念； 第三段就用到了上面两个概念的铺垫了，他说place characteristic的预测不仅和自身的观测变量有关，还和相邻的(connected)的地点的特征相关，然后介绍了两个measure connection的研究。然后就是说道研究的局限性，局限性其实他表述了比较多的方面，也可能是我理解的比较抽象，这一段的内容可能比较关键,因为他把两个概念穿了起来，并且引出了本文的研究点； 第四段理解上就比较简单写了，引入GCNN对于解决model connection的问题很有效； 第五段简介自己的研究内容。      Methodology\n Building the Place-Based Graph Predicting Place Characteristics Using GCNNs    Case Study\n Study Area Data Preparation  Delineating Place Boundaries. Quantifying Place Characteristics.   A GCNN Model to Predict Places’ Functional Features    我把他方法论和Case Study的部分列出来是想说他这两部分的划分我有点看不懂。方法论部分提取出来，然后Case Study去讲具体的步骤。通常的文章里面都不分开吧？或者具体的步骤放在implementation里面？\n  2020-Urban Function as a New Perspective for Adaptive Street Quality Assessment  Refer: Sustainability A Abstract  Street Quality Assessment =\u0026gt; managing natural and public resources, organizing urban morphologies and improving city vitality from the perspective of the variation in urban functions urban function detection + urban function-driven multilevel street quality assessment   Introduction  assess street networks =\u0026gt; enriches the current description of street networks and enhances the evaluation of street network performance these studies have discussed greenery, mobility patterns, and land-use connectivity but ignored the different urban functions that each type of street serves [静态的？]the detection of urban functions in most research is static commercial, residential and traffic functions    ","description":"","id":53,"section":"posts","tags":["城市功能区","特征融合","论文阅读"],"title":"Papers Reading:Urban functions/Urban land use","uri":"https://www.xunhs.cyou/2020/10/21/102/"},{"content":" 献给十月份：相遇。收获。积累。感动。\n [00:00.000] 作词 : 唐映枫[00:00.113] 作曲 : 陈鸿宇[00:00.226] 编曲 : 陈鸿宇 马雨阳[00:00.340]混音：马雨阳[00:01.340]雨后有车驶来[00:03.510]驶过暮色苍白[00:06.090]旧铁皮往南开 恋人已不在[00:10.890]收听浓烟下的 诗歌电台[00:15.700]不动情的咳嗽 至少看起来[00:20.420]归途也还可爱[00:22.870]琴弦少了姿态[00:25.160]再不见那夜里 听歌的小孩[00:30.170]时光匆匆独白[00:32.380]将颠沛磨成卡带[00:34.810]已枯卷的情怀 踏碎成年代[00:39.970][00:49.170]就老去吧 孤独别醒来[00:54.650][00:55.310]你渴望的离开[00:59.540]只是无处停摆[01:03.700]就歌唱吧 眼睛眯起来[01:09.858]而热泪的崩坏[01:14.218]只是没抵达的存在[01:18.650][01:37.090]青春又醉倒在[01:39.840]籍籍无名的怀[01:42.200]靠嬉笑来虚度 聚散得慷慨[01:46.989]辗转却去不到 对的站台[01:51.890]如果漂泊是成长 必经的路牌[01:56.530]你迷醒岁月中[01:58.840]那贫瘠的未来[02:01.418]像遗憾季节里 未结果的爱[02:05.808]弄脏了每一页诗[02:08.310]吻最疼痛的告白[02:10.859]而风声吹到这 已不需要释怀[02:15.718]就老去吧 孤独别醒来[02:20.598][02:21.869]你渴望的离开[02:26.000]只是无处停摆[02:30.138]就歌唱吧 眼睛眯起来[02:36.000]而热泪的崩坏[02:40.220]只是没抵达的存在[02:47.239][03:06.019]就甜蜜地忍耐[03:08.459]繁星润湿窗台[03:10.878]光影跳动着像在 困倦里说爱[03:15.679]再无谓的感慨[03:18.348]以为明白[03:20.418]梦倒塌的地方 今已爬满青苔    2020.10.1 在崇阳，孙繁结婚，我和陈浩做伴郎；岳阳楼一日游，与你相遇。可怜希希jio又紫又肿；第五天。 2020.10.2 在张家舅舅舅妈的带领下，与家人一起游玩内冲-瑶族古镇。云间起相思；第六天。 2020.10.3 准备宴席、 2020.10.4 开宴；第八天。 2020.10.5 返校；哈哈，论文小修啦，这次是真的“小修”~；第一天。 2020.10.6 好冷，明天穿秋裤!? 2020.10.7 Idea: using street view image to evaluate urban road safety; 第三天 2020.10.8 科报会；第四天。 2020.10.9 最美的人在和你聊天?；第五天。 2020.10.10 申请参评“高校GIS新秀” 2020.10.11 GS老师帮我详细修改了稿件，逐字逐句。莫名的感动。前两天还跟WJ开玩笑，自己写的论文，除了自己和润色编辑会逐字逐句阅读没人会认真看。真心的感激~ 2020.10.12 要预约疫苗嘛 2020.10.13 Elastic + kibana的可视化真的是太好用啦 2020.10.14 You deserve better; 今天把小米pro换上了Mac系统，和拯救者搭配使用，放在宿舍闲着太浪费资源啦 2020.10.15 fast.io要取消免费套餐，好不容易找到一个好用的外链床。哎、 2020.10.16 我是不是太闲了? 2020.10.17 我听钢琴曲单纯是为了发呆 2020.10.18 Jellyfin搭建家庭影院；docker搭建在线音乐播放器;好好学一下穿搭:https://www.zhihu.com/question/25464960/answer/487926263 2020.10.19 我都是烂在骨子里的人了 一颗干净纯粹的心还热爱着你呢 2020.10.20 小理想MacBook Pro 13.3 ✊ 2020.10.21 想借来全城电力，我们约定暗号，你一路的灯泡明灭三下，短长短，便是“我想你”，你抬头看看，整个星空也会跟着一起迎合着欢快闪烁。 -热带汽水 2020.10.22 夜晚的长度会被无限拉长 晚风一遍一遍陷入循环 异常的高温不堪加班之苦 地球退烧 反季而来的暴雨变得匆匆 但我不在乎这些玩意儿 不想关心温室效应世界和平宇宙爆炸 我只想你在哪在干嘛 2020.10.23 就是很感动啊? 2020.10.24 组队去公司附近的蹦床体验馆 满足你所有好奇心 2020.10.25 后知后觉 2020.10.26 海洋是球面的，清晨我们出发，带上酒和狗，顺着季风一直向南，再向南，穿过浮空的棕榈岛屿、五彩霓虹灯色的水母群、喷射冰蓝色火焰的鲸鱼、水面上升起的仙后座α星、唱着歌的阿刻洛伊得斯，傍晚就可以到家。 2020.10.27 文章终于中啦~ 对于科研工作者，最令人兴奋的一句话莫过于“I am pleased to inform you that your manuscript has been accepted for publication. ” 2020.10.28  余秀华《给你》\n一家朴素的茶馆，面前目光朴素的你皆为我喜欢\n你的胡子，昨夜辗转的面色让我忧伤\n我想带给你的，一路已经丢失得差不多\n除了窗外凋谢的春色\n遇见你以后，你不停地爱别人，一个接一个\n我没有资格吃醋，只能一次次逃亡\n所以一直活着，是为等你年暮\n等人群散尽，等你灵魂的火焰变为灰烬\n我爱你，我想抱着你\n抱你在人世里被销蚀的肉体\n我原谅你为了她们一次次伤害我 因为我爱你\n我也有过欲望的盛年，有过身心俱裂的许多夜晚\n但是我从未放逐过自己 我要我的身体和心一样干净\n尽管这样，并不是为了见到你 太难了，终于通关一次了，还是用的拳套，准确说应该是雷电-冰-投掷流~   2020.10.29 记得早先年少时 大家诚诚恳恳 说一句 是一句；清早上火车站 长街黑暗无行人 卖豆浆的小店冒着热气；从前的日色变得慢 车，马，邮件都慢 一生只够爱一个人；从前的锁也好看 钥匙精美有样子 你锁了 人家都懂了 -木心《从前慢》 2020.10.30  The Corpse Bride\nWith this hand, I will lift your sorrows.\nYour cup will never empty, for i will be your wine.\nWith this candle, I will light your way in darkness.\nWith this ring, I ask you to be mine. 僵尸新娘\n以我的手，来抚平你的伤悲。\n你永远不会感到孤寂，因为我会时刻与你相伴。\n以这烛光，我会为你照亮漫漫前路。\n以这戒指，我请求你将人生托付于我。   2020.10.31 今天在报告厅看lol S10总决赛，第一次感受大家一起呼喊加油的气氛，充满热情，有些感动  ","description":"","id":54,"section":"posts","tags":null,"title":"2020-10","uri":"https://www.xunhs.cyou/posts/journals/2020-10-01-2020-10/"},{"content":" 国奖\n [00:09.180]You've been running round, running round, running round throwing that dirt all on my name[00:14.040]Cause you knew that I, knew that I, knew that I'd call you up[00:18.690]You've been going round, going round, going round every party in LA[00:23.580]Cause you knew that I, knew that I, knew that I be at one[00:27.070][00:29.020]I know that dress is karma, perfume regret[00:33.300]You got me thinking 'bout when you were mine[00:38.490]And now I'm all up on ya, what you expect[00:42.850]But you're not coming home with me tonight[00:45.970][00:46.670]You just want attention[00:49.080]You don't want my heart[00:51.470]Maybe you just hate the thought of me with someone new[00:56.020]Yeah, you just want attention[00:58.810]I knew from the start[01:01.090]You're just making sure I'm never getting over you[01:04.960][01:06.840]You've been running round, running round, running round throwing that dirt all on my name[01:11.550]'Cause you knew that I, knew that I, knew that I'd call you up[01:16.350]Baby, now that we're, now that we're, now that we're right here standing face to face[01:21.260]You already know, already know, already know that you won, oh[01:26.410][01:26.560]I know that dress is karma, perfume regret[01:30.920]You got me thinking 'bout when you were mine[01:33.430]You got me thinking 'bout when you were mine[01:36.220]And now I'm all up on ya, what you expect[01:40.580]But you're not coming home with me tonight[01:44.350][01:44.360]You just want attention[01:46.680]You don't want my heart[01:49.090]Maybe you just hate the thought of me with someone new[01:53.590]Yeah, you just want attention[01:56.310]I knew from the start[01:58.650]You're just making sure I'm never getting over you[02:02.740][02:05.300]What are you doing to me?[02:06.930]What are you doing, huh? (What are you doing)[02:09.980]What are you doing to me?[02:11.870]What are you doing, huh? (What are you doing)[02:14.790]What are you doing to me?[02:16.660]What are you doing huh? (What are you doing)[02:19.540]What are you doing to me?[02:21.480]What are you doing, huh?[02:23.360][02:24.240]I know that dress is karma, perfume regret[02:28.610]You got me thinking 'bout when you were mine[02:33.800]And now I'm all up on ya, what you expect[02:38.130]But you're not coming home with me tonight[02:41.340][02:44.300]You just want attention[02:46.760]You don't want my heart[02:48.990]Maybe you just hate the thought of me with someone new[02:53.570]Yeah, you just want attention[02:56.310]I knew from the start[02:58.620]You're just making sure I'm never getting over you (over you)[03:04.000][03:05.230]What are you doing to me? (hey)[03:07.030]What are you doing, huh? (What are you doing, what?)[03:10.150]What are you doing to me?[03:11.860]What are you doing, huh? (yeah you just want attention)[03:14.850]What are you doing to me? (I knew from the start)[03:16.760]What are you doing huh? (You're just making sure I'll never get in over you)[03:19.720]What are you doing to me?[03:21.420]What are you doing, huh?    2020.9.1 偏僻的未来城校区一下子来了这么多人，好不热闹、 2020.9.2 参考别人的出租车处理流程跑了一遍。别人处理数据只需几分钟，你处理同样数据写的代码却需要几个小时，也是醉了 2020.9.3 是什么让你我越发的疏远、 2020.9.4 实验室人手一个机械键盘，太吵人了！ 2020.9.5 1) 晚上睡不着，早上起不来🐼; 2) that is your cage. 2020.9.6 我又不脆弱 2020.9.7 再跑步5次差不多可以凑够第一个100公里了~ 2020.9.8 跟甄博士夜聊感情，我表示厌倦追求，会觉得过程很累，且付出不一定会有回报；而他却说非常喜欢追求女生过程中的新鲜感，并会感觉到刺激，他会表现的主动🌚 2020.9.9 收到纸质的CSC派出文件，中文、英文正式写着我的名字，标明我的身份。我逐字逐句的阅读，生怕错过那一个细节。努力可以收到回报，至少在学业上、事业上是无疑的。自勉，愿自己可以更加努力！ 2020.9.10 春华秋实夏蝉冬雪 2020.9.11 喝咖啡睡不着 不喝咖啡睡得香 这是要戒咖啡？ 2020.9.12 正直，谦逊，纯真，勇敢 2020.9.13 其实没什么感觉 反正这个世界上没有谁能一直离不开谁 我也不太需要；第一天；拿得起，放得下。学会放弃，控制欲望。 2020.9.14 出去看了个电影，半年了第一次在电影院看电影吧，吃了个烤鱼还被老板“逮”到；第二天；拥抱过后我的双手应该放在哪里。 2020.9.15 今天和老师新生聚餐，聊了蛮多，有徐老师在，没有想象中那么尴尬。和老板闲聊蛮多，他讲了很多读书时候的事情，蛮有意思的~还有就是老板竟然是跑步减肥的，他每天早上10km！太不可思议了。但是转念想想我也有希望了，早上跑步确实要蛮多毅力的，可以试一下早点睡觉，早上起来跑步🏃；Restart, 第一天。 2020.9.16 一场雨 把我困在这里；第二天。 2020.9.17 第三天。 2020.9.18 复现了一个视频行人检测Real-time_multi-person_tracker的代码， 使用Yolov5 + Deep Sort with PyTorch；Restart, 第一天。 2020.9.19 对我们普通人来说，无论在大城市还是小城市，都有很多需要去努力和改变的事，不存在一劳永逸的选择和人生。 - From 兰卡lanka08； 第二天。 2020.9.20 Make it happen；第三天。 2020.9.21 连续多日的小雨 是小孩子潮湿的坏脾气；今天路上见到她，还是一见倾心，却没有勇气再提追求，或许她也在等我开口呢？By any chance\u0026hellip;； 第四天。 2020.9.22 Enclosed please find the manuscript. 一封邮件写了一个多小时📧； 第五天。 2020.9.23 渣男语录：吃了没，早点睡，今天很忙有点累；没电了，刚开机，今天一天在想你；你别闹，真没有，就是一块喝点酒；你很好，我不配，忘了我吧下一位 哈哈； 第六天。 2020.9.24 Have Patience. Ethan；搏一搏，加油☄；第七天！ 2020.9.25 Hold on. Ethan；第八天。 2020.9.26 找不到步行街的江汉路、舒服的天气、悠闲的汉口江滩🤗；Restart, 第一天。 2020.9.27 It is not suitable to do this in that room; Restart, 第一天。 2020.9.28 Live in the moment. 第二天 2020.9.29 跟论文，张修远；第三天。 2020.9.30 国奖答辩；通过啦🙋；崇阳；第四天。  ","description":"","id":55,"section":"posts","tags":["开学","失眠","甄博士","咖啡","看电影","聚餐","多雨","Manuscript","国奖","崇阳"],"title":"2020-9","uri":"https://www.xunhs.cyou/posts/journals/2020-09-01-2020-9/"},{"content":" 转载自Chinese NLP，根据个人理解做适当札记。\n Chinese Word Segmentation Overview Chinese is written using characters (hanzi), where each character represents a syllable. A word is usually taken to consist of one or more character tokens. There are no spaces between words. Less than 3500 distinct characters are normally encountered. Word segmentation (or tokenization) is the process of dividing up a sequence of characters into a sequence of words.\nExample Input:\n亲 请问有什么可以帮您的吗？ Output:\n亲 请问 有 什么 可以 帮 您 的 吗 ？ Metrics Word F1 score:\n Gold: 共同 创造 美好 的 新 世纪 —— 二○○一年 新年 贺词\n  Hypothesis: 共同 创造 美 好 的 新 世纪 —— 二○○一年 新年 贺词\n Precision = 9 / 11 = 0.818\nRecall = 9 / 10 = 0.9\nF1 = 0.857\nChinese Word Embeddings Background Word embedding ingests a large corpus of text and outputs, for each word type, an n-dimensional vector of real numbers. This vector captures syntactic and semantic information about the word that can be employed to solve various NLP tasks. In Chinese, the unit of encoding may be a character or a sub-character unit, rather than a word. [词嵌入（Word embedding）摄取了大量的文本语料，并为每个词类型输出一个n维实数向量。 这个向量捕获了关于该词的语法和语义信息，可以用来解决各种NLP任务。 在中文中，编码单位可以是一个字符或一个子字符单位，而不是一个词]\nExample Input:\nLarge corpus of text Output:\n“查询”, vec(W) = [-0.059569, 0.126913, 0.273161, 0.225467, -0.185914, 0.018743, -0.18434, 0.083859, -0.115781, -0.216993, 0.063437, -0.005511, 0.276968,…, 0.254486] Standard Metrics Word vectors can be evaluated intrinsically (e.g., whether similar words get similar vectors) or extrinsically (e.g., to what extent word vectors can improve a sentiment analyzer). [词向量可以从内在（例如，相似的词是否得到相似的向量）或外在（例如，词向量可以在多大程度上改进情感分析器）进行评估。]\nIntrinsic evaluation looks at\n Word relatedness : Spearman correlation (⍴) between human-labeled scores and scores generated by the embeddings on Chinese word similarity datasets wordsim-240 and wordsim-296 (translations of English resources). Word Analogy: Accuracy on the word analogy task (e.g: “ 男人 (man) : 女人 (woman) :: 父亲 (father) : X ”, where X chosen by cosine similarity). Different types of word analogy tasks (1) Capitals of countries (2) States/provinces of cities (3) Family words  Extrinsic evaluation:\n Accuracy on Chinese sentiment analysis task F1 score on Chinese named entity recognition task Accuracy on part-of-speech tagging task  See e.g. Torregrossa et al., 2020 for a more detailed comparison of metrics\nWord relatedness-Chinese word similarity lists  wordsim-240 and wordsim-296 list pairs of Chinese words with human similarity judgments proposed by Chen et. al. (2015) and SemEval Task 4: Evaluating Chinese Word Similarity. These are Chinese translations of the English lists prepared in 2002. Datasets can be found at https://github.com/Leonard-Xu/CWE/tree/master/data     Test set # word pairs with human similarity judgments     wordsim-240 240   wordsim-296 297    Metrics  Spearman correlation (⍴) between human-labeled scores and scores generated by the embeddings on Chinese word similarity datasets. Implementation: https://github.com/HKUST-KnowComp/JWE/blob/master/src/word_sim.py  Results  The SoTA system (VCWE) published in NAACL 2019, combines intra-character compositionality (computed via convolutional neural network ) and inter-character compositionality (computed via a recurrent neural network with self-attention) to compute the word embeddings     System wordsim-240 (⍴) wordsim-296 (⍴)     Sun et. al. (2019) (VCWE) 57.81 61.29   Yu et. al. (2017) (JWE) 51.92 59.84    Word Analogy-Chinese word analogy lists Given “France : Paris :: China : ?”, a system should come up with the answer “Beijing”.\n Chen et. al. (2015) manually constructed 1,225 analogies in 3 domains  capitals of countries, state/provinces of cities, family relationships   Datasets can be found at: https://github.com/Leonard-Xu/CWE/blob/master/data/analogy.txt     Test set # analogies     Capitals of countries 687   States/provinces of cities 175   Family relationships 240    Metrics  Accuracy. Implementation: https://github.com/HKUST-KnowComp/JWE/blob/master/src/word_analogy.py  Results    System Accuracy (capital) Accuracy (state) Accuracy (family) Accuracy (total)     Yu et. al. (2017) (JWE) 0.91 0.93 0.62 0.85   Yin et. al. (2016) (MGE) 0.89 0.88 0.39 0.76   CBOW (baseline) 0.84 0.88 0.60 0.79    Extrinsic evaluation-Chinese sentiment analysis  This test measures how much the sentiment analysis task benefits from different word vectors. There is no agreed-upon baseline (e.g., sentiment classifier code), so it is difficult to compare across papers. Sentiment dataset available at http://sentic.net/chinese-review-datasets.zip (Peng et. al. (2018))  Consists of Chinese reviews in 4 domains: notebook, car, camera and phone Binary classification task: reviews are either positive or negative Does not have train/dev/test split.       Test set # positive reviews # negative reviews     Notebook 417 206   Car 886 286   Camera 1,558 673   Phone 1,713 843    Results    System Accuracy (notebook) Accuracy (car) Accuracy (camera) Accuracy (phone) Accuracy (overall)     Sun et. al. (2019) (VCWE) 80.95 85.59 83.93 84.38 88.92   Yu et. al. (2017) (JWE) 77.78 78.81 81.70 81.64 85.13   Baseline (skip-gram) 69.84 77.12 80.80 81.25 86.65    Extrinsic evaluation-Chinese name tagging  This test measures how much the name tagging task benefits from different word vectors. There is no agreed-upon baseline (e.g., name tagging code), so it is difficult to compare across papers. This evaluation evaluates entity taggers on three types of entities: Person (PER), Location (LOC), and Organization (ORG): Levow (2006)     Test set Size (words) Genre     SIGHAN 2006 NER MSRA 100,000 Newswire, Broadcast News, Weblog    Results    System F1 score     Sun et. al. (2019) (VCWE) 85.77   Yu et. al. (2017) (JWE) 85.30    Resources    Train set Size (words) Genre     SIGHAN 2006 NER MSRA 1.3M Newswire, Broadcast News, Weblog    Chinese Transliteration (中文翻译) Background Transliteration translates proper names and technical terms across languages that use different alphabets and sound systems.\nExample input/output Input:\n约翰伍兹 (yue han wu zi) Output:\nJohn Woods Standard Metrics  Word Accuracy in Top-1 (ACC) measures correctness of the first transliteration candidate in a candidate list produced by a transliteration system. Fuzziness in Top-1 (Mean F-score). Mean Reciprocal Rank (MRR). MAP measures precision in the n-best candidates for i-th source name, for which reference transliterations are available.  Chinese Text Classification Background Text classification assigns tags or categories to text according to its topical content, typically training on labeled documents. Topics are sometimes broad and akin to genre (news, sports, arts) but sometimes as fine-grained as hashtags.\nExample input/output Input:\n[国足]有信心了 中国国奥队取得热身赛三连胜 Output:\nSports Standard Metrics  Accuracy: the percentage of correctly classified samples.  Chinese Text Summarization Background Text summarization takes a long text document and creates a shorter text document that is a fluent and accurate summary of the longer text document.\nExample Input:\n 较早进入中国市场的星巴克， 是不少小资钟 情的品牌。相比在美国的平民形象，星巴克在中国就 显得“高端”得多。用料并无差别的一杯中杯美式咖 啡，在美国仅约合人民币12元，国内要卖21元，相当 于贵了75%。第一财经日报 Output:\n媒体称星巴克美式咖啡售价中国比美国 贵75%。 Standard Metrics ROUGE compares an automatically produced summary with human-produced, reference summaries. ROUGE-1 records unigram overlap, ROUGE-2 bigram overlap, and ROUGE-L the longest common subsequence. ROUGE can be computed over characters or words. [ROUGE将自动生成的摘要与人工生成的参考摘要进行比较。 ROUGE-1记录单字重叠，ROUGE-2记录大字重叠，ROUGE-L记录最长的共同序列。 ROUGE可以对字符或单词进行计算。]\nImplementations\n http://www.berouge.com/Pages/default.aspx https://github.com/lancopku/superAE/blob/master/data/script/PythonROUGE.py  Chinese Spelling Correction Background A spelling corrector finds and correct typographical errors in text. These errors often occur between characters that are similar in appearance, pronunciation, or both.\n纠正\nExample Input:\n1986年毕业于国防科技大学计算机应用专业，获学时学位。 Output:\n1986年毕业于国防科技大学计算机应用专业，获学士学位。 (时 -\u0026gt; 士) Standard Metrics Spelling correction performance is typically evaluated using accuracy, precision, recall, and F1 score. These metrics can be computed at the character level or the sentence level. Detection and correction are typically evaluated separately.\n Detection: all locations of incorrect characters in a given passage should be completely identical with the gold standard. Correction: all locations and corresponding corrections of incorrect characters should be completely identical with the gold standard.  Chinese Simplified/Traditional Conversion Background Chinese Simplified/Traditional conversion converts simplified Chinese characters into traditional Chinese characters, and vice versa.\nExample Input:\n苟利国家生死以,岂因祸福避趋之. Output:\n苟利國家生死以,豈因禍福避趨之. Standard Metrics Accuracy\nStandard Test Set None, to our knowledge.\nChinese Sentiment Analysis Background Sentiment Analysis detects identifies and extracts subjective information from text.\nExample Input:\n总的感觉这台机器还不错，实用的有：阴阳历显示，时间与日期快速转换, 记事本等。 Output:\nPositive Standard Metrics Accuracy\n The percentage of correctly classified samples on test set.  F1-score\n Combination of precision and recall. Wiki Page  ","description":"","id":56,"section":"posts","tags":["转载","NLP","Chinese NLP"],"title":"转载-Chinese NLP","uri":"https://www.xunhs.cyou/posts/notes/2020-08-10-%E8%BD%AC%E8%BD%BD-chinese-nlp/"},{"content":" 开学前的一个月，在学校封闭度过、有收到贺信和生日的喜悦，有失眠、麻木、不知所措的彷徨。开始锻炼了，打羽毛球，拍篮球，隔一天的半小时慢跑。继续加油吧，还是很喜欢那句话，进一步有进一步的欢喜。\n \n 2020.8.1 八月有很多事情要发生、 2020.8.2 熬到凌晨快两点还没睡着 我这是怎么了😭 2020.8.3 昨天晚上费劲九牛二虎之力把空调插头插到插座上 凭借着富贵险中求的理念 爬上摇摇晃晃的架子 真是拼了老命了 2020.8.4 1）大论文太难了。只想开题就好头疼; 2）人所努力的一切目的，都是为了让自己感到幸福。 ​​​​- From 漫画家-那个黄同学 2020.8.5 收到贺信的那一刻很平淡，多年的追求和努力得到了见证。很开心能听到老爸的高兴，希望在他眼里我也算一个有出息的小子，不负这么多年一直惹他生气。 2020.8.6 生日快乐 2020.8.7 MASKED FOR REVIEW. 不知道哪里出了错😭 2020.8.8 大家觉得我拿到资助之后就会很闲了、我每天都在忙什么？现在反而成为我最迷茫的时期。感觉有点像回到15年大学毕业的暑假，充满激情和憧憬来到武汉，我该准备些什么、 2020.8.9 怨只怨人在风中 聚散都不由我 2020.8.10 1) Mark - Kang Liu: POI-type semantic analysis + 城市道路交通空间交互度量; 2) 写手，不要停止鸭☄ 2020.8.11 进一寸有进一寸的欢喜 2020.8.12 1) 晚上做了一个梦，不知道算不算噩梦。梦见自己被刀捅了，嗯，更准确的是被刀“插”了一下。然后就一直捂着伤口在去医院的路上。是的，一直在路上，知道我醒了。在路上的时候还遇到一些奇葩甚至奇怪的事情，比如司机半路去上厕所上了好久，比如说路上有特别多特别多的小麻雀却不怕人不飞走。还有就是，伤口一直没流血，但是感觉到痛感。最近一直在失眠、一直睡不好。不过也有发现，比如说天猫精灵的白噪音有点作用，总是不知不觉的睡着了。原理是什么也不懂。 2) 斯文败类本类。 2020.8.13 1) 海枯石烂。2) 多看论文少焦虑。 2020.8.14 拍拍我的小篮球 2020.8.15 Sometimes you shuold switch off your brain. 2020.8.16 信工楼停电了竟然不知道去哪里。。外面太热了不想动弹。躲在宿舍看电影吧 哈哈哈 2020.8.17 打饭碰到一个超有气质的妹子，哇真的被惊艳到了。后来进门的时候发现她也是信工楼的，真的是即惊喜又无奈、 2020.8.18 地理大数据驱动下的城市空间结构及空间交互研究 2020.8.19 今天去和浩子谈心，关于工作的事情。每个人在不同时期都会纠结，都有自己的烦恼、去光谷吃了披萨解了嘴馋，剪了短发，发型师很“手残”很想吐槽（19.9既不要多说了吧啊自己），还有85度C的焦糖玛奇朵 下次要大杯 每次喝都会想起你（不喝也会想Orz），还有去做了背部按摩 虽然很疼 再不锻炼就废了 每次也只是说说。关于工作，我无保留的诉诸我自己的想法，从我的角度的利与弊、与他权衡。祝好🌻 2020.8.20 Attention:: 2020.8.21 在实验室打了一天的游戏了🐭 2020.8.22 行吧~ 2020.8.23 一个星期过去了，说实话这两周没做什么事情，每天来实验室也是放松自己、游戏打到了最强王者了，现在可以收收心啦 明天开始，慢慢进入状态吧、 2020.8.24 1) Though we are far away in distance, please trust that our hearts are close. 2) 基于问题驱动的研究，使用成熟的（机器学习）的方法解决问题即可，无需随大流，关注热门的方法。+ 多看论文找问题呀😂 -熊哥 2020.8.25 孤寡（呱~） 2020.8.26 现在的我挺好，虽然没有谈恋爱，但日子过得有声有色，看书，写字，知道自己想要什么不想要什么，更喜欢动物，一直以来都想养条狗，虽然有时会觉得孤单，并不会孤独。唯一遗憾并愧疚的是父母对我婚姻的担忧。还是许个愿吧，希望我能遇到个合适的人让我重新信任，依赖，并对日后生活充满期待。 2020.8.27 TGIS的文章被拒了、 2020.8.28 Four-Oh-Four🌝 2020.8.29 1) Interesting project - Neural Cellular Automata; 2) 一篇好的论文需要酝酿 2020.8.30 平平无奇的周末 2020.8.31 开学啦 大家都回学校了 假期结束！⏳  ","description":"","id":57,"section":"posts","tags":["失眠","生日","贺信","迷茫","奇怪的梦","白噪音","停电","想开","谈心","游戏","行吧","孤寡","开学"],"title":"2020-8","uri":"https://www.xunhs.cyou/posts/journals/2020-08-01-2020-8/"},{"content":" 再次研读地理大数据的实施方案，以期启发开题、大论文灵感，并做简要笔记、记录。\n 项目主要内容 地理大数据统一表达、聚合与可视化挖掘理论 面向对地观测、社交网络等结构化和非结构化地理大数据的认知、协同表达和理解的需求，拟从地理大数据的时空认知→地理大数据统一表达→地理大数据聚合→地理大数据的统计推断与可视化挖掘等方面,开展地理大数据认知与理解的基础理论和地理大数据协同、聚合与表达的关键技术研发，实现对地理大数据的本身的认知和理解，为地理大数据的深度分析和挖掘提供基础。\n 地理大数据时空认知模型，研究地理大数据的产生机理、认知方式与表现形式，构建多视角交互的地理大数据时空认知、概念化描述与形式化表达模型；    地理大数据时空统一框架与协同表达，研究地理大数据尺度、语义、时间、关系等多元特征归一化表达方法，构建地理大数据时空统一框架与协同表达模型；\n  地理大数据不确定性分析与统计推断，研究地理大数据不确定性及其传播机理，构建地理大数据时空统计推断模型；\n  地理大数据多元聚合分析，研究基于位置、语义、时间、关系等的地理大数据聚合模式，实现不同尺度、不同时态、不同视角、不同语义时空大数据的协同、信息派生与增殖；\n  地理大数据动态可视化挖掘，构建集成时间、空间、语义和关系多维度特征的大数据感知模型和动态可视化挖掘算法，实现地理大数据在线可视化挖掘及动态制图表达\n  地理大数据位置多重感知 位置是广义的空间概念，可以是经纬度坐标所指代的唯一空间实体点，可以是由特定边界围成的地理面状区域，亦可以是具有模糊边界的特定场所。位置信息是以位置作为空间载体的地理信息，是人类行为和情感在时空维度上的反映，往往包含活动、关联、交互、情感、特征等语义信息，具有空间特征、时间特性、位置不确定性、描述形式多样性等特点。位置感知在指在知识发现层面，获取对位置的认知以及对位置信息的理解的过程，能够实现对地理大数据位置多重语义的理解，并且为时空格局的理解与透视、地理事件的发现及预警提供支持。地理大数据位置多重感知将解决地理大数据中的位置认知与语义理解的问题，为结构-功能的理解和要素互作用研究提供表达的核心元素。\n 基于位置语义表达理论模型，构建模糊位置精准化方法，实现位置语义在现实世界和虚拟世界中的一致表达； 地理位置信息自动发现与匹配，研究位置信息的自动发现、提取、跟踪与匹配方法以及多层次空间关系描述模型； 位置语义关联与空间行为推测，研究位置上的活动、关联、交互、情感和特征等多重语义的大数据感知理论和方法，发现位置的深层知识，实现多重位置语义的深层信息感知，在此基础上研究位置语义关联、推理方法，支持基于位置语义的应用； 虚拟空间位置及场所表达与重建，从虚拟社交空间和虚拟现实空间两个层面，研究虚拟空间中位置语义的表达与重建方法，及其与现实空间的关联映射机理； 基于位置的个性化推荐应用，以北京、上海等特大城市为研究对象，开展情境感知的个性化旅游景点推荐、城市商业网点的购物推荐、设施选址推荐等三类应用示范。  通过上述研究，面向社交网消费性大数据，突破位置数据自动发现和模糊位置精准化等关键问题，构建人-地-时框架下地理大数据位置多重感知的理论模型与技术体系，建立地理大数据模糊位置精准化表达模型、实现地理位置及空间关系的自动发现与匹配、位置语义关联与空间行为推测、虚拟空间位置及场所表达与重建等关键技术，并开展基于位置语义的城市空间分析与个性化推荐应用，最终实现地理大数据位置多重感知。\n地理大数据时空格局理解与透视 地理大数据时空格局理解与透视是以精细化地理空间结构构建为基础，遵循从空间、时间、属性三个维度对对地观测大数据隐含的时空模式进行挖掘的思路，分别设计了多层感知器（空间）、时空协同反演（时间）和多粒度决策器（属性）三大关键模型，重点解决地理实体形态、类型、演化与隐含模式挖掘等关键问题，并提供面向事件发生的图谱计算与应用服务。具体来讲，是在对空间结构进行粒化基础上，逐步融入时序演化特征、自然与社会经济静态属性以及生产活动动态信息，对基于图斑的时空分布特征、隐含功能属性、时空动力机制等进行精准模式推测与专题制图，进而为应用示范提供资源配置规划、宜居环境评价和生产活动决策等信息服务。\n 地理图斑空间结构感知与变化更新，研发多层感知器模型，探索基于深度学习的图斑形态提取、基于迁移学习的图斑类型判别、图斑形态结构与类型与指标的演化更新机制、图斑空间结构构建与多尺度表达，实现图斑空间格局的感知层理解； 地理图斑时序分析与指标反演，研究时空协同反演模型，在图斑结构上融合各种来源的遥感数据，发展基于图斑的时序数据处理与特征重建，研究利用时序变化反演图斑材质、覆盖类型以及城市环境定量指标的方法，对变化指标进行定量计算与分析评价，实现对地理大数据机理层的理解； 图斑动力模式挖掘与时空解析，在收集多源多模态数据基础上，研究图斑“静-动”态属性扩展方法以及基于多粒度计算的规则提取与推测制图方法，并研制地理大数据时空解析工具集，通过图斑单元的多源信息聚合，逐层实现地理大数据隐含功能属性的透视和时空动力模式的挖掘； 地理态势图谱计算与应用服务，基于以上三大研究内容，研究资源配置图谱、居住环境图谱以及生产活动图谱的制作和服务，并选择相关研究区开展应用示范，为项目研究提供面向事件发生的图谱计算与应用服务支撑。  地理大数据多元流协同计算 地理大数据多元流协同计算将围绕城市流动和区域交互的应用问题，解决地理流数据的互作用解析与系统分析等关键问题。\n 地理流时空表达模型，研究地理流过程的表达模型，构建地理多元流对象的时空统一框架和协同表达方法； 地理流空间的协同计算与模式分析，研究地理流位置、地理流事件的关联分析方法，构建地理流要素协同模式挖掘模型； 地理多元流网络结构测度与识别，研究地理多元流网络模型的构建方法、网络结构的测度指标及网络模式的识别方法； 地理多元流要素互作用解析，以城市流为对象研究其互作用影响机理以及相关模型； 地理多元流的不确定性分析，研究地理多元流分析的不确定性来源、分类及表达，评估地理多元流分析方法的不确定性； 地理多元流时空过程仿真模型与应用，以北京为代表的京津冀典型城市及苏州、横琴实验区等城市系统为例，研究地理多元流互作用模型下的演化过程模拟与情景分析，应用于城市公共资源利用的评估与优化，为城市动态监测、智慧交通、公共安全、城市规划等提供决策支撑。  地理大数据典型事件发现及预警 地理大数据典型事件发现及预警针对自然和人文等地理事件的时空不确定性、突发性及复杂关联性，系统研究虚拟空间与物理世界融合的地理事件认知表达、时空异常特征探测、公共事件快速发现及可信预警等关键技术，并选择突发公共安全、重大自然灾害等典型地理事件案例研制地学信息图谱。\n以地理事件在真实地理空间和虚拟网络空间的认知为基础，研究与构建虚拟空间热点事件发现，真实地理空间时空异常探测及融合多模态地理大数据的事件地理语义关联与推理方法体系，为全面刻画地理事件本源、过程及结果预警奠定基础。\n 地理事件的认知与建模。研究地理事件在社交网络、媒体等虚拟空间和客观世界的表象、传播和时空群聚特征；不同类型地理事件的分类体系及认知等，建立地理事件的演化概念模型及形式化表达，为地理事件发现与挖掘提供理论框架； 地理空间与虚拟空间异常探测与挖掘。基于地理事件在地理空间和虚拟空间的产生-演化传播-级联等的认知，开展虚拟空间的群聚行为与事件发现的可视化表达、地理空间的异常探测与模式挖掘研究，建立不同空间下不同类型地理事件的点-流-格局-网络的多层次、多尺度异常探测与挖掘的方法体系； 地理事件发现与重构。基于虚拟空间与地理空间的异常探测与模式挖掘，研究地理事件在虚拟空间和地理空间之间的关联耦合模式及形式化表达，建立地理事件的空间语义模型，和基于地理语义关联模式挖掘及不同空间互联的历史事件重构方法，实现地理事件不同空间互联与发现，重构与可视化的方法体系。 地理事件的模拟与预警。基于不同空间地理事件的互联与重构，研究不同类型地理事件突发后在虚拟空间和地理空间的信息传播机制及级联效应，建立地理事件的“级联效应-态势推演”的情景模拟及推理预警方法，实现地理事件的提前预警与应急决策。 典型地理事件快速发现与预警实例研究，基于上述模型与方法，选择城市交通、重大自然灾害以及社会安全等几个领域的典型事件案例开展不同类型地理事件的认知表达、重构及级联预警的实例研究，构建点-轨迹-格局-网络多层次，多维度的事件发现与预警集成与决策平台，为解决城市交通拥堵、自然灾害及公共安全问题提供技术支撑。  地理大数据时空解析原型系统 地理大数据时空解析原型系统，通过建立基于大数据云平台的地理大数据分布式计算与模型集成平台，实现地理大数据的时空解析并开展应用示范。\n 地理大数据存储管理平台，研究海量地理大数据的索引机制与存储架构，实现多源地理大数据的一体化存储与管理； 地理大数据高性能计算架构，研究针对地理大数据计算的分布式计算架构与高性能计算模式，构建可拓展的地理大数据高性能计算环境； 地理大数据模型算法集成环境，研究松耦合模式下的系统集成方式，构建灵活的地理大数据应用模型算法集成平台； 地理大数据挖掘的算法模块，100种地理大数据解析算法的代码实现，每个功能模块的系统集成与测试； 地理大数据可视化分析模块，研究面向显示终端的地理大数据时空动态可视化技术，实现地理大数据的可视化交互分析； 地理大数据虚拟环境仿真模块，研究地理大数据的高维动态过程表达与虚拟现实场景模拟； 地理大数据时空解析应用模块，面向交通、突发自然灾害以及社会安全等领域，构建以地理事件推断与预警为核心的应用分析模块。  感兴趣的技术路线 活动感知 所属子课题：2.2.3位置语义关联与空间行为推测\n 针对基于海量带有个体时空标记的地理大数据，感知其中蕴含的人类移动模式和活动特征，通过研究多源地理大数据融合的方法，建立位置活动感知的方法体系，实现位置活动语义的多角度表达，丰富地理位置的语义信息。    活动感知：对个体移动行为的感知和对活动时变规律的感知\n 个体移动行为从微观层面体现了活动的时空足迹，在统计意义上能够反映群体活动的时空规律。  停留时间分布对人类个体的空间扩散速度有着决定性的影响 出行距离分布则直接反映城市的经济性和效率，并对传染病的传播范围和群体感染率等有显著的影响 轨迹熵则集中反映了个体居民移动活动的主观意愿和惯性模式，突出居民移动活动内在的重复性、规律性和可预测性   活动指标在聚合层面上呈现出随时间的演变规律，作为地理位置活动的典型特征，与社会经济属性直接相关。    运用离散傅里叶变换（Discrete Fourier Transform）分析的方法发现序列的主要时间区间长度（Dominant period length），从而挖掘活动的周期性特征。离散傅里叶变换是傅里叶变换在时域和频域上都呈现离散的形式，在处理地理大数据时，以位置采样的时间顺序作为时域横轴，活动指标如签到数、上下车数等作为频域纵轴，将时域信号的采样变换为在离散时间傅里叶变换（DTFT）频域的采样。通常，城市居民活动的主导周期为24小时，及每天的活动规律大体相似。\n  关联感知 所属子课题：2.2.3位置语义关联与空间行为推测\n 针对地理场所之间的关联特征，测度地理场所的空间联系状态，建立网络特征提取和规律挖掘方法，刻画网络的局部聚集性和整体的连通性等特征，实现地理场所的网络关联特征感知，丰富地理场所语义的感知内容。   网络基本特征研究内容：网络距离的测度，网络连通性测度，结构洞分析，小团体分析，以及网络中心性分析 网络社区组团识别研究内容：在基于关联感知构建的嵌入式空间网络中，由于网络存在分层结构特征且网络中节点的度分布不同，某些节点组呈现出内部密集外部松散的结构特征，这些节点组通常被称为“社团”。对网络中的社区组团识别是关联感知中的重要研究内容 网络拓扑结构分析及网络最优化研究：网络聚集系数、网络分层模块度研究、网络拓扑结构演化，以及基于地理约束的网络最优化研究。  情感感知  利用带有地理标签的社交媒体大数据，建立时空分析方法，获取特定位置或场所的特征词，感知与位置相关的情感信息，并探索人们对于特定时间的情感响应，实现地理场所的情感信息的感知。   针对获取到的社交媒体情感数据，首先采用文本语义挖掘方法以及图像识别和深度学习挖掘数据中的语义信息，在语义信息提取的基础上，运用决策树、关联规则和粗糙集等基于规则的分类方法或朴素贝叶斯、支持向量机、K均值等基于统计的分类方法对情感语义的特征进行分类，并将所得情感映射到地理场所中，实现地理场所的情感信息表达。最终，通过语义挖掘和分类而感知到的地理位置情感语义可以进一步应用到具体的场景中，如：获取特定地理位置的功能主题或评价指标、追踪灾害、疾病和事故等热点事件的时空演化等  空间行为推测   针对表征时空个体行为的地理大数据，通过先验知识库和空间事务数据库，构建出位置语义-空间行为规则数据库，通过多种方法在位置语义和空间行为、不同空间行为以及不同位置之间建立关联与推断模型，实现对个体以及群体的空间出行轨迹推测、行为类型预测等内容。\n 根据个体或群体当前的行为，推断将要到达的空间位置 根据当前所处的位置，预测将要发生的行为类型 根据当前位置推断将来所处的位置，根据当前空间行为推断将来的空间行为     空间行为推荐主要的推测模型  空间行为贝叶斯概率(Bayesian probability)模型: 对于历史行为及对应位置语义数据学习空间行为、位置间的条件概率分布，然后基于此模型，对给定的行为或位置信息，利用贝叶斯定理求出后验概率最大的下一时刻的空间行为 以深度学习(deep learning)方法构建预测模型 采用网络分析(network analysis)的方法: 将位置视为网络的节点，将空间行为附加到节点上，边的权重可由位置间的距离和行为间的转移概率确定。由此形成网络模型后，将个体或群体嵌入到网络节点中，依据网络演化和传播原理，将历史的行为和位置信息、当前的行为信息作为输入，推测其最有可能出现的位置，并对连续的空间位置的变化进行模拟和推断。 集成多源信息的定性空间推理(qualitative spatial reasoning)方法    ","description":"","id":58,"section":"posts","tags":["地理大数据","札记"],"title":"地理大数据挖掘专项实施方案-札记","uri":"https://www.xunhs.cyou/posts/notes/2020-07-31-%E5%9C%B0%E7%90%86%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%93%E9%A1%B9%E5%AE%9E%E6%96%BD%E6%96%B9%E6%A1%88-%E6%9C%AD%E8%AE%B0/"},{"content":" 拷贝自Github-StyleTransferTrilogy。Github上刷到比较好玩的风格迁移的代码和讲解，并做部分笔记\n 风格迁移三部曲 (Style Transfer Trilogy) 风格迁移是一个很有意思的任务，通过风格迁移可以使一张图片保持本身内容大致不变的情况下呈现出另外一张图片的风格。本文会介绍以下三种风格迁移方式以及对应的代码实现：\n 固定风格固定内容的普通风格迁移（A Neural Algorithm of Artistic Style） 固定风格任意内容的快速风格迁移（Perceptual Losses for Real-Time Style Transfer and Super-Resolution） 任意风格任意内容的极速风格迁移（Meta Networks for Neural Style Transfer）  本文所使用的环境是 pytorch 0.4.0，如果你使用了其他的版本，稍作修改即可正确运行。\n固定风格固定内容的普通风格迁移 最早的风格迁移就是在固定风格、固定内容的情况下做的风格迁移，这是最慢的方法，也是最经典的方法。\n最原始的风格迁移的思路很简单，把图片当做可以训练的变量，通过优化图片来降低与内容图片的内容差异以及降低与风格图片的风格差异，迭代训练多次以后，生成的图片就会与内容图片的内容一致，同时也会与风格图片的风格一致。\nVGG16 VGG16 是一个很经典的模型，它通过堆叠 3x3 的卷积层和池化层，在 ImageNet 上获得了不错的成绩。我们使用在 ImageNet 上经过预训练的 VGG16 模型可以对图像提取出有用的特征，这些特征可以帮助我们去衡量两个图像的内容差异和风格差异。\n在进行风格迁移任务时，我们只需要提取其中几个比较重要的层，所以我们对 pytorch 自带的预训练 VGG16 模型稍作了一些修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class VGG(nn.Module): def __init__(self, features): super(VGG, self).__init__() self.features = features self.layer_name_mapping = { \u0026#39;3\u0026#39;: \u0026#34;relu1_2\u0026#34;, \u0026#39;8\u0026#39;: \u0026#34;relu2_2\u0026#34;, \u0026#39;15\u0026#39;: \u0026#34;relu3_3\u0026#34;, \u0026#39;22\u0026#39;: \u0026#34;relu4_3\u0026#34; } for p in self.parameters(): p.requires_grad = False def forward(self, x): outs = [] for name, module in self.features._modules.items(): x = module(x) if name in self.layer_name_mapping: outs.append(x) return outs vgg16 = models.vgg16(pretrained=True) vgg16 = VGG(vgg16.features[:23]).to(device).eval()   经过修改的 VGG16 可以输出 relu1_2,relu2_2,relu3_3,relu4_3 这几个特定层的特征图。下面这两句代码就是它的用法：\n1 2  features = vgg16(input_img) content_features = vgg16(content_img)   举个例子，当我们使用 vgg16 对 input_img 计算特征时，它会返回四个矩阵给 features，假设 input_img 的尺寸是 [1, 3, 512, 512]（四个维度分别代表 batch, channels, height, width），那么它返回的四个矩阵的尺寸就是这样的：\n relu1_2 [1, 64, 512, 512] relu2_2 [1, 128, 256, 256] relu3_3 [1, 256, 128, 128] relu4_3 [1, 512, 64, 64]  内容 我们进行风格迁移的时候，必须保证生成的图像与内容图像的内容一致性，不然风格迁移就变成艺术创作了。那么如何衡量两张图片的内容差异呢？很简单，通过 VGG16 输出的特征图来衡量图片的内容差异。\n提示：在本方法中没有 Image Transform Net，为了表述方便，我们使用了第二篇论文中的图。\n这里使用的损失函数是：\n其中：\n 是输入图像（也就是生成的图像） 是内容图像 代表 VGG16 在这里是 relu3_3 指的是 x 图像输入到 VGG 以后的第 j 层的特征图 是第 j 层输出的特征图的尺寸  根据生成图像和内容图像在 relu3_3输出的特征图的均方误差（Mean Squared Error）来优化生成的图像与内容图像之间的内容一致性。\n那么写成代码就是这样的：\n1  content_loss = F.mse_loss(features[2], content_features[2]) * content_weight   因为我们这里使用的是经过在 ImageNet 预训练过的 VGG16 提取的特征图，所以它能提取出图像的高级特征，通过优化生成图像和内容图像特征图的 mse，可以迫使生成图像的内容与内容图像在 VGG16 的 relu3_3 上输出相似的结果，因此生成图像和内容图像在内容上是一致的。\n风格 Gram 矩阵 那么如何衡量输入图像与风格图像之间的内容差异呢？这里就需要提出一个新的公式，Gram 矩阵：\n其中：\n 是输入图像（也就是生成的图像） 是风格图像 是第 j 层输出的特征图的尺寸。 指的是 x 图像的第 j 层特征图对应的 Gram 矩阵，比如 64 个卷积核对应的卷积层输出的特征图的 Gram 矩阵的尺寸是 。 指的是 Gram 矩阵第 坐标对应的值。 指的是 x 图像输入到 VGG 以后的第 j 层的特征图，指的是特征图 坐标对应的值。  Gram 矩阵的计算方法其实很简单，Gram 矩阵的 坐标对应的值，就是特征图的第 张和第 张图对应元素相乘，然后全部加起来并且除以 的结果。根据公式我们可以很容易推断出 Gram 矩阵是对称矩阵。\n具体到代码，我们可以写出下面的函数：\n1 2 3 4 5 6  def gram_matrix(y): (b, ch, h, w) = y.size() features = y.view(b, ch, w * h) features_t = features.transpose(1, 2) gram = features.bmm(features_t) / (ch * h * w) return gram   参考链接：\nhttps://github.com/pytorch/examples/blob/0.4/fast_neural_style/neural_style/utils.py#L21-L26\n假设我们输入了一个 [1, 3, 512, 512] 的图像，下面就是各个矩阵的尺寸：\n relu1_2 [1, 64, 512, 512]，gram [1, 64, 64] relu2_2 [1, 128, 256, 256]，gram [1, 128, 128] relu3_3 [1, 256, 128, 128]，gram [1, 256, 256] relu4_3 [1, 512, 64, 64]，gram [1, 512, 512]  风格损失 根据生成图像和风格图像在 relu1_2、relu2_2、relu3_3、relu4_3 输出的特征图的 Gram 矩阵之间的均方误差（MeanSquaredError）来优化生成的图像与风格图像之间的风格差异：\n其中：\n 是输入图像（也就是生成的图像） 是风格图像 指的是 x 图像的第 j 层特征图对应的 Gram 矩阵  那么写成代码就是下面这样：\n1 2 3 4 5 6  style_grams = [gram_matrix(x) for x in style_features] style_loss = 0 grams = [gram_matrix(x) for x in features] for a, b in zip(grams, style_grams): style_loss += F.mse_loss(a, b) * style_weight   训练 那么风格迁移的目标就很简单了，直接将两个 loss 按权值加起来，然后对图片优化 loss，即可优化出既有内容图像的内容，也有风格图像的风格的图片。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  input_img = content_img.clone() optimizer = optim.LBFGS([input_img.requires_grad_()]) style_weight = 1e6 content_weight = 1 run = [0] while run[0] \u0026lt;= 300: def f(): optimizer.zero_grad() features = vgg16(input_img) content_loss = F.mse_loss(features[2], content_features[2]) * content_weight style_loss = 0 grams = [gram_matrix(x) for x in features] for a, b in zip(grams, style_grams): style_loss += F.mse_loss(a, b) * style_weight loss = style_loss + content_loss if run[0] % 50 == 0: print(\u0026#39;Step {}: Style Loss: {:4f}Content Loss: {:4f}\u0026#39;.format( run[0], style_loss.item(), content_loss.item())) run[0] += 1 loss.backward() return loss optimizer.step(f)   此处使用了 LBFGS，所以 loss 需要包装在一个函数里，代码参考了：\nhttps://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n效果 最终效果如图所示：\n可以看到生成的图像既有风格图像的风格，也有内容图像的内容，很完美。不过生成一幅256x256 的图像在 1080ti 上需要18.6s，这个时间挺长的，谈不上实时性，因此我们可以来看看第二篇论文中的方法。\n固定风格任意内容的快速风格迁移 有了上面的铺垫，理解固定风格任意内容的快速风格迁移就简单很多了。思路很简单，就是先搭建一个转换网络，然后通过优化转换网络的权值来实现快速风格迁移。由于这个转换网络可以接受任意图像，所以这是任意内容的风格迁移。\n模型 模型结构很简单，分为三个部分：\n 降维，三层卷积层，逐渐提升通道数为128，并且通过 stride 把特征图的宽高缩小为原来的八分之一 5个 ResidualBlock 堆叠 升维，三层卷积层，逐渐降低通道数为3，并且通过 nn.Upsample 把特征图的宽高还原为原来的大小  先降维再升维是为了减少计算量，中间的 5 个 Residual 结构可以学习如何在原图上添加少量内容，改变原图的风格。下面让我们来看看代码。\nConvLayer 1 2 3 4 5 6 7 8 9 10 11 12  def ConvLayer(in_channels, out_channels, kernel_size=3, stride=1, upsample=None, instance_norm=True, relu=True): layers = [] if upsample: layers.append(nn.Upsample(mode=\u0026#39;nearest\u0026#39;, scale_factor=upsample)) layers.append(nn.ReflectionPad2d(kernel_size // 2)) layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride)) if instance_norm: layers.append(nn.InstanceNorm2d(out_channels)) if relu: layers.append(nn.ReLU()) return layers   首先我们实现了一个函数，ConvLayer，它包含：\n nn.Upsample（可选） nn.ReflectionPad2d nn.Conv2d nn.InstanceNorm2d（可选） nn.ReLU（可选）  因为每个卷积层前后都可能会用到这些层，为了简化代码，我们将它写成一个函数，返回这些层用于搭建模型。\nResidualBlock 1 2 3 4 5 6 7 8 9 10  class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv = nn.Sequential( *ConvLayer(channels, channels, kernel_size=3, stride=1), *ConvLayer(channels, channels, kernel_size=3, stride=1, relu=False) ) def forward(self, x): return self.conv(x) + x   这里写的就不是函数，而是一个类，因为它内部包含许多层，而且并不是简单的自上而下的结构（Sequential），而是有了跨层的连接（self.conv(x) + x），所以我们需要继承 nn.Module，实现 forward 函数，才能实现跨层连接。\nTransformNet 最后这个模型就很简单了，照着论文里给出的表格搭建即可。我们这里为了实验方便，添加了 base 参数，当 base=8 时，卷积核的个数是按 8, 16, 32 递增的，当 base=32 时，卷积核个数是按 32, 64, 128 递增的。有了这个参数，我们可以按需增加模型规模，base 越大，图像质量越好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class TransformNet(nn.Module): def __init__(self, base=32): super(TransformNet, self).__init__() self.downsampling = nn.Sequential( *ConvLayer(3, base, kernel_size=9), *ConvLayer(base, base*2, kernel_size=3, stride=2), *ConvLayer(base*2, base*4, kernel_size=3, stride=2), ) self.residuals = nn.Sequential(*[ResidualBlock(base*4) for i in range(5)]) self.upsampling = nn.Sequential( *ConvLayer(base*4, base*2, kernel_size=3, upsample=2), *ConvLayer(base*2, base, kernel_size=3, upsample=2), *ConvLayer(base, 3, kernel_size=9, instance_norm=False, relu=False), ) def forward(self, X): y = self.downsampling(X) y = self.residuals(y) y = self.upsampling(y) return y   数据 训练的时候，我们使用了 COCO train 2014、val2014、test2014， 一共有 164k 图像，实际上原论文只用了训练集（80k）。图像宽高都是256。\n We resize each of the 80k training images to 256 × 256 and train our networks with a batch size of 4 for 40,000 iterations, giving roughly two epochs over the training data.\n 1 2 3 4 5 6 7 8 9 10 11 12  batch_size = 4 width = 256 data_transform = transforms.Compose([ transforms.Resize(width), transforms.CenterCrop(width), transforms.ToTensor(), tensor_normalizer, ]) dataset = torchvision.datasets.ImageFolder(\u0026#39;/home/ypw/COCO/\u0026#39;, transform=data_transform) data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)   返回：\nDataset ImageFolder Number of datapoints: 164062 Root Location: /home/ypw/COCO/ Transforms (if any): Compose( Resize(size=256, interpolation=PIL.Image.BILINEAR) CenterCrop(size=(256, 256)) ToTensor() Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ) Target Transforms (if any): None 其中的 tensor_normalizer 是为了使用 pytorch 自带的预训练模型，在官方文档中提到了要进行预处理：https://pytorch.org/docs/master/torchvision/models.html\n1 2 3  cnn_normalization_mean = [0.485, 0.456, 0.406] cnn_normalization_std = [0.229, 0.224, 0.225] tensor_normalizer = transforms.Normalize(mean=cnn_normalization_mean, std=cnn_normalization_std)   训练 超参数 虽然官方开源给出的 style_weight 是 5，但是我这里测试得并不理想，可能是不同的预训练权值、不同的预处理方式造成的差异，设置为 1e5 是比较理想的。\n We use Adam [51] with a learning rate of 1 × 10−3.\n 优化器使用了论文中提到的 Adam 1e-3。\n The output images are regularized with total variation regularization with a strength of between and , chosen via cross-validation per style target.\n tv_weight 感觉没有太大变化，所以按论文中给出的参考设置了 1e-6。\n train our networks with a batch size of 4 for 40,000 iterations\n batch_size 按论文设置为了4。\n由于我这里使用的图片变多了，所以为了保持和官方的训练 step 一致（40k），训练代数（epoch）设置为了1。\nTotalVariation  Total Variation Regularization. To encourage spatial smoothness in the output image , we follow prior work on feature inversion [6,20] and super- resolution [48,49] and make use of total variation regularizer .\n 论文中提到了一个 TV Loss，这是为了平滑图像。它的计算方法很简单：\n将图像水平和垂直平移一个像素，与原图相减，然后计算绝对值的和，就是 TotalVariation。\n参考链接：https://en.wikipedia.org/wiki/Total_variation_denoising\n代码 由于代码太长，这里只贴一些关键代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  for batch, (content_images, _) in pbar: optimizer.zero_grad() # 使用风格模型预测风格迁移图像 content_images = content_images.to(device) transformed_images = transform_net(content_images) transformed_images = transformed_images.clamp(-3, 3) # 使用 vgg16 计算特征 content_features = vgg16(content_images) transformed_features = vgg16(transformed_images) # content loss content_loss = content_weight * F.mse_loss(transformed_features[1], content_features[1]) # total variation loss y = transformed_images tv_loss = tv_weight * (torch.sum(torch.abs(y[:, :, :, :-1] - y[:, :, :, 1:])) + torch.sum(torch.abs(y[:, :, :-1, :] - y[:, :, 1:, :]))) # style loss style_loss = 0. transformed_grams = [gram_matrix(x) for x in transformed_features] for transformed_gram, style_gram in zip(transformed_grams, style_grams): style_loss += style_weight * F.mse_loss(transformed_gram, style_gram.expand_as(transformed_gram)) # 加起来 loss = style_loss + content_loss + tv_loss loss.backward() optimizer.step()   通过对 loss 的优化，进而约束模型输出与内容图像的内容相似、与风格图像风格相似的图像，从而得到一个可以较快速度输出风格迁移图像的模型。\n效果 最终效果如图所示：\n可以看到对于任意内容图片，转换网络都能转换为固定风格的图像。根据下面这段代码进行的测速，1080ti 可以在4.82秒内完成 1000 张图像的风格迁移，相当于207fps，可以说是具有了实时性：\n但是整个模型的训练时间需要1小时54分钟，如果我们想做任意风格图像的风格迁移，这个时间几乎是不可接受的，因此让我们来看看第三篇论文的思路。\n任意风格任意内容的极速风格迁移 首先我们先对三种情况进行总结：\n情况1 其中：\n 是内容损失函数 是风格损失函数 是内容权重 是风格权重 是VGG16的固定权值 是风格图像 是内容图像 是输入图像  那么通过对输入图像 进行训练，我们能够得到固定风格、固定内容的风格迁移图像。\n情况2 其中：\n 是生成图像，是图像转换网络  通过对权值的优化，我们可以得到一个快速风格迁移模型，它能够对任何内容图像进行风格转换，输出同一种风格的风格迁移图像。\n情况3  是 的权值 是转换网络的权值，，所以我们可以说转换网络的权值是 MetaNet 通过风格图像生成的。 是转换网络生成的图像，  总的来说就是风格图像输入 得到转换网络 ，转换网络可以将任意内容图像进行转换。通过输入大量风格图像和内容图像 ，可以训练出能够产出期望权值的 。该模型可以输入任意风格图像，输出情况2中的迁移模型，进而实现任意风格任意内容的风格迁移。\n转换网络（TransformNet） 论文中的转换网络很有意思，粉色部分的权重是由 MetaNet 生成的，而灰色部分的权重则与 MetaNet 一起训练。由于这个模型的需求比较个性化，我们的代码需要一些技巧，下面让我们详细展开讨论。\nMyConv2D 转换网络的结构还是与之前的一样，但是为了调用方便，我们需要实现一个新的类，这个类和卷积层类似，但是权值和偏置都需要是常量。这是因为权值已经是 MetaNet 的输出，如果赋值为 TransformNet 的权值，那么这个计算图就断了，这不符合我们的预期，我们应该让 MetaNet 的输出继续参与计算图，直到计算出 loss，不然 MetaNet 的权值将不会更新。因此我们事先了一个新的类，MyConv2D。\n为了体现两者的差异，我们使用 TensorBoard 进行了可视化：\n从上图中可以看到，nn.Conv2d 内部有两个参数（ Paramter），这是可以参与训练参数，也就是说在 loss.backward() 的时候会计算对应的梯度。而 MyConv2D 里面的权值和偏置都是常量（Constant），不会计算相应的梯度。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  class MyConv2D(nn.Module): def __init__(self, in_channels, out_channels, kernel_size=3, stride=1): super(MyConv2D, self).__init__() self.weight = torch.zeros((out_channels, in_channels, kernel_size, kernel_size)).to(device) self.bias = torch.zeros(out_channels).to(device) self.in_channels = in_channels self.out_channels = out_channels self.kernel_size = (kernel_size, kernel_size) self.stride = (stride, stride) def forward(self, x): return F.conv2d(x, self.weight, self.bias, self.stride)   ConvLayer 为了区分以下两种情况：\n 权值是是可训练的参数 权值由 MetaNet 给出  我们写出了下面的代码：\n1 2 3 4 5 6 7 8 9  def ConvLayer(in_channels, out_channels, kernel_size=3, stride=1, upsample=None, instance_norm=True, relu=True, trainable=False): ...... if trainable: layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride)) else: layers.append(MyConv2D(in_channels, out_channels, kernel_size, stride)) ...... return layers   很简单，当权值由 MetaNet 给出时，它是不参与训练的，我们设置 trainable=False，然后使用 MyConv2D 层。\nTransformNet 下面就直接贴代码了，模型结构按照上面论文中的图去搭就好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class TransformNet(nn.Module): def __init__(self, base=8): super(TransformNet, self).__init__() self.base = base self.downsampling = nn.Sequential( *ConvLayer(3, base, kernel_size=9, trainable=True), *ConvLayer(base, base*2, kernel_size=3, stride=2), *ConvLayer(base*2, base*4, kernel_size=3, stride=2), ) self.residuals = nn.Sequential(*[ResidualBlock(base*4) for i in range(5)]) self.upsampling = nn.Sequential( *ConvLayer(base*4, base*2, kernel_size=3, upsample=2), *ConvLayer(base*2, base, kernel_size=3, upsample=2), *ConvLayer(base, 3, kernel_size=9, instance_norm=False, relu=False, trainable=True), ) def forward(self, X): y = self.downsampling(X) y = self.residuals(y) y = self.upsampling(y) return y ....   TransformNet(32) 每一层对应的权重数量如下：\ndefaultdict(int, {'downsampling.5': 18496, 'downsampling.9': 73856, 'residuals.0.conv.1': 147584, 'residuals.0.conv.5': 147584, 'residuals.1.conv.1': 147584, 'residuals.1.conv.5': 147584, 'residuals.2.conv.1': 147584, 'residuals.2.conv.5': 147584, 'residuals.3.conv.1': 147584, 'residuals.3.conv.5': 147584, 'residuals.4.conv.1': 147584, 'residuals.4.conv.5': 147584, 'upsampling.2': 73792, 'upsampling.7': 18464}) 通过 TensorBoard，我们可以对模型结构进行可视化：\nMetaNet 那么我们怎么样才能获得 TransformNet 的权值呢？当然是输入风格图像的特征。\n那么我们知道风格图像经过 VGG16 输出的 relu1_2、relu2_2、relu3_3、relu4_3 尺寸是很大的，假设图像的尺寸是 (256, 256)，那么卷积层输出的尺寸分别是 (64, 256, 256)、(128, 128, 128)、(256, 64, 64)、(512, 32, 32)，即使取其 Gram 矩阵，(64, 64)、(128, 128)、(256, 256)、(512, 512) 也是非常大的。我们举个例子，假设使用 512*512 个特征来生成 147584 个权值（residual 层），那么这层全连接层的 w 就是 512x512x147584=38688260096 个，假设 w 的格式是 float32，那么光是一个 w 就有 144GB 这么大，这几乎是不可实现的。那么第三篇论文就提到了一个方法，只计算每一个卷积核输出的内容的均值和标准差。\n We compute the mean and stand deviations of two feature maps of the style image and the transferred image as style features.\n 只计算均值和标准差，不计算 Gram 矩阵，这里的特征就变为了 (64+128+256+512)x2=1920 维，明显小了很多。但是我们稍加计算即可知道，1920x(18496+73856+147584x10+73792+18464)=3188060160，假设是 float32，那么权值至少有 11.8GB，显然无法在一块 1080ti 上实现 MetaNet。那么作者又提出了一个想法，使用分组全连接层。\n The dimension of hidden vector is 1792 without specification. The hidden features are connected with the filters of each conv layer of the network in a group manner to decrease the parameter size, which means a 128 dimensional hidden vector for each conv layer.\n 意思就是隐藏层全连接层使用14x128=1792个神经元，这个14对应的就是 TransformNet 里面的每一层卷积层（downsampling2层，residual10层，upsampling2层），然后每一层卷积层的权值只连接其中的一小片128，那么整体结构参考下图：\n如果看不清可以点击查看原图。\n在经过重重努力之后，模型大小终于限制在 1GB 以内了。当 base=32 时，保存为 pth 文件的模型大小为 870MB。\n下面是代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class MetaNet(nn.Module): def __init__(self, param_dict): super(MetaNet, self).__init__() self.param_num = len(param_dict) self.hidden = nn.Linear(1920, 128*self.param_num) self.fc_dict = {} for i, (name, params) in enumerate(param_dict.items()): self.fc_dict[name] = i setattr(self, \u0026#39;fc{}\u0026#39;.format(i+1), nn.Linear(128, params)) def forward(self, mean_std_features): hidden = F.relu(self.hidden(mean_std_features)) filters = {} for name, i in self.fc_dict.items(): fc = getattr(self, \u0026#39;fc{}\u0026#39;.format(i+1)) filters[name] = fc(hidden[:,i*128:(i+1)*128]) return filters   直接 print 模型：\nMetaNet( (hidden): Linear(in_features=1920, out_features=1792, bias=True) (fc1): Linear(in_features=128, out_features=18496, bias=True) (fc2): Linear(in_features=128, out_features=73856, bias=True) (fc3): Linear(in_features=128, out_features=147584, bias=True) (fc4): Linear(in_features=128, out_features=147584, bias=True) (fc5): Linear(in_features=128, out_features=147584, bias=True) (fc6): Linear(in_features=128, out_features=147584, bias=True) (fc7): Linear(in_features=128, out_features=147584, bias=True) (fc8): Linear(in_features=128, out_features=147584, bias=True) (fc9): Linear(in_features=128, out_features=147584, bias=True) (fc10): Linear(in_features=128, out_features=147584, bias=True) (fc11): Linear(in_features=128, out_features=147584, bias=True) (fc12): Linear(in_features=128, out_features=147584, bias=True) (fc13): Linear(in_features=128, out_features=73792, bias=True) (fc14): Linear(in_features=128, out_features=18464, bias=True) ) 数据  There are about 120k images in MS- COCO trainval set and about 80k images in the test set of WikiArt.\n 要想训练这么大的模型，那么就必须要海量的风格图像和内容图像。原论文依旧选择了 COCO 作为内容数据集。而风格数据集选择了 WikiArt，该数据集包含大量艺术作品，很适合作为风格迁移的风格图片。\n During training, each content image or style image is resized to keep the smallest dimension in the range [256, 480], and randomly cropped regions of size 256 × 256.\n 论文提到图像要先缩放到 [256, 480] 的尺寸，然后再随机裁剪为 256 × 256。\n代码如下：\n1 2 3 4 5 6 7 8  data_transform = transforms.Compose([ transforms.RandomResizedCrop(width, scale=(256/480, 1), ratio=(1, 1)), transforms.ToTensor(), tensor_normalizer ]) style_dataset = torchvision.datasets.ImageFolder(\u0026#39;/home/ypw/WikiArt/\u0026#39;, transform=data_transform) content_dataset = torchvision.datasets.ImageFolder(\u0026#39;/home/ypw/COCO/\u0026#39;, transform=data_transform)   训练 超参数  The weight of content loss is 1 while the weight of style loss is 250.\n 虽然论文里给出的 style_weight 是 250，但是我这里测试得并不理想，可能是不同的预训练模型、不同的预处理方式造成的差异，设置为 25 是比较理想的。\n We use Adam (Kingma and Ba 2014) with fixed learning rate 0.001 for 600k iterations without weight decay.\n 优化器使用了论文中提到的 Adam 1e-3。\n The transferred images are regularized with total variations loss with a strength of 10.\n 因为这篇论文的作者用的是 caffe，VGG16 的预训练权值与 pytorch 差异比较大，所以我这里的 tv_weight 没有设置为论文中的10，而是选择了 1e-4。\n The batch size of content images is 8 and the meta network is trained for 20 iterations before changing the style image.\n 这里的 batch_size 很有意思，每次来8张内容图片，但是每当训练20个 batch 之后，换一张风格图片。这样做的目的是为了保证 TransformNet 能在每张风格图像上都收敛一段时间，切换图像又能保证 MetaNet 能够适应所有的风格图像。\n代码 由于代码太长，这里也只贴一些关键代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  for batch, (content_images, _) in pbar: # 每 20 个 batch 随机挑选一张新的风格图像，计算其特征 if batch % 20 == 0: style_image = random.choice(style_dataset)[0].unsqueeze(0).to(device) style_features = vgg16(style_image) style_mean_std = mean_std(style_features) # 检查纯色 x = content_images.cpu().numpy() if (x.min(-1).min(-1) == x.max(-1).max(-1)).any(): continue optimizer.zero_grad() # 使用风格图像生成风格模型 weights = metanet(mean_std(style_features)) transform_net.set_weights(weights, 0) # 使用风格模型预测风格迁移图像 content_images = content_images.to(device) transformed_images = transform_net(content_images) # 使用 vgg16 计算特征 content_features = vgg16(content_images) transformed_features = vgg16(transformed_images) transformed_mean_std = mean_std(transformed_features) # content loss content_loss = content_weight * F.mse_loss(transformed_features[2], content_features[2]) # style loss style_loss = style_weight * F.mse_loss(transformed_mean_std, style_mean_std.expand_as(transformed_mean_std)) # total variation loss y = transformed_images tv_loss = tv_weight * (torch.sum(torch.abs(y[:, :, :, :-1] - y[:, :, :, 1:])) + torch.sum(torch.abs(y[:, :, :-1, :] - y[:, :, 1:, :]))) # 求和 loss = content_loss + style_loss + tv_loss loss.backward() optimizer.step()   这里有几点问题值得思考：\n 如果内容图像是纯色的，那么权值会直接 nan，原因不明，为了避免这个问题，需要检查纯色，然后 continue 来避免 nan。 权值会逐渐增大，目前没有比较好的解决方案。  效果 最终效果如图所示：\n可以看到对于任意内容图片，转换网络都能转换为固定风格的图像。\n根据下面这段代码进行的测速，1080ti 可以在8.48秒内对 1000 张风格图像产出风格迁移模型，相当于117fps。而风格迁移模型转换的速度也很快，达到了4.59秒，相当于217fps。假设我们每一帧都用不同的风格，转换1000张图片也只需要13.1秒，相当于76fps，可以说做到了实时任意风格任意内容的极速风格迁移。\n总结 我们使用 pytorch 实现了以下三种风格迁移：\n 固定风格固定内容的普通风格迁移（A Neural Algorithm of Artistic Style） 固定风格任意内容的快速风格迁移（Perceptual Losses for Real-Time Style Transfer and Super-Resolution） 任意风格任意内容的极速风格迁移（Meta Networks for Neural Style Transfer）  首先第一篇论文打破了以往的思维定式：只有权值可以训练。它通过对图像进行训练实现了风格迁移。然后第二篇论文就比较正常，通过训练一个模型来实现风格迁移。第三篇论文就很神奇了，通过模型来生成权值，进而实现任意风格的风格迁移。不得不感谢这些走在科技前沿的科研工作者，给了我们许多新奇的思路。\n","description":"","id":59,"section":"posts","tags":["风格迁移","style transfer","深度学习"],"title":"2020-07-18-风格迁移三部曲","uri":"https://www.xunhs.cyou/posts/notes/2020-07-18-%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E4%B8%89%E9%83%A8%E6%9B%B2/"},{"content":" 续博士论文阅读札记-1\n 构造-流体-成矿系统自组织临界性模拟研究 熊义辉-2019-中国地质大学（武汉）\n徐老师推荐（整体框架很棒，非常值得参考。3个90分的大论文）\n绪论部分 研究背景与意义  第一段（介绍构造-流体-成矿系统）  矿床-矿床的形成-子过程的影响-多因素影响 构造和流体是最重要的控制因素  构造和构造应力：控制一定区域中各地质体间耦合关系的主导因素 流体：成矿物质从矿源地汲取并搬运的主要媒介   构造-流体-成矿系统：在时空范围内，以构造和流体的主导作用，控制并改造与矿床形成、保存紧密相关的地质要素、过程及其最终产物的整体，是一个由多种组成和多重作用相互耦合的复杂动力学系统。 对深入了解成矿流体运移以及成矿元素富集过程具有重要意义   第二段（阐述当前研究现状，引出本文研究主题及研究内容，简介本文研究作用及意义）  目前对于成矿过程的研究主要表现在两个方面  侧重于野外观测与地球化学分析方法  如矿床地质地球化学特征、成矿时代等 研究大多数都停留在概念模型的定性描述的阶段   侧重于成矿作用动力学模型  通过定量数学模型与数值模拟实现在计算机的虚拟时空中再现整个成矿复杂系统的演化进程 主要研究对象：成矿物质的化学运动和各种力学运动 在化学动力学和各种动力学研究的基础上可以进一步上升到对复杂系统和复杂过程深层次、普遍动力学规律的研究-分形理论、混沌动力学及自组织临界性方法     非线性理论和复杂性理论，特别是混沌理论、分形/多重分形理论、自组织临界性等理论，对揭示矿床形成的复杂过程、成矿物质的富集规律、成矿信息的获取具有非常重要的意义  分形/多重分形模型多侧重于对现象的表现形式描述和解释现象的复杂特征 自组织临界性则侧重于现象的机理与本质规律分析   自组织临界性  复杂性系统的一个重要特性，对于深入理解系统复杂性产生机理具有重要作用 基于元胞自动机的数值模拟方法是研究具有自组织临界性过程的重要工具。   论文工作：基于此，论文  利用元胞自动机模型数值重现构造-流体耦合作用下的复杂性成矿过程， 分析流体参与下断裂过程以及它们对成矿元素自组织富集成矿的制约与影响， 定量认识构造和流体对矿床的时空分布规律及元素的迁移与富集规律的影响。   作用：  一方面可以厘清构造-流体相互作用对成矿自组织临界性过程的制约作用，有助于深入理解成矿演化过程； 另一方面全面综合探索非线性和复杂性科学在成矿系统中的应用。   意义：  利用元胞自动机模拟现象的机理，揭示现象本质规律（过程）； 利用分形模型描述现象的表现形式（结果），二者融为一体，丰富非线性与复杂性理论在复杂性成矿系统中的应用。      国内外研究现状与存在问题 引言段：\n 构造-流体-成矿系统  具有自组织临界性的内在基本特性 形成机理和触发机制极其复杂，即可表现出确定性也会表现出一定的随机性 认知和预测这类现象意义重大的同时也充满挑战   在复杂性特征上具有高度的相似性  可利用自组织临界性理论和模型加以解释 对自组织临界性的理解多源于元胞自动机的数值模拟   基于此，论文  首先总结了构造-流体-成矿系统及其动力学研究现状 随后对自组织临界性在地学里的应用现状进行了总结归纳    构造-流体-成矿系统及其动力学研究现状  第一段  成矿系统  矿床学研究的一个重要研究方向 概念（是一个具有成矿功能的地质系统） 众多子系统相互作用和相互依存组成的有机整体   内部结构  控制成矿因素：如构造、岩浆、变质、流体、热动力 成矿要素：如矿源、流体、能量、空间、时间等 成矿作用过程：如成矿发生、持续、终结以及成矿后的变化和保存等； 成矿产物：如矿床和异常系列   构造-流体-成矿系统概念的提出：基于区域成矿学研究的不断深入，学者认识到构造与流体之间并非各自独立而是存在强烈的相互作用，并在成矿作用过程中具有重要意义，进而提出了构造-流体-成矿系统的概念   第二段（这部分讲构造应力和流体在成矿过程中的重要作用吧，太专业了看不懂）  构造-流体的时空演化过程 构造应力 流体   第三段  构造-流体耦合成矿动力学  提供了有效研究途径 侧重研究成矿作用机制，演化过程及其动力来源 研究的核心为构造与流体之间耦合作用下的成矿系统形成过程及其动力学特征   构造-流体-成矿系统  相互耦合的一个复杂的动力学系统 研究过程可从传统的对矿床成因及成矿规律的研究、静态的定性研究上升到动态的定量研究   目前对成矿动力学的研究  由传统的侧重于化学过程而较少关注与成矿相关的物理过程，转向多相、多组成和多耦合方向发展 构造-流体耦合成矿动力学比单一的流体或构造方面的研究更接近地质事实 实质是通过阐明构造变形与流体热-力学-化学相互作用和耦合，来探讨对矿床形成和分布的制约作用   一系列成矿动力学模型  一个典型的动力学机制     第四段：计算机数值模拟在理解构造-流体耦合成矿动力学机制方面意义重大，为理解矿床成因、服务找矿勘探和优选找矿靶区上发挥了重要作用。 第五段  成矿动力学进一步上升到复杂系统的理论和方法 地质系统复杂性研究 成矿复杂性研究   第六段  成矿过程  地球系统内的一种自组织临界现象 最终产物满足幂律分布 可用分形/多重分形模型来描述   分形  用于刻画物体在不同的尺度下具有自相似的几何性质 分形频率分布 成矿元素在时空分布上表现出不均匀性=\u0026gt;时空分布结构的研究=\u0026gt;简单的分形频率分布则不足以度量成矿物质时空分布结构规律 多重分形理论      自组织临界性应用研究现状   第一段（自组织临界性理论）\n 作者科普 自组织临界性现象的理解多源于元胞自动机的数值模拟    第二段（元胞自动机）\n 在时间、空间和状态上都表现为离散状态，常用于研究自组织系统的演化过程 复杂系统可源自于简单子系统之间的相互作用 基于微分方程式动力学模型可能存在几个不足 元胞自动机不是通过严格的物理方程或函数来表达，而是通过一系列局部演化规则构成，它为研究复杂动力学提供了另一种可供选择的方法    第三-八段（元胞自动机在不同领域的自组织临界性研究）\n  第三段：简介基于元胞自动机模型的地震过程自组织临界性研究\n  第四段：简介基于元胞自动机模型火山断裂系统自组织临界性研究\n  第五段：简介基于元胞自动机模型滑坡现象自组织临界性研究\n  滑坡规模与频率满足幂律分布\n  沙堆元胞自动机模型\n    第六段：崩塌、滑坡、泥石流等地质灾害运动过程的自组织临界性\n  第七段：基于元胞自动机的森林火灾模型\n  第八段：范围广泛地区中降水量及其他水文变量时间序列均表现出自组织临界特性\n    第九段（总结）\n 一方面可从这些自然现象具有的幂律分布、长程相关性、尺度不变性、1/f 噪声等自组织临界性的复杂性特征着手 另一方面可借助元胞自动机强大的复杂系统建模能力和灵活的扩展能力，对模型各组成部分进行灵活的扩展，从而构建相应的专题元胞自动机模型，来把握现象自组织演化的内在机制 对于自组织临界性的成矿过程的元胞自动机模拟还有待进一步研究    存在的主要问题   研究主题：构造-流体-成矿系统的自组织临界性模拟分析\n  目前对这类成矿系统的研究侧重于成矿作用动力学模型的研究\n  非线性理论和复杂性理论\n  现有对热液成矿过程的自组织临界性研究多侧重于利用分形/多重分形模型对现象的表现形式描述和解释现象的复杂特征；而对于产生这些复杂特征的自组织临界性的内在机理的研究还有待进一步深入\n  进一步解决这类科学问题\n 基础：已有的典型成矿动力学模型，地震自组织临界性数值模型 利用元胞自动机模型  数值化模拟流体在断层带中沿断裂上升运移过程以及“断裂阀-地震泵吸-周期性破裂愈合”的构造-流体耦合成矿动力学模式 模拟成矿流体输运和成矿定位过程   揭示  流体参与下地震以及断裂构造生成机制 成矿流体运移机制 构造-流体耦合作用下成矿物质如何运移与自组织富集成矿过程      研究内容与思路 研究内容 针对目前所存在的问题，论文从流体呈批次上升运移以及断裂阀成矿模型入手，提取其演化规则，并整合到元胞自动机模型中，计算机重现其演化过程，进而对构造-流体耦合成矿过程的自组织临界性进行分析\n 从两方面探讨断裂构造体系的自组织临界特性  从矿床断裂构造体系在空间上具备的分形分布特性来探讨断裂构造过程的自组织临界性 借助地震弹簧-滑块元胞自动机模型来探讨不同外力驱动下断裂演化过程的自组织临界性   在地震弹簧-滑块元胞自动机数值模型基础上+考虑流体压力对岩石破裂的影响+脉体的形态与分布不规则性进行分析 对地震断层带中构造-流体耦合作用对成矿物质运移、自组织富集成矿过程的影响进行模拟分析  研究思路 主要步骤\n 设定元胞属性、元胞状态以及元胞邻居类型 提取系统演化规则 模拟结果分析  自组织临界性研究相关理论 自组织临界性理论 找到这个白话文解释\n自组织  自组织（Self-organized）:在没有外界的特定干扰作用下，系统内部组分通过非线性相互作用自发地实现系统在时间、空间和功能上的有序演化。  均匀简单的平衡状态 演变 复杂有序的非平衡状态 系统通过自组织演化而形成稳定状态特征   自组织理论：研究系统在一定约束条件下，从无序自发演变为有序，从低级无序自发演变为高级有序的内在作用机制。  理论群：耗散结构理论、协同学理论、突变论、分形理论、混沌理论=\u0026gt;共同构成了自组织的理论框架 耗散结构理论：侧重于对可发生自组织演化过程及自组织系统构建所需条件的研究=\u0026gt;自组织条件方法论 协同学理论：侧重于研究自组织演化过程建立之后自组织活力的保持过程=\u0026gt;自组织动力学方法论 突变论：侧重于研究系统自组织演化过程中可能出现的演化途径=\u0026gt;自组织演化途径方法论 分形理论：侧重于自组织演化过程中，系统从简单性结构到复杂性结构的变化过程=\u0026gt;自组织演化空间形态方法论 混沌理论：侧重于系统自组织演化过程中时间的复杂性问题研究=\u0026gt;自组织动力学发展方法论    临界性  临界性（Criticality）:  与物理学中的连续相变具有类似的特性: 系统内部具有完全相同的物理和化学性质的均匀部分可定义为一个相，当物质的物理化学性质发生改变，足以使物质从一个相转变为另一相时，此时系统发生相变。 临界态的系统往往表现出 长程时空相关性 和 时空分形结构 两个显著的特性(不懂)    自组织临界性   自组织临界性: 解释复杂性系统的时-空延展并具有巨大相互作用的动力学行为\n  兼具时间和空间自由度的时-空延展的开放动力学系统: 如地质学、地震学、气象学等领域\n 不需要进行任何外部控制因素的调节与主导 在外界能量及物质输入的驱动下 系统内部子系统之间通过非线性相互作用，可自发演化到一个在宏观动力学稳定而在局域动力学上不稳定的临界状态。    临界状态下,\n 外界对系统微小的扰动可能被无限放大 可触发链式反应甚至影响到整个系统 导致了系统的长程时空关系特性的产生，在系统发生崩塌的过程中，会向外界耗散输出物质和能量    自组织临界动力学具有一定的鲁棒性\n 外界扰动及系统内部涨落对初始条件的改变极其不敏感，表现出一定的稳定性 系统在偏离临界状态之后也会自发演化回归临界状态    呈临界态的系统常在空间和时间上表现出分形特性，其耗散的能量和物质规模尺度分布可用幂律分布来度量\n  这类动态系统\n  能量加入到系统以持续缓慢的、均匀的方式进行\n  能量耗散则以瞬时的、崩塌式的的方式进行\n  沙堆模型（科普博文：跨出理解“自相似“的一小步）\n 在该沙堆模型中，缓慢的向一个平台上添加沙粒，逐渐形成一个沙堆 在沙堆形成的初始阶段，新加入的沙粒受到低坡度的制约不会出现远距离的滑动 随着沙粒的加入，沙堆坡度增加，此时新加入的沙粒可能会导致不可预测的结果，沙粒可能会落在原地或仅出现近距离滑动，也有可能引发链式反应甚至发生大范围沙粒崩塌，其崩塌大小可能仅包含少数沙粒，也有可能涉及到沙堆表面所有沙粒。 沙堆系统此时表现出自组织临界特性  能量耗散（沙粒崩塌）的规模及尺度分布服从幂律分布 在时间上其频谱表现出 噪声的特点   利用元胞自动机数值模拟方法可重现该过程，并可得到与实际沙堆模型几乎相符的非线性特性   二维平面模型表示 小总结：沙堆模型可表现出丰富的非线性特性，在设置不同模型参数的条件下，如临界高度 取不同整数值、崩塌之后沙粒选择滑向随机方向、设置不同边界条件，模型均可表现出幂律分布特性，表明沙堆模型演化过程遵从自组织临界性的内禀属性。      总结：自组织临界性系统，\n 系统具有耗散结构，需要外界能量的不断加入，如沙堆模型中沙粒的连续加入、地质系统中地壳的运动。 系统呈现出鲁棒性，与系统初始设置状态无关。 系统达到临界态时，发生的能量耗散事件规模和时间可用幂律分布度量，表现出时空长程相关性。    元胞自动机 元胞自动机的定义与构成   一种的动力学系统\n 时间、空间和状态上都离散 在相同的局部演化规则作用下同步更新 区别于一般的动力学模型，元胞自动机通过一系列局部演化规则取代传统的由物理方程和函数来定义模型结构。    构成要素\n  元胞\n  状态\n  元胞空间： 任意维数（一维、二维或多维）的空间规则划分\n  邻域：\n 冯诺依曼（Von. Neumann）型 摩尔（Moore）型 扩展的摩尔（Moore）型    转换规则： 元胞从当前状态演化到下一时刻状态的动力学状态转移函数\n 可通过机器学习方法自动学习演化规则 也可在现象演化的概念模型基础之上提取模型演化规则    时间\n    元胞自动机的分类及特征  基本特征  同质性：主要反映在元胞空间内的每个元胞单元格都以相同的转换规则或函数演化 齐次性：主要指元胞具备相同的大小、形状及空间分布方式； 空间离散：元胞主要分布在按照特定规则划分的离散的元胞空间上； 时间离散：系统演化以等间距的离散时间分步进行，元胞在时刻的状态直接取决于该元胞及其邻域元胞在 时刻的状态。元胞自动机的离散时间变量与微分方程中的连续时间变量相对立； 状态离散有限：元胞的状态只包含有限个数的离散值； 计算同步并行：各个元胞在某一时刻的状态变化是独立的行为，相互之间不会存在影响，因而其演化及数据处理过程是同步进行的，适合构建并行计算过程； 时空局部性：每一个元胞在时刻的状态取决于其邻域元胞单元在时刻的状态，表现出时空局部性； 变量维数无限：元胞自动机的元胞空间是定义在一维、二维或多维空间上的无穷维动力系统。在具体应用中或计算机模拟时往往处理由大量元胞组成的系统，因而也表现出元胞自动机研究中的高维特性。   元胞自动机的动力学行为: 平稳型、周期型、混沌型、复杂型 自下而上的计算模型  多重分形模型 断裂构造的自组织临界性分析 流体上升运移及脉体形成自组织临界性分析 构造-流体耦合成矿作用自组织临界性模拟分析 总结与展望 深度卷积学习支持下的建筑物模式分析 晏雄锋-2019-武汉大学\n用新方法解决经典问题\n层次分明；善于举例子，容易理解；写的蛮好的;\n图卷积神经网络讲的蛮好的，特别是图画的清晰易懂，文章中可以借鉴\n论文写的是真的好，包括实验和分析阶段的思路和过程，都是值得借鉴的。文章的内容也很丰富，没有感觉多余的话，以后写论文不知道写什么内容了，可以过来多看看。\n可以追一下英文论文\n绪论部分 选题背景与意义   模式可以泛指一切事物之间的规律关系，包括图形图像、文字符号、运动状态，甚至是抽象关系和思维方式\n  空间模式: 在基础的表达结构上所提炼出更高层次的空间关系或时间规律\n 基于栅格模型存储表达的图像中所共存的纹理、形状或特定对象 (从高分辨率影像中提取建筑物区域) 基于矢量数据存储表达的图形中对象所具备的一些重复出现的特征 (地形图中重复出现的城市道路格网、环形、放射形态等 ) 基于时间序列存储的时空数据中所呈现的变化规律 (从人们的出行轨迹中可探测出人类活动的行为模式)    建筑物\n 地理空间数据库中重要的组成部分，是表达空间现象、支撑空间分析和提供空间服务的基础之一。 无论在个体形态还是群组结构，都存在显著的模式特征：  具有较强的人为性，特征可控 城市经过数百甚至千年的自我发展和演化，已形成一定稳定性的结构规律，而建筑物是表达这种规律最直接的载体之一      如何对这种模式特征进行表达、分类、识别、分析也是学者们所青睐的方向之一， 具有较为显著的实际意义：\n 从地理信息科学角度，研究建筑物模式结构有益于地理空间数据库，特别是多尺度数据库的建设、更新和质量评价 从城市科学角度， 探索建筑物的模式特点有助于深入揭示人类活动规律， 理解人类与空间的交互过程， 并应用于城市规划和管理。 从地理学角度，分析建筑物模式分布有利于进一步了解政治、经济、文化、宗教特点， 诠释民族甚至全人类文明的发展和演化规律。    尽管建筑物的模式研究在很多应用上都有着基础支撑作用，但目前研究成果并不成熟完善：\n 以视觉认知为基础的人工识别阶段，离自动化的模式识别和表达仍有不小的距离 建筑物的存储和表达方式也给后续的分析和处理带来一些困难  建筑物的二维面状结构， 相比于其同源数据体系——道路网的点、 线结构， 在形状、 形态上更难以形式化和定量化 道路网通过交叉口、立交桥等连通，而建筑物块之间相互分离，在关系表达上存在一定的模糊性和不确定性，难以统一描述      深度学习\n 以建筑物为处理对象之一的空间模式分析和空间认知问题上， 引入深度学习方法所面临的最大障碍是数据组织结构的非规范性，即采用几何模型表达对象之间的关系。 论文尝试以图结构为数据基础， 构建深度学习模型，并为建筑物模式分析等经典问题提供新的思路和方法，这也是本研究的主要动机所在。    建筑物模式研究 不同尺度下的建筑物模式  微观尺度下的个体形态模式  从计算机存储的角度，建筑物是由一系列空间点相互连接所构成的集合， 其所组合得到的形态结构是人们对建筑物模式最微观的理解 在局部结构上，建筑物的直角转折、 轴线对称和方向走向等特征 单体建筑物的整体形状特征   中观尺度下的群组结构模式  一定范围内建筑物（即建筑物群组） 的连接关系和形态结构 主观和客观因素   宏观尺度下的大区域结构模式  大规模建筑区域的整体性地域结构   三种尺度对应三种认知形式：空间特征感知、空间对象认知和空间格局认知  建筑物模式的特点  联想性（象征性）：对事物的次要信息进行抽象和简化， 而对主要信息进行提取和增强 不确定性（模糊性） ：  建立模糊隶属度函数 将形状的相似性划分为不同的等级：非常相似、相似、弱相似、不相似   部分与整体组合性（层次性）：  建筑物模式的部分与整体组合性 骨架线：建筑物内部的骨架线和建筑物之间的骨架线    建筑物模式识别和分析方法  在大尺度城市空间中，建筑物的个体表达在方向、尺寸和形状等方面都具有较稳定的模式性。 随着比例尺的缩减， 学者们对建筑物模式的分析焦点从目标的个体特征转向群组分布所隐含的空间结构化信息和相关规律，该分析过程通常基于聚类来完成；建筑物聚类通常需要综合考虑位置方向、形状大小、视觉距离等因素度量目标之间的邻近性 在距离度量的基础上，针对建筑物的聚类也成果颇丰，主要包括划分算法、层次算法、密度算法、格网算法以及图论算法等几类 建筑物在聚类后所呈现的分布排列即建筑物的结构模式 总结：  核心问题集中在特征描述和关系表达 主要方法是基于图结构的几何度量和基于认知心理学的判断策略    地理空间数据的深度学习 深度学习概述 ==以后写AI、DL相关背景可以借鉴这个==\n 人工智能（Artificial intelligence, AI） 政府重视AI，相继出台各种规划纲要 深度学习（Deep learning）是实现人工智能的一种技术和方法 热度增长：SCI 论文数量和 Google 搜索趋势 体现 DL的迭代与变革  推理为主导的诞生阶段 以知识和专家系统为主导的寒冬阶段 以学习为主导的复兴阶段   神经网络（Neural network）的品牌重塑  结构上并行计算 功能上自适应学习能力   无法完全解释 + 缺少算力支持  理论上一度被条件及规则表达理论（如专家系统）所压制 方法上也被更简洁、解释性更强的模型（如支持向量机）所超越   随着计算能力的提升、数据时代的来临，神经网络开始逐渐复兴  受生物学启发的那种方法已经很大程度上被抛弃 取而代之的是基于统计学和信号处理的更加实用的方法    深度学习在空间数据分析中的潜在可行性 拟合能力（Approximation ability，即对训练数据的特征提取）+ 归纳能力（Generalization ability，即基于训练数据提取的特征应用到其他数据）\n  大数据时代丰富的空间数据资源为深度学习提供素材\n 基础地理信息数据库体系 众源地理信息    通过视觉信息的机器学习发现空间数据的模式、形态\n  地理空间数据具备典型的局部相关性和多尺度特征\n 卷积核和权值共享等技术实现的局部特征保持 池化等操作实现多尺度的特征提取    深度学习方法为地理空间的智能问题提供解决途径\n  深度学习方法在空间数据处理中有多维度应用的可能\n  但现有研究中， 其主要是应用于遥感影像等栅格数据\n  针对矢量的空间数据， 直接采用深度学习方法的应用则寥寥无几 。处理策略：\n 其一是将矢量数据栅格化 其二是舍弃对象在空间上的关系，将二维数据降维为一维数据，并基于无序的数据进行特征学习    制约深度学习应用于空间矢量数据处理的主要原因是常规的学习模型对输入数据有规范性要求，即要求输入数据的邻域结构（局部感受野）是固定的、规范的、可准确定义的\n 图像处理中的正方形栅格数据和自然语言处理中的线性序列数据 对地理信息科学中的大多数矢量数据，其数据之间的排列、组合和连接关系是非常多样的， 通常也是用非规范结构的图来建模， 难以满足常规深度学习模型的数据输入要求      深度学习的新方向：图卷积网络  图卷积网络  综述论文：Geometric deep learning: going beyond Euclidean data;    空间方法：空间方法直接在图的节点域构造卷积运算 谱方法： 谱方法是以图傅里叶变换（Graph Fourier transform） 理论为基础，在谱域执行卷积运算 图卷积网络是深度学习方法的延伸，相关研究成果已尝试应用于处理  欧式结构数据（Euclidean data） 非欧式结构数据（non-Euclidean data） 建筑物作为一种典型的非规范化空间数据    地理深度学习   图卷积神经网络搭建了深度学习与空间矢量数据分析之间的桥梁， 为深度学习应用于不同数据组织方式的地理空间数据补充了一块重要的拼图   地理深度学习的不同层次\n 图深度学习（ Graph DL）： 如何将深度学习推广到广泛的、通用的图结构中 几何深度学习（ Geometric DL）：几何形态特征或模式的理解, 例如从道路交通网络中识别交叉口、从建筑物群组中识别格网等 地理深度学习（Geographical DL） ：地学问题，其学习的特征或模式都将被赋予了更强的语义信息和地理意义 三个层次分别从“数”、“形”、“地” 等不同角度切入，最终形成完整的地理深度学习概念。 但是目前研究仍处于数学方法层次，针对地理意义上几何形态分析和应用问题解决相关的成果较为稀缺    ​\n研究内容及论文组织 研究对象  研究对象：建筑物 关注： 在个体表达和群组分布上的结构和模式特征 研究方法：基于图傅里叶理论和卷积定理的图卷积运算及在此基础上构建的深度学习方法 实验数据  广州市多尺度城市数据库 2012年完成 包括了 1:2k、 1:10k、 1:25k、 1:50k 等多个尺度的建筑物、水系、道路网等基础地理数据 建筑物是以矢量多边形表示，道路和水系以矢量线段表示    研究内容  基于图结构的深度学习理论 个体建筑物的形状表达与匹配 建筑物群组聚集关系探测 建筑物群组结构模式划分  实验平台 内容组织 图直观形象\n建筑物模式分析的几何模型和理论基础 建筑物空间模式 空间模式的科学范畴  社会学角度、计算机角度、计算机角度 空间信息科学角度  模式可以认为是人们与空间交互过程中对空间所形成的一种理解和表达 交互过程与空间行为（如导航、探路等） 密切相关， 是基于经验的， 且受空间环境大小的约束 空间模式的研究也可以从空间尺寸（Sizes of space） 和空间类型（Kinds of space） 两个维度展开   空间类型维度的表现形式  感知空间：在较小尺寸空间环境中（较小物体到房间范围），主要是通过感知行为与空间交互，例如触碰某一物体 认知空间：在中等尺寸空间环境中（房屋到城市范围），主要是通过认知行为与空间交互，例如视觉辨识某一区域 符号空间：在较大尺寸空间环境中（小区到宇宙范围），主要是通过符号象征方式与空间交互，例如点状符号表达城市    建筑物基本模式与分类  建筑物的模式分类  模式划分体系的侧重点不同， 即空间类型的划分意义不同  从城市建模角度的模式分类侧重于建筑物的物理意义 从社会经济功能和使用用途角度的分类侧重于建筑物的社会意义 从数字制图和视觉感知角度的分类则侧重于建筑物的情感意义    支撑建筑物模式分析的几何模型 几何模型特点\n 能够描述建筑物的空间特征和语义性质 能够表达建筑物之间的关系，如方向关系、拓扑关系和距离关系等 能够支持基本的几何操作，如合并、删除、移位等  约束 Delaunay 三角网   Delaunay 三角网两个重要性质\n 空外接圆性质 最大最小角性质    约束 Delaunay 三角网\n  地理空间对象构建三角网模型时，对象的边界应该保持与三角形的边界一致 =\u0026gt; 狭长的三角形问题\n  采用加密点方式构建约束 Delaunay 三角网\n    类 Voronoi 图\n 对象与周围邻近对象对平面空间的竞争结果 有效地反映出空间对象的影响区域 线状和面状要素 Voronoi 图 =\u0026gt; 类 Voronoi 剖分图  良好性质（应用于地理对象建模）  除边界区域，三角形的骨架线连接后形成了闭合环，每个环包围一个建筑物多边形， 且区域内的点都近似与该建筑物距离最近 内部区域中闭合环的边构成了建筑物之间空白区域的近似剖分 骨架线与建筑物凸壳连接后可形成边界区域的闭合环，同样每个环包围着一个边界处的建筑物多边形      最小支撑树（MST）  利用条边将个对象相互连接的极小连通子图 建筑物的 MST  将每个建筑物与最邻近的建筑物联系起来， 明确了邻近关系 存储建筑物的“链条” 保留了建筑物之间的顺序，并隐含地传达了建筑物群组的线性形状，有效地顾及了建筑物之间的连续性 不存在循环结构，可轻松进行分割或聚合操作，在建筑物聚类和局部结构识别过程中极具价值。    建筑物模式的理论基础和认知参量 从认知角度讨论其模式特征-从认知角度讨论其模式特征-结合认知心理学领域知识-Gestalt 理论\nGestalt 认知理论  Gestalt 规律原则  认知参量描述 定量化的模型\n  个体建筑物的认知参量: 位置、尺寸、方向和形状\n  建筑物群组的认知参量：\n  密度\n  距离     图卷积神经网络 主线：“图-卷积-学习”\n “图”是数学结构 “卷积”是运算操作 “学习”是优化求解过程  图理论基础 基本定义 拉普拉斯矩阵 拉普拉斯矩阵一般用来表述无向图\n相关参考\n 快速了解：【图论】拉普拉斯矩阵（Laplacian matrix） 推导（图函数）：拉普拉斯算子和拉普拉斯矩阵  图卷积运算 将图节点域的卷积运算转换为傅里叶域的点乘运算\n傅里叶变换  任何一个（周期性）函数（或信号）可以由一组合适的三角函数组合而成 本质上，傅里叶变换是使用一种特殊的正交基（正交函数）对原始函数进行线性变换 傅里叶变换在于将函数（或信号）从一个域（如时间域或空间域） 转换到另一个域（如频率域），即以不同的方式或角度呈现同样的信息； 且变换过程信息总量保持不变，即满足帕塞瓦尔定理 核心思想是变换和分解，在空间数据分析中被广泛应用于数据的多尺度表达和变换  卷积运算  通过两个可积函数和得到新函数的运算过程 卷积运算可以理解为一次翻转操作（“卷”）和平移加权求和（“积”）   卷积定理: 满足函数卷积的傅里叶变换等于函数傅里叶的乘积  图傅里叶变换  傅里叶变换本质上是利用一组正交的三角函数对原始函数进行线性变换 对于图结构数据, 利用正交的拉普拉斯矩阵的特征向量代替三角谐波函数进行线性变换 图函数（或函数） 的两种表达: 空间节点域和拉普拉斯特征域  图傅里叶变换对应的则是空间（节点）域和谱（特征）域的关系  图卷积运算  图结构数据， 节点排列不均匀，邻域结构不固定， 难以执行“翻转” 操作=\u0026gt;无法定义节点域的卷积运算 将图的卷积运算转换为谱域中傅里叶变换的点乘运算 三个步骤：图傅里叶变换、点积运算和图傅里叶逆变换  争议性问题  谱特征和图结构并不完全等价 该运算与常规卷积运算并无直接对应关系    基于多项式拟合的快速局部卷积 神经网络 神经元处理单元   最早的神经元计算模型：M-P模型\n  本质上是“加权和转移” 的数学模型\n  网络拓扑结构（架构）   感知器（Perceptron）\n  双层感知器\n双层感知器使得模型的表达能力更强， 在理论上已被证明可以处理任何复杂的分类问题\n  多层感知器（Multilayer oerceotron, MLP）\n  学习过程   在训练之前， 网络中的连接权重和偏置量都被随机初始化，之后根据训练数据不断调整，即学习\n  基于梯度的反向传播（Back propagation， BP） 算法\n 正向传播过程: 输入带标签的训练样本， 经输入层和隐含层的状态转移，最终通过输出层得到网络估计值 反向传播过程: 比较估计值与标签值，若有误差，将误差通过链式求导法则由输出层传播到隐含层和输入层，并利用梯度下降算法（Gradient descent） 调整神经元权值 小批量梯度下降法    可接收多个外界输入信息，并通过自身一组相互连接的神经元处理单元对输入信息进行线性或非线性操作，最终产生输出结果的并行式、分布式计算模型。\n  图卷积神经网络 卷积神经网络  网络的优化过程即调整卷积核参数和偏置量的过程   池化：计算某一局部范围的统计值 以较小尺寸卷积提取空间局部结构， 并组合得到整体特征， 该过程是一种多尺度的特征表征方式 优势  特征提取过程符合对象的语义分解性和认知层次性 使用较小尺寸的卷积核操作输入信号，能大幅减少模型的参数数量、 降低模型复杂性，从而提高模型学习能力    图卷积神经网络   思想\n 每一个神经元处理单元都可以接收同一图结构上的多个输入信号，即可以输入多维的图结构信号 神经元运算操作都具备空间局部特性，即运算后的图节点输出仅和邻域节点相关 都可以通过参数共享减少参数、降低模型复杂度，一个维度下的图输入信号仅需要少量运算参数    图池化\n  图卷积神经网络（Graph convolutional neural network， GCNN）\n这个图真的很容易看懂GCNN了！\n  GCNN 模型中的消息传递过程：建筑物及其邻域的描述参量通过某种非线性变换，得到新特征，而变换过程中的参数则通过训练得到\n   应用中，可根据实际情况调整 GCNN 架构  图卷积神经网络学习过程 面向边界化简的个体建筑物形状分析 引言  P1  形状 形状分析：模式的提取和描述过程  几何特征的定量描述：从认知的角度， 采用某个指标描述形状，如紧凑度、分形维度、延展度、凹度、重叠度等 结构模式的自动识别：从模式分析的角度，把一些稳定的、典型的、重复出现的形状理解为模式     P2  从建筑物中提取稳定、典型特征形状的过程则需要考虑其地理意义和应用场景 论文考虑地图综合的应用场景，即建筑物边界化简，来分析个体建筑物的形状模式   P3  边界化简 目的是对建筑物轮廓进行抽象和简化，同时保持其几何特征、群落结构及分布模式 寻找重复出现的形状，亦称之为模板， 并利用这些模板置换具有相似形状结构的建筑物来完成化简 研究进展  形状的形式化描述 建筑物边界化简      形状的形式化描述 建筑物边界化简 几何、形态学和优化算法\n面向边界化简的个体建筑物形状分析 总体框架  基本思路：提取一些稳定的形状并构建一系列的模板 三个步骤：模板构建、形状度量和模板匹配  模板构建   模板库\n  大致划分为四类：简单形状、 象征形状、 复合形状和自动提取形状\n  ​\t四类模板的示例， 其中模板 A、 B 是简单形状，模板 C、 D 是象征形状，模板 E 是复合形状，模板 F-J 是自动提取形状\n相似性度量 基于转角函数的相似性度量   转角函数（Turning function, TF）\n  将二维建筑物形状转换为一维函数表达\n  对于多边形𝐴、 𝐵，分别记其转角函数为𝑓𝐴(𝑠)、 𝑓𝐵(𝑠)，其形状差异可利用函数组成的𝐿𝑝空间距离来度量，定义距离𝐿𝑝(𝐴, 𝐵) ；多边形𝐴、 𝐵相似度越高，则𝐿𝑝(𝐴, 𝐵)值越小；对多边形旋转角度和边界起始点的选择都非常敏感\n  形状相似度𝑆2(𝐴, 𝐵) ；多边形的缩放、平移等并不会影响相似性的计算；不同起始点和计算方向，其相似度也不相同\n  通过遍历模板上所有的转角节点作为起始点，比较各节点相似值，取其最小值即该模板与建筑物之间的相似度\n  基于 GCNN 的形状自编码模型   边界点特征\n  基于局部结构\n  基于区域结构\n    基于图卷积运算的自编码器（Graph convolutional autoencoder, GCA）\n  以图卷积运算代替全连接的神经元运算\n  不需要输入数据的标注信息，即是非监督学习\n  关注重点也不在于输出结果，而在于对中间编码方式加入一些特定约束从而实现某些目的，例如减少表达维度以提取其主要特征， 实现降维目的\n  集成和压缩了原始的形状描述，得到新的形状编码方式。 基于该编码可使用欧式距离等计算得到形状之间的相似度\n    基于最小二乘的模板匹配   模板的匹配过程需要保证模板与原始建筑物的位置、 尺寸、方向一致 =\u0026gt; 2D Helmert 变换模型\n  根据最小二乘原理， 误差最小时， 模板与建筑物达到“最佳” 匹配状态\n  建筑物和模板的边界点数量和次序都不确定，因此在使用最小二乘模型之前，需要建立其匹配关系\n  动态规划算法建立建筑物与模板边界上弧段的匹配关系\n  实验与结果  比较基于转角函数和 GCA 模型对形状表达的有效性 论述模板匹配化简方法的合理性和可行性  数据准备和模板库  625 个建筑物多边形 包含若干典型的居住社区 模板库：以人工方式提取，54个模版  形状相似性度量实验   度量指标-匹配度\n  比较和讨论转角函数和 GCA 模型对形状相似性度量的有效性\n  训练 GCA 模型所需的数据集\n  针对 11 个典型建筑物构建出 11 个相应的模板，并通过几何变换方式对模板加入噪音\n  可设置不同的变换强度σ\n  按正态分布为每一种变换随机生成 100 种强度，最终得到 5500 个形状组成的训练数据集\n    GCA 模型训练\n  通过加密点的方式得到每个建筑物 64 个边界点\n  每个边界点基于局部结构和区域结构的 7 个特征，特征采用Z-score 方法标准化\n  模型参数：输入批量数为 100，采用 Sigmoid 函数激活， 输出为 32 维特征。 Adam 优化算法被用于求解模型， 其学习率和指数衰减率分别为 0.001 和 0.95。 模型经过 50 轮训练。\n    基于转角函数与 GCA 模型计算的相似度与匹配度之间的相关性-呈高度正相关\n  t-SNE 算法GCA 编码特征降维可视化\n  相似的形状其位置点也较为接近\n  其他几类形状都可以从视觉上区分出明显的群簇关系\n  由于形状的复杂性，并不存在哪种形状度量方法在处理不同应用场景时都能具备显著优势\n 对于转角函数，其仅考虑了边界点切角特征，对于一些存在连续弯曲的建筑物，其切角变化可能存在震荡，从而导致形状度量效果不甚理想 GCA 模型可以考虑边界点更多的描述特征，但编码后的表达实际上是一种有损压缩，可能会造成对某些参量的敏感性      模板匹配化简实验  以转角函数度量形状相似性，并使用所构建的模板库对实验区域内的建筑物进行化简 （这里并没有采用GCA 模型） 化简后， 其形状更加规整、 统一 模板匹配方法的优势在于能更好地保持局部范围内建筑物形状的规整性和统一性 定量化统计分析：结果表明[0,0.25]区间内建筑物数占比为 94.2%， 这表明模板匹配化简在大多数情况下可以取得较令人满意的结果  模板匹配方法比较  基于最小二乘法的模板匹配，并与其他两个方法进行了比较（几何度量方法，最小外接矩形（SBR）方法）  分析与讨论  模板的多样性 粗粒度与细粒度模板  本章小结  聚焦于个体建筑物形状模式的分析；并针对地图综合的应用场景， 从整体上提炼出一些稳定的、典型的、重复出现的形状作为模板，来替换原始的建筑物，实现边界化简 面向边界化简任务的个体建筑物形状分析框架，包括模板构建、相似性度量、模板匹配三个主要步骤  代表性形状模板库 建筑物和模板之间的相似性度量 基于转角函数和图卷积自编码器（GCA）两种方法 基于最小二乘的模板匹配方法   性能比较，结果评价，分析讨论  图卷积学习支持下的建筑物聚类 这部分有些没看懂，这是聚类任务么，什么是有监督的聚类？\n有迁移学习的味道，先用分类学习特征，在用特征聚类\n人工标记样本\n针对建筑物群组的模式分析\n 何为“群组” ？ 如何探测“群组” ？  引言  人们的社会行为决定了建筑物具备一些特定特征， 包括由人类群居行为所决定的聚集性分布特征 意义 常见的聚集性特征分析方法-空间聚类  空间聚类的目标：同一群组中对象之间的相似度尽可能高，而不同群组中对象之间的差异性尽可能大 建筑物空间聚类在算法设计和约束条件等特点和难点  属性信息的复杂性 认知参量的模糊性 约束条件的不确定性 建筑物数据的尺度特征     提出监督式的 GCNN 聚类模型：分别以节点和边为学习对象， 提出了两个聚类方法：节点聚类和边聚类  建筑物聚类的形式化定义 问题定义\n建筑物聚类研究现状 以图结构为基础的聚类\n 采用图结构定量化描述建筑物对象之间的关系 考虑不同的认知参量和约束条件 利用相关算法得到聚类结果  基于 GCNN 模型的节点聚类 总体框架 数据划分、 图结构构建、图节点特征映射以及结果输出 （好好理解，先分类，后聚类）\n样本标注   图像分割：并不知道分割区域是什么\n  图像语义分割：不但划分出区域，还判别区域是什么\n  以深度学习等监督式建筑物聚类则和图像语义分割任务相似\n  两种标注方式\n 按聚类后建筑物群组的结构类别或语义信息进行标注 按聚类后建筑物的位置进行标注， 即将同一个群组内的建筑物标注为相同位置    面向聚类问题的GCNN模型  聚类问题=\u0026gt;特征映射问题: 将一组数据的多个特征进行非线性的组合， 并嵌入到二维特征空间中，最终按新特征空间中的距离进行聚类  输入：包含𝑁个建筑物的图结构𝒢 = (𝒱, ℰ, 𝒲)，其中每个建筑物代表一个节点，且包含𝑚个描述特征{𝑓1, 𝑓2, … , 𝑓𝑚}，全部节点构成𝑁 × 𝑚特征向量；建筑物之间的距离构成𝑁 × 𝑁权值矩阵； 标注： 𝑁 × 2向量，即每个节点所处群组的中心点位置坐标(𝑥𝑖, 𝑦𝑖)； 输出： 𝑁 × 2向量，即预测每个节点的平面位置坐标。  模型的损失函数可通过预测位置与标注位置之间距离的均值确定 在建筑物聚类任务中， GCNN 模型主要是通过监督信息，将位置、 尺寸、方向、形状、密度等变量信息进行集成， 并嵌入到二维平面坐标。 基于新的坐标可计算建筑物之间的距离， 并可采用经典的 K-means 算法将其聚类成 K 个群组。    基于 GCNN 模型的边聚类 总体框架  边聚类是预测边的状态 划分为同一个群组的建筑物之间仍保留连接边，而不同群组的建筑物之间则删除边连接=\u0026gt;聚类后边具备两种状态：保留和删除  边描述特征提取   分布差异性：一定邻域内节点某个指标𝐴的统计分布差异\n  空间自相关性：探测对象的指标值在空间分布上是否呈现高高相邻或者高低间错等特征\n  实验结果与讨论 数据准备 注意到这里并没有使用全部数据进行训练，而是有一个匹配、选择的过程\n 首先以道路、水系等物理分割作为全局约束条件， 提取一定区域内的建筑物，每个区域对应为一个样本 从比例尺为 1:10k 数据中查询出每个样本所对应的建筑物，利用叠置分析计算出两个尺度间的匹配关系； 再者， 根据匹配关系挑选出恰当的样本用于训练； 最后， 标注样本 共提取出 4170 个有效样本，每个样本包含 16~64 个建筑物，全部样本包含 162781 个建筑物 按6: 2: 2比例将全部样本随机划分为训练集、验证集和测试集 （ARI计算的是测试集的聚类评价） 根据该数据输入的要求，需要保证各个样本之间的数量的一致，因此需要对数量不足的样本添加伪节点。 这些伪节点不与其他节点存在任何连接， 且描述指标全部为 0。  聚类评价指标  非监督聚类评价  类内高聚合、类间低耦合 紧密性、间隔性、戴维森堡丁指数和邓恩指数 适应于通用的点数据，而非建筑物数据   监督聚类评价  通过定义指标来比较标注聚类结果与算法预测聚类结果之间的差异性 调整兰德系数（Adjusted Rand index， ARI）， ARI 值越高，聚类效果越好    建筑物聚类实验  节点聚类  每个节点包含了 11 维输入特征 采用 Delaunay 三角网构造图结构   边聚类  每条边包含了 28 维输入特征（22 个构造特征𝐹𝐷(𝐴)和𝐹𝑀(𝐴)，以及 6 个距离指标    参数敏感性分析  对比：仅使用一个描述指标 + 剔除该指标  方法比较 分析与讨论 图卷积学习支持下的建筑物群组模式分类 引言  建筑物的群组模式分析本质上可以理解为分类问题，即某一个群组在整体结构上属于一种模式或另一种模式 对建筑物群组的模式并没有形成明确的、 统一的定义和分类标准 方法上，现有的基于规则和基于机器学习的模式分类方法也面临着需要手工定义模式规则或提取描述特征等问题 论文以视觉认知结果作为监督信息，提出基于GCNN 模型的建筑物群组模式分类方法  收集多名观察者的认知结果来尽可能保证一致性 端对端（End-to-end）的学习方式，不需要手工定义模式规则和提取特征    群组模式形式化表达 群组模式识别方法  基于规则的方法：查询相邻建筑物之间是否存在某些相似的结构或特定的排列 基于机器学习算法  基于 GCNN 模型的建筑物群组模式分类 总体框架 建筑物聚类、图结构构建、图卷积分类和结果输出\n建筑物群组模式的层次性  城市邻区模型：街坊、街区、超级街区以及社区   不同层次下， 建筑物群组模式的关注重点和识别方法均存在差异。  街区层次下，对建筑物群组的关注点侧重于其排列方式 而社区层次下内，关注点可能侧重于其分布密集程度等   尺度分析  街坊层次：每个群组内包含 2~5 个建筑物，街坊层次下的群组内建筑物数量较少， 构建图结构后，邻域概念不明显， 大部分建筑都只有 1~2 阶邻域 超级街区和社区层次：建筑物群组的模式较为复杂、多样，不利于总结出稳定的模式并训练分类 论文主要从街区层次分析建筑物群组的模式特征   类别划分  从视觉上区分 规则模式  建筑物群组结构同质，视觉上有规则的间隔和排列 如新规划建设的住宅区   不规则模式  建筑物内形状多样、尺寸不一或者排列错乱      面向分类任务的 GCNN 模型 实验和结果 数据准备   模式分类前需要将建筑物被划分为独立群组， 即聚类\n  每个群组通过 3 名参与者将其标注为规则或不规则模式\n  模糊群组\n  混合群组\n  一些模糊或混合的群组会被剔除\n    2647 个规则模式和 2646 个非规模模式的群组，每个群组包含 20~128 个建筑物， 总共包含 318641 个建筑物\n  每一个建筑物群组都可以看作是 GCNN 模型的一个输入样本，所有样本按6: 2: 2比例随机划分为训练集、验证集和测试集\n  添加伪节点\n  群组模式分类实验   GCNN 模型对某个建筑物群组的激活过程 （这个分析很有意思）\n特征图的傅里叶变换值越来越稳定和稀疏；GCNN 模型保留了从训练集中提取的主要特征，而逐渐忽略了次要信息\n  分析了一些被错误分类的建筑群组\n 当存在狭窄的建筑物横跨在群组的边缘时， 分类性能急剧下降    参数敏感性分析  网络深度  5 折交叉验证实验 开始阶段模型性能随着深度的增加而逐渐提升，随后趋于稳定；当模型深度达到 12 层时，性能开始急剧下降。 解决方案是使用残差连接（Residual connections）     不同的输入图结构（即 Delaunay 三角网和 MST）和不同的卷积多项式阶数𝐾（即 1~6）    个体建筑物的认知参量对整体群组模式分类的影响\n  只使用某一个建筑物描述指标和剔除该指标时模型的分类性能表现\n    方法比较 分析与讨论 总结与展望 论文总结  建筑物模式分析  重要意义：地理信息科学和城市空间研究等领域 聚焦于：微观尺度下建筑物个体形态模式和中观尺度下群组结构模式 提出了：基于图结构的卷积神经网络深度学习方法   主要内容：  以“问题—模型—理论” 为主线， 介绍了建筑物模式分析的研究问题、几何模型与理论基础。 以“图—卷积—学习” 为主线， 介绍建筑物模式分析的数学结构和分析方法。 从地图综合的角度分析个体建筑物的模式特征，并提出了基于模板匹配的建筑物边界化简方法，该方法主要包括模板构建、形状度量和模板匹配等步骤。 借鉴图像语义分割的思想，提出了基于 GCNN 的建筑物监督式聚类方法，并根据图节点和边的对偶关系， 分别以节点特征和边状态作为学习对象，提出了两个聚类方法：节点聚类和边聚类。 借鉴图像分类的思想， 提出了基于图卷积神经网络的建筑物群组模式分类方法。    研究展望 论文尝试以图结构为数据基础，尝试构建图卷积神经网络深度学习模型，并以解决建筑物模式分析等经典问题为切入点，取得了一定的进展。 但相关研究仍处于初步阶段，特别是地理深度学习的概念需要不断地完善和丰富\n 建筑物模式的研究范围需要进一步拓宽  其他层次的建筑物群组模式，甚至大尺度下城市的形态模式，如城市范围内全部建筑物 从视觉上区分出更详细的模式（例如圆形、发散性等），或者面向其他应用场景划分出新的类别   图卷积神经网络的理论方法需要持续性探索  池化技术 网络结构   深度学习在地理空间矢量数据分析中的应用价值需要不断地挖掘 研究探索的过程中将涉及到一些共性的步骤， 包括领域问题定义、训练样本收集、学习方法构建、 工程实践开源等，每个步骤都需要我辈后生勤耕不辍、努力不懈。  地质大数据表示与关联关键技术研究 2018-马凯-中国地质大学（武汉）\n绪论 研究背景及意义  P1  多源异构的地质数据 地质大数据的分析挖掘 对现有地质数据中的空间对象与非空间、非结构化文本对象特征进行合理的表示，并构建二者的关联关系，是实现“图文融合”、“文图互查”等应用场景的关键。 切入点：地质空间实体对象与非空间地质文本对象的匹配与关联问题 语义特征、属性特征、拓扑特征表示 主要目的  挖掘对实体相似性有决定作用的高效特征表示模型 地质实体的关联与表示方法 进而实现地质智能协同服务应用     P2  研究面向地质文本对象与地质空间实体对象关联任务的高效表示学习方法 研究非结构化地质报告中实体与空间地质数据中实体的语义关联性度量方法 基于地质本体的地质实体识别与地质实体信息网络构建方法（超边构建策略、网络表示学习）=\u0026gt; 多标签分类和节点类型相似度查询   P3  本文的研究目标由地质行业实际应用需求与学科技术发展趋势共同驱动，研究成果可以有效支撑地质知识获取、融合和推理， 为实现地质空间与非空间数据的模式与特征提取、地质实体普遍关系发现及认识其他隐含在地质数据中的特征规律提供理论和技术基础， 将为智能地质调查平台提供多源地质数据的关联和应用新方法，提供地质数据“图文融合”、“实体关联”、“网络表示”等新的地质信息应用范式。 也能够充分挖掘现有地质数据中蕴含的知识，加快实现各类地质信息的社会化共享，充分提升现有地质大数据的潜在应用价值，满足政府、地质调查专业人员和社会公众的需要。    研究目标与内容  P1（研究目的）  基于深度学习的地质数据关联方法  对地质空间实体数据与外部地质文本数据进行向量化处理 对两类对象进行语义相似性度量   构建地质领域本体库：地质实体进行分类和识别，在此基础上构建地质实体信息网络，丰富提取实体的语义联系 对实体网络中的节点进行表示学习，获取节点的低维实值表示，以便于进行节点分类和相似性检索 开发初步的原型系统：设计地质大数据的处理、访问、计算与组织管理方法   P2  理论和方法：表示学习技术、地理信息系统、自然语言处理、网络表示等 问题1：现有地质数据缺少合理的语义表示和随之产生的异质异构数据关联困难、数据挖掘不便开展  通过构建和标注实验数据集，引入深度学习方法 分析地质数据特性，研究地质空间实体与文本对象的合理表示方法 突出在空间实体与文本实体信息量不对称、表达方式不一致的情况下，进行相似性比较度量   问题2：地质文本中提取出的地质实体间缺少语义关联  提出基于领域本体的地质实体信息网络构建方法，选择合理的网络表示模型对其进行表示 对提出的模型适应性进行了评估     P3（关键科学问题）  地质空间实体与地质文本对象的语义化表示问题 地质空间实体与描述文本的匹配问题 地质实体信息网络构建与表示 设计实现了原型系统    创新点   P1\n 立足于：地质大数据的信息服务应用需求 问题1：  地质空间数据中的地质实体对象与非结构化地质报告等文本数据的表示与关联问题 构建了文本对象与空间对象的深度表示模型   问题2：  地质领域文本数据与空间数据的语义相似度计算问题 提出基于领域本体的地质信息实体网络构建方法 并选择合适的网络表示模型获取网络节点的有效表示   贡献：为地质资料整合提供新方法，为地质资料应用提供新范式    P2（主要创新点）\n 地质空间实体的语义化表示问题  基于句向量组合的层次化地质空间实体语义化表示方法 利用九交模型获取地质实体与相邻实体的空间拓扑语义表示 把地质空间实体的属性表示与空间拓扑表示串联起来作为深度循环神经网络模型的输入 学习得到蕴含地质实体属性与空间拓扑信息的地质空间实体语义表示向量 用以与外部地质实体描述文本进行语义匹配   地质空间实体与外部文本描述的关联问题  带注意力机制的层次化孪生网络模型 学习到两类对象面向关联任务的低维、实值语义向量表示 最小化匹配的样本对向量之间的距离，同时最大化不匹配的样本对之间的距离   地质领域文本中地质实体信息抽取后实体间缺少语义关联的问题  构建了地质本体库辅助进行实体关系识别 基于此构建了地质异质实体信息网络 提出和定义了地质实体超网信息模型，设计了网络超边构建策略 利用地质实体间超边的一阶相似性来确定超边中节点的不可分性，利用二阶相似性来保持超边中的节点近邻关系 利用表示学习技术对超网络结构的地质异质实体信息网络进行了特征表示 获取的节点特征进行了多标签分类和实体相似性查询分析    论文技术路线及组织结构   地质大数据的构成与相关表示技术  P1：大数据的表示=\u0026gt;地质大数据的合理表示 P2：本文研究的地质大数据  来源：地质调查成果报告 具体内容主要：  平面地质矢量图中的地质实体对象=\u0026gt;结构化的形式 相关的各类地质报告或文档中的文本数据=\u0026gt;半结构化（表格）或非结构化形式      地质大数据构成 地质大数据组织与管理 地质空间大数据特征及表示技术 地质文本大数据特征及表示技术 ","description":"","id":60,"section":"posts","tags":["论文阅读","博士论文","自组织临界性","元胞自动机","图卷积神经网络","建筑物模式","建筑物"],"title":"博士论文阅读札记(2)","uri":"https://www.xunhs.cyou/posts/notes/2020-07-16-%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AD%E8%AE%B0-2/"},{"content":" 家👪到学校🏫，状态切换\n \n 2020.7.1 我还是蛮喜欢开车的 2020.7.2 过春天-看不懂的青春片 2020.7.3 今天终于把老妈的电话卡给办好了。已经拖了将近半个月。去京东服务点6次，最后竟然带着老妈去服务点。听的最多的一句话：“必须本人持身份证来办理！”，话说本来你们应该是上门服务的好吗？吐槽归吐槽，“每次去都有不一样的收获呢。” 2020.7.4 玩《使命召唤：二战》真的太刺激了，还原度、战争场景带来的感触还是蛮震撼的，除了一味的射击，还有真是的暗杀、伪装等任务，有些关卡还是蛮难的，手残党死了好几次（同时查攻略了。。。）才过关。话说，这比王者荣耀带来的“成就感”和“放松感”棒多了！不用一直发“干得漂亮”嘲讽队友了、 2020.7.5 1）菜鸡本菜；2）简单写了一个OneDrive的上传工具（基于Fast.io，PyQt5和OneList的OneDriveUploader），可以当作一个图床（其实视频床、文件床都可以。。。）使用吧（如下图篇测试）、 2020.7.6 高考加油！ 2020.7.7 1) 通关了？; 2) 心存敬畏 2020.7.8 复现了一下视觉词袋模型，采用The Google image dataset of SIRI-WHU的数据集，采样部分图片，构建SIFT特征尝试多场景分类（12类 * 20Smaple = 240）。总体而言分类效果较差。存在明显改进的地方，比如说特征构建方面，聚类改进方面等，不过这方面了解较少，以后感兴趣再说吧。 2020.7.9 梦想还是要有的 不然哪天你喝多了跟人聊啥 2020.7.10 1) 老妈每日一催：还没有通知什么时候返校吗？; 2) 复现了基于神经网络的遥感影像场景分类模型，对原始代码（zdaiot）修改，改用的SIRI-WHU数据集，分类效果很好。 2020.7.11 今天收到可以返校的消息，去医院问了一下，缴费等待明天核酸检测。 2020.7.12 今天做完核酸检测，结果阴性没有问题，但是申请的时候行程不好写，车站关门了，等明天买票再说吧，其实很想和老爸开车去岳阳东站，然后做高铁去武汉。我知道不现实，他不可能同意；在和大姐聊天的时候，和老爸大吵了一顿，觉得他管我管多了，我长大了不需要这样的管束。我们生活观念不一样，不需要屈从于另一方。我的态度不好，我承认。说的话也有些重了。以后要注意。 2020.7.13 1）申请很快就通过了，明天出发；2）追远。3）看了一下hugo,虽然相比hexo有些优势，但目前不想折腾了。 2020.7.14 上午九点钟出发，下午2点半才到终点站，真的再也不想做这个长途汽车，太慢了。司机也不遵守规则，在一个地方等了有半个多小时，（弱弱的）真心想投诉。还好有徐老师来开车接了一段时间，非常感激。来学校后东翻西找，很多东西都没找到，感觉脑子还没有从家里带回来。折腾一下午，收拾宿舍，最终校园卡还是没找到。今晚洗澡感觉够呛了，可能落在家里了。先不管啦，晚上好好休息。明天在说。 2020.7.15 1）校园卡终于找到啦 原来在实验室的桌子上；2）cities的意见回来了，一开始看到小修的决定还蛮开心的，但是看到Reviewers的意见立刻就头晕了，特别是Reviewer#2，给了意见一大堆，真真的痛并快乐着；3）更新博客服务器，使用github+netlify持续部署，摆脱服务器依赖，say goodbye to aliyun。记录一下，目前博客基于hexo搭建，主题使用melogy，图床有三个：gitee(限制1MB图片，速度快)，github+jsdeilver（时常出现上传和访问问题，原因为止），MS OneDriver+imfast（速度中等，大小、文件类型无限制，同时自己用python写了一个上传工具），博客source放在github上，然后基于netlify持续部署，方便部署和迁移。4）看自己几个月前写的论文，最大的感受是：what a piece of shit! 2020.7.16 1）树莓派的dietpi镜像很可以，部署、安装环境很方便，同时把本机的Cloudreve服务部署到树莓派上了；2）反正拧发条鸟每天都飞临附近树上，拧动我们所属的这个静谧天地的发条。-《奇鸟行状录》 村上春树 2020.7.17 两情若是久长时 又岂在朝朝暮暮 2020.7.18 EMOJI CHEAT SHEET 😓 2020.7.19 正则表达式速查 + Python正则表达式提取字符串 2020.7.20 不知所措 无法逃脱😖 2020.7.21 没有广播没有电视没有报纸没有杂志。就在这一瞬的时间里，东京说不定给核弹夷为平地，瘟疫说不定席卷山下人世，火星人是否占领澳大利亚亦未可知。纵然如此，我也完全无从知晓。-《寻羊冒险记》 村上春树 2020.7.22 1) 我看村上的作品可能更多的是喜欢他的偏文艺的文笔，小资的情调。具体地小说本身讲述的故事，理解甚微。看完《寻羊冒险记》，再去看书评，仿佛自己看到的不是一本书一般😢; 2) 前端九部 - 入门者手册2019 2020.7.23 小修终于改完了，感觉这次的小修好折磨人。又不能做别的事情，因为总会想着这个。正如徐老师说的，自己还是不成熟，什么时候做到不以物喜，不以己悲，才能够真正沉稳下来。 2020.7.24 整天说模式模式，什么是模式？ 2020.7.25 早上被WJ的电话叫醒，她要去医院看病叫我陪同。想到在武汉看病都没有人陪，便有些失落。WJ在医院可谓是轻车熟路，她完全可以自己来的，问路+挂号+报销，她的操作完全比我熟练多了，很多都是我在问她“去哪里”，“怎么搞”。这也算是一种社会经验吧、总之，医院还是能少去就少去吧😅 2020.7.26 爱一个人不只是喜欢一个人的体温，也是越来越贴近那个人的体温。 -《请回答1988》 2020.7.27 听何老师的话，这也算很幸福的时间吧、确实没有其他事，可以安心读论文、写论文。还是多读书（论文）吧、、、 2020.7.28 今天去了公司一趟 以为能见到老板 交流一下最近的烦恼 老板出差去了 问及如何到的公司 有些支支吾吾 不知为何不想说自己已经出校、如何出校 总觉得有些恍惚 不知道是不是真正脑子不太好 2020.7.29 怎样的我能让你更想念 2020.7.30 今天和家里视频聊天 老爸的第一句话竟然是“我是不是把她俩忘记了”😑 2020.7.31 我竟然有再重新读一次博士的想法、  {% dplayer \u0026ldquo;url=https://1drv.ws/v/s!Av4QPqlXky0kkRCouFmCSGDr3lVu?e=tnENzw\u0026rdquo; \u0026ldquo;loop=yes\u0026rdquo; \u0026ldquo;theme=#FADFA3\u0026rdquo; \u0026ldquo;autoplay=false\u0026rdquo; \u0026ldquo;width=600px\u0026rdquo; \u0026ldquo;height=400px\u0026rdquo; %}\n","description":"","id":61,"section":"posts","tags":["京东快递","使命召唤","OneDrive","场景分类","返校","吵架","netlify持续部署","树莓派","dietpi","寻羊冒险记","医院","请回答1988","大论文主线思考"],"title":"2020-7","uri":"https://www.xunhs.cyou/posts/journals/2020-07-01-2020-7/"},{"content":" 思考开题和研究大论文的主线是长期让我头疼的问题。通过阅读相关的博士论文，从作者的角度出发，挖掘他们的论文主线和思考他们的行文思路，从而为开题和大论文提供参考。\n OpenStreetMap城市建筑物数据质量评价方法研究 徐永洋-2019-中国地质大学（武汉）\n绪论部分 研究背景与意义  第一段：地理信息-志愿者地理信息（VGI）-在线开放街区地图（OSM） 第二段：OSM的质量与价值问题-OSM数据中建筑物数据的质量问题 第三段：  总述：OSM研究价值；城市建筑物数据有很大帮助；深度学习的成功 因此，本文：  研究对象：OSM数据中城市建筑物数据 研究内容：OSM建筑物数据质量评价 具体地：建筑物形状相似性、数据完备性等评价指标+深度学习方法+基于矢量参考数据、遥感参考数据 本文奠基于具有更加坚实的理论和更加先进的人工智能技术，在数据规模和深刻性上都达到了较高的水平。（这句话蛮有深意）     第四段：应用价值+学术价值  研究现状与分析 总的思路是在定量和定性两个方面展开讲\n  VGI数据质量评价研究现状\n 基于官方数据的定量评价方法：数据完备性、逻辑一致性、位置精度、时间精度、主题精度和可靠性 基于VGI本身特征的定性评价方法：数据指标、人口统计指标、社会经济指标以及贡献者指标    OSM 建筑物数据质量评价研究现状\n OSM 建筑物与参考建筑物数据比较 研究 OSM 建筑物数据特点对其数据质量进行评价    研究现状总结与存在问题\n 目前仍无统一的空间数据质量评价模型  一方面定量和绝对的分析需要参考数据     另一方面，定性的分析虽然不需要权威参考数据，但又不能给出针对 OSM 建筑物数据给出绝对的评价结果。   遥感技术（如卫星和航空摄影）的发展 - 高质量的非矢量参考数据比权威矢量数据的容易获取得多\n  基于深度学习通过高分辨率遥感图像目标提取已经取得了不错的成果，这为研究 OSM 数据质量评价问题提供了新的思路\n  综上分析，本研究将评价过程分为两种情况：\n  研究区有可利用矢量参考数据\n  如何客观地、综合地对OSM 建筑物数据质量进行评价是基于参考数据定量评价过程中存在的主要问题\n  如何精确地对其形状精度进行计算也是目前基于参考数据定量评价OSM 建筑物数据质量过程中存在的问题\n    研究区不能获得矢量参考数据\n 如何从高分辨率遥感影像中提取高精度建筑物数据轮廓信息，并基于提取信息对 OSM 建筑物数据质量进行评价是目前基于高分辨率遥感影像数据对其数据质量评价过程中存在的主要问题        研究目标与内容  研究的目的  对空间实体形状描述合理表示 + 针对不同描述形式的多边形相似性度量方法 针对矢量参考数据，定义包括形状精度（形状相似度）在内的一系列评价指标 + 深度自编码网络方法 =\u0026gt; 解决 OSM 建筑物数据质量综合、客观评价问题 针对一些地区矢量参考数据难以获得，高分辨遥感影像着手 =\u0026gt; 实现 OSM 建筑物数据质量定量评价   关键科学问题  研究多边形形状相似性度量问题 研究 OSM 建筑物数据综合评价问题 研究基于高分辨率遥感影像数据进行 OSM 建筑物数据质量评价问题    论文创新点 本文应用深度学习技术、地理信息科学、遥感图像处理等多个学科理论和方法，立足于志愿者地理信息数据应用需求，通过对跨学科的研究为志愿者地理信息数据质量评价提供了新思路。\n 构建顾及空间分布和几何变换的多边形相似性度量模型。 基于标准矢量参考数据，提出利用深度自编码神经网络 OSM 建筑物数据综合评价方法。 基于高分辨率遥感影像数据，提出利用多任务特征学习提取参考数据进而实现 OSM 建筑物数据完整性与位置精度评价方法。  OSM 数据质量评价相关理论 空间数据质量概述 数据-空间数据-数据质量-空间数据质量-空间数据质量问题\nOSM 数据质量问题描述 影响 OSM 数据质量的原因主要有三个：空间实体对象客观存在问题、人类认识主观性以及数据采集仪器的局限性等引起的质量问题。\n空间相似性与 OSM 数据质量 相似性研究-空间相似性=\u0026gt;OSM 与参考数据之间的空间相似度越高，说明 OSM 数据质量越好。=\u0026gt; 。建筑物数据质量可以被表示为：被评价数据与标准数据的接近程度，反应数据与真实值之间的相似度。=\u0026gt; 在本研究中将 OSM 建筑物与标准数据中建筑物之间的几何形态相似性作为评价 OSM 建筑物数据质量中的几何形态精度。\n顾及空间分布和几何变换的多边形相似性度量模型 总述：空间相似性-几何形态-几何形态的相似性；各种形式建筑物可以表示为简单多边形，带洞多边形和复合多边形。\n引言   第一段：引入概念：相似性-几何形态；空间相似性评价可以表示为与等价性偏离的程度，通过已知形状和未知形状的形态差异计算得到；多边形形状相似度被视为 OSM 建筑物数据评价过程中重要的一方面\n  第二段：空间实体几何相似性的相关应用/研究。几何相似度，其相似性一般通过描述子之间的距离来反应。\n  第三段：（1）现有研究不足：形状上下文描述符可以利用随机参考点在大尺度上描述局部信息，但是它缺乏描述全局信息的能力；目前的形状相似性测量方法和模型是针对简单的几何对象，而不能直接用于复杂几何结构（带洞多边形、复合多边形）的，因为它们缺少子图之间位置描述以及不对称匹配时细节表达。（2）解决方案：凹凸性；快速傅立叶变换结合+最远点距离构建形状描述子\n  基于最远点描述的简单多边形相似性度量模型   简单多边形：结构较为简单，不存在嵌套、组合等现象\n  本文主要从构造多边形描述周期函数，以及基于傅里叶变换函数转换来构建多边形几何不变性描述子，将简单图形的相似度计算转换为度量两个描述子向量距离\n  周期函数-形状签名函数-最远距离点（FPD）的形状签名：没有相似轮廓的形状具有明显不同的 FPD 特征，FPD 具有足够描述形状的能力\n  直接通过签名度量形状之间的相似性通常是非常复杂的-离散傅立叶变换-归一化的傅里叶描述子:由于归一化的傅立叶描述符在旋转、缩放和移动等操作中都保持不变，因此在度量相似性时，FPD 的傅立叶描述符可以用来表示形状。\n  几何多边形经过傅里叶变换之后可以利用傅里叶变换系数组成向量表示。系数从低阶到高阶分别用了描述多边形的轮廓信息和局部细节信息。不同多边形的之间的相似度可以通过距离来度量\n  余弦相似度：余弦值越大说明向量夹角越小，多边形之间的相似度也越高\n  基于方位图的带洞多边形相似性度量模型   带洞多边形：形式复杂，而且相互嵌套，是一个整体，属性结构完全相同，如“回”字结构或者其他中间镂空形式\n  关键问题：解决内洞与内洞之间、内洞与整个复杂集合形状之间的关系\n  利用方位图内洞空间分布描述\n 带洞多边形之间的相似性度量可以分为两部分：内洞之间的相似性和多边形轮廓之间的相似性。提出方法是获得带洞多边形的质心与其内洞之间的关系，用于描述带洞多边形的特征。 描述带洞多边形特征： 多边形质心与内洞质心、切点、内洞边界的最远点与最近点之间的距离 多边形的内洞分布：中心点方位图、最远点方位图、最近点方位图、最近切点方位图。    相关几何变换描述子定义与相似度计算方法（专业性较强，有点难理解，就不做详细记录了）\n 方位图描述与相似性度量：平衡力？ 内洞几何变换描述与度量 ：自旋和公旋？ 内洞与轮廓形状相似性度量 带洞区整体相似性度量 ：所有相似性的加权求和    基于匹配控制子图的复合多边形相似性度量模型  复合多边形：一些连栋建筑物常常会被表示成多个多边形，但这些多边形又是一个整体，组成完整的建筑物，这些多边形之间彼相邻或者相离，属性结构完全相同。 四个步骤（专业性较强，有点难理解，就不做详细记录了）  首先通过计算寻找复合多边形中的匹配控制子图 然后根据“控制多边形”匹配相应的子多边形，构建匹配位置图 再应用傅立叶变换和基于凸包的局部矩变量计算每个匹配对的相似性 最后，对位置图之间的相似度和对应的复合多边形子图对之间的相似度进行加权求和，实现计算复合多边形之间的相似度    基于矢量参考数据 OSM 建筑物数据综合评价 引言  OSM-数据贡献者可能未经培训或不具备相关知识引起的数据质量问题-数据质量评估是必要的-一般使用 OSM 数据和官方数据\n之间的特征关系来进行数据质量评估-缺乏对 OSM 全面且客观的数据评估 自我学习-深度自编码网络  分析数据的深层次规律来学习数据特征 不需要样本标签数据集 利用重构误差来进行评价 训练模型在小概率样本的编码和重构中表现不佳，且会有较大的重构误差   质量评估指标-异常 OSM 数据将表现出与 OSM 数据质量相对应的较大的重构误差  基于数据匹配的训练样本集构建 学习样本集构建： 一是将 OSM 中的建筑物和参考数据集中的对应的建筑物进行匹配；二是将匹配的数据用规则格网划分，生成面积相同的单元网格，将每个单元网格作为一个深度学习样本去训练网络结构模型。\n 建筑物数据的匹配  问题所在：OSM 中建筑物表示的精度与 Bing 地图的分辨率有关，几个相邻的建筑物可能在 OSM 中被数字化成 1 个建筑物。1:m，n:1，和 n:m； 较高的建筑物在 OSM 和参考数据集之间可能有较大的偏移；由于光线斜射原因，在图像上重叠的地方可能占有很大的面积比例 =\u0026gt; 过滤和细化两个处理步骤 过滤：重叠方法 细化：相加多边形面积   划分成规则的网格  优势：提高了样本的数据量，避免深度学习的过度拟合问题；划分研究区域会大大减少计算量；以一个网格单元进行评估比整个数据作为一个整体更为有效 划分尺度  网格单元尺寸越小会产生越细节的评估结果，同时也会产生更大的样本量，这样可以训练一个更稳定的模型 六边形网格单元：比方形和三角形提供了更完整的覆盖范围；与相邻的网格单元共享更多的边缘，将会产生更平滑的评估结果 选择正方形和蜂窝六边形将数据格网划分，并比较了不同划分方式对评价结果的影响   建筑物被分割成多个部分归属问题：建立缓冲区包含相邻单元去识别匹配目标    基于深度自编码网络综合评价模型 深度自编码网络的综合评估方法首先需要根据构建的每个样本分别计算评价指标；然后利用每个样本中的评价因子作为模型输入去训练设计的深度自编码网络结构，直到网络的重构误差达到最小且稳定；最后根据深度网络输入与输出数据的差异进行 OSM 建筑物数据质量评估。\n OSM 建筑物评价因子  输入数据的每个维度单元在深度自编码网络中必须是相互独立的 OSM与参考数据对比计算相似度=\u0026gt;数据完整性、位置精度 、形状精度 、方向一致性 、语义精度   深度自编码网络  输出数据是对输入数据的评估，这两者数据之间的差异被定义为重构误差，用于检测异常 重构误差越大说明具有越多的异常输入数据   OSM 建筑物数据质量综合评价   首先，将 OSM 数据与官方矢量参考数据通过网格划分成等大的数据单元\n  然后在每个数据单元中通过 OSM 建筑物数据与参考数据中建筑物比较，计算几何形态精度（相似度）、位置精度、方向精度、据完整性以及语义精度\n  最后，以每个数据单元作为一个样本，每个样本中的计算得到的评价因子作为样本特征去训练构建的深度自编码网络，当重构误差达到最小且稳定后网络训练成熟。成熟网络针对每个数据单元的重构误差被用来表示该数据单元中的 OSM 建筑物综合评价。\n    实验验证与分析 介绍了一些参数设定和实验分析过程，比较丰富。早就知道师兄的这篇文章，今天终于是弄懂了。\n基于遥感影像数据 OSM 建筑物数据质量评价 引言  定性评价方法的指标不能对 OSM 数据质量做出绝对描述；定量评价方法在一些缺乏高质量权威矢量数据地区具有一定的局限性。 + 高分辨率遥感影像 + 深度卷积网络在影像建筑物提取中的良好性能 高分影像应用 + 语义分割简介 + 已有基于高分影像语义分割的研究 提及方法直接用于遥感图像建筑物目标提取并不能取得很好的效果  建筑物、街道、阴影和车辆等目标的类内方差的增加和类间方差的减少 不同对象可能在遥感图像中呈现出相同的光谱值（同谱异物），光谱相似类别的分离变得更加困难 在遥感影像中，一些物体的边界仍然被阴影影响从而变得模糊   全卷积神经网络（FCNs） 不仅可以学习如何对像素进行分类并确定它是什么，而且还可以预测空间对象的结构。该模型能够检测出地面上不同类别的物，并预测其形状，如建筑物，道路，树木等等。 本文工作总述：多任务 Res-U-Net + 后处理 + 局部和全局数据完整性评价 + 不同位置精度评价  遥感影像建筑物提取训练集构建  数据预处理  解决 OSM 建筑物数据中的一些拓扑错误问题 原始遥感图像-椒盐噪声-应用高斯滤波器来模糊图像   构建建筑物提取训练数据集  将每个具有 650×650像素的单元作为一个训练样本 不同图像尺度上训练  一个数据集是通过将原始图像缩放到一半的尺度获得 另一个数据集是通过对原始图像进行裁剪得到      基于多任务特征学习参考建筑物数据提取   多任务特征学习的深度卷积神经网络构建\n 将两个不同尺度的深层卷积神经网络的像素级预测结果进行组合，得到新的预测结果。 然后，需要对结果进行后处理：将预测的像素级结果转换为具有地理坐标的多边形，并将其视为建筑物轮廓。小于阈值的多边形的面积将被移除   神经网络模型  左部是 ResNet，用于提取输入数据的特征 右边是扩展部分，目标是使用特征图提取建筑物      基于指导滤波优化建筑物像素级提取结果\n 由于输入图像（引导图像）的引导，滤波结果更加结构化且平滑较少 引导滤波器认为引导图像和滤波结果之间存在局部线性模型，从而有利于优化建筑物目标分类。 为了去除椒盐类噪声，原始图像被当作优化边界的引导器。    参考矢量建筑物数据生成\n 将栅格数据的结果转换为矢量多边形 转换坐标系： 像素坐标 =\u0026gt; 地理坐标    OSM 建筑物数据完整性与位置精度评估\n 全局数据完整性 局部数据完整性 基于质心距离的位置精度    实验验证与分析 总结与展望 研究总结  空间数据质量评价=\u0026gt; OSM 建筑物数据质量评价过程中的若干关键技术问题=\u0026gt;具体成果总结如下：  探讨了 OSM 数据质量评价的研究背景和实际意义。总结了、阐述了、分析了、由点及面\u0026hellip; 系统阐述了地理空间数据质量评价模型的理论基础。 多边形的几何形状相似性 客观地、综合地对 OSM 建筑物数据质量进行评价: 官方标准矢量参考数据+深度自编码网络 消除矢量参考数据的约束，充分利用高分辨率遥感影像   主要创新点总结如下  建立了顾及空间分布和几何变换的多边形相似性度量模型 提出了综合、客观的 OSM 建筑物数据质量评价模型 提出了基于遥感影像数据的 OSM 建筑物数据质量定量评价模型    研究展望  数据质量模糊问题，难点：评价方法不能够保证客观全面；参考数据的依赖性。 简述本文贡献（针对上述难点） 取得了一些成果，但也存在一下几个方面需要进一步展开：  一些被树覆盖的建筑物的形状不能精确的检测，且一些模糊和不规则的辩解还是很难被分类=\u0026gt;考虑场景语义 受遥感图像特征的限制，图像中有些建筑物为斜入射，有些建筑物边缘被树木覆盖。因此，所提出的方法无法提取一些建筑物的实际边缘（实际边界为直线，但基于高分辨率遥感影像提取结果往往是折线）和一些面积非常小的建筑物。 道路、湖泊等其他要素类型的提取及评价    基于手机位置大数据的城市人群聚散时空特性研究：以深圳市为例 杨喜平-2017-武汉大学\n错别字有点多，内容理解难度不大，作者“概念化”做得很好\n绪论 研究背景与意义   研究背景\n 第一段：城市发展-城市问题 第二段：城市问题的产生与人群在城市中活动密切相关-理解城市人群的移动模式 第三段：信息与通讯技术-个体移动轨迹数据-数据基础 第四段：手机-感知人群在城市中的位置随时间的变化-手机位置数据-研究城市人群移动模式的重要数据源 第五段：研究现状简述：手机位置数据已经使得我们可从不同的视角来观察城市人群的时空移动模式，以及挖掘人群移动与城市空间结构之间的相互作用规律。 第六段：综上所述/背景：诸多城市问趣的涌现使得我们迫切需要理解城市人群移动时空模式及其与城市空间结构的之间的关系；手机位置大数据为研究城市人群移动时空模式和理解城市空间结构提供了丰富的数据基础；多种学科交叉理论的发展（人文和城市地理学、计算机科学、地理信息科学等）为我们研究城市人群移动模式提供强大的理论基础。    问题提出与研究意义\n 第一段：提出人群聚散模式 第二段：本论文主要的科学研究问题-如何利用轨迹大数据来深入理解城市人群聚散的时空特性，加深对人群移动与城市空间交互的理解  人群聚散时空模式 人群聚散的稳定性 人群聚散稳定性与城市空间结构的关系   第三段：鉴于\u0026hellip;的重要意义，以\u0026hellip;为研究对象，以\u0026hellip;为主题，重点研究\u0026hellip;，构建\u0026hellip;的定量模型，探索\u0026hellip;的关系。本文旨在\u0026hellip;，具体地，\u0026hellip;具有以下方面的意义。    研究内容与技术路线  研究内容  研究目的：分析城市人群聚散的时空特性以及与城市空间结构的关系，从时空的角度加深理解人群在城市中的时空间行为。 手机位置数据-人群移动OD矩阵-人群移动时空模式-人群聚散稳定性评价模型-分析人群聚散动态稳定性和城市空间结构的关系 研究内容划分：  城市人群聚散时空模式提取分析：  提出一种从手机位置数据中识别人群聚散时空模式的方法 具体流程：（1）基于人群移动OD矩阵，定义描述人群聚集和消散强度的指标；（2）根据人群聚散强度统计分布，对人群聚散强度进行等级分类并添加标签；（3）构建基于聚散等级标签的人群动态变化时间序列矩阵；（4）利用聚类算法对该时间序列矩阵进行聚类，找出具体相似人群聚散变化的时空模式；（5）将聚散时空模式与城市空间结构功能区进行关联，分析每种功能区上主要的人群聚散模式。   构建人群聚散稳定性的定量模型  反映一个地方人群动态变化的程度，从而潜在的反映该地方对交通需求的变化程度 评价城市公交系统覆盖人群的动态稳定性   定量分析城市空间结构要素与人群聚散稳定性的关系  社会经济属性、土地利用和路网三个维度解释变量 相对重要性       研究方法与技术路线  数据预处理 聚散时空模式识别 结合城市功能区分析两者之间的关系    人群移动模式研究综述 引言  城市问题：空间污染、交通拥堵、规划落后=\u0026gt;城市计算（郑宇）、城市信息学（李清泉） 研究城市人群的时空移动模式对于解决城市问题具有重要的意义-人群感知（位置）数据-社会感知（刘喻）-多学科交叉的课题=\u0026gt;四个方面论述：城市时空动态分析、人群移动时空模式、城市空间结构研究、城市交通地理研究  城市时空动态分析 人群在城市中的分布是随时间不断变化=\u0026gt;城市时空动态\n传感器普及=\u0026gt;实时监测、分析城市人群韵律、精细估计人口分布\n 城市时空动态监测  麻省理工大学城市感知实验室 实时分析城市人群的移动动态，从空间和时间上定量可视化人群移动模式（Urban mobility landscape: Real time monitoring of urban mobility patterns） Flickr数据-分析旅游者在城市的热点分布区域，监测旅游活动随季节的变化（From social sensor data to collective human behaviour patterns: Analysing and visualising spatio-temporal dynamics in urban environments）   人群移动动态韵律分析  周期性、空间差异性 时间节奏 地域文化差异-时空地理差异 不同时间尺度时间规律性的稳定性   人口分布估计  美国橡树岭国家实验室 手机通话数据可以监测城市的时空动态，为估计人口密度分布提供一种新的思路。    人群移动时空模式研究 人群移动语义信息\n提取人群移动的典型模式和统计规律=\u0026gt;时空间行为规律\n 人群移动时空统计规律  人群移动的统计特性-三个方面：人群移动可预测性、城市居民交通出行距离分布、人群移动交互预测模型 人群移动可预测性  非随机 人更愿意在一个有限的范围内活动，具有高度时间和空间规律性，并且具有很高的概率回到之前频繁活动的位置 用户访问地点序列的信息熵=\u0026gt;高度可预测性   交通出行距离分布  城市居民出行的分布是随着距离衰减，但衰减的具体过程仍不确定 居民乘坐出租车和私家车出行距离服从指数分布，但指数系数是存在差异的，受特定城市结构环境影响。   人群移动交互预测模型  预测两个不同地方之间人群的流量，即两个地方的空间交互强度 经典模型：重力模型、介入机会模型、辐射模型     群体时空移动模式  动态节奏性（Spatio-temporal analytics for exploring human mobility patterns and urban dynamics in the mobile age） 构建描述人群动态变化指标的时间序列   锚点提取与活动识别  锚点：人在移动过程中重要的停留驻点，表示人为了从事某种活动在这些地方停留 城市人群的停留模式 大多数研究工作主要关注的是人群移动的部分，忽略了人移动过程中停留行为的分析（？？？） 两方面研究：锚点的提取方法+锚点的活动类型识别 锚点的提取方法  从轨迹的角度出发，讲人的移动轨迹分为移动和停留两个交替的部分=\u0026gt;识别停留和移动的SMoT（Stop and Move of Trajectory）模型 两个重要的阈值参数：空间范围+停留时间长度 锚点既可以是轨迹中实际的记录的位置点，也可以是一个由空间范围内的轨迹点计算出来的虚拟位置   锚点的活动类型识别  丰富轨迹的语义信息（Predicting human mobility with activity changes） POI时空吸引力 POI排序+距离衰减 仍十分困难，只能从概率上推测人群的活动类型     人群活动空间分析  人一天中所访问的位置所构成的空间活动范围=\u0026gt;衡量居民对城市空间的利用状况 标准误差椭圆、置信椭圆、最小凸多边形、潜在活动区域、回旋半径 人群的活动空间差异（Another tale of two cities: Understanding human activity space using actively tracked cellphone location data）：三个指标（每天的活动范围、活动锚点的数量和移动频率）    城市空间结构研究  热点区域探测和语义识别  人群移动热点区：人群的活动显著高于其临近区域的地方=\u0026gt;城市中吸引力较高、人群出行需求较高、交通设施中较为关键的区域 热点区域对时间具有依赖性（吸引力随时间不断变化） 核密度表面（KDE）等方法（Detecting and analyzing mobility hotspots using surface networks） 从网络文本中发现有意义的地理知识   土地利用探测分析  利用人群动态移动模式推测城市土地利用分布 总体思路：（1）讲城市分割成不同的空间分析单元；（2）构建每个单元内的人群活动的时间序列；（3）采用机器学习中分类方法和聚类方法对时间序列进行分类；（4）根据每一类人群的变化模式分析土地利用类型。 EM算法（基于北京公交刷卡数据和兴趣点的功能区识别）   空间交互结构分析  人群在城市中不同区域间移动可以反映区域之间的交互关系，潜在的反映城市不同区域的联系紧密程度以及城市多中心结构 识别城市中心及多中心结构（基于手机数据识别上海中心城的城市空间结构，Identifying the city center using human travel flows generated from location-based social networking data） OD流+社区发现：（1）从轨迹数据中提取人群移动OD位置，构建基于人群移动流量的网络；（2）利用复杂网络中的社区探索算法进行社区发现，发现网络中交互强度较大的人群移动局部紧密社区，发现城市中潜在的人群移动社区结构（Detecting urban road network accessibility problems using taxi GPS data）    职住分布与可达性研究 交通地理-揭示人群移动、交通设施、城市空间三者之间的关系\n 职住分布与OD估计  职住分布主要研究内容：职住地识别方法研究、职住关系的平衡、就业中心体系测度、职住通道平衡性与轨道交通拥挤程度的关系 （动态）OD矩阵   通勤行为  在通勤时间段，城市中会出现大规模的人群同时移动行为，导致城市交通拥堵瘫痪。 我觉得他这里没有说明、引用很好的文献   城市空间可达性  衡量城市空间中某一地方到其他地方便捷性的一种指标，用来反映城市空间区位的公平性和优先级 出租车轨迹数据  能反映城市不同区域人群的出行起点和终点 反映城市道路王的动态路况等信息 广泛应用与可达性研究   POI可达性、城市特定位置可达性、探测城市中可达性较低的居住区域、公共健康设施可达性等 可达性的研究很广泛，个人认为作者可达性部分概述比较简单，有很大扩展    人群聚散时空模式 个人理解：实验整体不难，方法部分理解不难，理论、分析部分比较充足\n引言  人群移动、城市空间结构、城市交通-三者相互作用、密切相关-研究城市人群移动时空模式对城市空间结构的规划、城市交通的管理具有重要意义 目前研究：构建人群变化描述指标-基于指标的时间变化序列分析-显著差异的人群移动时空模式 人群聚散是城市人群移动时空模式的一个重要特征 传统研究=\u0026gt;大规模人群移动轨迹数据=\u0026gt;提取城市人群聚散模式 灵魂发问：城市中存在什么样的人群聚散时空模式？每种模式人群聚散的强度以及持续时间如何差异？如何提取城市人群聚散时空模式？不同功能区人群聚散模式是否差异？=\u0026gt;探索这些问题的意义：加深理解 本章主要目的：从海量的手机位置数据中提取出城市人群聚散的时空模式+本章内容  人群聚散时空模式提取方法   人群聚散指标\n 人群聚集表示大量的人群在一定的时间内从其他地方汇聚到此地；人群消散表示在一定的时间内有大量的人群从该地方去往城市中其他地方，人群的这种聚散是随着空间和时间不断变化的 净流量（netflow）作为衡量指标  流入量和流出量的差值表示人群变化量 净流量绝对值反映人群聚散的强度      强度等级分类\n 十分位数法划分=\u0026gt;十个强度等级    时空聚类\n 构建矩阵+X-means聚类（WEKA中实现）+欧氏距离函数（通过等级分类后构建的是离散值的矩阵，Kmean也能对离散值进行聚类么？那它这个距离函数就错了啊） 个人认为很简单的方法，但是作者概念性的东西讲述地很丰富，值得参考    实验结果与分析 整体难度不大。前文提及在WEKA中运行聚类，但缺少对聚类参数评价部分，仅分析聚类结果。分析部分内容比较多，“能说会道”，看图说话的本事自己还是比较欠缺啊（但是看文章的时候自己又总是跳过。。恶性循环）\n人群聚散稳定性定量模型与评价 引言  群移动的稳定性：该地方人群突变的程度，潜在地反映了该地方交通需求的稳定性 分析人群聚散的时间序列变化=\u0026gt;人群聚散稳定性评价模型 真心觉得他写的很多内容都比较赘述（重复）  人群聚散稳定性评价模型  人群聚散过程及序列定义  具有生命周期的过程： 时间序列、聚集过程、消散过程、聚散过程（交替过程）   人群聚散过程稳定性  影响因素：  持续时间 净流量累计值变化量：趋势线的斜率来表示 波动幅度：真值和趋势值的差来定量聚集过程；波动幅度的标准差来衡量整个聚集过程的波动情况   整个聚集过程的稳定性  净流量累计值变化量的稳定性f 波动幅度的稳定性g 整个聚集过程的稳定性s=f*g     人群聚散序列稳定性  聚散序列多边形的面积A来表示聚散序列的稳定性程度 聚集过程和消散过程交替的波动幅度：上边界的长度P来衡量其波动幅度 面积越大越稳定，而上边界越长越不稳定。采用两者的比率来定义整个聚散序列的稳定性Q=A/P    实验结果与分析  针对每一个基站分析 划分三个时间段分析 基于交通分析区（TAZ）分析 基于公交系统分析 与信息熵指标对比  城市空间结构要素与人群聚散稳定性的关联性分析 引言  城市人群移动模式与城市空间结构密切相关，研究人群移动模式和城市空间结构的关系 探索城市基础设施、土地利用、路网特性、社会经济特性等对人群移动距离、通勤模式、活动空间范围、时空动态等影响 在城市空间结构中哪些因素对人群聚散稳定性具有显著的影响？ 将其人群移动稳定性作为因变量，从社会经济属性、土地利用结构和路网中心性结构三个方面来构建解释变量，然后构建因变量（稳定性）和解释变量（城市空间结构）之间的多元线性回归模型来定量分析城市空间结构中这些因素对人群聚散稳定性的影响  城市空间结构指标  社会经济属性  指城市人群的社会经济活动所赋予的特性。 每个TAZ的人口、面积、人口密度、房价 人口：从手机定位数据中识别每个交通小区的居住人口数据：如果用户在凌晨00点-06点时间段在某一基站停留时长大于4小时，将该基站作为该用户的居住地，根据该方法可以识别出每个基站位置的居住人数。该居住人数并非绝对的居住人数，而只是从数据定位数据识别出的居住人数。 人口密度分布与人口分布存在显著差异 采用房价来反映交通小区的经济发展和个人收入水平   土地利用结构  指一个区域内各种功能用地类型的比例及其相互影响、作用所形成的空间结构关系 土地功能结构的内涵  该区域由哪些土地利用类型组成及其比例关系 该区域内各种土地利用类型之间的相互作用关系及其随时间的演变   土地利用类型：商业用地（C）、工业用地（I）、居住用地（R）、公共用地（P）、交通用地（T）和其他用地（O） 土地利用比例 区位熵  指某区域某种土地利用类型面积占整个研究区域该土地利用类型的比重与该区域土地总面积占整个研究区域土地面积比重之比 表示的是交通小区内某种类型的土地利用所占的比例与全局相比是否存在区位优势。区位熵越大表示该土地类型的优势越大   信息熵  反映一个区域的土地利用结构的混合度和多样性 信息熵是指一个区域内各种类型的土地组织安排的有序度，信息熵越大，该区域土地利用的有序度越低，表示该区域土地利用混合度越高 用来衡量区域内不同土地利用类型比例之间的关系   均衡度  信息熵与最大熵的比值 信息熵仅仅反映的是单个小区内不同类型土地的混合度，无法反映小区内各土地利用类型的均衡程度，这使得小区之间缺乏可比性     道路网结构  分类 路网密度  该区域路网的密集程度 一个区域内所有道路的总长度与区域的总面积之比   路网中心性  无向网络 将位于TAZ内部路段节点中心性的平均值作为该TAZ的中心性 接近中心性  衡量一个节点与路网中其他所有节点的临近程度 城市空间中心位置，接近中心性最高；处于城市边缘，接近中心性越低   介数中心性  衡量某一节点在路网中起中介作用的程度 介数中心性常用来衡量城市道路中节点和路段的交通流量 高等级道路的介数中心性较高，如快速路和主干路，这些路段在城市中起到重要的连通作用   直达中心性  衡量网络中节点的直达效率   全局中心性：通过计算该节点到路网中其他所有的节点的最短路径距离，是从全局的角度来搜索路网中其他所有的节点 局部中心性：在计算中心性时，只搜索该节点一定范围内的节点，超出该距离范围无需计算（5km. 10km, 15km, 20km, 25km, 30km）      多元线性回归模型 实验结果与分析 拟合优度太太太小了。作者竟然完全不提拟合优度优劣的问题。这么低的拟合优度，后续的分析真的有用么？\n总结与展望 论文总结 城市矛盾/城市问题、人群移动模式研究、群体移动轨迹大数据\n研究内容：\n 人群聚散时空模式识别方法研究 人群聚散动态稳定性评价模型研究 人群聚散动态稳定性与城市空间结构关联性研究  主要创新点 更多的是说明解决了什么问题\n本文基于海量的手机位置数据，以人群聚散为主题，以时间地理学为理论指导，从居民时空间移动行为角度入手研究城市人群聚散的时空特性，包括人群聚散的时空模式、聚散时空动态稳定性以及与城市空间结构的关系。创新点如下：\n 提出一种从海量手机位置数据中识别人群聚散时空模式的方法 提出了一种评价人群聚散动态稳定性的定量模型 探索了城市空间结构要素与人群聚散稳定性的关系  研究展望 说的有点虚。围绕上述几点“进一步”。。。\n面向高分辨率遥感影像场景语义理解的概率主题模型研究 朱祺琪-2018-武汉大学\n  对场景分类研究不熟悉，有些步骤比较跳跃，部分句子较难理解，感觉重复的话好多；不过她的图都蛮好看的\n  内容真的很丰富！别人每一章都对应了一篇论文，她一章对应了两篇论文吧~而且逻辑思路很通顺，虽然部分章节看不懂，但是内容这么多整理成这种程度很厉害了。最后总结成果，提出一个原型系统，也是蛮有创意的。\n  希望你的移动硬盘没事。不要再五雷轰顶了、\n  绪论 研究背景与意义   第一段：高分辨率遥感影像数据-影像信息提取与分类-可持续发展重大战略意义-尤其中国\n  第二段：类内方差增大以及类间方差减小现象-面向对象的地物分类方法-多目标、不同空间分布方式、场景多变-底层特征与高层语义信息之间的语义鸿沟-高层场景语义理解新阶段\n  第三段：\n 对高分影像进行自动标注、获取不同区域语义信息=\u0026gt;场景分类=\u0026gt;建立影像底层特征到高层场景语义之间的映射关系 基于目标识别的场景分类方法（传统研究）  根据地物解译结果得到不同目标的类别信息 构建不同地物目标之间的空间关系 限制：需要目标的先验信息；受地物分类精度影响   无需目标先验的场景分类方法  基于底层特征的场景分类方法：基于颜色、纹理、结构等底层特征直接描述场景，利用分类器进行分类=\u0026gt;很难描述场景中地物目标空间分布复杂的特性 基于中层特征的场景分类方法：挖掘局部特征，将底层特征映射到字典空间或参数空间，基于影像的词袋模型表达获得描述能力更高的中层语义特征 基于高层特征的场景分类方法：基于信息的层次化抽取，自动学习高分影像的本质特征，避免手工选取特征的影像。（应用深度学习构建端对端模型，自动学习特征时的套话，可以学习一下）      概率主题模型  将影像降维地表达为若干潜在主题的混合分布，而每个主题又是关于一组影像块的概率分布。 常用概率主题模型，以及模型的学习与推理优化方法 基于概率主题模型的场景理解流程，including高分遥感影像常用的区域采样方法以及底层特征提取方法  经典概率主题模型 视觉词袋模型（Bag-of-visual-word, BoVW），利用概率理论将词袋模型的统计变量转化为概率分布变量，代表为概率潜在语义分析模型和潜在狄利克雷分布模型\n 视觉单词袋模型（BoVW）  一道鸿沟：在NLP领域，文档集、文档、词语三个基本元素都是真实存在并且具有实际意义，而在影像处理领域并没有对应的显式元素 视觉单词袋模型：提取影像块中的局部特征（颜色、纹理、光谱等），将其类比为文本中的单词（即视觉单词），然后对影像块进行向量量化，依据一定的准则把影像表示为由多个视觉单词组成的文档 基于视觉单词袋模型的场景理解方法：分块采样、特征提取、视觉单词构造、视觉单词直方图生成及分类参考：视觉单词模型、词袋模型BoW、视觉词袋模型+极端随机森林建立图像分类器（Python实践）、Bag of Features(BoF)图像分类实践（理论部分和图解不错）   概率潜在语义分析（PLSA）  使用概率图模型来表示影像、主题和视觉单词之间的关系，将影像和视觉单词映射到同一主题空间 参考：概率潜在语义分析 缺陷  每幅影像仅仅是主题离散概率的混合数字表达式，容易导致过拟合 不能将概率分配给训练样本之外的影像     潜在狄利克雷分布（LDA）  层次化贝叶斯模型，每幅影像的概率视为潜在主题中随机出现词语概率的混合比例，克服PLSA的缺陷 参考：文本主题模型之LDA    基于概率主题模型的场景分类方法  区域采样  均匀网格采样法对于高分遥感影像分类效果最佳   底层特征提取  光谱特征提取方法  光谱特征：地物组成成分属性的反映 灰度值向量法、直方图统计法、均值标准差统计法   纹理特征提取方法  纹理：某种局部的“样式”再一个序列更大区域内的不断重复 统计法、模型法、频谱法 常用灰度共生矩阵（GLCM）纹理提取方法 常用纹理特征测度：同质性、能量、对比度、相关性和熵   结构特征提取方法  光谱和纹理特征仅能反映高分影像上地物的物质属性以及宏观结构特性，但不能完全描述地物语义的所有特性，如形状结构等局部特性。 尺度不变特征变换算法（SIFT）、HOG算子     视觉词袋构造  相同的视觉单词在不同的影像中可能会呈现不同的特征值 kmeans聚类   主题特征挖掘与分类  多元特征语义融合的主题模型场景分类方法 传统基于主题模型的场景分类方法通常提取单个特征，无法对包含多种地物和复杂空间分布的高分遥感影像场景进行准确描述\n概述  基于词袋模型的场景分类方法=\u0026gt;概率主题模型=\u0026gt;多种特征（如基于纹理，颜色和结构信息的特征）有效融合 目前缺陷：  不同特征的特征向量值通常差别很大；不同特征相互干扰；混合像元影像；归一化操作对保留和利用有用信息的贡献很小 光谱或SIFT特征只能描述高分影像中连续的局部光谱或结构信息，不包含从全局角度提取的特征   本章研究点：  融合局部全局特征的词袋模型高分遥感场景分类方法（LGFBOVW） 多元特征语义融合的概率主题模型高分遥感场景分类方法（SAL-PTM：SAL-PLSA + SAL-LDA）    融合局部全局特征的词袋模型高分遥感场景分类方法（LGFBOVW） 总述：（1）设计全局纹理特征：形状不变纹理指数（SITI）；（2）多特征融合策略：在直方图层次上进行融合，直方图交叉核的SVM\n 局部光谱结构特征提取  光谱特征和SIFT特征是局部连续特征 全局特征基于整个影像提取，描述高分遥感影像的紧凑性和区分性，是全局离散特征   全局纹理特征提取  SITI更多关注场景的全局形状特征，如形状的伸长和紧凑性 SITI是光谱和SIFT特征的补充特征，包含伸长直方图、紧致直方图、尺度比直方图和对比直方图等特征描述   场景的特征融合与分类  全局连续特征通过拉伸形成一定尺度的一维直方图 所谓多特征融合是直接拼接的一维直方图么？ 框架图作图蛮好看的    多元特征语义融合的概率主题模型高分遥感场景分类方法（SAL-PTM） 总述：（1）场景分类过程中k均值聚类及融合能力不足，以及不同特征之间的相互干扰问题；（2）特征表达策略（传统的多特征融合方法，在k均值聚类之前连接光谱、纹理和SIFT特征；SAL策略：在语义层上融合三个特征）；（3）潜在语义分配挖掘\n 场景多特征的多个1维直方图表达 PLSA及LDA模型的多特征语义层融合 多特征分类  同异质主题联合的稀疏主题模型场景分类方法 本来上一章有些地方看的模糊不懂，这一章就更不懂了Orz\u0026hellip;\n传统：主题特征稠密且重叠度高 + 包含关键性地物目标语义的场景描述能力不足 =\u0026gt; 利用稀疏推理方法代替狄利克雷分布 + 超像素分割实现同异质特征联合表达\n概述  传统模型缺陷：针对不同场景类别建立多个模型，未考虑不同场景类别的潜在主题空间之间的相关性 + 密集的语义表示通常包含大量不具代表性的场景信息 训练样本标注困难，利用好有限的训练样本获取好的分类表现 全稀疏主题模型（FSTM）：FSTM挖掘的稀疏主题可能会丢失具有代表性的语义信息，直接应用于高分遥感影像场景分类想过不佳 均匀网格采样：影像块通常是异构的（没读懂），代表性视觉单词的比例非常小，降低了场景识别精度 单纯基于遥感数据的场景标注结果只能反映土地覆盖地物的自然属性；叠加道路网数据分割得到的某些影像块面积通常较大，存在语义混淆 本章研究内容：  提出异质特征表达的稀疏主题模型场景分类方法（FSSTM） 提出同异质主题联合稀疏建模的场景分类方法（SHHTFM）    异质特征表达的稀疏主题模型场景分类方法（FSSTM） 王婆卖瓜，先说贡献：（1）能够挖掘出影像本质的底层信息，并用稀疏主题来表示复杂的高分遥感影像；（2）适合主题模型的场景分类流程；（3）稳健性，适应训练样本数量的变化\n 异质特征描述：这个“异质”的表述是什么意思？？？ 稀疏语义特征挖掘：将稀疏主题模型，看不懂 稀疏语义融合及分类：  同异质主题联合稀疏建模的场景分类方法（SHHTFM） 具有代表性地物目标或同质性区域的场景类别中代表性视觉单词语的比例变得非常小，降低场景识别精度=\u0026gt;简单线性迭代聚类（SLIC）超像素分割方法=\u0026gt;生成同质性区域； 水、植被边界、道路网络集成=\u0026gt;土地利用/土地覆盖场景标注\n 同异质底层特征提取（搞不懂同异质的意思）  均匀网格区域采样=\u0026gt;异质性信息 SLIC采样策略=\u0026gt;同质性信息   稀疏主题表达 结合多源地理数据的场景理解  基于多层次语义表达的高分辨率遥感影像场景分类方法 基于主题模型的场景分类方法=\u0026gt;提取局部特征，难以提取全局语义信息，忽略影像块的空间位置信息\n基于深度特征的场景分类方法=\u0026gt;提取全局特征，对于显著性局部特征不能很好的把握\n自适应深度稀疏语义建模的场景分类方法：将主题特征与深度特征进行自适应融合\n概述  （1）传统方法很大程度上取决于手动底层特征的选择和中层特征的设计=\u0026gt;先验信息；（2）迁移性有限；（3）仅计算局部特征的出现次数，不能对影像中的空间关系建模.=\u0026gt;影像被表示为无序的局部特征集合，视觉单词的空间布局信息被忽略 概率主题模型获取的主题特征是密集的=\u0026gt;特征冗余，高时间消耗；全稀疏主题模型=\u0026gt;可能丢失影像的细节信息，难以从全局角度获取特征 深度学习的成功=\u0026gt;CNN多层次表达中挖掘特征；CNN可迁移性=\u0026gt;基于迁移学习的高分遥感场景分类方法=\u0026gt;与基于主题模型的方法相比，从CNN中提取的高层特征通常更多包含高分遥感影像的全局信息，并可以发现目标的细节信息 本章研究：  融合多层次语义模型信息的场景分类方法（DLGFF） 自适应深度稀疏语义建模的场景分类方法（ADSSM）    融合多层次语义模型信息的场景分类方法 提出基于深度局部全局特征融合的场景理解框架（DLGFF），主要贡献：（1）从高分辨率遥感影像中捕捉场景的代表性语义和空间结构；（2）在DLGFF框架中提出了两种方法，即融合了全连接特征（LGFF）和融合拉伸卷积特征（LGCF）的局部和全局特征。\n 局部及全局底层特征提取  代表性手工视觉描述子：全局纹理特征，局部光谱特征和局部结构特征（同第三章的特征构建方法）   卷积及全连接层特征生成  采用预训练的CNN-CaffeNet 允许对网络的任何层进行特征提取 最后一个Conv层的四维Conv5特征被选取以充分利用Conv层中的密集信息 第一层FC层（FC6）被提取作为FC特征描述空间分布信息 每个遥感影像具有D5维度的特征   基于LGCG和LGFF的特征融合及分类  自适应深度稀疏语义建模的场景分类方法 提出将稀疏主题和深层特征相结合的自适应深度稀疏语义建模（ADSSM）框架，主要创新：（1）基于FSTM和CNN特征的ADSSM框架；（2）不同特征的自适应标准化策略\n 高层深度特征学习  预处理：输入影像除以最大像素值，获得归一化影像 特征提取  卷积层上滑动卷积滤波器进行卷积计算，获得特征映射 对于每个通道，应用pooling操作获取区域像素的ju\u0026rsquo;bu最大值或平均值，获得对噪声和杂波更加鲁棒且对影像变换保持不变的特征 特征分类：FC+softmax     中层稀疏主题建模（同第四章） 自适应特征标准化及融合分类  所谓自适应的概念：两类特征，针对不同的特征，归一化处理方式不同  主题特征非常稀疏且具有代表性，特征值范围从0-1 深层特征更密集且更全面，特征值大得多 直接链接深层特征和主题特征不能充分利用代表性主题特征 深层特征：0-1归一化；主题特征：适应性拉伸       基于主题模型的高分辨率遥感影像场景理解原型系统 系统设计 系统的使用 可独自使用，也可根据需求进行方法组合\n 在不限制描述场景特征所占用的存储资源的情况下 在限制描述场景特征维度，且限制GPU并行计算资源的情况下 在限制描述场景特征的存储资源，不限制GPU并行计算资源的情况下 引入多源地理数据为场景块边界提供地学信息约束  概率主题模型场景理解方法综合对比与应用场合  适用于对分类精度有较髙要求的应用场合-自适应深度稀疏建模场景理解方法 适用于要求计算效率的应用场合-同异质主题联合稀疏建模的场景理解方法 可以接受的计算效率获得稳定满意的分类精度-基于密集多特征语义融合的场景理解方法  总结与展望   背景：遥感影像的空间分辨率提升=\u0026gt;同物异谱等现象影像解译新挑战=\u0026gt;面向像素分类到面向对象分类的转变=\u0026gt;无法提取场景高层语义信息=\u0026gt;基于语义目标的场景分类=\u0026gt;需要目标的先验信息并且会受到地物分类精度的影响\n  本文：地物目标的多样性、可变性、分布复杂等特点；三方面研究：底层特征描述、中层主题建模和高层语义理解\n  总结 主要工作以及创新概括：\n 归纳总结研究现状，详细介绍高分遥感影像场景理解方法 针对底层特征学习能力不足的问题，在未考虑主题稀疏性的条件下，提出（1）融合局部全局特征的词袋模型场景分类方法和（2）多元特征语义融合概率主题模型（PTM）的高分辨率遥感场景分类方法 针对中层主题建模未考虑主题稀疏性及同质性的问题，在基于稀疏主题建模的条件下，提出（1）异质特征表达的稀疏主题模型场景分类方法和（2）同异质主题联合稀疏建模的场景分类方法 针对高层语义理解层面忽略空间位置信息及全局性的问题，在基于稀疏主题建模的条件下，提出（1）融合多层次语义模型信息的场景分类方法和（2）自适应深度稀疏语义建模的场景分类方法 在上述研宄基础上，开发了高分辨率遥感影像场景理解的原型系统，并针对不同的应用情况，对系统的使用进行了说明。  展望 集中在以下几个方面：\n 多传感器多分辨率迁移的场景理解 结合多源社交媒体数据的场景类别定义与场景理解：现有基于遥感影像的解译方法往往只能从光谱和空间角度描述城市特性，缺少行政规划边界等地学数据约束与社会经济语义信息的分析，难以全面理解城市形态 多尺度多时相高分辨率遥感影像场景变化分析  ","description":"","id":62,"section":"posts","tags":["论文阅读","博士论文"],"title":"博士论文阅读札记-1","uri":"https://www.xunhs.cyou/posts/notes/2020-06-21-%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%9C%AD%E8%AE%B0-1/"},{"content":" 最近两天趁着写完小论文不想做事情。尝试玩了一下2019年百度AI搞得城市功能区划分的比赛。比赛提供了遥感影像数据和区域居民活动数据(可惜没有具体的位置信息)，初赛样本量4W，复赛样本量40W，拿初赛的样本玩了玩，实现了Baseline（0.67）。其实也是照抄别人代码，主要是为了熟悉pytorch环境和多模学习。对了，这个练习赛最开始是在本机上实现，但后来模型增大，显存无法承载，显存不足，转到Google 的Colab实现。别说，配合谷歌自带的网盘，这个Colab真的挺好用(主要是免费GPU，前提你的VPN要稳定)。\n 准备   比赛链接: https://aistudio.baidu.com/aistudio/competition/detail/13\n  数据\n 飞桨基线挑战赛（训练集）:https://aistudio.baidu.com/aistudio/datasetdetail/12529 飞桨基线挑战赛（测试集）:https://aistudio.baidu.com/aistudio/datasetdetail/12530 预处理数据: https://github.com/ABadCandy/BaiDuBigData19-URFC    分数:\n 官方基线Pytorch实现(本文主要参考): https://github.com/ABadCandy/BaiDuBigData19-URFC 团队Expelliarmus(0.88767): https://aistudio.baidu.com/aistudio/projectdetail/195440 URFC-top4(本文主要参考): https://github.com/destiny19960207/URFC-top4    import\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  !pip install pretrainedmodels import numpy as np from functools import partial import pandas as pd import os import time import json import torch import random import warnings import torchvision import numpy as np import pandas as pd from skimage import io from tqdm import tqdm from datetime import datetime from torch import nn,optim from collections import OrderedDict from torch.autograd import Variable from torch.utils.data import DataLoader from torch.optim import lr_scheduler from sklearn.model_selection import train_test_split from timeit import default_timer as timer from sklearn.metrics import f1_score,accuracy_score from pathlib import Path from torch import nn, optim import torch.nn.functional as F from torchvision import transforms as T from torch.utils.data import Dataset, DataLoader import torchvision from imgaug import augmenters as iaa import pretrainedmodels from pretrainedmodels.models import * import ssl ssl._create_default_https_context = ssl._create_unverified_context # 防止ssl报错    Vars init  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  torch.backends.cudnn.benchmark = True warnings.filterwarnings(\u0026#39;ignore\u0026#39;) # 1. set random seed random.seed(2050) np.random.seed(2050) torch.manual_seed(2050) torch.cuda.manual_seed_all(2050) #os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;] = \u0026#34;0,1\u0026#34; torch.backends.cudnn.benchmark = True warnings.filterwarnings(\u0026#39;ignore\u0026#39;) # dir \u0026amp; fp root_dir = Path(\u0026#39;./data\u0026#39;) images_dir = Path(root_dir, \u0026#39;images\u0026#39;) visits_dir = Path(root_dir, \u0026#39;visits\u0026#39;) train_df_fp = Path(root_dir, \u0026#39;train.csv\u0026#39;) log_dir = Path(\u0026#39;./logs\u0026#39;) checkpoints_dir = Path(\u0026#39;./checkpoints\u0026#39;) if not Path.exists(log_dir): Path.mkdir(log_dir) if not Path.exists(checkpoints_dir): Path.mkdir(checkpoints_dir) # config  loss_name =\u0026#39;focal_loss\u0026#39; pre_train_name = \u0026#39;densenet121\u0026#39; # se_resnext101_32x4d env=\u0026#39;default\u0026#39; model_name = \u0026#34;multimodal_%s_%s\u0026#34; % (pre_train_name, loss_name) num_classes = 9 img_weight = 100 img_height = 100 fold = 1 lr = 0.004 lr_decay = 0.5 weight_decay =1e-5 batch_size = 256 epochs = 30    工具函数  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  # utils # save best model def save_checkpoint(state, is_best_acc,is_best_loss,is_best_f1,fold): checkpoints_dir = Path(\u0026#34;./checkpoints\u0026#34;) best_models_dir = Path(checkpoints_dir, \u0026#34;best_models\u0026#34;) model_fp = Path(checkpoints_dir, \u0026#34;{}_{}_checkpoint.pth.tar\u0026#34;.format(model_name, str(fold))) torch.save(state, model_fp) if is_best_acc: shutil.copyfile(model_fp,\u0026#34;%s/%s_fold_%s_model_best_acc.pth.tar\u0026#34;%(best_models_dir,model_name,str(fold))) if is_best_loss: shutil.copyfile(model_fp,\u0026#34;%s/%s_fold_%s_model_best_loss.pth.tar\u0026#34;%(best_models_dir,model_name,str(fold))) if is_best_f1: shutil.copyfile(model_fp,\u0026#34;%s/%s_fold_%s_model_best_f1.pth.tar\u0026#34;%(best_models_dir,model_name,str(fold))) # evaluate meters class AverageMeter(object): \u0026#34;\u0026#34;\u0026#34;Computes and stores the average and current value\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.reset() def reset(self): self.val = 0 self.avg = 0 self.sum = 0 self.count = 0 def update(self, val, n=1): self.val = val self.sum += val * n self.count += n self.avg = self.sum / self.count # print logger class Logger(object): def __init__(self): self.terminal = sys.stdout #stdout self.file = None def open(self, file, mode=None): if mode is None: mode =\u0026#39;w\u0026#39; self.file = open(file, mode) def write(self, message, is_terminal=1, is_file=1 ): if \u0026#39;\\r\u0026#39; in message: is_file=0 if is_terminal == 1: self.terminal.write(message) self.terminal.flush() #time.sleep(1) if is_file == 1: self.file.write(message) self.file.flush() def flush(self): # this flush method is needed for python 3 compatibility. # this handles the flush command by doing nothing. # you might want to specify some extra behavior here. pass def get_learning_rate(optimizer): lr=[] for param_group in optimizer.param_groups: lr +=[ param_group[\u0026#39;lr\u0026#39;] ] #assert(len(lr)==1) #we support only one param_group lr = lr[0] return lr def time_to_str(t, mode=\u0026#39;min\u0026#39;): if mode==\u0026#39;min\u0026#39;: t = int(t)/60 hr = t//60 min = t%60 return \u0026#39;%2dhr %02dmin\u0026#39;%(hr,min) elif mode==\u0026#39;sec\u0026#39;: t = int(t) min = t//60 sec = t%60 return \u0026#39;%2dmin %02dsec\u0026#39;%(min,sec) else: raise NotImplementedError class FCViewer(nn.Module): # 转化为二维tensor((x.size(0), -1)) def forward(self, x): return x.view(x.size(0), -1) # resize/reshape tensor   数据处理 文件夹信息 预处理数据下载解压后去除test(无标签)数据后，整理为两个文件夹(images和visits)。根据文件夹路径，记录文件id(区域id)、功能区id(0-8)、影像(Image, *.jpg)路径、用户访问(Visit, *.npy)路径属性\n1 2 3 4 5 6 7 8 9  train_df = pd.read_csv(train_df_fp, header=0) image_fp_list = list(images_dir.iterdir()) stem2fp_dict = {x.stem: x for x in image_fp_list} train_df[\u0026#39;image_fp\u0026#39;] = train_df.Id.map(stem2fp_dict) visit_fp_list = list(visits_dir.iterdir()) stem2fp_dict = {x.stem: x for x in visit_fp_list} train_df[\u0026#39;visit_fp\u0026#39;] = train_df.Id.map(stem2fp_dict) train_df.to_csv(train_df_fp, header=True, index=False) train_df.head()   torchvision.Dataset \u0026amp; Dataloader 使用torchvision提供的API载入两类数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  # create dataset class class MultiModalDataset(Dataset): def __init__(self,file_df,augument=True): self.file_df = file_df.copy() #csv self.augument = augument def __len__(self): return len(self.file_df) def __getitem__(self,index): X = self.read_images(index) visit=self.read_npy(index).transpose(1,2,0) y = self.file_df.iloc[index].Target if self.augument: X = self.augumentor(X) # 图像增强 X = T.Compose([T.ToPILImage(),T.ToTensor()])(X) visit=T.Compose([T.ToTensor()])(visit) return X.float(),visit.float(),y def read_images(self,index): row = self.file_df.iloc[index] images = io.imread(row.image_fp) return images def read_npy(self,index): row = self.file_df.iloc[index] visit=np.load(row.visit_fp) return visit def augumentor(self,image):# 图像随机增强 augment_img = iaa.Sequential([ iaa.Fliplr(0.5), iaa.Flipud(0.5), iaa.SomeOf((0,4),[ iaa.Affine(rotate=90), iaa.Affine(rotate=180), iaa.Affine(rotate=270), iaa.Affine(shear=(-16, 16)), ]), iaa.OneOf([ iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0 iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7 iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7 ]), #iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images ], random_order=True) image_aug = augment_img.augment_image(image) return image_aug # split data all_files_df = pd.read_csv(train_df_fp) train_df,val_df = train_test_split(all_files_df, test_size=0.1, random_state = 2050) # load dataset train_gen = MultiModalDataset(train_df) train_loader = DataLoader(train_gen,batch_size=batch_size,shuffle=True,pin_memory=True,num_workers=0) #num_worker is limited by shared memory in Docker! val_gen = MultiModalDataset(val_df, augument=False) val_loader = DataLoader(val_gen,batch_size=batch_size,shuffle=False,pin_memory=True,num_workers=0)   Note:\n  torch.transpose: 高维向量转置.如原始向量维度(7,26,24), torch.transpose(1,2,0)转换后，向量维度根据索引位置改变而变化为(26,24,7)。 (索引位置: 0-\u0026gt;7, 1-\u0026gt;26, 2-\u0026gt;24)\n  image_aug: 图像增强，别人都说强；训练集图像增强后有利于缓解模型过拟合，增强模型泛化能力。\n  num_workers: window10下只能设置为0，不然报错\n  模型设计 从单一模型(ImageNet, VisitNet)到复合模型(MulitNet)的思路开始尝试，先载入预训练模型进行简单修改，后尝试基于预训练模型进行自定义，最后尝试结合两种模型。\n载入预训练模型进行简单修改  ImageNet  1 2 3 4  model = torchvision.models.resnet18(pretrained=True) model = torchvision.models.resnet34(pretrained=True) # 更改最后输出为9类 model.fc = nn.Linear(model.fc.in_features, num_classes)    VisitNet  1 2 3 4 5  model = torchvision.models.resnet152(pretrained=True) # 改为7通道,原始图片输入为3通道，visit输入为7通道 model.conv1 = nn.Conv2d(7, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) model.fc = nn.Linear(model.fc.in_features, num_classes) model.to(device)   基于预训练模型进行自定义  ImageNet  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  class ImageModalNet(nn.Module): def __init__(self, backbone=\u0026#39;densenet121\u0026#39;, drop=0.25, pretrained=True): super().__init__() if pretrained: img_model = pretrainedmodels.__dict__[backbone](num_classes=1000, pretrained=\u0026#39;imagenet\u0026#39;) else: img_model = pretrainedmodels.__dict__[backbone](num_classes=1000, pretrained=None) self.img_encoder = list(img_model.children())[:-2] self.img_encoder.append(nn.AdaptiveAvgPool2d(1)) self.img_encoder = nn.Sequential(*self.img_encoder) if drop \u0026gt; 0: self.img_fc = nn.Sequential(FCViewer(), nn.BatchNorm1d(img_model.last_linear.in_features), nn.Dropout(drop), nn.Linear(img_model.last_linear.in_features, 256)) else: self.img_fc = nn.Sequential( FCViewer(), nn.BatchNorm1d(img_model.last_linear.in_features), nn.Linear(img_model.last_linear.in_features, 256) ) self.relu = nn.ReLU(inplace=True) self.bn = nn.BatchNorm1d(256) self.dropout = nn.Dropout(0.5) self.cls = nn.Linear(256, num_classes) def forward(self, x_img): x = self.img_encoder(x_img) x = self.img_fc(x) x = self.relu(x) x = self.bn(x) x = self.dropout(x) x = self.cls(x) return x    VisitNet (DPN网络)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119  class VisitNet(nn.Module): #随机初始化的DPN26: https://github.com/destiny19960207/URFC-top4 def __init__(self): super(VisitNet, self).__init__() k = 1 in_channel = 7 layer1_1 = [] layer1_1.append(nn.Conv2d(in_channel, 64 * k, kernel_size=(6, 1), stride=(6, 1))) layer1_1.append(nn.BatchNorm2d(64 * k)) layer1_1.append(nn.ReLU()) layer1_1.append(nn.Conv2d(64 * k, 64 * k, kernel_size=(1, 7), stride=(1, 7))) layer1_1.append(nn.BatchNorm2d(64 * k)) layer1_1.append(nn.ReLU()) self.cell_1_1 = nn.Sequential(*layer1_1) layer1_2 = [] layer1_2.append(nn.Conv2d(in_channel, 64 * k, kernel_size=(1, 7), stride=(1, 7), padding=(0, 0))) layer1_2.append(nn.BatchNorm2d(64 * k)) layer1_2.append(nn.ReLU()) layer1_2.append(nn.Conv2d(64 * k, 64 * k, kernel_size=(6, 1), stride=(6, 1), padding=(0, 0))) layer1_2.append(nn.BatchNorm2d(64 * k)) layer1_2.append(nn.ReLU()) self.cell_1_2 = nn.Sequential(*layer1_2) layer1_3 = [] layer1_3.append(nn.Conv2d(in_channel, 64 * k, kernel_size=(6, 5), stride=(6, 1), padding=(0, 2))) layer1_3.append(nn.BatchNorm2d(64 * k)) layer1_3.append(nn.ReLU()) layer1_3.append(nn.Conv2d(64 * k, 64 * k, kernel_size=(5, 7), stride=(1, 7), padding=(2, 0))) layer1_3.append(nn.BatchNorm2d(64 * k)) layer1_3.append(nn.ReLU()) self.cell_1_3 = nn.Sequential(*layer1_3) layer1_4 = [] layer1_4.append(nn.Conv2d(in_channel, 64 * k, kernel_size=(5, 7), stride=(1, 7), padding=(2, 0))) layer1_4.append(nn.BatchNorm2d(64 * k)) layer1_4.append(nn.ReLU()) layer1_4.append(nn.Conv2d(64 * k, 64 * k, kernel_size=(6, 5), stride=(6, 1), padding=(0, 2))) layer1_4.append(nn.BatchNorm2d(64 * k)) layer1_4.append(nn.ReLU()) self.cell_1_4 = nn.Sequential(*layer1_4) layer2_1 = [] layer2_1.append(nn.Conv2d(256 * k, 256 * k, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))) layer2_1.append(nn.BatchNorm2d(256 * k)) layer2_1.append(nn.ReLU()) layer2_1.append(nn.Dropout(0.1)) layer2_1.append(nn.Conv2d(256 * k, 256 * k, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))) layer2_1.append(nn.BatchNorm2d(256 * k)) layer2_1.append(nn.ReLU()) layer2_1.append(nn.Dropout(0.1)) self.cell_2_1 = nn.Sequential(*layer2_1) layer2_2 = [] layer2_2.append(nn.Conv2d(256 * k, 256 * k, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))) layer2_2.append(nn.BatchNorm2d(256 * k)) layer2_2.append(nn.ReLU()) layer2_2.append(nn.Dropout(0.1)) layer2_2.append(nn.Conv2d(256 * k, 256 * k, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))) layer2_2.append(nn.BatchNorm2d(256 * k)) layer2_2.append(nn.ReLU()) layer2_2.append(nn.Dropout(0.1)) self.cell_2_2 = nn.Sequential(*layer2_2) layer3_1 = [] layer3_1.append(nn.Conv2d(512 * k, 512 * k, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))) layer3_1.append(nn.BatchNorm2d(512 * k)) layer3_1.append(nn.ReLU()) layer3_1.append(nn.Dropout(0.2)) layer3_1.append(nn.Conv2d(512 * k, 512 * k, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))) layer3_1.append(nn.BatchNorm2d(512 * k)) layer3_1.append(nn.ReLU()) layer3_1.append(nn.Dropout(0.2)) self.cell_3_1 = nn.Sequential(*layer3_1) layer4_1 = [] layer4_1.append(nn.Conv2d(512 * k, 512 * k, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))) layer4_1.append(nn.BatchNorm2d(512 * k)) layer4_1.append(nn.ReLU()) layer4_1.append(nn.Dropout(0.2)) layer4_1.append(nn.Conv2d(512 * k, 512 * k, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))) layer4_1.append(nn.BatchNorm2d(512 * k)) layer4_1.append(nn.ReLU()) layer4_1.append(nn.Dropout(0.2)) self.cell_4_1 = nn.Sequential(*layer4_1) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) fc_dim = 4 * 3 * 512 * k self.fc = nn.Sequential(FCViewer(), nn.Dropout(0.5), nn.Linear(fc_dim, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, 256) ) def forward(self, x): x1_1 = self.cell_1_1(x) x1_2 = self.cell_1_2(x) x1_3 = self.cell_1_3(x) x1_4 = self.cell_1_4(x) x_in = torch.cat([x1_1, x1_2, x1_3, x1_4], 1) x_out_1 = self.cell_2_1(x_in) x_out_2 = self.cell_2_2(x_in) x_in = torch.cat([x_out_1, x_out_2], 1) x_out = self.cell_3_1(x_in) x_in = x_in + x_out x_out = self.cell_4_1(x_in) x_in = x_in + x_out out = self.fc(x_in) return out   模型结合 \u0026amp; 多模学习  自己写的  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  class MultiModalNet(nn.Module): def __init__(self, backbone, drop, pretrained=True): super().__init__() if pretrained: img_model = pretrainedmodels.__dict__[backbone](num_classes=1000, pretrained=\u0026#39;imagenet\u0026#39;) else: img_model = pretrainedmodels.__dict__[backbone](num_classes=1000, pretrained=None) self.img_encoder = list(img_model.children())[:-2] self.img_encoder.append(nn.AdaptiveAvgPool2d(1)) self.img_encoder = nn.Sequential(*self.img_encoder) visit_model = torchvision.models.resnet152(pretrained=True) visit_model.conv1 = nn.Conv2d(7, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # 改为7通道 visit_model.fc = nn.Linear(visit_model.fc.in_features, 256) self.visit_encoder = list(visit_model.children())[:-2] self.visit_encoder.append(nn.AdaptiveAvgPool2d(1)) self.visit_encoder = nn.Sequential(*self.visit_encoder) self.fc_viewer = nn.Sequential(FCViewer()) self.relu = nn.ReLU(inplace=True) self.bn = nn.BatchNorm1d(3072) self.dropout = nn.Dropout(0.5) self.cls1 = nn.Linear(3072, 1024) self.cls2 = nn.Linear(1024, num_classes) def forward(self, x_img, x_visit): x_img = self.img_encoder(x_img) x_img = self.fc_viewer(x_img) x_visit = self.visit_encoder(x_visit) x_visit = self.fc_viewer(x_visit) x_cat = torch.cat((x_img, x_visit), 1) x = self.relu(x_cat) x = self.bn(x) x = self.dropout(x) x = self.cls1(x) x = self.cls2(x) return x    有些修改  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class MultiNet(nn.Module): def __init__(self, drop): super().__init__() img_model = pretrainedmodels.__dict__[\u0026#39;resnet50\u0026#39;](num_classes=1000, pretrained=\u0026#39;imagenet\u0026#39;) # seresnext101 self.img_encoder = list(img_model.children())[:-2] self.img_encoder.append(nn.AdaptiveAvgPool2d(1)) self.img_encoder = nn.Sequential(*self.img_encoder, FCViewer(), nn.Dropout(drop), nn.Linear(2048, 256), ) self.visit_conv = VisitNet() #### cat 512-\u0026gt;9 cat_dim = 256 + 256 self.fc = nn.Sequential(FCViewer(), nn.ReLU(), nn.Dropout(drop), nn.Linear(cat_dim, cat_dim), nn.ReLU(), nn.Dropout(drop), nn.Linear(cat_dim, num_classes) ) def forward(self, x_img, x_vis): x1 = self.img_encoder(x_img) x2 = self.visit_conv(x_vis) x3 = torch.cat([x1, x2], 1) out = self.fc(x3) return out   其实调试过程中很多报错是很烦躁的，又不懂模型原理，只能检索后慢慢调试。这里声明一下\u0026quot;Google大法好\u0026quot;,解决90%问题。报错内容大体忘记了，通常包含维度不一致等。\n主函数 训练\u0026amp;验证函数 这里比较通用，主要是模型和参数修改比较大\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  def train(train_loader,model,criterion,optimizer,epoch,valid_metrics,best_results,start): losses = AverageMeter() f1 = AverageMeter() acc = AverageMeter() model.train() for i,(images,visit,target) in enumerate(train_loader): visit=visit.to(device) images = images.to(device) indx_target=target.clone() target = torch.from_numpy(np.array(target)).long().to(device) # compute output output = model(images,visit) loss = criterion(output,target) losses.update(loss.item(),images.size(0)) f1_batch = f1_score(target.cpu().data.numpy(),np.argmax(F.softmax(output).cpu().data.numpy(),axis=1),average=\u0026#39;macro\u0026#39;) acc_score=accuracy_score(target.cpu().data.numpy(),np.argmax(F.softmax(output).cpu().data.numpy(),axis=1)) f1.update(f1_batch,images.size(0)) acc.update(acc_score,images.size(0)) optimizer.zero_grad() loss.backward() optimizer.step() print(\u0026#39;\\r\u0026#39;,end=\u0026#39;\u0026#39;,flush=True) message = \u0026#39;%s%5.1f%6.1f| %0.3f%0.3f%0.3f| %0.3f%0.3f%0.4f| %s%s%s| %s\u0026#39; % (\\ \u0026#34;train\u0026#34;, i/len(train_loader) + epoch, epoch, acc.avg, losses.avg, f1.avg, valid_metrics[0], valid_metrics[1],valid_metrics[2], str(best_results[0])[:8],str(best_results[1])[:8],str(best_results[2])[:8], time_to_str((timer() - start),\u0026#39;min\u0026#39;)) print(message , end=\u0026#39;\u0026#39;,flush=True) log.write(\u0026#34;\\n\u0026#34;) #log.write(message) #log.write(\u0026#34;\\n\u0026#34;) return [acc.avg,losses.avg,f1.avg] # 2. evaluate function def evaluate(val_loader,model,criterion,epoch,train_metrics,best_results,start): # only meter loss and f1 score losses = AverageMeter() f1 = AverageMeter() acc= AverageMeter() # switch mode for evaluation model.to(device) model.eval() with torch.no_grad(): for i, (images,visit,target) in enumerate(val_loader): images_var = images.to(device) visit=visit.to(device) indx_target=target.clone() target = torch.from_numpy(np.array(target)).long().to(device) output = model(images_var,visit) loss = criterion(output,target) losses.update(loss.item(),images_var.size(0)) f1_batch = f1_score(target.cpu().data.numpy(),np.argmax(F.softmax(output).cpu().data.numpy(),axis=1),average=\u0026#39;macro\u0026#39;) acc_score=accuracy_score(target.cpu().data.numpy(),np.argmax(F.softmax(output).cpu().data.numpy(),axis=1)) f1.update(f1_batch,images.size(0)) acc.update(acc_score,images.size(0)) print(\u0026#39;\\r\u0026#39;,end=\u0026#39;\u0026#39;,flush=True) message = \u0026#39;%s%5.1f%6.1f| %0.3f%0.3f%0.3f| %0.3f%0.3f%0.4f| %s%s%s| %s\u0026#39; % (\\ \u0026#34;val\u0026#34;, i/len(val_loader) + epoch, epoch, acc.avg,losses.avg,f1.avg, train_metrics[0], train_metrics[1],train_metrics[2], str(best_results[0])[:8],str(best_results[1])[:8],str(best_results[2])[:8], time_to_str((timer() - start),\u0026#39;min\u0026#39;)) print(message, end=\u0026#39;\u0026#39;,flush=True) log.write(\u0026#34;\\n\u0026#34;) #log.write(message) #log.write(\u0026#34;\\n\u0026#34;) return [acc.avg,losses.avg,f1.avg]   main 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  start_epoch = 0 best_acc=0 best_loss = np.inf best_f1 = 0 best_results = [0,np.inf,0] val_metrics = [0,np.inf,0] device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = MultiNet(0.25) model.to(device) optimizer = torch.optim.Adam([{\u0026#39;params\u0026#39;: model.parameters()}], lr=lr, weight_decay=1e-4) criterion = nn.CrossEntropyLoss().to(device) all_files_df = pd.read_csv(train_df_fp) train_df,val_df = train_test_split(all_files_df, test_size=0.1, random_state = 2050) # load dataset train_gen = MultiModalDataset(train_df) train_loader = DataLoader(train_gen,batch_size=batch_size,shuffle=True,pin_memory=True,num_workers=0) #num_worker is limited by shared memory in Docker! val_gen = MultiModalDataset(val_df, augument=False) val_loader = DataLoader(val_gen,batch_size=batch_size,shuffle=False,pin_memory=True,num_workers=0) scheduler = lr_scheduler.ReduceLROnPlateau(optimizer) start = timer() log = Logger() log.open(\u0026#34;logs/%s_log_train.txt\u0026#34;%model_name,mode=\u0026#34;a\u0026#34;) log.write(\u0026#34;\\n----------------------------------------------- [START %s] %s\\n\\n\u0026#34; % (datetime.now().strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;), \u0026#39;-\u0026#39; * 51)) log.write(\u0026#39; |------------ Train -------|----------- Valid ---------|----------Best Results---|------------|\\n\u0026#39;) log.write(\u0026#39;mode iter epoch | acc loss f1_macro | acc loss f1_macro | loss f1_macro | time |\\n\u0026#39;) log.write(\u0026#39;-------------------------------------------------------------------------------------------------------------------------|\\n\u0026#39;) fold = 1 for epoch in range(0, epochs): print(\u0026#39;lr:\u0026#39;, lr / (2 ** np.sqrt(epoch + 0.1))) optimizer = torch.optim.Adam([{\u0026#39;params\u0026#39;: model.parameters()}], lr=lr / (2 ** np.sqrt(epoch + 0.1)), weight_decay=1e-4) scheduler.step(epoch) # train train_metrics = train(train_loader, model, criterion, optimizer, epoch, val_metrics, best_results, start) # val val_metrics = evaluate(val_loader, model, criterion, epoch, train_metrics, best_results, start) # check results is_best_acc = val_metrics[0] \u0026gt; best_results[0] best_results[0] = max(val_metrics[0], best_results[0]) is_best_loss = val_metrics[1] \u0026lt; best_results[1] best_results[1] = min(val_metrics[1], best_results[1]) is_best_f1 = val_metrics[2] \u0026gt; best_results[2] best_results[2] = max(val_metrics[2], best_results[2]) # save model save_checkpoint({ \u0026#34;epoch\u0026#34;: epoch + 1, \u0026#34;model_name\u0026#34;: model_name, \u0026#34;state_dict\u0026#34;: model.state_dict(), \u0026#34;best_acc\u0026#34;: best_results[0], \u0026#34;best_loss\u0026#34;: best_results[1], \u0026#34;optimizer\u0026#34;: optimizer.state_dict(), \u0026#34;fold\u0026#34;: fold, \u0026#34;best_f1\u0026#34;: best_results[2], }, is_best_acc, is_best_loss, is_best_f1, fold) # print logs print(\u0026#39;\\r\u0026#39;, end=\u0026#39;\u0026#39;, flush=True) log.write( \u0026#39;%s%5.1f%6.1f| %0.3f%0.3f%0.3f| %0.3f%0.3f%0.3f| %s%s%s| %s\u0026#39; % ( \\ \u0026#34;best\u0026#34;, epoch, epoch, train_metrics[0], train_metrics[1], train_metrics[2], val_metrics[0], val_metrics[1], val_metrics[2], str(best_results[0])[:8], str(best_results[1])[:8], str(best_results[2])[:8], time_to_str((timer() - start), \u0026#39;min\u0026#39;)) ) log.write(\u0026#34;\\n\u0026#34;) time.sleep(0.01)   文件打包 下载地址:RSURFC.rar\n","description":"","id":63,"section":"posts","tags":["练习赛","Baseline","城市功能区划分","Pytorch","深度学习"],"title":"RSURFC-练习赛Baseline实现","uri":"https://www.xunhs.cyou/posts/notes/2020-06-07-rsurfc-%E7%BB%83%E4%B9%A0%E8%B5%9Bbaseline%E5%AE%9E%E7%8E%B0/"},{"content":" 小猫咪造访。\n \n  2020.6.1 好像漂浮了很久\n  2020.6.2 豆瓣2019年度电影榜单\n  看了好多遍看不懂。来自新版白话空间统计（13）：随机的力量; 百度百科\n 天之道，其犹张弓与？高者抑下，下者举之，有余者损之，不足者补之。\n天之道，损有余而补不足。人之道，则不然，损不足以奉有余。\n孰能有余以奉天下，唯有道者。是以圣人为而不恃，功成而不处，其不欲见贤。\n释义: 自然的规律，不是很像张弓射箭吗？弦拉高了就把它压低一些，低了就把它举高一些，拉得过满了就把它放松一些，拉得不足了就把它补充一些。\n自然的规律，是减少有余的补给不足的。可是社会的法则却不是这样，要减少不足的，来奉献给有余的人。\n那么，谁能够减少有余的以补给天下人的不足呢？只有有道的人才可以做到。因此，有道的圣人这才有所作为而不占有，有所成就而不居功。他是不愿意显示自己的贤能。\n   2020.6.3 RSURFC这个比赛，分别单独跑了一下RS和visit的baseline,一个0.33，一个0.58.有点意思。\n  2020.6.4 这一天被粗心的作者遗漏了。\n  2020.6.5 我是不是还活在昨天？？？;今天换了一个博客主题。\n  2020.6.6 什么是城市内部居民移动模式？如何从出租车轨迹中挖掘？;Image+Visit结合的多模学习终于跑通了。两类特征结合果然精度一下子就升上来了，也刚刚跑到Baseline(0.67)。想想那些能把精度从0.67升到0.88的人，确实是下了不少功夫。\n  2020.6.7 身无彩凤双飞翼，心有灵犀一点通。\n  2020.6.8 无可奈何花落去，似曾相识燕归来。小园香径独徘徊。\n  2020.6.9 明月别枝惊鹊，清风半夜鸣蝉。我梦见自己蹲监狱了。具体什么原因忘记了。就是进去了。\n  2020.6.10 即是平庸之人，又有什么可失去的呢？\n  2020.6.11 优博基金获批了，有点意外。但高兴不起来？\n  2020.6.12 相思山。\n  2020.6.13 调音把1弦弄断了，盲目自信。\n  2020.6.14 断弦修复。\n  2020.6.15 小猫咪造访。\n  2020.6.16 你的背影无法从那晚的夕阳中抽离 所以我决定爱上每个黄昏\n  2020.6.17 拿出吉他练习 回想起博一博二那段时间 在314吧 会听到隔壁同学晚上练琴 过去的时间总会让人怀念'\n  2020.6.18 其实分别也没有这么可怕。65万个小时后，当我们氧化成风，就能变成同一杯啤酒上两朵相邻的泡沫，就能变成同一盏路灯下两粒依偎的尘埃。宇宙中的原子并不会湮灭，而我们，也终究会在一起。-《Apocalypse》网易云\n  2020.6.19 会思考的金毛恩佐\n  2020.6.20 读博压力大 熬夜又脱发 读博生活苦 科研心里堵\n  2020.6.21 突然发现头发长有另外一个好处 可以不显胖 :(\n  2020.6.22 深圳市手机信令数据下载与处理(包括ETC/公交卡/出租车轨迹等);珞珈一号卫星影像下载以及预处理\n  2020.6.23 开车还是不稳啊，倒车的时候只看倒车影像，不看后视镜，把车刮了一个印。老父亲说你你还不服气，换了别人早被骂臭了还得赔钱。长记性啊，特别是倒车、上坡起步的时候。开车要稳当，一失足千古恨。\n  2020.6.24 无所谓没有阳光，前行的你就是焦点。-某博士论文\n  2020.6.25 艾草\n  2020.6.26 莫过于爱情是百般不如意。\n  2020.6.27 你们有没有特别害怕失去的东西 有时候为了这些东西 你会去做你们不愿意做的事情\n  2020.6.28 秋葵\n  2020.6.29 该死的老家伙，为什么要抱走我养的猫\n  2020.6.30 第二轮复研返校申请开始了\n  ","description":"","id":64,"section":"posts","tags":["回家","开车","土地利用分类","优博基金","吉他","猫"],"title":"2020-6","uri":"https://www.xunhs.cyou/posts/journals/2020-06-01-2020-6/"},{"content":" osmnx是下载、处理等osm路网很好用的一个包。networkx是图论学习中很好用的包，两者结合为基于图论的方法研究osm road network提供便利。以下内容为整理两个包常用的功能函数方法。\n osmnx基础 Init 1 2 3 4 5 6 7  import osmnx as ox import networkx as nx %matplotlib inline ox.config(log_console=True, use_cache=True) ox.__version__ from pathlib import Path   Query place 1 2  place =\u0026#34;Shenzhen\u0026#34; G = ox.graph_from_place(place, network_type=\u0026#39;drive\u0026#39;,which_result=2)     Note parameter network_type means specify several different network types(Refer from overview-osmnx):\n \u0026lsquo;drive\u0026rsquo; - get drivable public streets (but not service roads) \u0026lsquo;drive_service\u0026rsquo; - get drivable streets, including service roads \u0026lsquo;walk\u0026rsquo; - get all streets and paths that pedestrians can use (this network type ignores one-way directionality) \u0026lsquo;bike\u0026rsquo; - get all streets and paths that cyclists can use \u0026lsquo;all\u0026rsquo; - download all non-private OSM streets and paths (this is the default network type unless you specify a different one) \u0026lsquo;all_private\u0026rsquo; - download all OSM streets and paths, including private-access ones    private-access road means roads with tag-access=private. (Refer from wiki-osm)\n  Plot graph 1  fig, ax = ox.plot_graph(G, node_size=0, edge_color=\u0026#39;w\u0026#39;, edge_linewidth=0.2, bgcolor=\u0026#39;k\u0026#39;)   Save/load shapefile \u0026amp; graphml Refer: osmnx-examples/05-save-load-networks.ipynb\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # get a network # save graph as a shapefile # save/load graph as a graphml file: this is the best way to save your model # for subsequent work later shenzhen_dir = Path(\u0026#39;./shenzhen\u0026#39;) shp_dir = Path(shenzhen_dir, \u0026#39;shp\u0026#39;) graph_fp = Path(shenzhen_dir, \u0026#39;shenzhen.graphml\u0026#39;) if not shp_dir.exists(): shp_dir.mkdir() # shapefile \u0026amp; graphml ox.save_graph_shapefile(G, filepath=str(shp_dir)) ox.save_graphml(G, filepath=str(graph_fp), gephi=False) # load graphml G = ox.load_graphml(graph_fp)   Calculate basic network indicators 1 2  stats = ox.basic_stats(G) stats   out:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  {\u0026#39;n\u0026#39;: 33121, \u0026#39;m\u0026#39;: 73564, \u0026#39;k_avg\u0026#39;: 4.442136408924851, \u0026#39;intersection_count\u0026#39;: 29210, \u0026#39;streets_per_node_avg\u0026#39;: 3.0009963467286616, \u0026#39;streets_per_node_counts\u0026#39;: {0: 0, 1: 3911, 2: 126, 3: 21360, 4: 7485, 5: 221, 6: 18}, \u0026#39;streets_per_node_proportion\u0026#39;: {0: 0.0, 1: 0.11808218350895203, 2: 0.0038042329639805562, 3: 0.6449080643700371, 4: 0.2259895534555116, 5: 0.006672503849521451, 6: 0.0005434618519972223}, \u0026#39;edge_length_total\u0026#39;: 14743317.355999907, \u0026#39;edge_length_avg\u0026#39;: 200.41484090043917, \u0026#39;street_length_total\u0026#39;: 10292802.579999937, \u0026#39;street_length_avg\u0026#39;: 207.1486592336165, \u0026#39;street_segments_count\u0026#39;: 49688, \u0026#39;node_density_km\u0026#39;: None, \u0026#39;intersection_density_km\u0026#39;: None, \u0026#39;edge_density_km\u0026#39;: None, \u0026#39;street_density_km\u0026#39;: None, \u0026#39;circuity_avg\u0026#39;: 1.0846412027749917, \u0026#39;self_loop_proportion\u0026#39;: 0.0014001413734979066, \u0026#39;clean_intersection_count\u0026#39;: None, \u0026#39;clean_intersection_density_km\u0026#39;: None}   Fast nearest node/edge search with OSMnx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  center_point = lat, lng # 注意坐标格式，纬度在前，经度在后 # find the nearest node to some point center_node = ox.get_nearest_node(G, center_point) # find the nearest nodes to a set of points # optionally specify `method` use use a kdtree or balltree index nearest_nodes = ox.get_nearest_nodes(G, lngs, lats, method=\u0026#39;balltree\u0026#39;) # find the nearest edge to some point nearest_edge = ox.get_nearest_edge(G, center_point) # find the nearest edges to some set of points # optionally specify `method` use use a kdtree or balltree index nearest_edges = ox.get_nearest_edges(G, lngs, lats)   OSMnx functions graph \u0026lt;-\u0026gt; GeoDataFrames Refer to : osmnx.utils_graph\nConvert a graph into node and/or edge GeoDataFrames 1 2 3  edges_gdf = ox.graph_to_gdfs(G, nodes=False) nodes_gdf = ox.graph_to_gdfs(G, edges=False) edges_gdf.head();nodes_gdf.head()   out:\nedges_gdf     u v key osmid name highway oneway length geometry lanes maxspeed ref bridge tunnel access width landuse junction     0 3377201155 3377199760 0 330725486 南同大道 secondary False 87.53 LINESTRING (114.2827267 22.6972648, 114.2818811 22.6971596) nan nan nan nan nan nan nan nan nan   1 3377201155 3145194682 0 330725486 南同大道 secondary False 284.987 LINESTRING (114.2827267 22.6972648, 114.2841709 22.6974048, 114.2854842 22.6975733) nan nan nan nan nan nan nan nan nan   2 3377201155 3377201142 0 330727857 nan unclassified False 332.196 LINESTRING (114.2827267 22.6972648, 114.2825873 22.6983075, 114.2826002 22.6984817, 114.2829494 22.7002143) nan nan nan nan nan nan nan nan nan   3 5296488468 2720855960 0 266553759 nan secondary_link False 9.983 LINESTRING (114.103413 22.7115999, 114.1033684 22.7116797) nan nan nan nan nan nan nan nan nan   4 5296488468 5296488469 0 548236871 中环大道 tertiary True 1143.42 LINESTRING (114.103413 22.7115999, 114.1037991 22.7116604, 114.1041064 22.711632, 114.1044133 22.7114466, 114.1047399 22.7111653, 114.104999 22.7108329, 114.1053723 22.7105961, 114.1062619 22.7103602, 114.1066166 22.7100907, 114.1067313 22.7096768, 114.1066358 22.7091382, 114.106247 22.7087397, 114.1057681 22.7082979, 114.1053296 22.7078727, 114.1050831 22.7075478, 114.1050484 22.7069286, 114.1051519 22.7064617, 114.105374 22.7060621, 114.1054614 22.7054678, 114.1054724 22.7048434, 114.1054836 22.7042894, 114.1054666 22.7039499) nan nan nan nan nan nan nan nan nan   nodes_gdf                      y x osmid highway ref geometry               \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;: \u0026mdash;\u0026mdash;\u0026ndash;: \u0026mdash;\u0026mdash;\u0026ndash;: \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;: \u0026mdash;\u0026mdash;\u0026mdash;-: \u0026mdash;\u0026mdash;: :\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-               3377201155 22.6973 114.283 3377201155 nan nan POINT (114.2827267 22.6972648)               5296488468 22.7116 114.103 5296488468 nan nan POINT (114.103413 22.7115999)               5296488469 22.7039 114.105 5296488469 nan nan POINT (114.1054666 22.7039499)               5296488477 22.704 114.103 5296488477 nan nan POINT (114.1033273 22.7039622)               2728263712 22.6701 114.138 2728263712 nan nan POINT (114.1384942 22.6700615)                 osmnx.utils_graph.graph_to_gdfs(G, nodes=True, edges=True, node_geometry=True, fill_edge_geometry=True)  G (networkx.MultiDiGraph) – input graph nodes (bool) – if True, convert graph nodes to a GeoDataFrame and return it edges (bool) – if True, convert graph edges to a GeoDataFrame and return it node_geometry (bool) – if True, create a geometry column from node x and y data fill_edge_geometry (bool) – if True, fill in missing edge geometry fields using origin and destination nodes    Convert node and edge GeoDataFrames into a MultiDiGraph 1  G = ox.graph_from_gdfs(gdf_edges=edges_gdf, gdf_nodes=nodes_gdf)    \u0026lsquo;osmnx.utils_graph.graph_from_gdfs(gdf_nodes, gdf_edges)\u0026rsquo;  gdf_nodes (geopandas.GeoDataFrame) – GeoDataFrame of graph nodes gdf_edges (geopandas.GeoDataFrame) – GeoDataFrame of graph edges    路径规划 Basic routing by distance Pick two nodes. Then find the shortest path between origin and destination, using weight=\u0026lsquo;length\u0026rsquo; to find the shortest path by minimizing distance traveled (otherwise it treats each edge as weight=1).\n1 2 3 4 5  # find the shortest path (by distance) between these nodes then plot it orig = list(G)[0] # node id 3377201155 dest = list(G)[-1] # node id 3377201149 route = nx.shortest_path(G, orig, dest) # [3377201155, 3145194682, ...] fig, ax = ox.plot_graph_route(G, route, route_linewidth=6, node_size=0, bgcolor=\u0026#39;k\u0026#39;)   The routing correctly handles one-way streets:\n1 2 3 4 5 6  orig_pnt = (22.67304, 114.0133) # 注意坐标格式，纬度在前，经度在后 dest_pnt = (22.589, 114.0973) origin_node = ox.get_nearest_node(G, orig_pnt) destination_node = ox.get_nearest_node(G, dest_pnt) route = nx.shortest_path(G, origin_node, destination_node) fig, ax = ox.plot_graph_route(G, route, route_linewidth=6, node_size=0, bgcolor=\u0026#39;k\u0026#39;)    Note shortest_path(G, source=None, target=None, weight=None, method='dijkstra')  G (NetworkX graph) source (node, optional) – Starting node for path. If not specified, compute shortest paths for each possible starting node. target (node, optional) – Ending node for path. If not specified, compute shortest paths to all possible nodes. weight (None or string, optional (default = None)) – If None, every edge has weight/distance/cost 1. If a string, use this edge attribute as the edge weight. Any edge attribute not present defaults to 1. method (string, optional (default = ‘dijkstra’)) – The algorithm to use to compute the path. Supported options: ‘dijkstra’, ‘bellman-ford’. Other inputs produce a ValueError. If weight is None, unweighted graph methods are used, and this suggestion is ignored. Return: path – All returned paths include both the source and target in the path.If the source and target are both specified, return a single list of nodes in a shortest path from the source to the target.If only the source is specified, return a dictionary keyed by targets with a list of nodes in a shortest path from the source to one of the targets.If only the target is specified, return a dictionary keyed by sources with a list of nodes in a shortest path from one of the sources to the target.If neither the source nor target are specified return a dictionary of dictionaries with path[source][target]=[list of nodes in path].    Routing by travel speeds and times add_edge_speeds: The add_edge_speeds function add edge speeds (km per hour) to graph as new speed_kph edge attributes. Imputes free-flow travel speeds for all edges based on mean maxspeed value of edges, per highway type. This mean-imputation can obviously be imprecise, and the caller can override it by passing in hwy_speeds and/or fallback arguments that correspond to local speed limit standards.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # impute speed on all edges missing data G = ox.add_edge_speeds(G) # calculate travel time (seconds) for all edges G = ox.add_edge_travel_times(G) # see mean speed/time values by road type edges = ox.graph_to_gdfs(G, nodes=False) edges[\u0026#39;highway\u0026#39;] = edges[\u0026#39;highway\u0026#39;].astype(str) edges.groupby(\u0026#39;highway\u0026#39;)[[\u0026#39;length\u0026#39;, \u0026#39;speed_kph\u0026#39;, \u0026#39;travel_time\u0026#39;]].mean().round(1) # round(1)取小数点后一位数 # same thing again, but this time pass in a few default speed values (km/hour) # to fill in edges with missing `maxspeed` from OSM hwy_speeds = {\u0026#39;residential\u0026#39;: 35, \u0026#39;secondary\u0026#39;: 50, \u0026#39;tertiary\u0026#39;: 60} G = ox.add_edge_speeds(G, hwy_speeds) G = ox.add_edge_travel_times(G)   out:\n   highway length speed_kph travel_time     [\u0026lsquo;living_street\u0026rsquo;, \u0026lsquo;residential\u0026rsquo;] 534.4 20 96.2   [\u0026lsquo;motorway\u0026rsquo;, \u0026lsquo;motorway_link\u0026rsquo;] 2978.7 94.1 113.9   [\u0026lsquo;motorway\u0026rsquo;, \u0026lsquo;secondary\u0026rsquo;] 3239.3 94.1 123.9   [\u0026lsquo;motorway\u0026rsquo;, \u0026lsquo;trunk_link\u0026rsquo;] 631.4 30 75.8   [\u0026lsquo;motorway_link\u0026rsquo;, \u0026lsquo;secondary\u0026rsquo;] 856.6 46.7 66.1    Routing by travel speeds and times\n1 2 3 4 5 6 7 8 9 10 11 12 13  # calculate two routes by minimizing travel distance vs travel time orig = list(G)[1] dest = list(G)[-1] route1 = nx.shortest_path(G, orig, dest, weight=\u0026#39;length\u0026#39;) route2 = nx.shortest_path(G, orig, dest, weight=\u0026#39;travel_time\u0026#39;) # compare the two routes route1_length = int(sum(ox.utils_graph.get_route_edge_attributes(G, route1, \u0026#39;length\u0026#39;))) route2_length = int(sum(ox.utils_graph.get_route_edge_attributes(G, route2, \u0026#39;length\u0026#39;))) route1_time = int(sum(ox.utils_graph.get_route_edge_attributes(G, route1, \u0026#39;travel_time\u0026#39;))) route2_time = int(sum(ox.utils_graph.get_route_edge_attributes(G, route2, \u0026#39;travel_time\u0026#39;))) print(\u0026#39;Route 1 is\u0026#39;, route1_length, \u0026#39;meters and takes\u0026#39;, route1_time, \u0026#39;seconds.\u0026#39;) print(\u0026#39;Route 2 is\u0026#39;, route2_length, \u0026#39;meters and takes\u0026#39;, route2_time, \u0026#39;seconds.\u0026#39;)   out:\nRoute 1 is 28753 meters and takes 1787 seconds.\nRoute 2 is 36221 meters and takes 1647 seconds.\n1 2 3 4 5 6 7 8 9 10 11  # pick route colors c1 = \u0026#39;r\u0026#39; #length c2 = \u0026#39;b\u0026#39; #travel_time rc1 = [c1] * (len(route1) - 1) rc2 = [c2] * (len(route2) - 1) rc = rc1 + rc2 nc = [c1, c1, c2, c2] # plot the routes fig, ax = ox.plot_graph_routes(G, [route1, route2], route_color=rc, route_linewidth=6, orig_dest_node_color=nc, node_size=0, bgcolor=\u0026#39;k\u0026#39;)   The blue route minimizes travel time, and is thus longer but faster than the red route.\n","description":"","id":65,"section":"posts","tags":["Python库","osm","osmnx","graph","networkx","road network"],"title":"Python库-osmnx\u0026networkx","uri":"https://www.xunhs.cyou/posts/notes/2020-05-27-python%E5%BA%93-osmnxnetworkx/"},{"content":"  Journal Article: 2017-Hierarchical semantic cognition for urban functional zones with VHR satellite images and POI data  Refer: ISPRS Journal of Photogrammetry and Remote Sensing A Abstract  [功能区划图不好拿]functional-zone maps are hardly available in most cities [急需(半)自动化的方法]an automatic/semi-automatic method for mapping urban functional zones is highly required [继承性语义识别]Hierarchical semantic cognition (HSC) relies on geographic cognition and considers four semantic layers with a very-highresolution (VHR) satellite image and point-of-interest (POI) data result: overall accuracy of 90.8%; the contributions of diverse semantic layers are quantified    Journal Article: 2018-Understanding Urban Functionality from POI Space  Refer: 2018 26th International Conference on Geoinformatics A Abstract:  understanding of the urban built environment revealing the co-occurrences of POIs POI Space the network of relatedness between POIs findings:  [核心-边缘分布]more common POIs are located in a densely connected core whereas rarer and more unique POIs occupy a less-connected periphery [扩散速度?]common POIs act more on the speed of diffusion, unique POIs act more on the scope of diffusion.      Journal Article: 2019-Beyond Word2vec: An approach for urban functional region extraction and identification by combining Place2vec and POIs Journal Article: 2019-DFCNN-Based Semantic Recognition of Urban Functional Zones by Integrating Remote Sensing Data and POI Data  Refer: Remote Sensing A recognition of physical and social semantics of buildings object-wise recognition strategy building semantic recognition  Journal Article: 2020-Understanding Place Characteristics in Geographic Contexts through Graph Convolutional Neural Networks   Refer: Annals of the American Association of Geographers\n  AAAAA\n  Place Characteristics; Geographic Contexts; Graph convolutional neural networks (GCNNs)\n  Abstract:\n both its observed attributes and the characteristics of the places to which it is connected spatial prediction task: predict the unobserved place characteristics based on the observed properties and specific place connections GCNNs capture the knowledge of the relevant geographic context A series of comparative experiments formalizing places for geographic knowledge representation and reasoning    Introduction\n place characteristics places are not isolated but are connecthsed ti each other the contextual information for a place (i.e., its connection to other places) is crucial to understand its characteristics place conncetions =\u0026gt; the measures between places (distance, adjacency and spatial interactions) [为什么会提到地理空间层次的上下文呢？我理解，正如作者所言，对位置地点属性的预测，不仅仅依赖于该地点的观测变量，同时还由该地点周边/相连接的地点的观测属性决定。这里的周边/相连接，对应着作者论述的地理空间上下文]geographic contexts =\u0026gt; The prediction of a place’s unknown characteristic relies on both the place’s observed characteristics and the characteristics of the places to which it is connected. [这里引入了GCNN,提到几个关键词:aggregation,neighbors,contextual infformation]process the connection information: GCNNs generally follow an aggregation scheme where each node aggregates characteristics of its neighbors to learn a deep representation of the contextual information each place is represented as a node, place characteristics are the node features to be computed, and place connections are represented as the graph edges Introduction部分可以说短小精悍了,内容不多但是论点阐述的很清楚。  第一段通过place引入place characteristic的概念，为后面做铺垫； 第二段说place不是孤立的而是相连的，引入了place connection的概念； 第三段就用到了上面两个概念的铺垫了，他说place characteristic的预测不仅和自身的观测变量有关，还和相邻的(connected)的地点的特征相关，然后介绍了两个measure connection的研究。然后就是说道研究的局限性，局限性其实他表述了比较多的方面，也可能是我理解的比较抽象，这一段的内容可能比较关键,因为他把两个概念穿了起来，并且引出了本文的研究点； 第四段理解上就比较简单写了，引入GCNN对于解决model connection的问题很有效； 第五段简介自己的研究内容。      Methodology\n Building the Place-Based Graph Predicting Place Characteristics Using GCNNs    Case Study\n Study Area Data Preparation  Delineating Place Boundaries. Quantifying Place Characteristics. Quantifying Place Characteristics.   A GCNN Model to Predict Places’ Functional Features    我把他方法论和Case Study的部分列出来是想说他这两部分的划分我有点看不懂。方法论部分提取出来，然后Case Study去讲具体的步骤。通常的文章里面都不分开吧？或者具体的步骤放在implementation里面？\n  Journal Article: 2020-Urban Function as a New Perspective for Adaptive Street Quality Assessment  Refer: Sustainability A Abstract  Street Quality Assessment =\u0026gt; managing natural and public resources, organizing urban morphologies and improving city vitality from the perspective of the variation in urban functions urban function detection + urban function-driven multilevel street quality assessment   Introduction  assess street networks =\u0026gt; enriches the current description of street networks and enhances the evaluation of street network performance these studies have discussed greenery, mobility patterns, and land-use connectivity but ignored the different urban functions that each type of street serves [静态的？]the detection of urban functions in most research is static commercial, residential and traffic functions    ","description":"","id":66,"section":"posts","tags":["Points of Interest","Urban functional zones"],"title":"Papers_Reading-Urban Functional Regions","uri":"https://www.xunhs.cyou/posts/notes/2020-05-05-papers-reading-urban-functional-regions/"},{"content":" 一转眼博士三年级已然还有几个月就结束了，从一月份到五月初在家度过的这段时间，虽然受疫情的影响无法回学校学习，但换种角度而言，也成为了这读博期间度过的一个”特别“的时期。所谓特别，主要在于两方面。\n 吴老师您好，\n一转眼博士三年级已然还有几个月就结束了，从一月份到五月初在家度过的这段时间，虽然受疫情的影响无法回学校学习，但换种角度而言，也成为了这读博期间度过的一个”特别“的时期。所谓特别，主要在于两方面：\n与自己相处。总的来说就是适应在家专心的学习。读书这么多年，也是从初中高中开始，每次放假回家，大部分时间都是放松自己，即使带作业、几本书回家，也都是拖到最后几天，或者回到学校恶补。自然而然的养成的习惯，亦或是说定性思维，在家的主要目的是放松自己。也就造成了读书以来，在家和在学校形成的两种不同的“环境”。1月份刚放假的那段时间，疫情还没有受到关注的时候，想着好好在家放松放松，在家里休息半个月后回学校好好干活。谁知在家一待就是几个月，直到现在提笔，也不知晓何时才能回学校。也是读书以来，第一次这么想回到学校。所谓与自己相处，不如说是一个克服懒惰、拖延、松散等坏习惯的一个过程。比如说，在学校的状态是一个训练了多年的模型，它可以很好的拟合在学校工作、学习等任务；但是，把这个模型迁移到家中，就会出现“问题”，比如说训练样本不足，调参等。与自己相处，是一个迁移学习的过程，需要做调参，以更好的拟合在家中学习这个任务。说的不好听一点，觉得自己有点”套概念“了。以后多的是环境的切换，多的是时境变迁，如何学会适应环境，调整自己的心性，做自己”该做“的事情，还需要很长的过程。还是心性不够成熟。\n与父母相处。两代人之间思想观念真的有很大差异，特别是生活在一个”狭小的空间“，遇到不同的观点，就会爆发矛盾。在家中，与父母相处的这几个月，经历了”争吵-磨合-再争吵-继续磨合“的过程。特别是在前一个半月，几乎每天都会与父亲争吵，一些思维观念上的矛盾，一些生活上的琐事，有时候甚至是刻意的不服和争辩。明知道是小孩子气，却就是不愿意”服软“。时间可以改变一切，事实证明也确实如此。不知从何开始，不知是两方都为了刻意避免矛盾而不愿意去抛出问题，从而避免了冲突。大家都做自己的事情，放弃了”商量“，放弃了询问对方。知道发现自己想明白一些事情，商量和咨询的目的是为了参考父母、长辈的意见，是希望可以站在他们的角度考虑问题本身，而非一定决定出个是非对错。所以为什么要去争吵呢？于是想明白之后，磨合之后的争吵变不再有火药味道，取而代之的是尊敬和权衡。是的，父母也都老了，二老的年龄加在一起也都快120岁了。难得的这么长的时间，能在家陪着父母。以后这种机会也很少吧。\n吴老师，可能在家的时间，身边少了许多同龄人一起交流，因此比较多的是个人的反思。有些是无趣的，有些甚至是多余的。但是有时候经历这些思考之后，自己确实能够在一段时间内得到短暂的提升。比如说在经历了漫长的拖延之后，把论文完成，并尝试投稿；比如说看到一审拒稿意见之后百般不知所措，但看到重投机会之后还是会坚持。在家中给自己的闲暇时间也多了。把以前没有好好做的事情好好搞了一下，买轻服务器，购买域名，搭建了一个一直以来向往的属于自己的空间。上面记录了一些自己的想法、闲言碎语、coding tips等。没有想让很多人知道。\n接下来的五月注定迎来了很多事情。CSC联培的申请和选拔，总结自己这三四年的研究成果和思路，规划后续的研究并打算准备开题的事情。同时，四月份进行的实验-基于出租车轨迹数据的城市空间结构挖掘，总觉得还需要补充实验，也打算能够尽快完成论文并投稿。同时也期望国内外的疫情能够尽快的结束，能够尽快的回到学校，专心体会“近黄昏”的读博时光。\n吴老师，以上是我这段时间的一个总结以及后续工作的整理。可能更多的是心性方面的思考和整理。打扰您了，吴老师~~\n此致夏宁！\n学生胡胜\n","description":"","id":67,"section":"posts","tags":["心性","邮件","五月","总结"],"title":"2020-5-中期总结邮件","uri":"https://www.xunhs.cyou/posts/journals/2020-05-04-2020-5-%E4%B8%AD%E6%9C%9F%E6%80%BB%E7%BB%93%E9%82%AE%E4%BB%B6/"},{"content":" 寻羊冒险记\n \n 2020.5.1 水里的空气 是你小心眼和坏脾气 2020.5.2 璇璇小朋友很喜欢舅舅，一直粘着我玩。 2020.5.3 成长的一方面意义是学会控制情绪，理性对待问题。喜欢的事喜欢着去做。不喜欢的事情慢慢接受后去做。 2020.5.4 以前有一件喜欢的T-shirt, 上面写着: You are the CSS of my HTML. 那段时间很喜欢，就像喜欢一个人一样喜欢。 2020.5.5 立夏。 2020.5.6 沉默是最大的谎言。 2020.5.7 一只蝴蝶飞进我们家里来，妈妈问“你是梁山伯呀还是祝英台？” 哈哈~ 2020.5.8 哼？ 2020.5.9 我不知道，但是我相信。 2020.5.10 1) 红酥手，黄藤酒，两个黄鹂鸣翠柳。2) 和自己做一个小协议吧。在回学校前呆在家里的这段时间，白天用来工作学习，晚上可以休息、放松。不可以无所谓的放肆了。 2020.5.11 1) 给你一个感官的世界; 2) 本来无一物，何处惹尘埃。 2020.5.12 时常焦虑未来。思考生活着的意义。仍然不懂得生活，不懂得权衡。20多岁的年纪总想着怎么过着舒坦。在真正工作不肯的耐下性子来。想些负面的没用的东西。即使以后遇到了，再去思考也不迟。 2020.5.13 这梦把我累的，各种跑。 2020.5.14 陆游气坏了，找欧阳修。 2020.5.15 “在不值一提的城市长大，从不值一提的中小学毕业。小时候沉默寡言，长大百无聊赖。和一个不值一提的女孩相识，有了不值一提的初恋。十八岁那年上大学来到东京。大学出来后和朋友两人开了一间小小的翻译事务所，好歹混口饭吃。大约三年前染指PR刊物和广告方面的工作，这方面也算进展顺利。同一个在公司工作的女孩相识，四年前结了婚，两个月前离了。原因一言难尽。养一只老公猫。每天吸烟四十支，死活戒不掉。有三套西服六条领带，还有过时唱片五百张。埃勒里·奎因小说里的犯人名字全不记得，普鲁斯特的《追忆逝水流年》也一本不缺，但只读了一半。夏天和啤酒，冬天威士忌。”-《寻羊冒险记》关于“我”的介绍 2020.5.16 其实很多时候，我都很想你，我也知道要见你不难，但我总觉得我要见的你，和我想起的你，并不是一个你 2020.5.17 好久不见 2020.5.18 謝謝你的出現，曾經慌亂的那段時間。 2020.5.19 夜长梦多。 2020.5.20 没人送就用来装点 2020.5.21 This used to be our playground. 2020.5.22 为了你而祈祷 而祝福 而感动 2020.5.23 早上起来去公司画图，回来路上去自选商场采购，一个人在家吃饭。调频广播一直开着不关，看书，写日记，在浴室洗长筒袜。公寓楼在海边上，终日有海涛声传来。冷飕飕的日子。-《寻羊冒险记》关于“她”的介绍；不知为何我很喜欢这样的叙述方式。虽然平淡，但是我觉得的很有味道。让人换位思考，身临其境。 2020.5.24 打了一天的游戏，也快要气死了 2020.5.25 很多人都在帮你，感激 2020.5.26 比赛组会讨论，集思广益的力量，确实比一个人做有意思些 2020.5.27 终于把游戏卸载了 2020.5.28 与你一同度过的时间都很耀眼 因为天气好 因为天气不好 因为天气适当 所有日子都很棒 2020.5.29 冷热无常，各生欢喜 2020.5.30 所有人都祝你快乐 我只愿你遍历山河 觉得人间值得 2020.5.31 完成一篇论文后的第一感受就是: What a piece of shit!  ","description":"","id":68,"section":"posts","tags":["璇璇小朋友和舅舅","立夏","蝴蝶","小协议","街景","焦虑","累人的梦","寻羊冒险记","想念","组会讨论","游戏","懒散","论文"],"title":"2020-5","uri":"https://www.xunhs.cyou/posts/journals/2020-05-01-2020-5/"},{"content":" git 常用命令以及免密push设置。 参考: oschina, todebug\n gitee 生成密钥对 ssh-keygen -t rsa -C \u0026quot;youremail\u0026quot;\n定义名字: id_rsa.gitee\nssh key 将生成的位于~/.ssh/id_rsa.gitee.pub的内容复制到你github setting里的ssh key中\ngit init mkdir gitalk cd gitalk echo \u0026quot;# gitalk\u0026quot; \u0026gt;\u0026gt; README.md git add README.md git commit -m \u0026quot;first commit\u0026quot; remote 如果你还没有克隆你的仓库，那你直接使用ssh协议用法:\ngit remote add origin git@github.com:xunhs/gitalk.git\n如果已经使用https协议克隆了，那么按照如下方法更改协议：\ngit remote set-url origin git@github.com:xunhs/gitalk.git\npush git push -u origin master\ngithub 同上\n创建配置解决ssh冲突 在.ssh文件夹中创建config文件,添加下面内容 1 2 3 4 5 6 7 8 9 10 11  # giteeHost gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa.gitee# githubHost github.comHostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa.github  测试连接  ssh -T git@gitee.com ssh -T git@github.com  gitignore 项目下新建.gitignore文件, 忽略该文件中记录的特定文件或文件夹\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  #以#开头代表注释行 #忽略node_modules文件夹 node_modules/ .deploy*/ #忽略cache.php文件 cache.php db.json *.log #忽略.o,.c文件 *.[oc] #忽略除了index.php外的所以文件 !index.php / 表示目录 *表示匹配多个字符 ?表示匹配单个字符 []匹配字符列 ！忽略文件或目录   ","description":"","id":69,"section":"posts","tags":["git","github","gitee","ssh","jsdelivr","图床"],"title":"git 初始化及常用操作","uri":"https://www.xunhs.cyou/posts/notes/2020-04-29-git-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"content":" Refer: deep_learning_60min_blitz\n Getting Started 1  import torch    PYTORCH CHEAT SHEET PYTORCH TUTORIALS PyTorch 1.4 中文文档  Tensors  Construct a randomly initialized matrix: x = torch.rand(5, 3) Construct a matrix filled zeros and of dtype long: x = torch.zeros(5, 3, dtype=torch.long) Construct a tensor directly from data: x = torch.tensor([5.5, 3]) or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user:  x = x.new_ones(5, 3, dtype=torch.double) x = torch.randn_like(x, dtype=torch.float)   Get its size (shape in numpy/pandas): x.size() [Note: torch.Size is in fact a tuple]  Operations  use standard NumPy-like indexing: x[:, 1] resize/reshape tensor, you can use torch.view:  1 2 3 4  x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # the size -1 is inferred from other dimensions print(x.size(), y.size(), z.size())   NumPy Bridge Torch Tensor \u0026lt;=\u0026gt; a NumPy\n Converting a Torch Tensor to a NumPy Array: tensor.numpy()  1 2  a = torch.ones(5) b = a.numpy()    Converting NumPy Array to Torch Tensor: torch.from_numpy(array)  1 2 3  import numpy as np a = np.ones(5) b = torch.from_numpy(a)   CUDA Tensors 1 2 3 4 5 6 7 8 9  # let us run this cell only if CUDA is available # We will use ``torch.device`` objects to move tensors in and out of GPU if torch.cuda.is_available(): device = torch.device(\u0026#34;cuda\u0026#34;) # a CUDA device object y = torch.ones_like(x, device=device) # directly create a tensor on GPU x = x.to(device) # or just use strings ``.to(\u0026#34;cuda\u0026#34;)`` z = x + y print(z) print(z.to(\u0026#34;cpu\u0026#34;, torch.double)) # ``.to`` can also change dtype together!   AUTOGRAD: AUTOMATIC DIFFERENTIATION To prevent tracking history (and using memory), you can also wrap the code block in with torch.no_grad(). This can be particularly helpful when evaluating a model because the model may have trainable parameters with requires_grad=True, but for which we don’t need the gradients.\nNEURAL NETWORKS Neural networks can be constructed using the torch.nn package.\nNow that you had a glimpse of autograd, nn depends on autograd to define models and differentiate them. An nn.Module contains layers, and a method forward(input)that returns the output.\nA typical training procedure for a neural network is as follows:\n Define the neural network that has some learnable parameters (or weights) Iterate over a dataset of inputs Process input through the network Compute the loss (how far is the output from being correct) Propagate gradients back into the network’s parameters Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient  Define the network 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 3x3 square convolution # kernel self.conv1 = nn.Conv2d(1, 6, 3) self.conv2 = nn.Conv2d(6, 16, 3) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6*6 from image dimension self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) \u0026#39;\u0026#39;\u0026#39; Out: Net( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=576, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u0026#39;\u0026#39;\u0026#39;    You just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function. The learnable parameters of a model are returned by net.parameters():  1 2 3 4 5 6 7  params = list(net.parameters()) print(len(params)) # 哪十层的参数呢？ print(params[0].size()) # conv1\u0026#39;s .weight \u0026#39;\u0026#39;\u0026#39; 10: torch.Size([6]) \u0026#39;\u0026#39;\u0026#39;   Note: 十层参数(-\u0026gt;): input -\u0026gt; conv2d -\u0026gt; relu -\u0026gt; conv2d -\u0026gt; relu -\u0026gt; view -\u0026gt; linear -\u0026gt; relu -\u0026gt; linear -\u0026gt; relu -\u0026gt; linear\n try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. To use this net on the MNIST dataset, please resize the images from the dataset to 32x32.  1 2 3  input = torch.randn(1, 1, 32, 32) out = net(input) print(out)    Zero the gradient buffers of all parameters and backprops with random gradients:  1 2  net.zero_grad() out.backward(torch.randn(1, 10))   Loss Function A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\nThere are several different loss functions under the nn package. A simple loss is: nn.MSELoss which computes the mean-squared error between the input and the target.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  input = torch.randn(1, 1, 32, 32) output = net(input) target = torch.randn(10) # a dummy target, for example target = target.view(1, -1) # make it the same shape as output criterion = nn.MSELoss() loss = criterion(output, target) print(loss) \u0026#39;\u0026#39;\u0026#39; out: tensor(0.9145, grad_fn=\u0026lt;MseLossBackward\u0026gt;) \u0026#39;\u0026#39;\u0026#39;   Backprop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  net.zero_grad() # zeroes the gradient buffers of all parameters print(\u0026#39;conv1.bias.grad before backward\u0026#39;) print(net.conv1.bias.grad) loss.backward() print(\u0026#39;conv1.bias.grad after backward\u0026#39;) print(net.conv1.bias.grad) \u0026#39;\u0026#39;\u0026#39; out: conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 1.2122e-03, -9.3038e-04, -3.8394e-04, 2.5266e-03, -1.4529e-03, 9.5785e-05]) \u0026#39;\u0026#39;\u0026#39;   Update the weights The simplest update rule used in practice is the Stochastic Gradient Descent (SGD): weight = weight - learning_rate * gradient\nAs you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: torch.optim that implements all these methods. Using it is very simple:\n1 2 3 4 5 6 7 8 9  import torch.optim as optim # create your optimizer optimizer = optim.SGD(net.parameters(), lr=0.01) # in your training loop: optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # Does the update   TRAINING A CLASSIFIER What about data? Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a torch.*Tensor.\n For images, packages such as Pillow, OpenCV are useful For audio, packages such as scipy and librosa For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful  For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\nTraining an image classifier We will do the following steps in order:\n Load and normalizing the CIFAR10 training and test datasets using torchvision Define a Convolutional Neural Network  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net()   Define a loss function  1 2 3  import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)   Train the network on the training data  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  for epoch in range(10): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(\u0026#39;[%d, %5d] loss: %.3f\u0026#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(\u0026#39;Finished Training\u0026#39;) \u0026#39;\u0026#39;\u0026#39; out: [1, 2000] loss: 2.151 [1, 4000] loss: 1.804 [1, 6000] loss: 1.634 [1, 8000] loss: 1.591 [1, 10000] loss: 1.499 [1, 12000] loss: 1.469 [2, 2000] loss: 1.389 [2, 4000] loss: 1.378 [2, 6000] loss: 1.362 [2, 8000] loss: 1.307 [2, 10000] loss: 1.302 [2, 12000] loss: 1.272 Finished Training \u0026#39;\u0026#39;\u0026#39;    save model:  1 2  PATH = \u0026#39;./cifar_net.pth\u0026#39; torch.save(net.state_dict(), PATH)    load model:  1 2  the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH))   Test the network on the test data   simple test:  1 2 3 4 5 6 7 8 9  dataiter = iter(testloader) images, labels = dataiter.next() # 4 images, (4,3,32,32) outputs = net(images) # outputs: (4, 10) _, predicted = torch.max(outputs, 1) print(\u0026#39;Predicted: \u0026#39;, \u0026#39; \u0026#39;.join(\u0026#39;%5s\u0026#39; % classes[predicted[j]] for j in range(4))) \u0026#39;\u0026#39;\u0026#39; Predicted: cat ship ship plane \u0026#39;\u0026#39;\u0026#39;   Note:\ntorch.max(input, dim, keepdim=False, out=None) -\u0026gt; (Tensor, LongTensor)\n按维度dim 返回最大值, 且返回索引. dim:(0: 列，1: 行)\n performs on the whole dataset:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(\u0026#39;Accuracy of the network on the 10000 test images: %d%%\u0026#39; % ( 100 * correct / total)) \u0026#39;\u0026#39;\u0026#39; Accuracy of the network on the 10000 test images: 55 % \u0026#39;\u0026#39;\u0026#39;    Hmmm, what are the classes that performed well, and the classes that did not perform well  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(\u0026#39;Accuracy of %5s: %2d%%\u0026#39; % ( classes[i], 100 * class_correct[i] / class_total[i])) \u0026#39;\u0026#39;\u0026#39; Accuracy of plane : 55 % Accuracy of car : 63 % Accuracy of bird : 25 % Accuracy of cat : 45 % Accuracy of deer : 41 % Accuracy of dog : 52 % Accuracy of frog : 66 % Accuracy of horse : 63 % Accuracy of ship : 72 % Accuracy of truck : 70 % \u0026#39;\u0026#39;\u0026#39;   Training on GPU 1 2 3 4 5 6 7 8 9 10  device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # Assuming that we are on a CUDA machine, this should print a CUDA device: print(device) \u0026#39;\u0026#39;\u0026#39; cuda:0 \u0026#39;\u0026#39;\u0026#39; # convert their parameters and buffers to CUDA tensors net.to(device) # send the inputs and targets at every step to the GPU too: inputs, labels = data[0].to(device), data[1].to(device)   Learning PyTorch with Examples two-layer network(torch.nn.Sequential) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  # -*- coding: utf-8 -*- import torch # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Use the nn package to define our model and loss function. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) loss_fn = torch.nn.MSELoss(reduction=\u0026#39;sum\u0026#39;) # Use the optim package to define an Optimizer that will update the weights of # the model for us. Here we will use Adam; the optim package contains many other # optimization algoriths. The first argument to the Adam constructor tells the # optimizer which Tensors it should update. learning_rate = 1e-4 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) for t in range(500): # Forward pass: compute predicted y by passing x to the model. y_pred = model(x) # Compute and print loss. loss = loss_fn(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Before the backward pass, use the optimizer object to zero all of the # gradients for the variables it will update (which are the learnable # weights of the model). This is because by default, gradients are # accumulated in buffers( i.e, not overwritten) whenever .backward() # is called. Checkout docs of torch.autograd.backward for more details. optimizer.zero_grad() # Backward pass: compute gradient of the loss with respect to model # parameters loss.backward() # Calling the step function on an Optimizer makes an update to its # parameters optimizer.step()   Custom nn Modules Sometimes you will want to specify models that are more complex than a sequence of existing Modules; for these cases you can define your own Modules by subclassing nn.Module and defining a forward which receives input Tensors and produces output Tensors using other modules or other autograd operations on Tensors.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  # -*- coding: utf-8 -*- import torch class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \u0026#34;\u0026#34;\u0026#34; In the constructor we instantiate two nn.Linear modules and assign them as member variables. \u0026#34;\u0026#34;\u0026#34; super(TwoLayerNet, self).__init__() self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, x): \u0026#34;\u0026#34;\u0026#34; In the forward function we accept a Tensor of input data and we must return a Tensor of output data. We can use Modules defined in the constructor as well as arbitrary operators on Tensors. \u0026#34;\u0026#34;\u0026#34; h_relu = self.linear1(x).clamp(min=0) y_pred = self.linear2(h_relu) return y_pred # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Construct our model by instantiating the class defined above model = TwoLayerNet(D_in, H, D_out) # Construct our loss function and an Optimizer. The call to model.parameters() # in the SGD constructor will contain the learnable parameters of the two # nn.Linear modules which are members of the model. criterion = torch.nn.MSELoss(reduction=\u0026#39;sum\u0026#39;) optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step()   Visualizing Models, Data, and Training with TensorBoard https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html#tracking-model-training-with-tensorboard\nPretained models torchvision.models 参考:\n torchvision.models pytorch中的pre-train函数模型引用及修改 Pytorch：利用预训练好的VGG16网络提取图片特征  pretrainedmodels 参考:\n pretrained-models.pytorch  Other tricks 清除GPU存储 参考:知乎\n有时Control-C中止运行后GPU存储没有及时释放，需要手动清空。在PyTorch内部可以torch.cuda.empty_cache(), 或在命令行可以先使用ps找到程序的PID，再使用kill结束该进程:\n1 2  ps aux | grep python kill -9 [pid]   或者直接重置没有被清空的GPUnvidia-smi --gpu-reset -i [gpu_id]\n常用训练和验证数据预处理 其中ToTensor操作会将PIL.Image或形状为H×W×D，数值范围为[0, 255]的np.ndarray转换为形状为D×H×W，数值范围为[0.0, 1.0]的torch.Tensor。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  train_transform = torchvision.transforms.Compose([ torchvision.transforms.RandomResizedCrop(size=224, scale=(0.08, 1.0)), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), ]) val_transform = torchvision.transforms.Compose([ torchvision.transforms.Resize(256), torchvision.transforms.CenterCrop(224), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), ])   pytorch-lighting hello world-mnist A more complete MNIST Lightning Module Example\n prepare_data() 💾  ​ - This is where we can download the dataset. We point to our desired dataset and ask torchvision\u0026rsquo;s MNIST dataset class to download if the dataset isn\u0026rsquo;t found there.\nsetup(stage) ⚙️  ​ - Loads in data from file and prepares PyTorch tensor datasets for each split (train, val, test).\n​ - Setup expects a \u0026lsquo;stage\u0026rsquo; arg which is used to separate logic for \u0026lsquo;fit\u0026rsquo; and \u0026lsquo;test\u0026rsquo;.\n​ - If you don\u0026rsquo;t mind loading all your datasets at once, you can set up a condition to allow for both \u0026lsquo;fit\u0026rsquo; related setup and \u0026lsquo;test\u0026rsquo; related setup to run whenever None is passed to stage (or ignore it altogether and exclude any conditionals).\nx_dataloader() ♻️  ​ - train_dataloader(), val_dataloader(), and test_dataloader() all return PyTorch DataLoader instances that are created by wrapping their respective datasets that we prepared in setup()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99  import os import torch from torch import nn from torch.nn import functional as F from torch.utils.data import DataLoader, random_split from torchvision.datasets import MNIST from torchvision import transforms import pytorch_lightning as pl from pytorch_lightning.metrics.functional import accuracy class LitMNIST(pl.LightningModule): def __init__(self, data_dir=\u0026#39;./\u0026#39;, hidden_size=64, learning_rate=2e-4): super().__init__() # Set our init args as class attributes self.data_dir = data_dir self.hidden_size = hidden_size self.learning_rate = learning_rate # Hardcode some dataset specific attributes self.num_classes = 10 self.dims = (1, 28, 28) channels, width, height = self.dims self.transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) # Define PyTorch model self.model = nn.Sequential( nn.Flatten(), nn.Linear(channels * width * height, hidden_size), nn.ReLU(), nn.Dropout(0.1), nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Dropout(0.1), nn.Linear(hidden_size, self.num_classes) ) def forward(self, x): x = self.model(x) return F.log_softmax(x, dim=1) def training_step(self, batch, batch_idx): x, y = batch logits = self(x) loss = F.nll_loss(logits, y) return loss def validation_step(self, batch, batch_idx): x, y = batch logits = self(x) loss = F.nll_loss(logits, y) preds = torch.argmax(logits, dim=1) acc = accuracy(preds, y) # Calling self.log will surface up scalars for you in TensorBoard self.log(\u0026#39;val_loss\u0026#39;, loss, prog_bar=True) self.log(\u0026#39;val_acc\u0026#39;, acc, prog_bar=True) return loss def test_step(self, batch, batch_idx): # Here we just reuse the validation_step for testing return self.validation_step(batch, batch_idx) def configure_optimizers(self): optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate) return optimizer #################### # DATA RELATED HOOKS #################### def prepare_data(self): # download MNIST(self.data_dir, train=True, download=True) MNIST(self.data_dir, train=False, download=True) def setup(self, stage=None): # Assign train/val datasets for use in dataloaders if stage == \u0026#39;fit\u0026#39; or stage is None: mnist_full = MNIST(self.data_dir, train=True, transform=self.transform) self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000]) # Assign test dataset for use in dataloader(s) if stage == \u0026#39;test\u0026#39; or stage is None: self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform) def train_dataloader(self): return DataLoader(self.mnist_train, batch_size=32) def val_dataloader(self): return DataLoader(self.mnist_val, batch_size=32) def test_dataloader(self): return DataLoader(self.mnist_test, batch_size=32)   ","description":"","id":70,"section":"posts","tags":["深度学习","PyTorch","Python","神经网络","预训练模型"],"title":"PyTroch学习笔记","uri":"https://www.xunhs.cyou/posts/notes/328/"},{"content":" Collecting some interesting and frequently used containers on Docker\n UnblockNeteaseMusic  通过代理的方式收听网易云音乐灰色无版权歌曲。 Refer: sources; 博客。 我用的docker的方式部署的，端口可以更改。  docker run -d --name unblockneteasemusic -p 12315:8080 nondanee/unblockneteasemusic Kepler.gl docker docker run –name kepler.gl -p 10087:80 -e MapboxAccessToken=\u0026ldquo;pk.eyJ1IjoidHJvcGljYWxocyIsImEiOiJjazZrZDJlMHgwMnZhM21wYW9oNWl4eGxoIn0.w_nfPS4RC5ERPpMMutwgLg\u0026rdquo; –restart always -d crazycapivara/kepler.gl\n2021.2.19\n为了保持kepler.gl保持最新版本，可使用docker build构建容器，然后拉取。参考：https://github.com/xunhs/docker-kepler.gl。\n另外，在这个仓库里面：1）添加apk和npm源，加速构建；2）默认将Mapbox的token加入build的环境变量中\n在线音乐搜索/播放器 Refer: https://github.com/oldiy/music-player\ndocker run -d --name online-music-player -p 264:264 -v \u0026lt;本机缓存目录\u0026gt;:/var/www/html/cache oldiy/music-player-docker CCAA（Aria2一键部署）  Linux一键安装Aria2 + AriaNg + FileBrowse实现离线下载、文件管理。 Refer: sources; 博客  OneindexMoe(docker一件安装) Refer: sources\n折腾了好久olaindex终于安装上了，晚上刷分享遇到这个docker一件安装成功了。\ndocker run -d --name oneindex -p 12316:80 --restart=always baiyuetribe/oneindex  2020.10.18 fast.io免费服务已终止 如果没有服务器部署，另外推荐一个在线网盘index工具-Fast.io，免费静态空间/目录浏览，支持OneDrive/Google Drive/Github，可以做文件外链，还不错  Elasticsearch  init\n创建三个文件夹config, data, plugins; 在文件夹config下创建elasticsearch.yml文件，并写入http.host: \u0026amp;#039;0.0.0.0\u0026amp;#039; 部署elasticsearch\n参考这个查看新版本\ndocker run -p 9200:9200 -p 9300:9300 --name elasticsearch \\   -e \u0026ldquo;discovery.type=single-node\u0026rdquo;\n-v /mnt/d/Docker/poi-elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml\n-v /mnt/d/Docker/poi-elasticsearch/data:/usr/share/elasticsearch/data\n-v /mnt/d/Docker/poi-elasticsearch/plugins:/usr/share/elasticsearch/plugins\n-d elasticsearch:7.8.0\n kibana\n参考这个查看新版本\ndocker run --name kibana -d \\   \u0026ndash;link e5ecbda26718:elasticsearch\n-p 5601:5601 kibana:7.8.0\ne5ecbda26718是elasticsearch的docker id  Docker Ubuntu Python基础环境配置   ubuntu18\ndocker run -it --name ubuntu_base ubuntu:18.04 /bin/bash\n(option)\ndocker exec -it ubuntu_base bash\n  换源:huawei mirror\nsed -i \u0026ldquo;s@http://.*archive.ubuntu.com@http://repo.huaweicloud.com@g\u0026rdquo; /etc/apt/sources.list \u0026amp;\u0026amp; sed -i \u0026ldquo;s@http://.*security.ubuntu.com@http://repo.huaweicloud.com@g\u0026rdquo; /etc/apt/sources.list \u0026amp;\u0026amp; apt-get update\n  开启ssh\n 安装ssh-server服务： sudo apt-get install openssh-server 确认ssh-server是否启动: ps -e | grep ssh =\u0026gt; sshd 修改配置文件: ssh-server配置文件位于/etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号，如222。（或把配置文件中的”PermitRootLogin without-password”加一个”#”号,把它注释掉，再增加一句”PermitRootLogin yes”）然后重启SSH服务：sudo /etc/init.d/ssh restart    基础包,参考: github\napt-get install -y software-properties-common\napt-get install -y build-essential python3.6 python3-pip\napt-get install -y git nano\n  python2.7(option): apt-get install -y python2.7 python-pip   pip换源\nPip的配置文件为用户根目录下的：~/.pip/pip.conf（Windows路径为：C:\\Users\u0026lt;UserName\u0026gt;\\pip\\pip.ini）, 您可以配置如下内容：\n[global]\nindex-url = https://repo.huaweicloud.com/repository/pypi/simple\ntrusted-host = repo.huaweicloud.com\ntimeout = 120\n  update pip\npython3.6 -m pip install pip \u0026ndash;upgrade\npython3.6 -m pip install wheel\n  commit=\u0026gt; images: docker commit CONTAINER_ID ubuntu_py:tag\n  docker 常用命令  运行容器: docker run -itd --name ubuntu_base ubuntu:18.04 /bin/bash 交互终端: docker exec -it ubuntu_base bash container重命名: docker rename CONTAINER_ID new_name 容器载入或导出:  查看容器: docker ps -a commit容器提交修改=\u0026gt;images：docker commit fbe3 xunhs/ml-workspace-gpu:0.12.1(docker commit container_id tag) 导出：docker save de9821e5a5a1 -o ./ml-workspace-gpu.tar 查看镜像：docker images 删除镜像：docker rmi de9821e5a5a1 载入：docker load -i ml-workspace-gpu.tar   开启自启动: --restart always  ","description":"","id":71,"section":"posts","tags":["Docker"],"title":"关于Docker的一些收藏","uri":"https://www.xunhs.cyou/2020/04/17/78/"},{"content":" Refer to scikit-learn-tips, Scikit-learn 0.22新版本发布。\n整理一些自己感兴趣，经常用到的\n 特征工程 归一化/标准化/正则化 参考: cnblogs\nStandardScaler Z-Score，或者去除均值和方差缩放\n1 2 3 4 5 6 7 8 9 10 11 12 13  from sklearn import preprocessing import numpy as np x = np.array([[1.,-1.,2.], [2.,0.,0.], [0.,1.,-1.]]) # 使用sklearn.preprocessing.StandardScaler类， # 使用该类的好处在于可以保存训练集中的参数（均值、方差） # 直接使用其对象转换测试集数据。 scaler = preprocessing.StandardScaler().fit(x) scaler.mean_ scaler.std_ scaler.transform(x) #跟上面的结果是一样的   MinMaxScaler 将属性缩放到一个指定范围,也是就是(x-min)/(max-min)\n1 2 3 4 5 6 7 8 9 10 11  x_train = np.array([[1.,-1.,2.], [2.,0.,0.], [0.,1.,-1.]]) min_max_scaler = preprocessing.MinMaxScaler() x_train_minmax = min_max_scaler.fit_transform(x_train) print(x_train_minmax) # 当然，在构造类对象的时候也可以直接指定最大最小值的范围： # feature_range = (min, max)，此时应用的公式变为： # x_std = (X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0)) # x_scaled = X_std/(max-min)+min   Normalization 1 2 3 4  # 可以使用processing.Normalizer()类实现对训练集和测试集的拟合和转换 normalizer = preprocessing.Normalizer().fit(x) print(normalizer) normalizer.transform(x)   ColumnTransformer-make_column_transformer/行处理 Use ColumnTransformer to apply different preprocessing to different columns:\n select from DataFrame columns by name passthrough(保留) or drop(丢掉) unspecified columns 引申：sklearn.preprocessing(TODO): 官网，cnblogs sklearn.impute.SimpleImputer: 填补缺失值, 参考官网, zhihu  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;, nrows=6) cols = [\u0026#39;Fare\u0026#39;, \u0026#39;Embarked\u0026#39;, \u0026#39;Sex\u0026#39;, \u0026#39;Age\u0026#39;] X = df[cols] from sklearn.preprocessing import OneHotEncoder from sklearn.impute import SimpleImputer from sklearn.compose import make_column_transformer ohe = OneHotEncoder() imp = SimpleImputer() ct = make_column_transformer( (ohe, [\u0026#39;Embarked\u0026#39;, \u0026#39;Sex\u0026#39;]), # apply OneHotEncoder to Embarked and Sex (imp, [\u0026#39;Age\u0026#39;]), # apply SimpleImputer to Age remainder=\u0026#39;passthrough\u0026#39;) # include remaining column (Fare) in the output # column order: Embarked (3 columns), Sex (2 columns), Age (1 column), Fare (1 column) ct.fit_transform(X) \u0026#39;\u0026#39;\u0026#39; output: array([[ 0. , 0. , 1. , 0. , 1. , 22. , 7.25 ], [ 1. , 0. , 0. , 1. , 0. , 38. , 71.2833], [ 0. , 0. , 1. , 1. , 0. , 26. , 7.925 ], [ 0. , 0. , 1. , 1. , 0. , 35. , 53.1 ], [ 0. , 0. , 1. , 0. , 1. , 35. , 8.05 ], [ 0. , 1. , 0. , 0. , 1. , 31.2 , 8.4583]]) \u0026#39;\u0026#39;\u0026#39;   ColumnTransformer-行选择 There are SEVEN ways to select columns using ColumnTransformer:\n column name integer position slice boolean mask regex pattern dtypes to include dtypes to exclude  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;, nrows=6) cols = [\u0026#39;Fare\u0026#39;, \u0026#39;Embarked\u0026#39;, \u0026#39;Sex\u0026#39;, \u0026#39;Age\u0026#39;] X = df[cols] from sklearn.preprocessing import OneHotEncoder from sklearn.compose import make_column_transformer # new in 0.20 from sklearn.compose import make_column_selector # new in 0.22 # all SEVEN of these produce the same results ct = make_column_transformer((ohe, [\u0026#39;Embarked\u0026#39;, \u0026#39;Sex\u0026#39;])) ct = make_column_transformer((ohe, [1, 2])) ct = make_column_transformer((ohe, slice(1, 3))) ct = make_column_transformer((ohe, [False, True, True, False])) ct = make_column_transformer((ohe, make_column_selector(pattern=\u0026#39;E|S\u0026#39;))) ct = make_column_transformer((ohe, make_column_selector(dtype_include=object))) ct = make_column_transformer((ohe, make_column_selector(dtype_exclude=\u0026#39;number\u0026#39;))) ct.fit_transform(X)   pipeline Chains together multiple steps: output of each step is used as input to the next step. Makes it easy to apply the same preprocessing to train and test!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  import pandas as pd import numpy as np train = pd.DataFrame({\u0026#39;feat1\u0026#39;:[10, 20, np.nan, 2], \u0026#39;feat2\u0026#39;:[25., 20, 5, 3], \u0026#39;label\u0026#39;:[\u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;B\u0026#39;]}) test = pd.DataFrame({\u0026#39;feat1\u0026#39;:[30., 5, 15], \u0026#39;feat2\u0026#39;:[12, 10, np.nan]}) from sklearn.impute import SimpleImputer from sklearn.linear_model import LogisticRegression from sklearn.pipeline import make_pipeline imputer = SimpleImputer() clf = LogisticRegression() # 2-step pipeline: impute missing values, then pass the results to the classifier pipe = make_pipeline(imputer, clf) features = [\u0026#39;feat1\u0026#39;, \u0026#39;feat2\u0026#39;] X, y = train[features], train[\u0026#39;label\u0026#39;] X_new = test[features] # pipeline applies the imputer to X before fitting the classifier pipe.fit(X, y) # pipeline applies the imputer to X_new before making predictions # note: pipeline uses imputation values learned during the \u0026#34;fit\u0026#34; step pipe.predict(X_new)   缺失值处理 标记缺失数值并将此标记作为新的特征 Add a missing indicator to encode \u0026ldquo;missingness\u0026rdquo; as a feature(在处理缺失数据的时候，标记缺失数值并将此标记作为新的特征)\nWhen imputing missing values, you can preserve info about which values were missing and use THAT as a feature!Why? Sometimes there\u0026rsquo;s a relationship between \u0026ldquo;missingness\u0026rdquo; and the target/label you are trying to predict.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import pandas as pd import numpy as np from sklearn.impute import SimpleImputer X = pd.DataFrame({\u0026#39;Age\u0026#39;:[20, 30, 10, np.nan, 10]}) # impute the mean imputer = SimpleImputer() imputer.fit_transform(X) \u0026#39;\u0026#39;\u0026#39; output: array([[20. , 0. ], [30. , 0. ], [10. , 0. ], [17.5, 1. ], [10. , 0. ]]) \u0026#39;\u0026#39;\u0026#39;   KNNImputer / IterativeImpute: Need something better than SimpleImputer for missing value imputation?\nTry KNNImputer or IterativeImputer (inspired by R\u0026rsquo;s MICE package). Both are multivariate approaches (they take other features into account!)\n另参考：csdn\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;, nrows=6) cols = [\u0026#39;SibSp\u0026#39;, \u0026#39;Fare\u0026#39;, \u0026#39;Age\u0026#39;] X = df[cols] # new in 0.21, and still \u0026#34;experimental\u0026#34; so it must be enabled explicitly from sklearn.experimental import enable_iterative_imputer from sklearn.impute import IterativeImputer impute_it = IterativeImputer() impute_it.fit_transform(X) \u0026#39;\u0026#39;\u0026#39; output: array([[ 1. , 7.25 , 22. ], [ 1. , 71.2833 , 38. ], [ 0. , 7.925 , 26. ], [ 1. , 53.1 , 35. ], [ 0. , 8.05 , 35. ], [ 0. , 8.4583 , 28.50639495]]) \u0026#39;\u0026#39;\u0026#39; # new in 0.22 from sklearn.impute import KNNImputer impute_knn = KNNImputer(n_neighbors=2) impute_knn.fit_transform(X) \u0026#39;\u0026#39;\u0026#39; output: array([[ 1. , 7.25 , 22. ], [ 1. , 71.2833, 38. ], [ 0. , 7.925 , 26. ], [ 1. , 53.1 , 35. ], [ 0. , 8.05 , 35. ], [ 0. , 8.4583, 30.5 ]]) \u0026#39;\u0026#39;\u0026#39;   训练 random_state: Set a \u0026ldquo;random_state\u0026rdquo; to make your code reproducible\nEnsures that a \u0026ldquo;random\u0026rdquo; process will output the same results every time, which makes your code reproducible (by you and others!)\n1 2 3 4  from sklearn.model_selection import train_test_split # any positive integer can be used for the random_state value X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)   划分三类：train, test, val 1 2 3 4 5 6 7 8 9 10 11 12 13 14  train_ratio = 0.75 validation_ratio = 0.15 test_ratio = 0.10 # train is now 75% of the entire data set # the _junk suffix means that we drop that variable completely x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio) # test is now 10% of the initial data set # validation is now 15% of the initial data set x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) print(x_train, x_val, x_test)   cross-validate and grid search (交叉验证，网格搜索): You can cross-validate and grid search an entire pipeline!\nPreprocessing steps will automatically occur AFTER each cross-validation split, which is critical if you want meaningful scores.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;) cols = [\u0026#39;Sex\u0026#39;, \u0026#39;Name\u0026#39;] X = df[cols] y = df[\u0026#39;Survived\u0026#39;] from sklearn.preprocessing import OneHotEncoder from sklearn.feature_extraction.text import CountVectorizer from sklearn.compose import make_column_transformer ohe = OneHotEncoder() vect = CountVectorizer() ct = make_column_transformer((ohe, [\u0026#39;Sex\u0026#39;]), (vect, \u0026#39;Name\u0026#39;)) from sklearn.linear_model import LogisticRegression clf = LogisticRegression(solver=\u0026#39;liblinear\u0026#39;, random_state=1) from sklearn.pipeline import make_pipeline pipe = make_pipeline(ct, clf) # Cross-validate the entire pipeline (not just the model) from sklearn.model_selection import cross_val_score cross_val_score(pipe, X, y, cv=5, scoring=\u0026#39;accuracy\u0026#39;).mean() \u0026#39;\u0026#39;\u0026#39; output: 0.8024543343167408 \u0026#39;\u0026#39;\u0026#39; # Find optimal tuning parameters for the entire pipeline # specify parameter values to search params = {} params[\u0026#39;columntransformer__countvectorizer__min_df\u0026#39;] = [1, 2] params[\u0026#39;logisticregression__C\u0026#39;] = [0.1, 1, 10] params[\u0026#39;logisticregression__penalty\u0026#39;] = [\u0026#39;l1\u0026#39;, \u0026#39;l2\u0026#39;] # try all possible combinations of those parameter values from sklearn.model_selection import GridSearchCV grid = GridSearchCV(pipe, params, cv=5, scoring=\u0026#39;accuracy\u0026#39;) grid.fit(X, y) # what was the best score found during the search? grid.best_score_ # which combination of parameters produced the best score? grid.best_params_   RandomizedSearchCV (随机化网格搜索) GridSearchCV taking too long? Try RandomizedSearchCV with a small number of iterations.\nMake sure to specify a distribution (instead of a list of values) for continuous parameters!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;) X = df[\u0026#39;Name\u0026#39;] y = df[\u0026#39;Survived\u0026#39;] from sklearn.feature_extraction.text import CountVectorizer from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import make_pipeline pipe = make_pipeline(CountVectorizer(), MultinomialNB()) # cross-validate the pipeline using default parameters from sklearn.model_selection import cross_val_score cross_val_score(pipe, X, y, cv=5, scoring=\u0026#39;accuracy\u0026#39;).mean() # specify parameter values to search (use a distribution for any continuous parameters) import scipy as sp params = {} params[\u0026#39;countvectorizer__min_df\u0026#39;] = [1, 2, 3, 4] params[\u0026#39;countvectorizer__lowercase\u0026#39;] = [True, False] params[\u0026#39;multinomialnb__alpha\u0026#39;] = sp.stats.uniform(scale=1) # try \u0026#34;n_iter\u0026#34; random combinations of those parameter values from sklearn.model_selection import RandomizedSearchCV rand = RandomizedSearchCV(pipe, params, n_iter=10, cv=5, scoring=\u0026#39;accuracy\u0026#39;, random_state=1) rand.fit(X, y); # what was the best score found during the search? rand.best_score_ # which combination of parameters produced the best score? rand.best_params_   网格化搜索结果输出 Hyperparameter search results (from GridSearchCV or RandomizedSearchCV) can be converted into a pandas DataFrame.\nMakes it far easier to explore the results!\n1 2 3 4 5 6 7 8  from sklearn.model_selection import GridSearchCV grid = GridSearchCV(pipe, params, cv=5, scoring=\u0026#39;accuracy\u0026#39;) grid.fit(X, y) # convert results into a DataFrame results = pd.DataFrame(grid.cv_results_)[[\u0026#39;params\u0026#39;, \u0026#39;mean_test_score\u0026#39;, \u0026#39;rank_test_score\u0026#39;]] # sort by test score results.sort_values(\u0026#39;rank_test_score\u0026#39;)   fit \u0026amp; transform the difference between \u0026ldquo;fit\u0026rdquo; and \u0026ldquo;transform\u0026rdquo;\n \u0026ldquo;fit\u0026rdquo;: transformer learns something about the data \u0026ldquo;transform\u0026rdquo;: it uses what it learned to do the data transformation  模型: 套用简单模型。尤其对于高维稀疏数据的regression问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  from sklearn.model_selection import StratifiedKFold from sklearn.model_selection import cross_val_score from sklearn.linear_model import Ridge from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.discriminant_analysis import LinearDiscriminantAnalysis from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC from sklearn.ensemble import AdaBoostClassifier from sklearn.ensemble import GradientBoostingClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import ExtraTreesClassifier models = [ (\u0026#39;LR\u0026#39; , LogisticRegression()), (\u0026#39;LDA\u0026#39; , LinearDiscriminantAnalysis()), (\u0026#39;KNN\u0026#39; , KNeighborsClassifier()), (\u0026#39;CART\u0026#39; , DecisionTreeClassifier()), (\u0026#39;NB\u0026#39; , GaussianNB()), (\u0026#39;SVM\u0026#39; , SVC(probability=True)), (\u0026#39;AB\u0026#39; , AdaBoostClassifier()), (\u0026#39;GBM\u0026#39; , GradientBoostingClassifier()), (\u0026#39;RF\u0026#39; , RandomForestClassifier()), (\u0026#39;ET\u0026#39; , ExtraTreesClassifier()) ] def run_models(x, y, models): num_folds = 10 scoring = \u0026#39;accuracy\u0026#39; results = [] names = [] for name, model in models: kfold = StratifiedKFold(n_splits=num_folds, random_state=123) cv_results = cross_val_score(model, x, y, cv=kfold, scoring=scoring) results.append(cv_results) names.append(name) msg = \u0026#34;%s: %f(%f)\u0026#34; % (name, cv_results.mean(), cv_results.std()) print(msg) return names, results names, results = run_models(X, Y, models) \u0026#34;\u0026#34;\u0026#34; 得到的结果: LR: 0.803470 (0.009425) LDA: 0.797354 (0.011074) KNN: 0.772755 (0.013865) CART: 0.719289 (0.018143) NB: 0.694681 (0.019061) SVM: 0.798207 (0.010633) AB: 0.805602 (0.010468) GBM: 0.804893 (0.013025) RF: 0.781855 (0.010472) ET: 0.769192 (0.016778) \u0026#34;\u0026#34;\u0026#34;   模型融合(ensemble) 参考：A Complete ML Pipeline Tutorial (ACU ~ 86%) | Kaggle\nvoting 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  from sklearn.ensemble import VotingClassifier \u0026#34;\u0026#34;\u0026#34; Ensemble from the best models. Basic Voting. \u0026#34;\u0026#34;\u0026#34; param = {\u0026#39;C\u0026#39;: 0.01, \u0026#39;penalty\u0026#39;: \u0026#39;l2\u0026#39;} model1 = LogisticRegression(**param) param = {\u0026#39;learning_rate\u0026#39;: 0.1, \u0026#39;n_estimators\u0026#39;: 170} model2 = AdaBoostClassifier(**param) param = {\u0026#39;learning_rate\u0026#39;: 0.1, \u0026#39;n_estimators\u0026#39;: 70} model3 = GradientBoostingClassifier(**param) estimators = [(\u0026#39;LR\u0026#39;, model1), (\u0026#39;AB\u0026#39;, model2), (\u0026#39;GB\u0026#39;, model3)] kfold = StratifiedKFold(n_splits=10, random_state=123) ensemble = VotingClassifier(estimators) results = cross_val_score(ensemble, X, Y, cv=kfold, scoring=\u0026#39;accuracy\u0026#39;) results.mean()   stacking StackingClassifier 和 StackingRegressor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  from sklearn.datasets import load_iris from sklearn.svm import LinearSVC from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import StandardScaler from sklearn.pipeline import make_pipeline from sklearn.ensemble import StackingClassifier from sklearn.model_selection import train_test_split X, y = load_iris(return_X_y=True) estimators = [ (\u0026#39;rf\u0026#39;, RandomForestClassifier(n_estimators=10, random_state=42)), (\u0026#39;svr\u0026#39;, make_pipeline(StandardScaler(), LinearSVC(random_state=42))) ] clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression() ) X_train, X_test, y_train, y_test = train_test_split( X, y, stratify=y, random_state=42 ) clf.fit(X_train, y_train).score(X_test, y_test)   mlens 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  \u0026#34;\u0026#34;\u0026#34; Stacking Model using lib: mlens. \u0026#34;\u0026#34;\u0026#34; def get_models(): \u0026#34;\u0026#34;\u0026#34;Generate a library of base learners.\u0026#34;\u0026#34;\u0026#34; param = {\u0026#39;C\u0026#39;: 0.01, \u0026#39;penalty\u0026#39;: \u0026#39;l2\u0026#39;} model1 = LogisticRegression(**param) param = {\u0026#39;learning_rate\u0026#39;: 0.1, \u0026#39;n_estimators\u0026#39;: 170} model2 = AdaBoostClassifier(**param) param = {\u0026#39;learning_rate\u0026#39;: 0.1, \u0026#39;n_estimators\u0026#39;: 70} model3 = GradientBoostingClassifier(**param) param = {\u0026#39;n_neighbors\u0026#39;: 23} model4 = KNeighborsClassifier(**param) param = {\u0026#39;C\u0026#39;: 1.7, \u0026#39;kernel\u0026#39;: \u0026#39;rbf\u0026#39;, \u0026#39;probability\u0026#39;:True} model5 = SVC(**param) param = {\u0026#39;criterion\u0026#39;: \u0026#39;gini\u0026#39;, \u0026#39;max_depth\u0026#39;: 3, \u0026#39;max_features\u0026#39;: 2, \u0026#39;min_samples_leaf\u0026#39;: 3} model6 = DecisionTreeClassifier(**param) model7 = GaussianNB() model8 = RandomForestClassifier() model9 = ExtraTreesClassifier() models = {\u0026#39;LR\u0026#39;:model1, \u0026#39;ADA\u0026#39;:model2, \u0026#39;GB\u0026#39;:model3, \u0026#39;KNN\u0026#39;:model4, \u0026#39;SVM\u0026#39;:model5, \u0026#39;DT\u0026#39;:model6, \u0026#39;NB\u0026#39;:model7, \u0026#39;RF\u0026#39;:model8, \u0026#39;ET\u0026#39;:model9 } return models base_learners = get_models() meta_learner = GradientBoostingClassifier( n_estimators=1000, loss=\u0026#34;exponential\u0026#34;, max_features=6, max_depth=3, subsample=0.5, learning_rate=0.001, random_state=123 ) from mlens.ensemble import SuperLearner # Instantiate the ensemble with 10 folds sl = SuperLearner( folds=10, random_state=123, verbose=2, backend=\u0026#34;multiprocessing\u0026#34; ) # Add the base learners and the meta learner sl.add(list(base_learners.values()), proba=True) sl.add_meta(meta_learner, proba=True) # Train the ensemble from sklearn.model_selection import train_test_split X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.2, random_state=0) sl.fit(X_train, Y_train) # Predict the test set p_sl = sl.predict_proba(X_test) pp = [] for p in p_sl[:, 1]: if p\u0026gt;0.5: pp.append(1.) else: pp.append(0.) print(\u0026#34;\\nSuper Learner Accuracy score: %.8f\u0026#34; % (Y_test== pp).mean())   结果评定/验证 特征的重要性 sklearn.inspection.permutation_importance， 可以用来估计每个特征的重要性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from sklearn.ensemble import RandomForestClassifier from sklearn.inspection import permutation_importance X, y = make_classification(random_state=0, n_features=5, n_informative=3) rf = RandomForestClassifier(random_state=0).fit(X, y) result = permutation_importance(rf, X, y, n_repeats=10, random_state=0, n_jobs=-1) fig, ax = plt.subplots() sorted_idx = result.importances_mean.argsort() ax.boxplot(result.importances[sorted_idx].T, vert=False, labels=range(X.shape[1])) ax.set_title(\u0026#34;Permutation Importance of each feature\u0026#34;) ax.set_ylabel(\u0026#34;Features\u0026#34;) fig.tight_layout() plt.show()   ROC曲线 Easily compare multiple ROC curves in a single plot\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import pandas as pd df = pd.read_csv(\u0026#39;http://bit.ly/kaggletrain\u0026#39;, header=0) cols = [\u0026#39;Pclass\u0026#39;, \u0026#39;Fare\u0026#39;, \u0026#39;SibSp\u0026#39;] X = df[cols] y = df[\u0026#39;Survived\u0026#39;] from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import plot_roc_curve X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) lr = LogisticRegression() dt = DecisionTreeClassifier() rf = RandomForestClassifier() lr.fit(X_train, y_train); dt.fit(X_train, y_train); rf.fit(X_train, y_train); disp = plot_roc_curve(lr, X_test, y_test) plot_roc_curve(dt, X_test, y_test, ax=disp.ax_); plot_roc_curve(rf, X_test, y_test, ax=disp.ax_);   ","description":"","id":72,"section":"posts","tags":["Python","sklearn"],"title":"Scikit Learn Tips","uri":"https://www.xunhs.cyou/posts/notes/209/"},{"content":" 拯救者Y9000p\n \n 2020.4.1 四月是你的谎言 2020.4.2 1)我是不是太斤斤计较了。难免有些以小人之心度君子之腹。2)我现在理解为什么好多人都要逃离国内的学术环境。我不能再深化心中这种想法。我不知道该怎样表达。3) 失落 2020.4.3 1) “自己还是比较幼稚，心性还不成熟”。 2) ROG冰刃太贵了。很漂亮（直观感觉），性能强；负重有点大，续航有待考究，看完评测没有理想主义中的好。放弃吧。 2020.4.4 今日份回老家。挂清明已跑断腿。 2020.4.5 气象报告天气很不错 太阳晒得我 脸颊红红 - 《123木头人》 2020.4.6 已经下单了。拯救者Y9000p 9299 2020.4.7 今天配置电脑弄了一天。电脑比较新装不了Linux系统（试了几次没成功，网上也没有教程），遂放弃。下载了Win10专业版，重新装机。 2020.4.8 值得开心的事是今天把tensorflow-gpu的环境安装好了。爱折腾竟然把lightgbm的gpu版本编译好了。虽然这是在晚上十点45马上睡觉的时候完成的“小事”。哎，自己永远不满足的心。 2020.4.9 老妈生日快乐 今天老妈做了一大桌子菜 请舅舅舅妈过来一起吃晚餐 2020.4.10 尝试keras+GridSearch调参，可真的是耗时间。发现深度学习调参真的是技术活。虽然我只用的简单的感知层。是不是这个原因？不好说 2020.4.11 1) Mark一下，想学vue.js+layuiPC端UI框架. 2) 妈妈发现了我还没有长大的事实:( “wuli fushen 莫利时候可以长大哟”来自妈妈的无奈。 2020.4.12 天空灰的像哭过。 2020.4.13 为什么这么困。 2020.4.14 素影。 2020.4.15 Cloudreve + Onedrive网盘存储+Aria2，还是很不错的。就是配置Oneindex没成功。 2020.4.16 1) 我这个折腾的心呐。。。2) 这两天折腾onedrive 的 web index框架上瘾。最后olaindex搭建成功，但是图床上传和页面刷新仍有问题。oneindex压根没成功。散了散了 2020.4.17 所有的事情最终都是对的。如果觉得不正确，那就是因为还没有到最后。 2020.4.18 好像做了一个很久的梦 2020.4.19 1) 你要学会以自己的方式成长，去面对这变化万千的世界。2) 得到博士学位不是终点，不代表你以后能比别人成功，但博士学位能代表的是，只要你愿意，你可以做好这个世界上几乎所有的、有技术含量的事情。 - 时间规划局 2020.4.20 为什么每次审稿意见返回了，我要先自己嫌弃一番。总是一种没有希望的感觉。 2020.4.21 各个击破！ 2020.4.22 这段时间家里兴起了麻将风波。爸妈、我热衷与QQ大众麻将~大家在比谁赢得欢乐豆多。这不，我爸大战又开始了。 2020.4.23 转角遇到爱。罗志祥的瓜吃的我怕了。熬夜弄出黑眼圈，怕出门被骂渣男。 2020.4.24 1) The “cut-and-paste” approach; 2) Colab Notebook很好用！ 3) NLP_beginner: FudanNLP/nlp-beginner, nlp-beginner-finish 2020.4.25 这一天又被粗心的作者丢失了。 2020.4.26 洗头发的时候，你会想什么呢 2020.4.27 1) JWPlayer视频播放插件，可惜没有放视频的“视频床”，放在服务器上带宽不够又很卡。2) Love means many things. 2020.4.28 我又换回Hexo啦~ 相信我 hexo修改起来比php这款最美的语言难度小很多啦。毕竟你还是懂一丢丢前端。 2020.4.29 今天好热啊。 2020.4.30 4月的最后一天。拖延了好几天的大修初稿提交给老师，等待明天的讨论。早上收到一个好消息，没想到中午学校就变卦了。我发现啊，要不就不要给予可能性，不然看到了可能性却不去兑现，会使人产生不公平。  ","description":"","id":73,"section":"posts","tags":["失落","ROG冰刃","挂清明","拯救者Y9000p","配置电脑","生日","调参","妈妈的无奈","oneindex","博士学位","审稿意见返回","拒稿重投","OneDrive","罗志祥","换回hexo"],"title":"2020-4","uri":"https://www.xunhs.cyou/posts/journals/377/"},{"content":" fmm 是在github上找到的比较好用的Map Matching路网匹配工具。\n 目录\n[TOC]\n环境搭建 (Installing)  建议在Ubuntu系统下搭建（笔者尝试Window 10 wsl2, cwing和Ubuntu 18.04均为成功，最终在Ubuntu16.04下编译成功）,docker ubuntu 16.04安装成功(2020.5.20) 主要参考FMM-wiki 项目打包: 链接1, 提取码: 9ksw;  Install requirements  添加ppa，更新gdal相关的库\nsudo add-apt-repository ppa:ubuntugis/ppa \u0026amp;\u0026amp; sudo apt update  P.S.: ppa包比较难下载，建议终端挂代理: export http_proxy=http://192.168.0.11:2802\n 安装库\nsudo apt-get install libboost-dev libboost-serialization-dev gdal-bin libgdal-dev make cmake  Install C++ program  编译  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  # Under the project folder mkdir build cd build cmake .. make sudo make install # cmake output: -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Found GDAL: /usr/lib/libgdal.so (Required is at least version \u0026#34;2.2\u0026#34;) -- GDAL headers found at /usr/include/gdal -- GDAL library found at /usr/lib/libgdal.so -- Boost version: 1.58.0 -- Found the following Boost libraries: -- serialization -- Boost headers found at /usr/include -- Boost library found at /usr/lib/x86_64-linux-gnu/libboost_serialization.so -- Try OpenMP C flag = [-fopenmp] -- Performing Test OpenMP_FLAG_DETECTED -- Performing Test OpenMP_FLAG_DETECTED - Success -- Try OpenMP CXX flag = [-fopenmp] -- Performing Test OpenMP_FLAG_DETECTED -- Performing Test OpenMP_FLAG_DETECTED - Success -- Found OpenMP: -fopenmp -- OpenMP_CXX_LIBRARIES found at -- Configuring done -- Generating done -- Build files have been written to: /home/only/Projects/fmm-master/build    Verfication of installation\nfmm:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  ------------ Fast map matching (FMM) ------------ ------------ Author: Can Yang ------------ ------------ Version: 2020.01.31 ------------ ------------ Applicaton: fmm ------------ A configuration file is given in the example folder Run `fmm config.xml` or with arguments fmm argument lists: --ubodt (required) \u0026lt;string\u0026gt;: Ubodt file name --network (required) \u0026lt;string\u0026gt;: Network file name --gps (required) \u0026lt;string\u0026gt;: GPS file name --output (required) \u0026lt;string\u0026gt;: Output file name --network_id (optional) \u0026lt;string\u0026gt;: Network id name (id) --source (optional) \u0026lt;string\u0026gt;: Network source name (source) --target (optional) \u0026lt;string\u0026gt;: Network target name (target) --gps_id (optional) \u0026lt;string\u0026gt;: GPS id name (id) --gps_geom (optional) \u0026lt;string\u0026gt;: GPS geometry name (geom) --candidates (optional) \u0026lt;int\u0026gt;: number of candidates (8) --radius (optional) \u0026lt;double\u0026gt;: search radius (300) --error (optional) \u0026lt;double\u0026gt;: GPS error (50) --pf (optional) \u0026lt;double\u0026gt;: penalty factor (0) --log_level (optional) \u0026lt;int\u0026gt;: log level (2) --output_fields (optional) \u0026lt;string\u0026gt;: Output fields opath,cpath,tpath,ogeom,mgeom,pgeom, offset,error,spdist,tp,ep,all For xml configuration, check example folder ------------ Program finished ------------   Install python extension 在Python2使用\n Swig installation  sudo apt-get install build-essential libpcre3-dev libpcre3 Build swig    1 2 3 4 5 6 7  tar -xf swig-4.0.1.tar.gz cd swig-4.0.1/ ./configure sudo make sudo make install swig -version    python-dev: sudo apt-get install python-dev Installation of fmm Python API\n编译:  1 2 3 4 5  cd python mkdir build cd build cmake .. make   Add the build folder to the environment variable PYTHONPATH:\n1 2  echo \u0026#39;export PYTHONPATH=${PYTHONPATH}:PATH_TO_BUILD_FOLDER\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc   PATH_TO_BUILD_FOLDER: /workspace/fmm-master/python/build\n 验证  1 2  cd .. python2 fmm_test.py   使用 样例文件打包:链接1\n路网数据准备  from osm-based osmnx  Download by place name\n1 2 3 4  import osmnx as ox place =\u0026#34;Stockholm, Sweden\u0026#34; G = ox.graph_from_place(place, network_type=\u0026#39;drive\u0026#39;,which_result=2) ox.save_graph_shapefile(G, filename=\u0026#39;stockholm\u0026#39;)   Download by a boundary polygon in geojson\n1 2 3 4 5 6 7 8  import osmnx as ox from shapely.geometry import shape json_file = open(\u0026#34;stockholm_boundary.geojson\u0026#34;) import json data = json.load(json_file) boundary_polygon = shape(data[\u0026#34;features\u0026#34;][0][\u0026#39;geometry\u0026#39;]) G = ox.graph_from_polygon(boundary_polygon, network_type=\u0026#39;drive\u0026#39;) ox.save_graph_shapefile(G, filename=\u0026#39;stockholm\u0026#39;)    自定义数据\n假设手头上有的路网数据仅有id和geometry字段，首先我们需要构建路网拓扑结构，使用的是arcmap+postgresql，参考这里  打断路网相交线 postgresql+postgis安装 导入shp数据至postgis db(多种方式: geopandas, psql bash command, PostGIS Shapefile and DBF Loader Exporter)  geopandas 参考博文Pandas/Geopandas Tricks中的Geopandas I/O   生成路网拓扑结构    1 2 3 4 5 6 7 8  ALTERTABLEpublic.bjrdv2proADDCOLUMNsourceinteger;ALTERTABLEpublic.bjrdv2proADDCOLUMNtargetinteger;ALTERTABLEpublic.bjrdv2proADDCOLUMNlengthdoubleprecision;SELECTpgr_createTopology(\u0026#39;public.bjrdv2pro\u0026#39;,0.00001,\u0026#39;geom\u0026#39;,\u0026#39;gid\u0026#39;);CREATEINDEXsource_idxONbjrdv2pro(\u0026#34;source\u0026#34;);CREATEINDEXtarget_idxONbjrdv2pro(\u0026#34;target\u0026#34;);updatebjrdv2prosetlength=st_length(geom);select*frombjrdv2pro;   建立双向拓扑(Complement bidirectional edges)\nDuplicate bidirectional edges, i.e., add a reverse edge  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  table_name = \u0026#39;bjrdv2pro\u0026#39; geom_col = \u0026#39;geom\u0026#39; sql_str = \u0026#34;select * from {}\u0026#34;.format(table_name) bjrd_gdf = gpd.read_postgis(sql=sql_str, con=engine, geom_col=geom_col) def reverse_coords(line_string): coords = list(line_string.coords) coords.reverse() return LineString(coords) _bjrd_gdf = bjrd_gdf.copy() _bjrd_gdf[\u0026#39;geom\u0026#39;] = _bjrd_gdf.geom.apply(lambda x: reverse_coords(x)) _bjrd_gdf[\u0026#39;source\u0026#39;] = bjrd_gdf.target _bjrd_gdf[\u0026#39;target\u0026#39;] = bjrd_gdf.source concat_gdf = pd.concat([bjrd_gdf, _bjrd_gdf], axis=0).reset_index(drop=True).set_geometry(\u0026#39;geom\u0026#39;) concat_gdf[\u0026#39;gid\u0026#39;] = concat_gdf.index concat_gdf.to_file(\u0026#39;bjrdv2probidrt.shp\u0026#39;)   配置\u0026amp;运行 配置参考：链接\n ubodt配置(Preprocessing of fmm)  1  ubodt_gen --network bjrdv2probidrt.shp --id gid --source source --target target --output ubodt.txt --delta 4.0   生成ubodt.txt 配置文件（类似是构建路网cache之类的）\n fmm配置文件\nfmm_config-bj.xml:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026lt;fmm_config\u0026gt; \u0026lt;input\u0026gt; \u0026lt;ubodt\u0026gt; \u0026lt;file\u0026gt;./bj_example/ubodt.txt\u0026lt;/file\u0026gt; \u0026lt;/ubodt\u0026gt; \u0026lt;network\u0026gt; \u0026lt;file\u0026gt;./bj_example/bjrdv2probidrt.shp\u0026lt;/file\u0026gt; \u0026lt;id\u0026gt;gid\u0026lt;/id\u0026gt; \u0026lt;source\u0026gt;source\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;target\u0026lt;/target\u0026gt; \u0026lt;/network\u0026gt; \u0026lt;/input\u0026gt; \u0026lt;parameters\u0026gt; \u0026lt;k\u0026gt;50\u0026lt;/k\u0026gt; \u0026lt;r\u0026gt;0.01\u0026lt;/r\u0026gt; \u0026lt;pf\u0026gt;0\u0026lt;/pf\u0026gt; \u0026lt;gps_error\u0026gt;0.005\u0026lt;/gps_error\u0026gt; \u0026lt;/parameters\u0026gt; \u0026lt;/fmm_config\u0026gt;   Note: 注意单位-如果是经纬度，单位就是度，0.001约等于100m; else单位是m\n built model  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  from __future__ import print_function import sys from pathlib import Path import geopandas as gpd import pandas as pd import os from shapely.wkt import dumps, loads sys.path.append(\u0026#39;/home/only/Projects/fmm-master/python/build\u0026#39;) import warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;) import fmm root_dp = Path(r\u0026#39;/home/only/Projects/fmm-master\u0026#39;) example_dp = Path(root_dp, \u0026#39;example\u0026#39;) py_test_dp = Path(root_dp, \u0026#39;python\u0026#39;) bj_example_dp = Path(py_test_dp, \u0026#39;bj_example\u0026#39;) fmm_config_fp = Path(bj_example_dp, \u0026#39;fmm_config-bj.xml\u0026#39;) bj_network_fp = Path(bj_example_dp, \u0026#39;bjrdv2probidrt.shp\u0026#39;) traj_tst_fp = Path(bj_example_dp, \u0026#39;TrajPntsTst.shp\u0026#39;) multi_traj_tst_fp = Path(bj_example_dp, \u0026#39;1140.geojson\u0026#39;) traj_tst_result_fp = Path(bj_example_dp, \u0026#39;traj_tst_result.geojson\u0026#39;) # fmm model model = fmm.MapMatcher(str(fmm_config_fp))    run and save result  1 2 3 4 5 6 7 8 9 10 11 12 13 14  traj_mm_df = multi_traj_tst_gdf[[\u0026#39;traj_id\u0026#39;, \u0026#39;geometry\u0026#39;]] def _mm(g): try: mrst = model.match_wkt(str(g)).mgeom return loads(mrst) except Exception as ex: return None traj_mm_df[\u0026#39;geometry\u0026#39;] = traj_mm_df.geometry.apply(lambda g: _mm(g)) # (可选操作)丢掉匹配度非常差的路径 traj_mm_df.dropna(inplace=True) traj_mm_df.set_geometry(\u0026#39;geometry\u0026#39;).to_file(traj_tst_result_fp, driver=\u0026#39;GeoJSON\u0026#39;)   ","description":"","id":74,"section":"posts","tags":["Map Matching","路网匹配"],"title":"fmm-Map Matching路网匹配工具环境搭建与使用","uri":"https://www.xunhs.cyou/posts/notes/148/"},{"content":" 常用加速镜像；python常用虚拟环境管理;Jupyter Notebook常用配置\n pip;conda;ubuntu镜像加速 参考：北京外国语大学开源镜像站-https://mirrors.bfsu.edu.cn/#\npip 1  pip config set global.index-url https://mirrors.bfsu.edu.cn/pypi/web/simple   conda 通过修改用户目录下的 .condarc 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  channels:- defaultsshow_channel_urls:truedefault_channels:- https://mirrors.bfsu.edu.cn/anaconda/pkgs/main- https://mirrors.bfsu.edu.cn/anaconda/pkgs/r- https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2custom_channels:conda-forge:https://mirrors.bfsu.edu.cn/anaconda/cloudmsys2:https://mirrors.bfsu.edu.cn/anaconda/cloudbioconda:https://mirrors.bfsu.edu.cn/anaconda/cloudmenpo:https://mirrors.bfsu.edu.cn/anaconda/cloudpytorch:https://mirrors.bfsu.edu.cn/anaconda/cloudsimpleitk:https://mirrors.bfsu.edu.cn/anaconda/cloud  ubuntu 根据不同版本设定：https://mirrors.bfsu.edu.cn/help/ubuntu/\nUbuntu 的软件源配置文件是 /etc/apt/sources.list，下面是20.04LTS版本\n1 2 3 4 5 6 7 8 9 10 11 12 13  # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.bfsu.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.bfsu.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.bfsu.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.bfsu.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.bfsu.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.bfsu.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.bfsu.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.bfsu.edu.cn/ubuntu/ focal-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.bfsu.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.bfsu.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse   虚拟环境 建议结合使用pyenv + virtualenvwrapper，管理python版本及虚拟环境。其次可使用conda\nvirtualenvwrapper virtualenv 可以创建一个虚拟的独立 Python 环境，但是 virtualenv 创建的环境相对分散不便于管理,Virtualenvwrapper 提供了一系列命令管理虚拟环境\n参考：1; 2\nVirtualenvwrapper 安装 1 2  pip install virtualenv virtualenvwrapper pip install virtualenvwrapper-win # windows平台使用这个命令   安装之后还需要配置， 在.zshrc中添加下列内容:\n1 2 3  # 设置虚拟环境的工作目录， 创建的虚拟环境都保存在这个目录下 export WORKON_HOME=$HOME/.virtualenvs source /usr/local/bin/virtualenvwrapper.sh    WORKON_HOME:存放相关工作文件及虚拟环境的目录 virtualenvwrapper.sh 文件位置根据实际目录填写，可以使用find / -name virtualenvwrapper.sh进行查找 配置好后执行source ~/.zshrc  创建环境  快速创建：mkvirtualenv [envname] 指定版本：mkvirtualenv ttenv --python=python3.5  --python参数可设定具体路径，如：mkvirtualenv daily --python=C:\\Users\\Only\\.pyenv\\pyenv-win\\versions\\3.6.8\\python3.6.exe    环境管理 列出所有环境：workon\n删除环境：rmvirtualenv [envname]\n切换与退出环境 切换虚拟环境：workon envname\n退出虚拟环境：deactivate\npyenv-python版本管理 安装 参考：https://zhuanlan.zhihu.com/p/30859003\npyenv-win: https://github.com/pyenv-win/pyenv-win\n常用命令   查看所有已安装Python版本\n1  pyenv version     查询所有可安装Python版本\n1 2 3  pyenv install -l # 查询3.6版本 python install -l | grep 3.6     安装指定版本\n1 2 3 4  pyenv install 3.6.12 # 使用镜像加速 # 注意：v 为 Python 版本号，请根据需要自行更改。 v=3.6.12;wget https://npm.taobao.org/mirrors/python/$v/Python-$v.tar.xz -P $(pyenv root)/cache/;pyenv install $v     卸载\n1  pyenv uninstall 3.6.12     设置Python版本 1 2 3  pyenv shell 2.7.14 # 设置面向 shell 的 Python 版本，通过设置当前 shell 的 PYENV_VERSION 环境变量的方式。 pyenv local 2.7.14 # 设置 Python 本地版本，通过将版本号写入当前目录下的 .python-version 文件的方式。通过这种方式设置的 Python 版本优先级较 global 高。 pyenv global 2.7.14 # 设置全局的 Python 版本，通过将版本号写入 ~/.pyenv/version 文件的方式。     注意： shell \u0026gt; local \u0026gt; global。pyenv 会从当前目录开始向上逐级查找 .python-version 文件，直到根目录为止。若找不到，就用 global 版本。Ps: 因为系统本身常常会依赖自带的 python 版本，所以尽量不要修改 global。\n  取消 shell 或 local python 版本\n1 2  pyenv shell --unset pyenv local --unset     pyenv-virtualenvwrapper   安装\n1  git clone https://github.com/pyenv/pyenv-virtualenvwrapper.git $(pyenv root)/plugins/pyenv-virtualenvwrapper     激活\n1  pyenv virtualenvwrapper   激活后需重启当前shell\n  使用\n1 2 3 4 5 6  # 1. 设置当前 shell的python版本 pyenv shell 3.6.12 # 2. 第一次使用新的 Python 环境需要安装此包，否则创建的虚拟环境 Python 版本仍为系统默认 pip install virtualenvwrapper # 3. 创建该版本的虚拟环境 mkvirtualenv [env_name] -p python3.6     conda 建议优先使用virtualenvwrapper。conda太庞大了，导入pycharm尤其明显。pycharm indexing过程让人奔溃。\n创建环境 1 2 3 4 5  conda create --name your_env_name # 创建制定python版本的环境 conda create --name your_env_name python=2.7 conda create --name your_env_name python=3.7   列举当前所有环境 1 2 3  conda env list # 或 conda info --envs   进入、退出某个环境 1 2 3  activate your_env_name [conda] deactivate   在当前环境使用pip 一定注意要先安装pip，不然pip定位到的是root环境的pip\nconda install pip pip -V 备份和恢复 参考: 链接\nconda提供了将虚拟环境导出为yaml文件的功能，使得我们可以保留好不容易创建好的虚拟环境中的配置信息\n 备份：  1  (python_spatial) C:\\Users\\hp\u0026gt;conda env export \u0026gt; C:\\Users\\hp\\Desktop\\python_spatial.yml    恢复：  1  conda env create -n new_python_spatial -f C:\\Users\\hp\\Desktop\\python_spatial.yml   移除某个环境 1  conda remove --name your_env_name --all   conda安装加速 conda install mamba -n base -c conda-forge 使用mamba加速安装：\nmamba install pip jupyter notebook Installing pip install notebook\n配置启动文件  新建配置文件root_jupyter_config.py 配置root_jupyter_config.py  1 2 3 4 5 6 7  c.NotebookApp.ip=\u0026#39;*\u0026#39; # 指定 可访问 IP 或者 使用 * 则可以用任意 IP c.NotebookApp.open_browser = False # 关闭自动打开浏览器 c.NotebookApp.port = 10086 # 端口随意指定，然后在阿里云开对应端口的防火墙即可 # 密码是 123345678 c.NotebookApp.password = u\u0026#39;sha1:a38e2b0e6384:a57ca7170591f36911041ae92cdd7418ff76979a\u0026#39; c.NotebookApp.allow_remote_access = True c.NotebookApp.notebook_dir = \u0026#39;/jupyter/notebooks\u0026#39; #指定默认打开的文件夹    启动时读取配置文件\njupyter notebook --config=/jupyter/config/root_jupyter_config.py [--allow-root]  allow-root: 在Linux中允许root用户启动    kernel管理 安装ipykernel pip install ipykernel\n注：如果添加虚拟环境下的kernel, ipykernel也需要在虚拟环境下安装\n在虚拟环境中，将环境写入notebook的kernel中 python -m ipykernel install --user --name [环境名] --display-name \u0026quot;[python 环境名]\u0026quot;\n查看所有kernel 查看所有已经安装的jupyter notebook 的 kernel\njupyter kernelspec list\n卸载指定kernel jupyter kernelspec remove kernel_name\nJupyter notebook extensions插件 Nbextensions是一个非常有用的插件，集合了很多插件。\ninstall  推荐conda安装:\nconda install -c conda-forge jupyter_contrib_nbextensions Install javascript and css files:\njupyter contrib nbextension install --user 然后重新启动Jupyter Notebook后，就会发现已经有Nbextensions标签了。  常用插件  Hinterland，代码自动补全 (2020.3.8 不推荐，用了之后没有想要的效果，而且你会感觉很烦人) Code prettify：它能重新调整代码块内容的格式并进行美化。 Scratchpad：这会添加一个暂存单元，让你可以无需修改笔记本就能运行你的代码。当你想实验你的代码但不想改动你的实时笔记本时，这会是一个非常方便的扩展。 Table of Contents(2)：这个很棒的扩展可以收集你的笔记本中的所有标题，并将它们显示在一个浮动窗口中。 Codefolding: 折叠代码 Collapsible headings: 放下/收起notebook的某些内容  ####更改样式（字体，代码高亮）\n使用附件替换C:\\Users\\Only\\.jupyter\\custom\\custom.css\n","description":"","id":75,"section":"posts","tags":["加速镜像","pyenv","Python","虚拟环境","包管理","virtualenvwrapper","conda","Jupyter notebook"],"title":"常用加速镜像\u0026Python虚拟环境/包管理\u0026Jupyter Notebook","uri":"https://www.xunhs.cyou/posts/notes/2020-03-08-python%E5%BA%93-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83_%E5%8C%85%E7%AE%A1%E7%90%86/"},{"content":" seaborn是python里面做数据分析和机器学习常用的可视化库。它对matplotlib进行了深度封装，从而可以用非常简单的api接口绘制相对复杂的图形，提供对数据的深入认识。\n VIsual Vocabulary 引用 1 2 3 4 5 6  import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np %matplotlib inline   sns.set 1  sns.set(style=\u0026#39;white\u0026#39;,palette=\u0026#39;muted\u0026#39;,color_codes=True)    style为图表的背景主题，有5种主题可以选择：\ndarkgrid 黑色网格（默认）\nwhitegrid 白色网格\ndark 黑色背景\nwhite 白色背景\nticks 四周都有刻度线的白背景 palette为设置主体颜色，有6种可以选择：\ndeep,muted,pastel,bright,dark,colorblind  matplotlib.pyplot cheatsheets handout 创建画布与创建子图 1 2  fig = plt.figure(figsize=(8,6),dpi=300) #设置画布大小及分辨率 ax = fig.add_subplot(2,1,1) #创建一个2行1列的子图，绘制第1张子图   matplotlib.pyplot元素结构图\n图像的各个部位名称\n细节处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14  ax.set_title(\u0026#39;Title\u0026#39;,fontsize=18) # 设置标题 ax.set_xlabel(\u0026#39;xlabel\u0026#39;, fontsize=18,fontfamily = \u0026#39;sans-serif\u0026#39;,fontstyle=\u0026#39;italic\u0026#39;) # x轴label ax.set_ylabel(\u0026#39;ylabel\u0026#39;, fontsize=\u0026#39;x-large\u0026#39;,fontstyle=\u0026#39;oblique\u0026#39;) # y轴label ax.legend() #  ax.set_aspect(\u0026#39;equal\u0026#39;) ax.minorticks_on() ax.set_xlim(0,16) # x轴范围 ax.grid(which=\u0026#39;minor\u0026#39;, axis=\u0026#39;both\u0026#39;) # 背景网格 ax.xaxis.set_tick_params(rotation=45,labelsize=18,colors=\u0026#39;w\u0026#39;) start, end = ax.get_xlim() ax.xaxis.set_ticks(np.arange(start, end,1)) ax.yaxis.tick_right()   保存绘图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import matplotlib.pyplot as plt import os eval_root = \u0026#39;/workspace/UrbanFunctionalRegionalization/result/evaluation\u0026#39; #分辨率 plt.rcParams[\u0026#39;figure.dpi\u0026#39;] = 300 fig, ax = plt.subplots(figsize=(12, 7)) ax = sns.pointplot(x=\u0026#34;threshold\u0026#34;, y=\u0026#34;purity\u0026#34;, data=eval_metrics_df) ax.set_xlabel(\u0026#39;min region size\u0026#39;, fontsize=14,) ax.set_ylabel(\u0026#39;purity\u0026#39;, fontsize=14,) # ax.set_xlim(0,100)  # ax.set_ylim(0,1) fig_fp = os.path.join(eval_root, \u0026#39;purity.jpg\u0026#39;) fig.savefig(fig_fp, dpi=300)   seaborn cheatsheets Categorical plots countplot 通过countplot会绘制出，每个值在样本中出现的次数。\n Show value counts for a single categorical variable  1 2 3  sns.set(style=\u0026#34;darkgrid\u0026#34;) tips = sns.load_dataset(\u0026#34;tips\u0026#34;) ax = sns.countplot(x=\u0026#34;day\u0026#34;, data=tips)    Show value counts for two categorical variables  1 2  ax= sns.countplot(x=\u0026#39;day\u0026#39;, hue=\u0026#39;smoker\u0026#39;, data=tips) # ax= sns.countplot(x=\u0026#39;day\u0026#39;, hue=\u0026#39;smoker\u0026#39;, data=tips) # 横向显示   barplot barplot主要用来描述样本的均值和置信区间（置信区间本质上应该算是对整个分布的预估，而不仅仅是展示当前样本里面的信息）\n Draw a set of vertical bar plots grouped by a categorical variable  1  ax = sns.barplot(x=\u0026#34;day\u0026#34;, y=\u0026#34;total_bill\u0026#34;, data=tips)     barplot是一个柱状图上面加一个黑线。柱状图的值默认情况下对应的要显示的样本的均值，而黑线默认情况则标识了95%的置信区间。\n何为95%的置信区间？95%的置信区间指的是对于当前样本所属的分布而言，当有个新的值产生时，这个值有95%的可能性在该区间内，5%的可能性不在该区间内。\n  显示标准差而非置信区间\n  1  ax = sns.barplot(x=\u0026#34;day\u0026#34;, y=\u0026#34;total_bill\u0026#34;, data=tips, order=[\u0026#39;Sun\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Thur\u0026#39;], ci=\u0026#39;sd\u0026#39;, capsize=.1)   - 参数说明: - order: 控制x轴的显示顺序 - ci: (float or “sd” or None, optional).Size of confidence intervals to draw around estimated values. If “sd”, skip bootstrapping and draw the standard deviation of the observations. If None, no bootstrapping will be performed, and error bars will not be drawn. - capsize: 竖线的上下添加一个“小勾勾”  pointplot 含义与barplox相同，表现形式变更\n1 2 3  ax = sns.pointplot(x=\u0026#34;day\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue=\u0026#39;sex\u0026#39;, data=tips, estimator=np.median, markers=[\u0026#39;o\u0026#39;, \u0026#39;x\u0026#39;], linestyles=[\u0026#39;-\u0026#39;, \u0026#39;--\u0026#39;], palette=\u0026#34;Set2\u0026#34;)    参数说明:  estimator: 评估器，默认为计算中值。此处设置计算中位数 markers： 如图，点形状 linestyles：如图，线型    boxplot boxplot是来表现样本里面的四分位值以及最大最小值的\n Draw a single horizontal boxen plot  1 2  sns.set(style=\u0026#34;whitegrid\u0026#34;) ax = sns.boxplot(x=\u0026#34;total_bill\u0026#34;, data=tips)   boxplot黑线起点是最小值，终点是最大值。而柱子的起点是25%处的值，终点是75%处的值。柱子中间的那条黑线则对应着50%处的值。跟我们通过df.describe()显示的结果一致\n Draw a vertical boxen plot grouped by a categorical variable  1  ax = sns.boxplot(x=\u0026#39;day\u0026#39;, y=\u0026#34;total_bill\u0026#34;, data=tips, palette=\u0026#34;Set3\u0026#34;)   violinplot violinplot是结合了boxplot和distplot的优点。\n通过violinplot既能看到当前样本的最大最小值和四分位值，又能看到对整体分布的预估，了解任意区间的概率分布情况。\n Draw a single horizontal violinplot  1 2  sns.set(style=\u0026#34;whitegrid\u0026#34;) ax = sns.violinplot(x=\u0026#34;total_bill\u0026#34;, data=tips, palette=\u0026#34;Set3\u0026#34;)    Draw split violins to compare the across the hue variable  1  ax = sns.violinplot(x=\u0026#34;day\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=tips, palette=\u0026#34;Set3\u0026#34;, split=True)   catplot 它是以上几种图的接口，以上categorical图表均可通过指定kind参数来绘制 + FacetGrid\n1  g = sns.catplot(x=\u0026#39;day\u0026#39;, y=\u0026#39;tip\u0026#39;, col=\u0026#39;sex\u0026#39;, data=tips, kind=\u0026#39;bar\u0026#39;)    参数说明:  col/row: 图表分类依据, names of variables；col横向；row竖向； kind: “point”, “bar”, “strip”, “swarm”, “box”, “violin”, or “boxen”的一种    Distribution plots distplot distplot主要用来对整体分布进行预估，并很容易观察出某个区间概率的大小情况。\n Show a default plot with a kernel density estimate and histogram with bin size determined automatically with a reference rule  1  ax = sns.distplot(a=tips.total_bill)   distplot展示了整体的分布情况，其中的曲线图则是概率密度函数。\n在概率密度函数中，某个点的概率是无意义的。而某两个点之间的概率则是通过对这两个点之间的面积计算得来的。对应到该图上，则意味着total_bill=40的概率是无意义的，但是total_bill在30和40之间的概率是二者之间的曲线下的面积。所以，整个曲线下的面积是1，对应着所有值出现的概率总和。\nkdeplot kernel density estimate\n Plot a basic univariate density  1  ax = sns.kdeplot(data=tips.total_bill, shade=True, color=\u0026#34;r\u0026#34;)    Plot a bivariate density  1  ax = sns.kdeplot(data=tips.total_bill, data2=tips.tip ,)    Plot two shaded bivariate densities  1 2 3 4 5 6 7  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) setosa = iris.loc[iris.species == \u0026#34;setosa\u0026#34;] virginica = iris.loc[iris.species == \u0026#34;virginica\u0026#34;] ax = sns.kdeplot(setosa.sepal_width, setosa.sepal_length, cmap=\u0026#34;Reds\u0026#34;, shade=True, shade_lowest=False, cbar=True) ax = sns.kdeplot(virginica.sepal_width, virginica.sepal_length, cmap=\u0026#34;Blues\u0026#34;, shade=True, shade_lowest=False, cbar=True)   - 参数说明:\n- cbar: drawing a bivariate KDE plot, add a colorbar.\nRelational plots scatterplot 散点图\n Draw a simple scatter plot between two variables  1 2  sns.set(style=\u0026#34;darkgrid\u0026#34;) ax = sns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips)    Show the grouping variable by varying both color and marker  1 2  sns.set(style=\u0026#34;darkgrid\u0026#34;) ax = sns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=tips, style=\u0026#34;smoker\u0026#34;)   - 参数说明:\n- hue: 分组变量\n- style: marker变量\n Show a quantitative variable by varying the size of the points  1  ax = sns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;size\u0026#34;, data=tips, size=\u0026#34;size\u0026#34;)   - 参数说明:\n- size: 决定圆大小的变量，可以是离散型的\n 聚类结果显示  1 2  ax= sns.scatterplot(x=\u0026#39;sepal_width\u0026#39;, y=\u0026#39;sepal_length\u0026#39;, data=iris, hue=\u0026#39;species\u0026#39;, style=\u0026#39;species\u0026#39;)   lineplot 1 2 3  ax = sns.lineplot(x=\u0026#39;tip\u0026#39;, y=\u0026#39;total_bill\u0026#39;, data=tips, hue=\u0026#34;smoker\u0026#34;, style=\u0026#34;smoker\u0026#34;, markers=True, dashes=True, ci=None)    参数说明:  markers: 实数点 分类标记 dashes: 线分类显示（实线、虚线） ci: 置信区间    relplot 散点图scatterplot()和折线图lineplot()的接口，散点图和折线图均可通过指定kind参数来绘制 + FacetGrid\n1 2 3  sns.set(style=\u0026#34;ticks\u0026#34;) g = sns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, col=\u0026#34;time\u0026#34;, data=tips, kind=\u0026#34;line\u0026#34;) g = sns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, col=\u0026#34;time\u0026#34;, data=tips, hue=\u0026#34;smoker\u0026#34;, kind=\u0026#34;scatter\u0026#34;)    参数说明:  col/row: 图表分类依据, names of variables；col横向；row竖向； kind: \u0026ldquo;line\u0026rdquo;, \u0026ldquo;scatter\u0026rdquo;    Regression plots regplot Plot data and a linear regression model fit.\n1 2  sns.set(style=\u0026#34;darkgrid\u0026#34;) ax = sns.regplot(x=\u0026#39;tip\u0026#39;, y=\u0026#39;total_bill\u0026#39;, data=tips)    参数说明:  marker: str, 可设置点的marker; marker=\u0026quot;+\u0026quot;    lmplot 功能比regplot更多一些\nPlot data and regression model fits across a FacetGrid\n1 2 3  g= sns.lmplot(x=\u0026#39;tip\u0026#39;, y=\u0026#39;total_bill\u0026#39;, data=tips, hue=\u0026#39;smoker\u0026#39;, col=\u0026#39;smoker\u0026#39;, markers=[\u0026#39;o\u0026#39;, \u0026#39;+\u0026#39;], palette=\u0026#34;Set2\u0026#34;)   Matrix plots heatmap(热力图) 1 2  pt = iris.corr() # pt为数据框或者是协方差矩阵 ax = sns.heatmap(pt, annot=True)   Examples highest and lowest  Identifying counties with highest and lowest Covid-19 Mortality Rates.\n Refer: https://www.kaggle.com/jmarfati/actual-spread-of-covid19-us-county-level-analysis?scriptVersionId=34667620\u0026amp;cellId=23\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # two parallel barplot plt.figure(figsize=(20,8)) plt.subplot(1, 2, 1) g=sns.barplot(x=\u0026#39;mortality\u0026#39;, y=\u0026#39;county_state\u0026#39;,data=df[df.confirmed\u0026gt;500].sort_values([\u0026#39;mortality\u0026#39;], ascending=False).head(10), color=\u0026#34;red\u0026#34;) show_values_on_bars(g, \u0026#34;h\u0026#34;, space=0.002, text_size=20) plt.xlim(0, 0.15) plt.xlabel(\u0026#34;Covid Mortality Rate\u0026#34;, size=20) plt.ylabel(\u0026#34; \u0026#34;, size=20) plt.yticks(size=15) plt.title(\u0026#34;Counties with highest Covid Mortality\u0026#34;, size=25) plt.subplot(1, 2, 2) g=sns.barplot(x=\u0026#39;mortality\u0026#39;, y=\u0026#39;county_state\u0026#39;,data=df[df.confirmed\u0026gt;500].sort_values([\u0026#39;mortality\u0026#39;], ascending=True).head(10), color=\u0026#34;blue\u0026#34;) show_values_on_bars(g, \u0026#34;h\u0026#34;, space=0.002, text_size=20) plt.xlim(0, 0.05) plt.xlabel(\u0026#34;Covid Mortality Rate\u0026#34;, size=20) plt.ylabel(\u0026#34; \u0026#34;) plt.yticks(size=15) plt.title(\u0026#34;Counties with lowest Covid Mortality\u0026#34;, size=25) plt.tight_layout()   association between two variables  Association between percentage of population above 65 in the county and covid mortality.\n Refer: https://www.kaggle.com/jmarfati/actual-spread-of-covid19-us-county-level-analysis?scriptVersionId=34667620\u0026amp;cellId=27\n1 2 3 4 5 6 7  # regplot + barplot(with qcut) plt.figure(figsize=(20,5)) plt.subplot(1, 2, 1) sns.regplot(df_temp.percent_above_65, df_temp.mortality) plt.subplot(1, 2, 2) sns.barplot(pd.qcut(df_temp.percent_above_65, 4), df_temp.mortality)   ","description":"","id":76,"section":"posts","tags":["seaborn","Python","可视化","学习笔记","matplotlib"],"title":"Python库-seaborn + matplotlib","uri":"https://www.xunhs.cyou/posts/notes/2020-03-03-python%E5%BA%93-seaborn_+_matplotlib/"},{"content":"  \n 2020.3.1 万万没想到昨天是二月的最后一天。不对，万万没想到今天的是三月的第一天。该怎样表述呢。没想到二月份就这样过去了。 2020.3.2 年轻时候犯下的错，一直深深的留在脑海里。那时候留下遗憾的东西，时常在梦里得到宽恕和满足。那种深爱且不舍不弃的感觉，在体会过撕裂和绝望后，逐渐演变为空虚，麻木和爱而不得的久久交错。现在，或者在梦里，再说一句我真的爱过你，还有用吗？ 2020.3.3 Time will tell. 2020.3.4 他能开朗的接纳旁人，却又活在深沉的孤独当中。 2020.3.5 Manjaro折腾了一天。我真是个折腾狂;Manjaro怎么不好编译python的包呢，查了半天资料没找到。 2020.3.6 处理北京出租车数据，北京taz分区修图。其他论文里的方法还是学不会 只能用笨办法。 2020.3.7 荣誉（honor）,智慧（wisdom）,慷慨（generosity）,英勇（valor）,怜悯（compassion）- 巫师3骑士五德 2020.3.8 今天木有学习。。。过周末吗？ 啊？ 2020.3.9  2020.3.10 好吃的鲫鱼汤~ 2020.3.11 这一天被粗心的作者遗漏了。 2020.3.12 1）看见街边的流浪小狗，劝说爸妈收养失败；经常听到它的哀叫，也看到它眼边留了许多泪。没有办法。2）今天去拿京东快递，骑着电车慢慢开了十分钟左右，觉得很舒适，大约很久没有出来透透气。街边人不多，没有那么压抑，但是路过医院看到排着队，还有不自然的远离医院大门。3）让老妈尝尝我刚买的速溶咖啡，没想到她还很喜欢喝，不断问我贵不贵，竟然问是不是补品，喝咖啡有什么之类的问题？看出她喜欢喝，但嫌贵。她说加点糖或许很好喝，被我劝阻了。看来她应该更喜欢偏甜的咖啡(P.S. 我这次入手的是比较常见的雀巢2+1原味，味道偏淡。) 2020.3.13 你的眼里有星辰大海，是我看不到的未来。 2020.3.14 始于唇齿 忠于岁月 2020.3.15 不患寡而患不均 2020.3.16 眷恋；三月已经过半了，拖了这么久的实验要快一些了，方法基本确定，对比也想好了，不要再一拖再拖；今天看到学校申请不答辩的消息，其实蛮高兴的，毕竟自己答辩这一块一直是弱项。但是同时有些忧虑，自己研修计划写的真不怎样，确实需要花心思好好休整一下。毕竟之前提交的只是应付学校提交。总之加油吧，这次希望很大。也希望疫情尽快好起来，大家都恢复健康和正常的工作。 2020.3.17 在window 10上布置fmm Map Matching的环境没有成功。不懂C++，布置一个环境都这么难。。能力有限。不过很感激作者耐心的帮助。github上一次次commit都能很快回复~ 2020.3.18 fmm在ubuntu上搭建好了，测试demo也跑通了。但是，emm有一个问题，自己建立的路网跑不通。思来想去，是没有建立双向路网。目前构建的路网关系是单向的。然后查看了作者关于osm map matching上的说明，确实有一个步骤是Complement bidirectional edges. map matching啊。 唉。好好做吧，这个做好了以后map matching只要做轨迹研究一定用的到的; 我觉得在Ubuntu上码代码和码字，很舒适。是的！ 2020.3.19 我想剪头发。。。Hair Cut 2020.3.20 小朋友，你是不是有很多问号。 2020.3.21 就像是失去神经，我感觉不到呼吸 2020.3.22 embedding + 协同过滤 =\u0026gt; 推荐系统的应用；再mark一个知乎用户，他的很多动态都是关于embedding的 2020.3.23 侬脑子瓦特啦 2020.3.24 今天跟小毛仔聊了很多，好久没说这么多话，嗓子都哑了。 2020.3.25 海鸟跟鱼相爱，只是一场意外。 2020.3.26 我确实有点偏执，或者说是很偏执。 2020.3.27 晚上就好困 不想做事情 人的精力是有限的 不是么 2020.3.28 所谓伊人 在水一方 2020.3.29 这一天被粗心的作者遗漏了。 2020.3.30 快到月底了，想问自己一个事情。这种每天一句话坚持了多久了？以前只是记录一些喜欢的句子，歌词之类的，后来开始写一两句记事，想法，感触，还有无聊的自言自语。以前总觉得自己很难坚持做一件事情，不知道这算不算改变。 2020.3.31 发现typecho官方的论坛，其实还是蛮活跃的，更新很多插件和模板等。我之前用的markdown解析，它会阻碍其他很多插件的实现，是我误以为很多插件均无效或者过期，最终决定放弃之前的markdown插件（EditorMD），使用typecho开发版原生的markdown编辑器。然后今天添加了好多功能（具体见博客相关）。三月的最后一天，又折腾了一天博客  ","description":"","id":77,"section":"posts","tags":["Manjaro","数据处理","巫师3","怀念","鲫鱼汤","疫情解封","流浪小狗","咖啡","博客维护","路网匹配","embedding","typecho"],"title":"2020-3","uri":"https://www.xunhs.cyou/posts/journals/138/"},{"content":" 关于QGIS若干记录\n 目录\n[TOC]\nInstall Ubuntu (16.04) 1 2 3 4 5  sudo sh -c \u0026#39;echo \u0026#34;deb http://qgis.org/ubuntugis xenial main\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list\u0026#39; sudo sh -c \u0026#39;echo \u0026#34;deb-src http://qgis.org/ubuntugis xenial main \u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list\u0026#39; sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install qgis python-qgis   PyQGIS 搭建PyQGIS环境（PyCharm）(QGIS3)(gdal)  Window安装OSGeo4W64。选择QGIS桌面版和gdal开发库安装(速度慢建议挂个代理)。 Setting up PyCharm for PyQGIS and Qt(参考1;参考2)  在根目录新建pycharm-pyqgis.bat,在脚本里面添加:  1 2 3 4 5 6 7 8 9 10 11 12 13 14  @echo off SET OSGEO4W_ROOT=D:\\Apps\\OSGeo4W64 SET PYCHARM=\u0026#34;D:\\Apps\\PyCharm 2019.2.2\\bin\\pycharm64.exe\u0026#34; call \u0026#34;%OSGEO4W_ROOT%\u0026#34;\\bin\\o4w_env.bat @echo off path %PATH%;%OSGEO4W_ROOT%\\apps\\qgis\\bin path %PATH%;%OSGEO4W_ROOT%\\apps\\Qt5\\bin path %PATH%;%OSGEO4W_ROOT%\\apps\\Python37\\Scripts set PYTHONPATH=%PYTHONPATH%;%OSGEO4W_ROOT%\\apps\\qgis\\python set PYTHONHOME=%OSGEO4W_ROOT%\\apps\\Python37 start \u0026#34;PyCharm aware of QGIS\u0026#34; /B %PYCHARM% %*    - 根据安装情况修改OSGEO4W_ROOT和PYCHARM - 运行`pycharm-pyqgis.bat`，新建项目。设置项目解释器=`D:\\Apps\\OSGeo4W64\\bin\\python3.exe` - 运行以下代码进行测试: ```Python import qgis.core import PyQt5.QtCore  不报错就没问题了  猜想搭建arcpy环境时也可以用类似方法。!  插件库 Note: 在插件管理的Settings中勾选Show also experimental plugins\n地图底图插件  OpenLayers Plugin QuickMapServices ","description":"","id":79,"section":"posts","tags":["QGIS","PyQGIS","Python","GIS开发","学习笔记"],"title":"学习笔记-QGIS","uri":"https://www.xunhs.cyou/posts/notes/2020-02-29-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-qgis/"},{"content":" kaggle中处理预测问题通用流程/基本框架，参考\nHow to get to TOP 25% with Simple Model (sklearn)\n case complete: House Prices: Advanced Regression Techniques\n目录\n[TOC]\nInit Adding needed libraries and reading data\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn import ensemble, tree, linear_model from sklearn.model_selection import train_test_split, cross_val_score from sklearn.metrics import r2_score, mean_squared_error from sklearn.utils import shuffle %matplotlib inline import warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;) train = pd.read_csv(\u0026#39;/kaggle/input/house-prices-advanced-regression-techniques/train.csv\u0026#39;) test = pd.read_csv(\u0026#39;/kaggle/input/house-prices-advanced-regression-techniques/test.csv\u0026#39;)   Checking for NAs Checking for missing data\n1 2 3  NAs = pd.concat([train.isnull().sum(), test.isnull().sum()], axis=1, keys=[\u0026#39;Train\u0026#39;, \u0026#39;Test\u0026#39;]) NAs[NAs.sum(axis=1) \u0026gt; 0]    output      Train Test     Alley 1369 1352   BsmtCond 37 45   BsmtExposure 38 44   BsmtFinSF1 0 1   BsmtFinSF2 0 1   BsmtFinType1 37 42   BsmtFinType2 38 42   BsmtFullBath 0 2   BsmtHalfBath 0 2   BsmtQual 37 44   BsmtUnfSF 0 1   Electrical 1 0   Exterior1st 0 1   Exterior2nd 0 1   Fence 1179 1169   FireplaceQu 690 730   Functional 0 2   GarageArea 0 1   GarageCars 0 1   GarageCond 81 78   GarageFinish 81 78   GarageQual 81 78   GarageType 81 76   GarageYrBlt 81 78   KitchenQual 0 1   LotFrontage 259 227   MSZoning 0 4   MasVnrArea 8 15   MasVnrType 8 16   MiscFeature 1406 1408   PoolQC 1453 1456   SaleType 0 1   TotalBsmtSF 0 1   Utilities 0 2    Importing public functions 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # Prints R2 and RMSE scores def get_score(prediction, lables): print(\u0026#39;R2: {}\u0026#39;.format(r2_score(prediction, lables))) print(\u0026#39;RMSE: {}\u0026#39;.format(np.sqrt(mean_squared_error(prediction, lables)))) # Shows scores for train and validation sets  def train_test(estimator, x_trn, x_tst, y_trn, y_tst): prediction_train = estimator.predict(x_trn) prediction_test = estimator.predict(x_tst) # Printing estimator print(estimator) # Printing train scores print(\u0026#34;Train\u0026#34;) get_score(prediction_train, y_trn) # Printing test scores print(\u0026#34;Test\u0026#34;) get_score(prediction_test, y_tst)   Splitting to features and labels and deleting variables I don\u0026rsquo;t need 1 2 3 4 5 6 7 8 9 10 11  # Spliting to features and lables and deleting variable I don\u0026#39;t need train_labels = train.pop(\u0026#39;SalePrice\u0026#39;) features = pd.concat([train, test], keys=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;]) # I decided to get rid of features that have more than half of missing information or do not correlate to SalePrice features.drop([\u0026#39;Utilities\u0026#39;, \u0026#39;RoofMatl\u0026#39;, \u0026#39;MasVnrArea\u0026#39;, \u0026#39;BsmtFinSF1\u0026#39;, \u0026#39;BsmtFinSF2\u0026#39;, \u0026#39;BsmtUnfSF\u0026#39;, \u0026#39;Heating\u0026#39;, \u0026#39;LowQualFinSF\u0026#39;, \u0026#39;BsmtFullBath\u0026#39;, \u0026#39;BsmtHalfBath\u0026#39;, \u0026#39;Functional\u0026#39;, \u0026#39;GarageYrBlt\u0026#39;, \u0026#39;GarageArea\u0026#39;, \u0026#39;GarageCond\u0026#39;, \u0026#39;WoodDeckSF\u0026#39;, \u0026#39;OpenPorchSF\u0026#39;, \u0026#39;EnclosedPorch\u0026#39;, \u0026#39;3SsnPorch\u0026#39;, \u0026#39;ScreenPorch\u0026#39;, \u0026#39;PoolArea\u0026#39;, \u0026#39;PoolQC\u0026#39;, \u0026#39;Fence\u0026#39;, \u0026#39;MiscFeature\u0026#39;, \u0026#39;MiscVal\u0026#39;], axis=1, inplace=True)     features = pd.concat([train, test], keys=['train', 'test']) 为上下拼接，并添加\u0026rsquo;train', \u0026lsquo;test\u0026rsquo;标签\n  有人说不建议在一开始丢弃变量\n   Don\u0026rsquo;t discard variables unless you have a good reason for it. Note that it is not a good reason to say it\u0026rsquo;s not correlated. Tree algorithms can use the information and are not harmed by including it. A good reason for excluting could be using KNN. The other main reason for discarding variables are if they are correlated with being in the test or training set e.g. in many competitions you goal is to predict out of time. So including time can be very harmfull.\n Filling NAs and converting features  取代NA值得方法  数值型  众数（filling with most popular values） 1  features[\u0026#39;MSZoning\u0026#39;].fillna(features[\u0026#39;MSZoning\u0026#39;].mode()[0])    0（filling with 0） 1  features[\u0026#39;TotalBsmtSF\u0026#39;].fillna(0)    平均值（filling with means） 1  features[\u0026#39;LotFrontage\u0026#39;].fillna(features[\u0026#39;LotFrontage\u0026#39;].mean())      category型  NA用新值代替 1  features[\u0026#39;Alley\u0026#39;].fillna(\u0026#39;NOACCESS\u0026#39;)          1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  # MSSubClass as str features[\u0026#39;MSSubClass\u0026#39;] = features[\u0026#39;MSSubClass\u0026#39;].astype(str) # MSZoning NA in pred. filling with most popular values features[\u0026#39;MSZoning\u0026#39;] = features[\u0026#39;MSZoning\u0026#39;].fillna(features[\u0026#39;MSZoning\u0026#39;].mode()[0]) # LotFrontage NA in all. I suppose NA means 0 features[\u0026#39;LotFrontage\u0026#39;] = features[\u0026#39;LotFrontage\u0026#39;].fillna(features[\u0026#39;LotFrontage\u0026#39;].mean()) # Alley NA in all. NA means no access features[\u0026#39;Alley\u0026#39;] = features[\u0026#39;Alley\u0026#39;].fillna(\u0026#39;NOACCESS\u0026#39;) # Converting OverallCond to str features.OverallCond = features.OverallCond.astype(str) # MasVnrType NA in all. filling with most popular values features[\u0026#39;MasVnrType\u0026#39;] = features[\u0026#39;MasVnrType\u0026#39;].fillna(features[\u0026#39;MasVnrType\u0026#39;].mode()[0]) # BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2 # NA in all. NA means No basement for col in (\u0026#39;BsmtQual\u0026#39;, \u0026#39;BsmtCond\u0026#39;, \u0026#39;BsmtExposure\u0026#39;, \u0026#39;BsmtFinType1\u0026#39;, \u0026#39;BsmtFinType2\u0026#39;): features[col] = features[col].fillna(\u0026#39;NoBSMT\u0026#39;) # TotalBsmtSF NA in pred. I suppose NA means 0 features[\u0026#39;TotalBsmtSF\u0026#39;] = features[\u0026#39;TotalBsmtSF\u0026#39;].fillna(0) # Electrical NA in pred. filling with most popular values features[\u0026#39;Electrical\u0026#39;] = features[\u0026#39;Electrical\u0026#39;].fillna(features[\u0026#39;Electrical\u0026#39;].mode()[0]) # KitchenAbvGr to categorical features[\u0026#39;KitchenAbvGr\u0026#39;] = features[\u0026#39;KitchenAbvGr\u0026#39;].astype(str) # KitchenQual NA in pred. filling with most popular values features[\u0026#39;KitchenAbvGr\u0026#39;] = features[\u0026#39;KitchenAbvGr\u0026#39;].astype(str) features[\u0026#39;KitchenQual\u0026#39;].fillna(features[\u0026#39;KitchenQual\u0026#39;].mode()[0]) # FireplaceQu NA in all. NA means No Fireplace features[\u0026#39;FireplaceQu\u0026#39;] = features[\u0026#39;FireplaceQu\u0026#39;].fillna(\u0026#39;NoFP\u0026#39;) # GarageType, GarageFinish, GarageQual NA in all. NA means No Garage for col in (\u0026#39;GarageType\u0026#39;, \u0026#39;GarageFinish\u0026#39;, \u0026#39;GarageQual\u0026#39;): features[col] = features[col].fillna(\u0026#39;NoGRG\u0026#39;) # GarageCars NA in pred. I suppose NA means 0 features[\u0026#39;GarageCars\u0026#39;] = features[\u0026#39;GarageCars\u0026#39;].fillna(0.0) # SaleType NA in pred. filling with most popular values features[\u0026#39;SaleType\u0026#39;] = features[\u0026#39;SaleType\u0026#39;].fillna(features[\u0026#39;SaleType\u0026#39;].mode()[0]) # Year and Month to categorical features[\u0026#39;YrSold\u0026#39;] = features[\u0026#39;YrSold\u0026#39;].astype(str) features[\u0026#39;MoSold\u0026#39;] = features[\u0026#39;MoSold\u0026#39;].astype(str) # Adding total sqfootage feature and removing Basement, 1st and 2nd floor features features[\u0026#39;TotalSF\u0026#39;] = features[\u0026#39;TotalBsmtSF\u0026#39;] + features[\u0026#39;1stFlrSF\u0026#39;] + features[\u0026#39;2ndFlrSF\u0026#39;] features.drop([\u0026#39;TotalBsmtSF\u0026#39;, \u0026#39;1stFlrSF\u0026#39;, \u0026#39;2ndFlrSF\u0026#39;], axis=1, inplace=True)    根据变量描述和特征逐一分析 data_description MSSubClass: Identifies the type of dwelling involved in the sale. 根据释义， MSSubClass更应该是一种category类型，因此代码中通过类型变换为字符串再通过后续变换从而转化成 category 类型  Log transformation  log变换  1 2 3 4 5 6 7  # Our SalesPrice is skewed right (check plot below). I\u0026#39;m logtransforming it.  ax = sns.distplot(train_labels) ## Log transformation of labels train_labels = np.log(train_labels) ## Now it looks much better ax = sns.distplot(train_labels)     output\nAfter transform:\n  注意最后的预测值要用 np.exp() 变换为原维度\n  Standardizing numeric data  数值类型变量标准化  1 2 3 4 5  ## Standardizing numeric features numeric_features = features.loc[:,[\u0026#39;LotFrontage\u0026#39;, \u0026#39;LotArea\u0026#39;, \u0026#39;GrLivArea\u0026#39;, \u0026#39;TotalSF\u0026#39;]] numeric_features_standardized = (numeric_features - numeric_features.mean())/numeric_features.std() ax = sns.pairplot(numeric_features_standardized)    output  Converting categorical data to dummies 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # Getting Dummies from Condition1 and Condition2 conditions = set([x for x in features[\u0026#39;Condition1\u0026#39;]] + [x for x in features[\u0026#39;Condition2\u0026#39;]]) dummies = pd.DataFrame(data=np.zeros((len(features.index), len(conditions))), index=features.index, columns=conditions) for i, cond in enumerate(zip(features[\u0026#39;Condition1\u0026#39;], features[\u0026#39;Condition2\u0026#39;])): dummies.ix[i, cond] = 1 features = pd.concat([features, dummies.add_prefix(\u0026#39;Condition_\u0026#39;)], axis=1) features.drop([\u0026#39;Condition1\u0026#39;, \u0026#39;Condition2\u0026#39;], axis=1, inplace=True) # Getting Dummies from Exterior1st and Exterior2nd exteriors = set([x for x in features[\u0026#39;Exterior1st\u0026#39;]] + [x for x in features[\u0026#39;Exterior2nd\u0026#39;]]) dummies = pd.DataFrame(data=np.zeros((len(features.index), len(exteriors))), index=features.index, columns=exteriors) for i, ext in enumerate(zip(features[\u0026#39;Exterior1st\u0026#39;], features[\u0026#39;Exterior2nd\u0026#39;])): dummies.ix[i, ext] = 1 features = pd.concat([features, dummies.add_prefix(\u0026#39;Exterior_\u0026#39;)], axis=1) features.drop([\u0026#39;Exterior1st\u0026#39;, \u0026#39;Exterior2nd\u0026#39;, \u0026#39;Exterior_nan\u0026#39;], axis=1, inplace=True) # Getting Dummies from all other categorical vars for col in features.dtypes[features.dtypes == \u0026#39;object\u0026#39;].index: for_dummy = features.pop(col) features = pd.concat([features, pd.get_dummies(for_dummy, prefix=col)], axis=1)    Condition 和 Exterior 为特殊处理  Obtaining standardized dataset 1 2 3 4 5 6  ### Copying features features_standardized = features.copy() ### Replacing numeric features by standardized values features_standardized.update(numeric_features_standardized)   Splitting train and test features 1 2 3 4 5 6 7 8  ### Splitting features train_features = features.loc[\u0026#39;train\u0026#39;].drop(\u0026#39;Id\u0026#39;, axis=1).select_dtypes(include=[np.number]).values test_features = features.loc[\u0026#39;test\u0026#39;].drop(\u0026#39;Id\u0026#39;, axis=1).select_dtypes(include=[np.number]).values ### Splitting standardized features train_features_st = features_standardized.loc[\u0026#39;train\u0026#39;].drop(\u0026#39;Id\u0026#39;, axis=1).select_dtypes(include=[np.number]).values test_features_st = features_standardized.loc[\u0026#39;test\u0026#39;].drop(\u0026#39;Id\u0026#39;, axis=1).select_dtypes(include=[np.number]).values    两类特征数据，一类未标准化 一类标准化过的 适应不同模型  tree-based model无需标准化 线性模型需标准化    Splitting to train and validation sets 1 2 3 4 5 6  ### Shuffling train sets train_features_st, train_features, train_labels = shuffle(train_features_st, train_features, train_labels, random_state = 5) ### Splitting x_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.1, random_state=200) x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(train_features_st, train_labels, test_size=0.1, random_state=200)    shuffle 打乱数据顺序  First level models Elastic Net using ElasticNetCV estimator to choose best alpha and l1_ratio for my Elastic Net model\n1 2 3 4 5  ENSTest = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000).fit(x_train_st, y_train_st) train_test(ENSTest, x_train_st, x_test_st, y_train_st, y_test_st)    output  1 2 3 4 5 6  Train R2: 0.9015542514742068 RMSE: 0.11906917427161198 Test R2: 0.8983659574062 RMSE: 0.10972333168339993   1 2 3 4  # Average R2 score and standart deviation of 5-fold cross-validation scores = cross_val_score(ENSTest, train_features_st, train_labels, cv=5) print(\u0026#34;Accuracy: %0.2f(+/- %0.2f)\u0026#34; % (scores.mean(), scores.std() * 2))    output  Accuracy: 0.88 (+/- 0.09)\nGradient Boosting We use a lot of features and have many outliers. So I\u0026rsquo;m using max_features='sqrt' to reduce overfitting of my model. I also use loss='huber' because it more tolerant to outliers. All other hyper-parameters was chosen using GridSearchCV.\n1 2 3 4 5 6 7 8 9  GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features=\u0026#39;sqrt\u0026#39;, min_samples_leaf=15, min_samples_split=10, loss=\u0026#39;huber\u0026#39;).fit(x_train, y_train) train_test(GBest, x_train, x_test, y_train, y_test)   1 2 3 4 5 6  Train R2: 0.9618766649349884 RMSE: 0.07600479015539144 Test R2: 0.9046920143397521 RMSE: 0.10696670219256725   1 2 3 4  # Average R2 score and standart deviation of 5-fold cross-validation scores = cross_val_score(GBest, train_features_st, train_labels, cv=5) print(\u0026#34;Accuracy: %0.2f(+/- %0.2f)\u0026#34; % (scores.mean(), scores.std() * 2))   Accuracy: 0.89 (+/- 0.04)\nEnsembling final model final ensemble model is an average of Gradient Boosting and Elastic Net predictions. But before that I retrained my models on all train data.\n1 2 3 4 5 6 7  # Retraining models GB_model = GBest.fit(train_features, train_labels) ENST_model = ENSTest.fit(train_features_st, train_labels) ## Getting our SalePrice estimation Final_labels = (np.exp(GB_model.predict(test_features)) + np.exp(ENST_model.predict(test_features_st))) / 2    融合模型，取输出的平均值  Saving to CSV 1 2  pd.DataFrame({\u0026#39;Id\u0026#39;: test.Id, \u0026#39;SalePrice\u0026#39;: Final_labels}).to_csv(\u0026#39;2020-02-25.csv\u0026#39;, index =False)   ","description":"","id":80,"section":"posts","tags":["Kaggle","预测模型","比赛"],"title":"Kaggle-Starter Simple Framework For Prediction Issues","uri":"https://www.xunhs.cyou/posts/notes/2020-02-25-kaggle-starter_simple_framework_for_prediction_issues/"},{"content":" 论文阅读，感兴趣点、关键词整理\n 博士论文: 基于出租车数据的城市居民活动空间与网络时空特性研究  大多数研究对于活动数据仅使用活动开始和结束的位置点数据，忽略行驶轨迹，数据利用不充分。 从个人轨迹段和POI时空吸引力棱镜的时空关系出发，确定个体活动所在的POI。 空间句法（space syntax）被用来解释道路网结构与城市布局之间的关系 空间句法将现实空间抽象表达为符号空间，如将道路段抽象为点，并利用句法模型的计算与分析将具有拓扑关系的图解与变量一一对应，成功将城市空间引入定量的表达。 基于重力模型计算可达性指标的方法 将空间划分为格网，定义出租车GPS轨迹为伪格网序列(pseudo cells)  计算轨迹长度并不是出租车实际行驶的网络距离 忽略路网环境导致在分析轨迹特征时无视城市交通条件   判别轨迹异常程度的指标  距离约束：实际距离与最短路径之间的量化差异 规避路段约束 时间约束。   出租车经过的城市关键结点  Journal Article: 2013-Land-Use Classification Using Taxi GPS Traces  Refer: IEEE Transactions on Intelligent Transportation Systems AAAA GPS traces of vehicles human mobility and activity information, which can be closely related to the land use of a region recognizing the social function of urban land pick-up/set-down(set-down表示下车点比较少见，用drop-off吧) dynamics/pattern:上下车模式 作者总结的贡献：   关于Remote sensing based land use classification\n Previous (2013) land-use classification research was based on the physical properties of studied objects in remote-sensing data Most urban land-use classification research has used remote-sensing data, particularly satellite images.  satellite resolution spectral reflectance and the nature of the materials methods: Pixel-based classification \u0026amp; Object-based classification      we verify that the social function of a certain urban area can be characterized by the temporal and spatial dynamics of the taxi pick-up/set-down number (the temporal and spatial dynamics: simply describe the variation of pick-up/set-down number over time)\n 换一种说法: verified that there is an inherent relationship between land-use classes and the temporal pattern of taxi pick-up/set-down dynamics    designed six features extracted from the pick-up/set-down data of different time lengths\n six features(P7): a recognition accuracy of 95% (太高了？几分类？)534 regions with eigth kinds of social functions: Four classical classifiers are evaluated(All the parameters for the algorithms are optimized.):  linear-kernel SVM (Best Classification Result with Feature I + II) k-nearest neighbor linear discriminate analysis three-layer BP      social function transition (变更) of regions\n   相关文献  taxi trace data  Ubiquitous mobility data contain information that is important for the smart environment; reflect urban traffic behaviors and convey lots of information about a city Taxi trace data could be used for:   urban land-use classification approaches using mobility data for land-use classification in the literature  clustering algorithm more land-use classes origin-destination(OD) flows      Journal Article: 2020-The Traj2Vec model to quantify residents’ spatial trajectories and estimate the proportions of urban land-use types  Refer: IJGIS; iGEODATA AAAAA Abstract  geo-semantic mining approach: quantify the trajectories of residents as highdimensional semantic vectors RF: model the relationship between the semantic vectors and\nmixed urban land uses 讲的一手好故事[分析混合指数和旅行距离之间的关系，发现他们之间有一种显著的（弱的）负相关关系，表明土地利用混合指数增加，居民出行距离缩短，进一步减少了能源消耗。]: analyzing the mixing index and the travel distance, a weak but significant negative correlation between them; an increase in the degree of mixing will reduce the travel distances of residents.   Introduction  urban land use  the spatial distribution of urban land use urban land uses and urban spatial structures have become increasingly diverse and sophisticated obtaining qualitative and quantitative data on mixed urban land uses quickly and accurately is very important for understanding and managing cities There is a general lack of such studies, because mixed urban land use is difficult to estimate using conventional methods.   trajectory data (套路讲的是极好的)  [所谓居民活动数据]Human activity data can provide more detailed and accurate information for analyzing mixed urban land-uses since urban land use is defined as the use of the urban space by residents and the activities within that area = (the data contain valuable information on how people utilize urban spaces) [LBSs能够提供居民活动信息，并用于城市空间结构研究]The rapid development of location-based services (LBSs) provides us with a large amount of human activity information that can be used to measure urban spatial structures and land uses. In particular, trajectory information is generated by residents in their daily lives and can represent the resident’s behavioral purposes. [以往的研究仅使用简单的特征] previous studies have only taken some simple features from human activity data, such as the frequency and volume. These methods may waste the majority of the spatial information and the inner spatial correlations in human activity data   geo-semantic mining techniques(大论文可参考)  explore the spatial semantic features of geospatial data [NLP中的语义挖掘]In NLP, semantic mining refers to the transformation of words, phrases, signs, and symbols into forms that computers can recognize and understand the relationships between them. Semantic information is a digital high-dimensional feature vector that can fully characterize these relationships. [地理语义挖掘解释]geo-semantic mining refers to mining potential relationships in geographical data. By exploiting the potential relationships, we can fully extract the information inside geographical data and apply it in various geographic applications. [目前的地理语义挖掘研究]Existing research on geo-semantic mining show that the semantic model can well discover the potential semantic information of the geospatial data, and the obtained information can be used to quantify the relationship between the urban land uses and geospatial data [文中的语义与传统的地理信息语义的关系]: In particular, there are some differences between the semantics here and the traditional geographical semantics. The semantics here is an abstract concept that uses feature vectors to represent the potential relationship within geographic data. Traditional geographic semantics refers to describing the meaning of spatial data and the relationship between them, and making the semantics of geographic information explicit.   consider the spatial context in spatial data  introduced the Word2Vec model to measure the potential contextual relationships between POIs and obtained satisfactory results in the classification of detailed urban land uses [POI数据是空间离散的，构建连续序列的方法很大程度上影响空间上下文关系]POIs are spatially discrete, so some methods were also developed to construct a continuous dataset from POIs. The method used to construct a continuous POI dataset largely affects the spatial contextual relationships, thus affecting the result of urban land-use identification [由POI的空间离散引申到轨迹的连续]A trajectory is continuous in space, and a person’s travel information can reflect the use of urban space. Therefore, it is expected that the use of the Word2Vec model to explore the potential semantic information in a trajectory can help us to better understand structures and land uses.      Journal Article: 2017-Road2Vec: Measuring Traffic Interactions in Urban Road System from Massive Travel Routes  Refer: IJGI AAA Abstract  [交通互作用？(反复出现)/我觉得用Traffic-Flow Dependency更恰当一些]traffic interactions among urban roads; quantify the implicit traffic interactions; can be effectively utilized for quantifying complex traffic interactions among roads and capturing underlying heterogeneous and non-linear properties large-scale taxi operating route data   Introduction  [城市道路的交通状况通常受邻近道路的影响]The traffic states of urban roads are often influenced by their neighboring roads. Different terms, such as spatial dependency/relationship in traffic and spatial correlation, are used in the literature to express such relationship between neighboring roads. In this paper, we use the term traffic interaction to describe the traffic influence between neighboring roads, which is fundamentally caused by the dynamic vehicle movements from one road to another. [道路之间的交互源于车辆的移动；因此道路之间的本质联系可以从车辆轨迹之间获取]Essentially, the traffic influence among roads originates from numerous vehicle movements on road systems; hence, the inherent relationships among roads should be extracted from massive vehicle travel routes. [向量之间的相似性解释]According to the principle of word embedding models, a high similarity between two word vectors indicates that the two words co-occur frequently in textual documents or their local contexts are very similar. Correspondingly, high similarity between two road segment vectors indicates that two road segments frequently co-occur in travel routes or they frequently share common upstream and/or downstream segments in travel routes. Both situations indicate that there are strong traffic interactions. [浮动车数据] (low-frequency) floating car data (FCD) collected by GPS-equipped taxies; [乘客上下车位置]passengers’ pick-up and drop-off locations; mapping each GPS point to a road segment=\u0026gt;travel routes [看来大家都喜欢计算这个平均相似度]calculate the average similarities of vectors among the first-order, second-order, third-order, and fourth-order neighboring roads, respectively    Journal Article: 2019-Identifying spatial interaction patterns of vehicle movements on urban road networks by topic modelling  Refer: CEUS; 未名时空 AAA 与上一篇(Road2Vec)同作者traffic interaction =\u0026gt; spatial interaction Abstract  investigate the spatial interactions derived from human movements = identify spatial interaction patterns of vehicle movements on urban road network [城市居民移动受限于车辆和城市路网=\u0026gt;道路之间的交互]in most cases, human movements are carried by vehicles and constrained by the underlying road network, which causes the interactions among roads \u0026ldquo;strokes\u0026rdquo; (i.e., natural streets) are chosen as geographical units to represent the vehicle moving paths.    Journal Article: 2017-Street as a big geo-data assembly and analysis unit in urban studies: A case study using Beijing taxi data  Refer: Applied Geography AAAAA 学会戴帽子 Abstract  understanding urban environments Spatial assembly: an essential analytical step to summarize and perceive geographical environment from individual behaviours [街道尺度]the adopted spatial units for data aggregation remain areal in nature; sensing cities from a street perspective, emphasizes the significance of street units in quantitative urban studies three-month taxi trajectory dataset [道路的动态功能和承载力]explore the spatio-temporal patterns of urban mobility on streets, cluster streets into nine types based on their dynamic functions and capacities is able to effectively minify the modifiable areal unit problem (MAUP) [意义套装]sense urban dynamics, depict urban functions, and understand urban structures   Introduction  [传感器数据]Through automated and routine movement tracking of individuals, various forms of locator devices work as sensors to collect geospatial data and characterize the activity of a city in both spatial and temporal perspectives [两个角度的帽子]From the perspective of individuals, citizens play the role of voluntary sensors and produce plenty of volunteered geographic information. At the collective level, the distribution of geographic phenomena such as land use (or social function) and the pattern of spatial interaction flows can be investigated after spatio-temporal aggregation of individual behaviour data. [两种属性用于理解城市问题]Utilizing massive amounts of geospatial data, the first-order distribution of urban attributes (e.g., economic indices, population intensity, condition of public facilities), as well as second-order interactions (e.g., human movements, flow of goods, financial flows, social ties) can be used to better understand human mobility, urban functions, and urban structures [空间集配(?)中的MAUP问题]Spatial assembly: inevitable to confront the issue of spatial resolution (or scale) when mapping individual details onto regular or irregular units  Voronoi polygons regular grids   [街道尺度研究的意义]using streets as the basic elements to characterize urban functions and understand urban structures.  the street system is never an insignificant part of a city. Lynch的城市映象,path为首 [城市内部的移动受路网/街道限制]It is now generally accepted that the physical movement in an urban space is usually constrained by a road network and streets interlink urban functions physically and cognitively [面状研究单元的替代]street unit is a promising substitute for areal units and can help us uncover hidden knowledge concealed under areas     Methodology  Temporal patterns of pick-ups and drop-offs Association of street classifications with dynamic street\npatterns  Hierarchical clustering based on dynamic street functions and\ncapacities: (1) vector; (2) normalization; (3) unsupervised hierarchical bisecting k-means clustering. Characterizing street types by dynamic functions and capacities: (1) classified into nine types. Uncovering urban structures in the street perspective: (1) Uncovering urban structures in the street perspective; (2) detect communities with the best modularity.   The complexity of streets  [未考虑土地利用的复杂性]comprise the complex land uses along streets [未考虑双向道路属性]the bidirectional nature of streets is not considered in our work for simplicity.      Journal Article: 2016-Incorporating spatial interaction patterns in classifying and understanding urban land use  Refer: IJGIS Abstract  Land use classification travel behaviour [(大数据)作为传统遥感影响数据方法的一种补充]complementing the outcome of traditional remote sensing methods spatial interaction patterns [未能得到验证和分析]have rarely been examined and analysed unsupervised land use classification method   Introduction  Traditionally, researchers collect residents’ trip information by travel surveys understand human movements and urban built environments [城市居民活动的追踪/足迹]the spatial footprints of citizens’ activities [人们的移动是可以预测的]people’s mobilities are highly predictable emphasizes the social function of a place [相同土地利用类型的区域用相似的时空活动模式]The routines of people guarantee that places of the same land use type, to some extent, share similar temporal activity variations. [仅仅扩充时空活动变量是无法补救的]simply adding more features of temporal activity variations for land use classification is not a remedy. [考虑轨迹连续性，提取交通流(特征)]consider the movement between two consecutive activities as a travel and extract traffic flows from the trajectory data    Journal Article: 2019-Detecting regional dominant movement patterns in trajectory data with a convolutional neural network  Refer: IJGIS Abstract  movement pattern detection detect regional dominant movement patterns (RDMP) in trajectory data a novel feature descriptor  directional flow image (DFI) to store the local directional movement information   a classification model  TRNet, designed based on CNN trained with a synthetic trajectory dataset [合成轨迹数据]   a sliding window detector - detect RDMP at multiple scales a clustering-based merging method - prune the redundant detection results Evalution  high training accuracy experiments on a real-world taxi trajectory dataset   Introduction  [移动模式重要性] Movement patterns embedded in trajectory data can provide valuable information for the tracked objects and the context, which play an important role in many applications. previous work =\u0026gt; low generalization capability [深度学习应用在交通领域的一些尝试] several attempts have been made in the transportation domain to employ deep learning methods to exploit the value of big data. Conventional CNN models  the input of CNN is required to be a fixed tensor A trajectory can contain a variable number of points, which belongs to vector data a trajectory provides two additional pieces of information: direction and connectivity between points   To address the above problem, this paper\u0026hellip;      ","description":"","id":81,"section":"posts","tags":["出租车轨迹","轨迹","Trajectory","论文","论文阅读","Human activity data","NLP","semantic","geo-semantic mining","geo-semantic","spatial context","interactions","vehicle moving paths"],"title":"Papers Reading-Taxi Trajectory/GPS Records","uri":"https://www.xunhs.cyou/posts/notes/2020-02-24-papers_reading-taxi_trajectory_gps_records/"},{"content":" 整理和总结了论文写作中关于城市主题模型、城市功能区域挖掘相关的短语词组或相关句型句式。\n 短语   城市功能区  urban function(s) urban functional zones urban functional areas    城市土地利用、土地利用斑块  (urban) land use land use of parcels    城市空间，城市环境，城市空间上下文  urban space, e.x., utilization of urban space 城市空间的利用 land parcels with diverse functions 不同功能的城市斑块 urban spatial structure 城市空间结构 spatial and social structure of urban environments 城市环境的空间和社会结构 (urban) socioeconomic environments 社会经济环境 in the context of geographical space 城市空间上下文    提取/描绘/识别/挖掘/探索/划分 城市功能区  infer/delineate/identified/discover/detect ~ understanding, representing, and reasoning accurate classification of urban functional zones 城市功能区的精确划分 sensing the spatial structures of urban land use quickly 感知城市土地利用的空间结构 identifying urban function structures accurately 识别城市功能结构 infer the territory of these functions 推断城市功能区的范围     地理空间/土地的一种特征/属性  an attribute of land geospatial features    城市交通，公共安全，城市管理  the city transportation, public security, and management    城市系统的复杂性  the comlexity of urban systems    高分辨率遥感影像  High spatial resolution (HSR) remote sensing images    作用，意义类描述  improve urban vitality 提升城市活力 meet the daily living needs of citizens 满足城市居民的日常需求 to better serve residents and their cities 更好的服务城市居民 The rational distribution of urban functions facilitates the daily living of citizens. 城市功能区的合理布局促进城市居民的日常生活。 characterize intra-city urban spatial structure 特征化城市空间结构 inform future planning and policy evaluation 未来规划和规划评价做参考 design better urbanization strategies for the future 设计更好的城市化策略      摘句 \u0026nbsp;   作用，意义类描述  Urban land use information plays an important role in urban management, government policy-making, and population activity monitoring. （城市土地利用信息在城市管理，政府决策和人类活动监测方面占用重要地位。） Land use and land cover (LULC) information comprises essential geographical spatial features for many fields, such as urban planning, government management, and sustainable development (可持续发展).（土地利用和土地覆盖信息包含大量的基本地理空间特征对许多领域，如。。。何可持续发展。） As an attribute of land, the urban function indicates the types of potential activities in such areas.（作为土地的一种属性，城市功能区表明该区域潜在活动的类型。） Cities support a variety of functions that relate to land use types, including residential, commercial, industrial, transportation, and business regions and infrastructure, while affording different types of human activities, such as living, working, commuting, shopping, eating, and recreation. 城市支持了与土地利用类型相关的大量功能，包括居住，金融，工业，交通，商业和基础设施，承载着不同类型的人类活动，如居住，工作，通勤，购物，饮食和休闲娱乐。 Cities consist of many different functional regions that interact with each other, which generates the complexities that shape a city. 城市中包含许多相互交互的不同功能区，促使城市的多样性。 The step of urbanization and modern civilization leads to (gradually fosters) different functional regions in a city, e.g., residential areas, business districts, and educational areas, which support different needs of people’s urban lives and serve as a valuable organizing technique for framing detailed knowledge of a metropolitan. 城市化和现代化的脚步（进步）促使在城市中形成了多种功能区，例如居住区，商业区和教育区等，这些功能区支持者生活在城市中的人们的不同需求，同时作为一种高价值的对城市理解和知识的组织技术。 Hence, sensing the spatial structures of urban land use quickly and identifying urban function structures accurately are of great significance in formulating effective policies and regulations for urban planning. 因此，感知城市土地利用的空间结构和识别城市功能结构在城市规划高效决策中有重要作用。 The discovered functional regions help people easily understand a complex metropolitan, benefiting a variety of applications, such as urban planning, location choosing for a business, advertisement casting, and social recommendations.功能区域（的发现）帮助人们理解复杂城市，有助于大量应用，如城市规划，商业位置选址，广告投放，社交推荐等。 对于从事城市规划的专家学者和城市的管理者来说，城市功能区的识别和区域重要程度分析可以启发城市的合理规划。城市空间布局复杂，区域功能发展很难预测和掌控。城市功能区的识别既可以对之前政策规划用地有效验证，同时又可以很好的监督土地使用情况指导城市可持续发展，协调管理城市资源环境的配置。对于城市居民来说，基于轨迹数据挖掘与兴趣点语义分析的城市功能区识别方法可以为商家和宅基地选址提供便利。合理的功能区分布也为城市居民的公共服务提供保障，使公共管理更加智慧，居民生活质量得到提升。    研究进展相关  The effective detection of urban land use patterns, which are significant for formulating effective urban planning policies, has been a controversial issue in recent studies. 有效的监测城市土地利用模式，成为一个近期研究中争议性的话题。 Regarding temporal activity signatures as the proxy of human activities, the close relationship between human activity patterns and urban functions has been recognized. 将人类活动特征作为代理，挖掘人类活动模式与城市功能区之间的关系。    城市快速发展，城市化进程  China's repid economic and urban developments have generated diverse and sohisticated(复杂的) urban functional zones which reflect in urban land use patterns. 中国快速的经济和城市发展促使多样和复杂的城市功能区的生成，反映城市土地利用模式。 In recent years, rapid urbanization and modern civilizations have generated diverse and sophisticated urban land use types, such as residential areas, education facilities and business districts, at different scales in China. 在最近几年，快速的城市化和现代文明化进程存生了多样的，复杂的和多尺度的土地利用类型，比如说居住区，教育设施，商业区。    城市功能区域/城市土地利用的支配性，受多方面影响  Urban function is directly determined by human activities and also related to the land use type, which is a static attribute planned by the government.（城市功能直接由人类活动决定，同时也与土地利用类型相关，这种土地利用类型是一种受政府部门规划的静态属性。） Urban land use patterns are affected not only by government policies but also indoor lifestyles, which are continuously changing with urban development.（城市土地利用模式不仅受政府决策的支配，同时受到持续变化的生活环境的影响。） Urban or regional land use patterns are not only determined by urban layouts specified by governments but also affected by people’s lifestyles, which cannot be stereotyped and are continuously changing with further urban development.（城市和局部土地利用模式不仅受政府决策的支配，同时受人们生活方式的影响。） Urban regions may be artificially designed by urban planners, or naturally formulated according to people’s actual lifestyle, and would change functions and territories (区域，范围) with the development of a city. (城市区域可能又城市规划者的人为设计，或者受到人们生活方式的自然影响，并且城市区域会受到城市发展而改变功能和范围)    数据层面描述，地理大数据  The development of information and communication technology (ICT) offers the opportunity to gain a significant amount of geo-data with fine-grained human activity information. Spatial-temporal analyses of human activities based on big geo-data, such as social media check-in data, taxi trajectory data, and mobile phone data, benefit the understanding of socioeconomic environments.（信息交流技术的快速发展提供一个重要的机会获取大量的地理数据，揭示细粒度的人类活动信息。基于这些地理数据的人类活动时空分析，例如社交媒体签到数据，出租车轨迹数据，移动手机数据，促进对社会经济环境的理解。） There is a growing trend of using location-awareness sensing data (e.g., trajectories from mobile phones), POI data, and social media feeds to study the spatial and social structure of urban environments.基于位置感知传感器数据，POI数据和社交媒体数据来研究城市环境的空间和社会结构受到越来越多的关注。     遥感影像描述  High spatial resolution (HSR) remote sensing images enable computation-based urban land use detection, where HSR image classification models have been extensively applied to extract and analyze LULC in recent studies.（高分辨率遥感影像使基于计算的城市土地利用监测成为可能，大量高分辨率遥感影像分类模型被广泛应用在提取和分析LULC研究中。） Analyses of urban LULC are primarily conducted with three types of spatial units; units of pixels and objects are usually employed to evaluate land cover, whereas scenes are commonly used to identify urban functional zones and accurate urban land use patterns. （分析城市LULC主要应用三种类型的空间单元。基于像素和基于对象的方法通常应用在评估土地覆盖，基于场景的方法通常应用于识别城市功能区域和土地利用模式。） Many studies applied object-oriented classification (OOC) models to extract urban land use patterns using physical features (such as spectral, shape, and texture features) of ground components. However, OOC models often overlook the spatial distribution and semantic features of ground components because they were only designed to mine the low-level semantic land cover information of ground components.（很多研究应用地面的物理特征（光谱，形状和纹理特征），采用基于对象的分类模型来提取城市土地利用模式。然而OOC模型通常忽视了地面的空间分布和语义特征。。） Remote sensing images together with spatial metrics have been widely used to classify urban land use and monitor change at different spatial scales.（基于空间指标的遥感影像已经被广泛应用于不同尺度的城市土地利用分类和监测。） However, human activities usually take place in different types of points of interest (POIs). Remote sensing techniques perform well in extracting physical characteristics, such as land surface reflectivity and texture of urban space but are not good in identifying functional interaction patterns or in helping understand socioeconomic environments. Compared with other datasets and methods in remote sensing and field mapping, using POI data, social media, and their associated methods can lead to a better understanding of individual- and group-level utilization of urban space at a fine-grained spatial and temporal resolution. （然而，人类活动通常在不同类型的POI发生。遥感技术在提取物理特征，如土地覆盖反射率和城市空间纹理，等特征时表现优异，但是并不擅长于识别功能交互模式或者理解社会经济环境。对比遥感和制图领域的其他数据集和相关方法，使用POI数据，社交数据和他们相应的方法可以更好的理解不同时空尺度的，以个人为单元、以集体为单元的城市空间利用。） However, methods derived for pure RS images can only reflect the natural properties of ground objects. Land use types in a region often have strong relationships with inner social–economic activities, which is difficult to detect from pure RS imagery. （然而，由纯遥感影像衍生的方法仅仅反映地表物体的自然属性。区域内的土地利用类型通常与内容的社会经济活动由强相关性，纯遥感方法是无法检测的。） Conventional methods of delineating urban functional areas heavily rely on remote sensing images. Although remote-sensing based methods are capable of capturing physical changes of urban functional areas, they do not provide sufficient socioeconomic information relating to urban functional areas. （描绘城市功能区传统的方法依赖于遥感影像。虽然基于遥感影像的方法能够捕捉城市功能区的物理变化，但是它们并不能提供充分的有关城市功能区域的社会经济信息。）    POI  The same types of POIs can be located in different land use types and may also support different functions. （相同类型的POI可能出现在不同的土地利用类型，也可能支持不同的功能。） We argue that geographic knowledge and measures of spatial distribution over POI types (categories) can be employed to derive latent classification features for these types, which will then enable the detection and the abstraction of higher-level functional regions (i.e., semantically coherent areas of interest) such as shopping areas, business districts, educational areas, and tourist zones.我们假设地理知识和POI类型的空间分布之间的测度可以被应用于潜在分类特征，这些潜在分类特征可以用于检测和抽象化高等级的功能区域，如购物区，商业区，教育区和旅游区。 POIs can effectively present regional functions as a result of their high accessibility from the Internet. In recent years, numerous in-depth discussions have been conducted to classify urban land use via POIs.POI可以较容易的从网上获取，可以有效的表达区域功能。在最近几年，应用POI进行城市土地利用划分吸引了大量的深入的讨论。 Previous studies have demonstrated that different POI types have distinctive semantic signatures (i.e., spatial, temporal, and thematic distributions) based on crowd-sourced location-based social media data analysis, in analogy to spectral bands in remote sensing.以往的研究表明通过将POI类比为遥感影像的光谱带，不同的poi类型存在显著地语义特征差异（空间，时间和主题分布）。 Moreover, due to the complexity of urban land use, it is clearly unsatisfactory to analyze land use patterns via POI frequencies alone.由于城市土地利用的复杂性，显然仅通过POI频率来分析土地利用模式是不可取的。 The abovementioned studies only take frequencies of POIs as the judgment of a region’s land use types without considering inner spatial correlations, which may lead to most of the spatial information of POIs being wasted.仅仅考虑POI的频率作为区域土地利用类型的评价指标，忽视了POI之间的内部关联，浪费了众多POI的空间信息。 By exploiting the potential of context relationships, information inside POIs can be better mined.通过探索上下文关系的潜力，POIs之间的相关信息被更好的利用（考虑）。     ","description":"","id":82,"section":"posts","tags":["摘抄","Writing","论文"],"title":"论文写作摘抄-城市功能区域挖掘","uri":"https://www.xunhs.cyou/posts/notes/127/"},{"content":" 英文邮件常用表达。同时很多内容可以用在论文审阅回复reviewer邮件中。\n参考自：哪些句子拯救了你的英文邮件？\n 目录\n[TOC]\n称呼  一般不加Dear 普通邮件：直接称呼名字即可。Hi Steven 学术场合：加抬头。 Hi Prof.Johnson  感谢  开头，感谢别人回复自己的邮件  Thanks for the quick reply. Thanks for getting back to me. Thanks for the update on the situation. Thanks for the updated information. Thanks for gathering the information this week on this issue.   也可以用thank you，在稍微正式场合。 简单回复，表示感谢  Thank you. Well noted. Noted/Received with thanks. Good information.    道歉  回复邮件晚了，先道歉  Sorry I haven\u0026rsquo;t got back to you sooner. Sorry for the delay getting back to you. 以上sorry替换成apologize更正式一些   临时通知  Apologies for the late/short notice.   上一封邮件没写清楚导致收件人误解  I apologize if this was not made clear.   提前给别人预警自己措辞过于强硬  I apologize if this may make you feel uncomfortable/bad. I apologize if this may sound a little harsh.    收尾  一般问别人意下如何  Let me know if you have any questions or concerns. Looking forward to your input/insight. Please let me know (what you think)/(your thoughts).    附件  Attached/Enclosed please find the report. I attached the report and let me know what you think. excel, pdf, word用 document(excel也可spreadsheet, ppt也可presentation)  Attached please find the document.    起承转合词  as/on a side note(原意是边注，引申为补充说明某件事情，特别是你想提醒别人做某件事，这样更加委婉，可以翻译成“友情提示)  Also, on a side note, can you XXX? As a side note, I\u0026rsquo;m begining to think our current measurement method doesn\u0026rsquo;t seem to be accurate enough.   specifically(特别说明一件事，用这个词，另写一个自然段)  Specifically, we are interested in XX. Specifically, we\u0026rsquo;d like to XX.   all said/with all that said(中文意思就是“说了那么多”，用于总结。)  All said, I think we are in an envialbe position going into XX.   that being said 话虽如此  That being said, we still need to..（话虽如此，我们仍需\u0026hellip;）   on another front代替on another side (另一方面) with regard to/regarding 关于\u0026hellip;的话题，代替about  I\u0026rsquo;ll have a business trip regarding the quality issue.   echo(本意是“回声”，引申为“附和，邮件经常用这个词来表示“我只是重复一下某人观点”，谦虚的说法)  To echo John\u0026rsquo;s direction, our plan is XX.   bring up(表示把一个问题/话题提出来，这个是最常用的表达，隐含提出来供大家讨论的意思，比mention的意思更丰富。)  One thing I\u0026rsquo;d like to bring up is XX. one of the ideas brought up by the team was to look at XX.   意见/信息/建议  direction(字面意思是“方向”，引申义为“指示”，不一定是上级对下级，任何“做某件事的方法”都可以叫direction.)  Thanks for your direction.   input(本意是「输入」的意思，但是实际工作中，经常做「提供信息/建议」理解。)  Thanks for your input. We value your input. I\u0026rsquo;d like your input on it.(你想问别人对这件事的看法)   insight(翻译成「洞见」，不接地气，但也找不出更好的表达（或者是「高见」？）)  Look forward to your insight. That\u0026rsquo;s valuable insight.     concern (字面意思是“方向”，引申义为“指示”，不一定是上级对下级，任何“做某件事的方法”都可以叫direction.)  quality concern delivery concern   dig into(深入研究)  We need to dig into the root cause.(深挖根本原因)    邮件礼仪  和陌生人发邮件如何自我介绍  不要说This is和I am这种句式 开头直接说 My name is  My name is Steven Gates. I work in the R\u0026amp;D department and am in charge of\u0026hellip;     问别人一个问题，前面加个wondering表示想知道，更加委婉  I was wondering what your thoughts are changing this design. I am wondering if you are using the same material.   请求别人帮忙做一件事情  If you cloud XXX, that would be great. By any chance, could you help check the data? (意为有时间可不可以帮忙\u0026hellip;)   问别人是否可以做一件事情  Is it possible for you to change the desgin?(而不是Could you change the design?)   tentative语气（试探性）：多用seem, appear, sound, look这样的词; 语气别那么生硬。  This seems to be wrong. (不用 This is wrong.) It seems we don\u0026rsquo;t have other option.(We don\u0026rsquo;t have other option.) 描述一个东西，就算是明显已经知道很好，也要说looks good, sounds good,而不是it\u0026rsquo;s good. 不要用maybe,如果确定性比较大，用probably (maybe是比较不确定，而不是有可能)  This is probably right. Could we have a better way to do it? - Probably.   给别人提供建议，不要用should，也不要用you\u0026rsquo;d better, 用it would be better  It would be better if we can change the design. You\u0026rsquo;ll need to buy a new machine if yhis one doesn\u0026rsquo;t work. (给need加将来时，更加委婉) It might be a good idea to fasten your seat belt. (委婉命令别人做某事，)   表示一件事希望你做，但是不强求，用It would be nice/great而不是I need you to XXX, I hope you XXX, could you?  It would be nice/great if you can come today(隐含的意思是still OK if you can\u0026rsquo;t make it.).   问别人要东西/信息时，用 May I have\u0026hellip;? 而不是 Could you give me?  May I have your name? May I have the drawing today? May I have the letter?   问有没有时间  Could I have a minute/moment of your time? (非常非常礼貌，销售员问法) Do you have a minute/monment? (一般礼貌，同事朋友之间用法)   指责别人，用现在进行时比一般现在时更委婉(表示某时某刻这个人处于的状态,不表示你把他彻底说死。)  You are being impatient//argumentative/unreasonable.（你很没耐心/强词夺理/无理取闹） You are better than that(指出别人错误的时候)   用would like代替want  I\u0026rsquo;d like to have a meeting with you.   慎用please(please有时候稍微带一点要求命令的语气)  Could you reply to me by today? (而不是Please reply to me by today.)   用let, allow更礼貌  Please let me know your feedback.(这里用please没问题，因为是自己let me) Please allow me to make a proposal. (I want to make a proposal.)   用I\u0026rsquo;m good代替no(中国习惯yes or no式的思维。但是有些场合回答no未免有点唐突.美国人一般用I\u0026rsquo;m good来婉拒帮助或者好意)  Would you care for some coffee? -I\u0026rsquo;m good. Thank you.   某些负面情况下用have difficulty 代替 can\u0026rsquo;t，委婉把责任推向自己这边  I have difficulty understanding your question. I have difficulty trusting you.     主题必须要“标题党”，必须包含必要信息，让人有打开的欲望。 一定不要用任何简写，比如c.u(see you)之类 一定不要用gonna, wanna这种形式，恶俗至极，请变成原形 going to, want to  ","description":"","id":83,"section":"posts","tags":["邮件","Email","Writing"],"title":"English Writing-Email","uri":"https://www.xunhs.cyou/posts/notes/108/"},{"content":" papers about investigating cognitive places\u0026amp;urban perception\n 相关概念 场所(place)是被赋予了个体经验、生活与情感意义的空间位置或区域，是理解地理环境的重要途径之一。（大众点评数据下的城市场所范围感知方法）\nCognitive region boundaries are typically substantially vague and their membership functions are substantially variable – the transition from outside to inside the region is imprecise or vague, and different places within the region are not equally strong or clear as exemplars of the region. (Vague cognitive regions in geography and geographic information science)\nvague geographic regions\ntaxonomy of geographic regions\nRegions in geography: Process and content Montello-2003-Foundations of geographic information science\nIntroduction  regions  the concept of regions has nearly always been of central importance the identification, description, and explanation of regions has played a critical role   in this eassy  revisit the regional concept  place can be considered a subset of the regions   contrast the concept of geographic regions propose a taxonomy of geographic regions: administrative, thematic, functional, and cognitive regions differentiate formal regions into administrative and thematic regions consider the individual vs. social nature of cognitive regions consider the important issue of boundaries  consider the important issue of boundaries how it applies to the four region types   The special status of administrative regions    What are geographic regions  P1: Regionalization=\u0026gt;Categorization=\u0026gt;Categories=\u0026gt;Spatial categories—regions P2: Geographic regions have certain shared properties P3: Geographic regions are thus examples of spatial regions in general P4: Geographic regions need not be contiguous  Regions in thought PROCESS- AND CONTENT-BASED TAXONOMY OF REGIONS new taxonomy of regions  Administrative regions are formed by legal or political action, by decree or negotiation. Thematic regions are formed by the measurement and mapping of one or more observable content variables or themes Functional regions are formed by patterns of interaction among separate locations on the earth Cognitive regions are produced by people’s informal perceptions and conceptions  traditional region taxonomy  formal, functional, and general regions internal similarity and external dissimilarity of regions  comment In applying the taxonomy, it is critical to recognize that people use the same region label at different times to refer to different regions; they also use it to refer to different types of regions. ( 在应用分类法时，关键是要认识到，人们在不同的时间使用同一个区域标签来指代不同的区域；他们也用它来指代不同类型的区域。)\nVague cognitive regions in geography and geographic information science Montello-2014-IJGIS\n regions are spatial categories (空间范畴): A region encompasses places that are internally similar to each other and externally dissimilar to places outside the region.   A region encompasses places internally similar; dissimilar to places outside the region   All regions have boundaries  One of the most important properties of boundaries is that they vary in their precision or sharpness or, conversely, their vagueness. geographic boundaries are not sharp at all but are really two-dimensional features – regions – themselves Vague boundaries are transition zones (过渡区域) rather than lines between neighboring regions, but they are just as real as sharp boundaries   Reseach about boundaries  discuss different reasons for boundary vagueness quantifying and representing vague boundaries in computational systems / cartographic depiction explored fuzzy logic as a formalization of vague boundaries   Taxonomy of geographic regions  administrative, thematic, functional, and cognitive regions Cognitive regions (traditionally called ‘perceptual’)  regions in the mind, reflecting informal ways that people organize places can be idiosyncratic to a single person but are often shared among members of cultural groups (因人而异, 同时具有群体一致性) reflect the type of spatially categorical thinking that so highly characterizes human thought and communication substantially vague boundaries: The transition (转变) from inside to outside the cognitive region is usually a probabilistically graded zone of significant width variable membership functions: As a corollary (必然结果) to boundary vagueness, their membership functions are variable or probabilistically graded so that all places within the region are not equally strong or clear as members or exemplars of the region.      Investigating urban metro stations as cognitive places in cities using points of interest  extracting and understanding the cognitive regions  extract the cognitive regions of metro stations identify the semantics of metro stations   polygon generation techniques detect the place characteristics of urban metro stations urban metro stations are typical cognitive places perceived by the crowd through interacting with the surrounding society and environment, which are characterized by vague boundaries and rich semantics（定义类） identify the semantics of the regions that can reflect the crowd\u0026rsquo;s impressions and perceptions. (意义类) geotagged data are not ideal for studying the metro station areas owing to issues of completeness and biases（复杂性和有偏性） Assuming that frequently co-occurred place names on web pages implies a strong relatedness between them, researchers have investigated the relationships between geographical entities（假设）  Representing place locales using scene elements  locale indicates the physical settings where everyday-life activities take place, including visible and tangible aspects of a place such as buildings, streets, parks, etc. （定义类） sense of place refers to the human experience and nebulous meanings associated with a place（定义类） a vague cognitive region of a place, which mines place semantics regarding human activities and perceptions how to formalize the concept of place with respect to locale and how to build a quantitative representation of locale remain unclear. analyze the physical appearance of an urban space by photos（物理视觉） enabled by the proliferation of computer vision and deep learning techniques, it has been proven possible to acquire the semantic information of every single pixel in a natural image with high accuracy, thus improving our ability to semantically understand scene content（计算机视觉） the purpose of this study is to formalize the concept of place in terms of locale - the physical appearance of place employ an image semantic segmentation technique to parse street-level images and obtain 64 scene elements (building, sky, grass, etc.) that constitute a typical street scene（图片语义分割技术） The scene visual descriptor enables the carrying out of measurements among places and contributes to the calculations between place and other spatial, demographic, and socioeconomic factors（贡献类） The street scene ontology illustrates the semantic relationships among a certain number of scene elements to support qualitative analysis of street characteristics.（量化分析） 64-dimensional computational vector, where each dimension corresponds to the cover ratio of a specific scene element in the field of view (FOV), which indicates the spatial area that is visible from a location contributes to the calculations between place and other spatial, and socioeconomic variables.（贡献类）  A human-machine adversarial scoring framework for urban perception assessment using street-view images  Traditionally, the evaluation of human perceptions towards their visual surroundings remains difficult due to the lack of high-throughput methods, inadequate sample problems and being restricted to interviews and questionnaires（传统方法的缺陷） urban perception assessment process multi-sources of geospatial big data massive geo-tagged imagery datasets intuitive way for urban residents to gain perceptions about their surrounding environments （意义类） tackle the large-scale derivation problem for urban perception（大数据带来的问题） has emerged as a promising data source to infer urban perceptions（数据源） Street-view imagery is primarily distributed along urban streets and represents the physical morphological properties of urban interior spaces （街景） assess the effect of a city’s environment on social and economic outcomes overcoming the inadequate sample problem and certain limits imposed by traditional interview and questionnaire approach（贡献类，客服传统数据的问题） their special political and economic status and physical environments（物理、社会经济环境两方面） an urban perception is a subjective assessment and is influenced by people’s social and cultural backgrounds（主观性制约） rapidly and costeffectively assess local urban perceptions（修饰类、快速有效） This study developed a framework with deep learning, street-view imagery and iterative feedback mechanism and to assess cityscale urban perceptions（修饰类，城市尺度） We conducted a case study of an urban perception assessment in a high-density urban environment, e.g., Wuhan, to demonstrate the efficacy of the proposed framework. （案例、评估） we analyzed the driving factors to explain the results from both the visual and urban functional aspects.（两方面，可视化和城市功能） ","description":"","id":84,"section":"posts","tags":["论文","cognitive places","street view images","POIs"],"title":"Papers Reading-Cognitive Places\u0026Urban Perception","uri":"https://www.xunhs.cyou/posts/notes/107/"},{"content":" 知乎文章-阅读笔记：从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史\n 目录\n[TOC]\n简介 NLP中的预训练技术是一步一步如何发展到Bert模型的\n Bert的思路是如何逐渐形成的 Bert的历史沿革是什么，继承了什么，创新了什么，为什么效果那么好，主要原因是什么 为何说模型创新不算太大，为何说Bert是近年来NLP重大进展的集大成者  先从图像领域的预训练说起  Frozen Fine-Tuning 对于层级的CNN结构来说，不同层级的神经元学习到了不同类型的图像特征，由底向上特征形成层级结构，如上图所示，如果我们手头是个人脸识别任务，训练好网络后，把每层神经元学习到的特征可视化肉眼看一看每层学到了啥特征，你会看到最底层的神经元学到的是线段等特征，图示的第二个隐层学到的是人脸五官的轮廓，第三层学到的是人脸的轮廓，通过三步形成了特征的层级结构，越是底层的特征越是所有不论什么领域的图像都会具备的比如边角线弧线等底层基础特征，越往上抽取出的特征越与手头任务相关。正因为此，所以预训练好的网络参数，尤其是底层的网络参数抽取出特征跟具体任务越无关，越具备任务的通用性，所以这是为何一般用底层预训练好的参数初始化新任务网络参数的原因。而高层特征跟任务关联较大，实际可以不用使用，或者采用Fine-tuning用新数据集合清洗掉高层无关的特征抽取器。  Word Embedding考古史  语言模型 神经网络语言模型(NNLM, 2003) Word2Vec(2013)  CBOW Skip-gram   Word Embedding后下游任务是怎么用它的  句子中每个单词以Onehot形式作为输入，然后乘以学好的Word Embedding矩阵Q，就直接取出单词对应的Word Embedding Word Embedding矩阵Q其实就是网络Onehot层到embedding层映射的网络参数矩阵   有什么问题值得改进的  Word Embedding其实对于很多下游NLP任务是有帮助的，只是帮助没有大到闪瞎忘记戴墨镜的围观群众的双眼而已 多义词问题 多义词Bank，有两个常用含义，但是Word Embedding在对bank这个单词进行编码的时候，是区分不开这两个含义的，因为它们尽管上下文环境中出现的单词不同，但是在用语言模型训练的时候，不论什么上下文的句子经过word2vec，都是预测相同的单词bank，而同一个单词占的是同一行的参数空间，这导致两种不同的上下文信息都会编码到相同的word embedding空间里去。所以word embedding无法区分多义词的不同语义，这就是它的一个比较严重的问题。    从Word Embedding到ELMO   基于上下文的Embedding-ELMO: Embedding from Language Models (From Deep contextualized word representation)\n  之前的Word Embedding本质上是个静态的方式，所谓静态指的是训练好之后每个单词的表达就固定住了，以后使用的时候，不论新句子上下文单词是什么，这个单词的Word Embedding不会跟着上下文场景的变化而改变，所以对于比如Bank这个词，它事先学好的Word Embedding中混合了几种语义 ，在应用中来了个新句子，即使从上下文中（比如句子包含money等词）明显可以看出它代表的是“银行”的含义，但是对应的Word Embedding内容也不会变，它还是混合了多种语义。\n  ELMO预训练\n ELMO的本质思想是：我事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用Word Embedding的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义去调整单词的Word Embedding表示，这样经过调整后的Word Embedding更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以ELMO本身是个根据当前上下文对Word Embedding动态调整的思路。 每个编码器的深度都是两层LSTM叠加。这个网络结构其实在NLP中是很常用的。 句子中每个单词都能得到对应的三个Embedding:最底层是单词的Word Embedding，往上走是第一层双向LSTM中对应单词位置的Embedding，这层编码单词的句法信息更多一些；再往上走是第二层LSTM中对应单词位置的Embedding，这层编码单词的语义信息更多一些。也就是说，ELMO的预训练过程不仅仅学会单词的Word Embedding，还学会了一个双层双向的LSTM网络结构，而这两者后面都有用。     预训练好网络结构后，如何给下游任务使用呢？\n 这样句子X中每个单词在ELMO网络中都能获得对应的三个Embedding，之后给予这三个Embedding中的每一个Embedding一个权重a，这个权重可以学习得来，根据各自权重累加求和，将三个Embedding整合成一个。然后将整合后的这个Embedding作为X句在自己任务的那个网络结构中对应单词的输入，以此作为补充的新特征给下游任务使用。 这一类预训练的方法被称为“Feature-based Pre-Training”    多义词问题解决了么\n 静态Word Embedding无法解决多义词的问题，那么ELMO引入上下文动态调整单词的embedding后多义词问题解决了吗？解决了，而且比我们期待的解决得还要好。    ELMO有什么缺点？\n ELMO使用了LSTM而不是新贵Transformer， Transformer提取特征的能力是要远强于LSTM的 ELMO采取双向拼接这种融合特征的能力可能比Bert一体化的融合特征方式弱 ELMO是基于特征融合的预训练方法    从Word Embedding到GPT  生成式预训练-GPT：Generative Pre-Training (第一个阶段是利用语言模型进行预训练，第二阶段通过Fine-tuning的模式解决下游任务) Transformer  Transformer是个叠加的“自注意力机制（Self Attention）”构成的深度网络，是目前NLP里最强的特征提取器，注意力这个机制在此被发扬光大，从任务的配角不断抢戏，直到Transformer一跃成为踢开RNN和CNN传统特征提取器，荣升头牌，大红大紫。 深度学习中的注意力模型 - 补充下相关基础知识 Transformer比较好的文章可以参考以下两篇文章  Jay Alammar可视化地介绍Transformer 哈佛大学NLP研究组写的The Annotated Transformer. Transformer在未来会逐渐替代掉RNN成为主流的NLP工具，RNN一直受困于其并行计算能力，这是因为它本身结构的序列性依赖导致的，尽管很多人在试图通过修正RNN结构来修正这一点，但是我不看好这种模式，因为给马车换轮胎不如把它升级到汽车，这个道理很好懂，更何况目前汽车的雏形已经出现了，干嘛还要执着在换轮胎这个事情呢？是吧？再说CNN，CNN在NLP里一直没有形成主流，CNN的最大优点是易于做并行计算，所以速度快，但是在捕获NLP的序列关系尤其是长距离特征方面天然有缺陷，不是做不到而是做不好，目前也有很多改进模型，但是特别成功的不多。综合各方面情况，很明显Transformer同时具备并行性好，又适合捕获长距离特征，没有理由不在赛跑比赛中跑不过RNN和CNN。     GPT训练好了如何使用  结构改造 （这里慢慢就没看懂了） 对网络参数进行Fine-tuning   GPT的缺点  要是把语言模型改造成双向的就好了    Bert的诞生   NLP的四大类任务\n  序列标注  中文分词，词性标注，命名实体识别，语义角色标注等 特点是句子中每个单词要求模型根据上下文都要给出一个分类类别   分类任务  文本分类，情感计算等 特点是不管文章有多长，总体给出一个分类类别即可   句子关系判断  Entailment，QA，语义改写，自然语言推理等 特点是给定两个句子，模型判断出两个句子是否具备某种语义关系   生成式任务  机器翻译，文本摘要，写诗造句，看图说话等 特点是输入文本内容后，需要自主生成另外一段文字      Bert普适性\n  Bert如何改造下有任务？\n  Bert效果如何\n 在11个各种类型的NLP任务中达到目前最好的效果，某些任务性能有极大的提升。    从GPT和ELMO及Word2Vec到Bert：四者的关系\n 如果我们把GPT预训练阶段换成双向语言模型，那么就得到了Bert；而如果我们把ELMO的特征抽取器换成Transformer，那么我们也会得到Bert。所以你可以看出：Bert最关键两点，一点是特征抽取器采用Transformer；第二点是预训练的时候采用双向语言模型。 Bert：最近几年NLP重要技术的集大成者    Bert如何改造双向语言模型？\n Masked LM Next Sentence Prediction    Bert评价及总结\n  Bert借鉴了ELMO，GPT及CBOW，主要提出了Masked 语言模型及Next Sentence Prediction，但是这里Next Sentence Prediction基本不影响大局，而Masked LM明显借鉴了CBOW的思想。所以说Bert的模型没什么大的创新，更像最近几年NLP重要进展的集大成者 首先是两阶段模型，第一阶段双向语言模型预训练，这里注意要用双向而不是单向，第二阶段采用具体任务Fine-tuning或者做特征集成；第二是特征抽取要用Transformer作为特征提取器而不是RNN或者CNN；第三，双向语言模型可以采取CBOW的方法去做 Bert最大的亮点在于效果好及普适性强，几乎所有NLP任务都可以套用Bert这种两阶段解决思路，而且效果应该会有明显提升。可以预见的是，未来一段时间在NLP应用领域，Transformer将占据主导地位，而且这种两阶段预训练方法也会主导各种应用。    ","description":"","id":85,"section":"posts","tags":["Bert","Embedding"],"title":"阅读笔记-从Word Embedding到Bert模型","uri":"https://www.xunhs.cyou/posts/notes/84/"},{"content":" Copy from:\nNLP papers\n 待整理\nA Model of Coherence Based on Distributed Sentence Representation pdf: 下载\n本文提出了一种基于分布式句子表示的模型，用来判断文本连贯性(Coherence)。模型的输入是多个句子（a window of sentences），输出是这些句子是连续的概率。模型的主要步骤如下：\n 对每个句子进行编码：论文实现了循环神经网络编码和递归神经网络编码两种方式，将每个句子表示成一个$k \\times 1​$的语义向量$h_{s_i}, i = 1,\u0026hellip;,L​$，其中$L​$为句子个数（窗口大小）； 将一个窗口内的所有句子的语义向量进行级联，得到大小为$(L \\times k) \\times 1​$的语义向量$h_C = [h_{s_1},h_{s_2},\u0026hellip;,h_{s_L}]​$后，进行非线性变换，即$q_C=tanh(W_{sen} \\times h_C + b_{sen})​$，得到大小为$H \\times 1​$的隐藏层语义表示向量$q_C​$，其中$W_{sen}​$为大小为$H \\times (L \\times k)​$的矩阵，$b_{sen}​$为大小为$H \\times 1​$的偏移向量； 最后将$q_C​$输入到全连接层进行二分类，即$p(y_C=1) = sigmoid(U^Tq_C + b)​$，其中$y_C=1​$表示该窗口中的句子是连贯的，等于0则表示不连贯。  给定一篇包含$N_d$个句子的文档$d={s_1,s_2, \u0026hellip;,s_{N_d}}$，假设$L=3$，可以生成如下的样本：\n$$\u0026lt; s _ { \\text{start} } , s _ { 1 } , s _ { 2 } \u0026gt; , \u0026lt; s _ { 1 } , s _ { 2 } , s _ { 3 } \u0026gt; , \\ldots \\ \u0026lt; s _ { N _ { d } - 2 } , s _ { N _ { d } - 1 } , s _ { N _ { d } } \u0026gt; , \u0026lt; s _ { N _ { d } - 1 } , s _ { N _ { d } } , s _ { e n d } \u0026gt;$$\n文档$d$的连贯性得分$S_d$可以定义为所以样本连贯性概率的乘积（得分越大表示越连贯），即\n$$S _ { d } = \\prod _ { C \\in d } p \\left( y _ { C } = 1 \\right)$$\n虽然论文的任务是判断文本连贯性，给了后续的研究者研究句子分布式表示的启示:类似于word2vec中使用相邻词预测的方式来获得word embedding，可以通过句子连贯性这个任务自动构建数据集，无需标注即可得到sentence embedding。\nSkip-Thought Vectors pdf: 下载\n本文提出了Skip-Thought模型用于得到句子向量表示Skip-Thought Vectors。基本思想与word2vec中的skip-gram模型类似：对当前句子进行编码后对其周围的句子进行预测。具体地，skip-thought模型如下图，给定一个连续的句子三元组，对中间的句子进行编码，通过编码的句子向量预测前一个句子和后一个句子。Skip-Thought向量的实验结果表明，可以从相邻句子的内容推断出丰富的句子语义。\n模型的基本架构与encoder-decoder模型类似，论文中使用的encoder和decoder都为GRU，使用单向GRU称为uni-skip,双向GRU称为bi-skip，将uni-skip和bi-skip生成的sentence embedding进行concat称为combine-skip。论文通过大量实验对比了上述三种变体的效果，总体上来说是uni-skip \u0026lt; bi-skip \u0026lt; combine-skip。包括如下实验：\n 语义相关性：the SemEval 2014 Task 1: semantic relatedness SICK dataset 释义识别：Microsoft Research Paraphrase Corpus 图像检索（Image-sentence ranking）：the Microsoft COCO dataset 句子分类：MR、CR、SUBJ、MPQA以及TREC五个数据集  词表扩展：skip-thought模型的词表规模往往是远小于现实中的词表（如用海量数据训练的word2vec）。为了让模型能够对任意句子进行编码，受论文Exploiting similarities among languages for machine translation的启发，本文训练一个线性映射模型，将word2vec的词向量映射为skip-thought模型encoder词表空间的词向量。假设训练后的skip-thought模型的词向量矩阵为$X$，大小为[num_words，dim1]，即词表大小为num_words，词向量维度为dim1，这num_words个词在word2vec中对应的词向量矩阵为Y，大小为[num_words, dim2]，即word2vec的词向量维度为dim2。我们的目的是word2vec中的词向量通过线性变换后得到词向量与skip-thought模型encoder空间的词向量无限接近，因此最小化线性回归。得到这个线性模型后，假设待编码的句子中的某个词不属于skip-thought词表，则首先在word2vec词表中进行look up得到word2vec对应的词向量，再通过线性模型映射为skip-thought模型encoder空间的词向量。\nLearning Distributed Representations of Sentences from Unlabelled Data pdf: 下载\n本文提出了两种无监督学习模型用于学习句子分布式表示。第一种模型称为序列去噪自编码器（SDAE: Sequential Denoising AutoEncoder）。AutoEncoder包括编码器和解码器两部分，输入信息通过编码器产生编码信息，再通过解码器得到输入信息，模型的目标是使输出信息和输入信息原来越接近。DAE (Denoising AutoEncoder)表示模型的输入信息首先经过了噪声处理后再进行编码和解码，并且希望解码的输出信息是不含噪声的输入信息，即去噪。DAE常用于图像处理，本文提出SDAE模型表示用来处理变长的句子（序列）。具体地，给定句子$S​$，采用噪声函数：$N(S|p_0,p_x)​$，其中$p_0, p_x​$为0到1之间的概率值。首先，对于$S​$中的每个词$w​$，噪声函数$N​$按照概率$p_0​$随机删除$w​$，然后对于$S​$中每个不重叠的bigram $w_iw_{i+1}​$，噪声函数$N​$按照概率$p_x​$对$w_i​$和$w_{i+1}​$进行交换。论文采用基于LSTM的encoder-decoder模型，SDAE的目标是预测出原始句子$S​$。SDAE模型在验证集上对超参数$p_0,p_x \\in {0.1, 0.2, 0.3}​$进行搜索，得到当$p_0=p_x=0.1​$为最优结果。论文还尝试令$p_0=p_x=0​$进行对比实验，SDAE模型即变成了SAE模型。 SDAE模型相较于Skip-Thought的优点是只需要输入单个句子，即不要求句子所在的文本是有序的，而Skip-Thought的输入必须是三个有序的句子。\n第二种模型称为FastSent，Skip-Thought模型采取语言模型形式的编码解码方式，导致其训练速度会很慢。FastSent采取了BOW形式的编码方式，使得模型训练速度大幅提高，因此称为FastSent。具体地，给定一个连续的句子三元组$S_{i-1}, S_i, S_{i+1}$，对中间的句子$S_{i}$进行编码，编码方式是$S_i$中所有词的词向量之和，即$\\mathbf { s } _ { \\mathbf { i } } = \\sum _ { w \\in S _ { i } } u _ { w }$，然后根据$\\mathbf { s } _ { \\mathbf { i } }$对$w \\in S_{i-1} \\cup S_{i+1}$进行预测，这与word2vec模型中的skip-gram基本一致，而无需像Skip-Thought一样按照句子中词的顺序生成（预测）。因此FastSent的损失函数如下:\n$$\\sum _ { w \\in S _ { i - 1 } \\cup S _ { i + 1 } } \\phi \\left( \\mathbf { s } _ { \\mathbf { i } } , v _ { w } \\right)$$\n其中$\\phi \\left( v _ { 1 } , v _ { 2 } \\right)$为softmax函数，$v_w$为目标句子中的词$w$的embedding。论文还提出了一种变体模型FastSent+AE，该变体不光是预测前后两个句子中的词，还预测本身句子的词，损失函数即为：\n$$\\sum _ { w \\in S _ { i - 1 } \\cup S _ { i } \\cup S _ { i + 1 } } \\phi \\left( \\mathbf { s _ { i } } , v _ { w } \\right)$$\n模型训练后，测试阶段，FastSent能够通过计算句子中所有词向量的和迅速得到句子embedding，即：$\\mathbf { s } = \\sum _ { w \\in S } u _ { w }​$。\n论文通过两种类型的下游任务来评测句子分布式表示的质量，分别为监督类型（包括释义识别，文本分类）和非监督类型（语义相关性：SICK数据集与STS数据集，直接计算句子向量的余弦相似度并与人类打分进行比较）。实验结果为SDAE模型在监督类型评测上比CBOW（将CBOW类型词向量直接相加得到句子向量）和Skipgram等简单模型要好，但是在非监督类型评测上结果却相反。类似地，Skip-Thought模型在监督类型评测上比FastSent模型效果好，但在非监督类型评测上，FastSent要好于Skip-Thought。实验结果表明，最佳方法主要取决于预期的应用。 更深，更复杂的模型（同时也需要更多的计算资源和训练时间）更适用于监督类型评测，但浅的对数线性模型更适合无监督类型评测。\nA simple but tough-to-beat baseline for sentence embeddings pdf: 下载\n从论文题目可以看出，本文提出了一种非常简单但是具有一定竞争力的句子向量表示算法。算法包括两步，第一步是对句子中所有的词向量进行加权平均，得到平均向量$v_s$；第二步是移出（减去）$v_s$在所有句子向量组成的矩阵的第一个主成分(principal component / singular vector)上的投影，因此该算法被简记为WR（W:weighting, R: removing）。\n第一步主要是对TFIDF加权平均词向量表示句子的方法进行改进。论文提出了一种平滑倒词频 (smooth inverse frequency, SIF)方法用于计算每个词的加权系数，具体地，词$w$的权重为$a / (a+p(w))$，其中$a$为平滑参数，$p(w)$为（估计的）词频。直观理解SIF，就是说频率越低的词在当前句子出现了，说明它在句子中的重要性更大，也就是加权系数更大。事实上，如果把一个句子认为是一篇文档并且假设该句中不出现重复的词（TF=1），那么TFIDF将演变成IF，即未平滑的倒词频。但是相较于TFIDF这种经验式公式，论文通过理论证明为SIF提供理论依据。对于第二步，个人的直观理解是移出所有句子的共有信息，因此保留下来的句子向量更能够表示本身并与其它句子向量产生差距。算法描述如下(其中$v_s, u$的shape均为[d, 1]，$uu^T$为[d,d]的矩阵，d为词向量维度)：\n论文实验表明该方法具有不错的竞争力，在大部分数据集上都比完全平均或者使用TFIDF加权平均的效果好，在使用PSL作为词向量时甚至能达到最优结果。当然，由于PSL本身是基于有监督任务（短语对）来训练词向量，因此PSL+WR能在文本蕴含或相似度计算任务上达到甚至打败LSTM的效果也在情理之中。\nUnsupervised Learning of Sentence Embeddings using Compositional n-Gram Features pdf: 下载\n本文是word2vec模型中CBOW形式的扩展，不仅仅使用窗口中的词来预测目标词，而是使用窗口中所有的n-grams来预测目标词（uni-gram）。为了得到句子向量，将句子看成一个完整的窗口，模型的输入为句子中的n-grams，目标是预测句子中的missing word(目标词），而句子向量是所有n-grams向量表示的平均。本文的模型与论文Enriching word vectors with subword information(FastText)很类似，主要区别有两点，其一是本文的模型输入是词级别的n-grams序列而FastText是字符级别的n-grams序列，其二是本文最终的表示是对输入的n-grams embedding进行平均而FastText是相加。\nAn efficient framework for learning sentence representations pdf: 下载\n本文提出了一种简单且有效的框架用于学习句子表示。和常规的编码解码类模型（如skip-thoughts和SDAE）不同的是，本文采用一种分类器的方式学习句子表示。具体地，模型的输入为一个句子$s$以及一个候选句子集合$S_{cand}$，其中$S_{cand}$包含一个句子$s_{ctxt}$是$s$的上下文句子（也就是$s$的前一个句子或后一个句子）以及其他不是$s$上下文的句子。模型通过对$s$以及$S_{cand}$中的每个句子进行编码，然后输入到一个分类器中，让分类器选出$S_{cand}$中的哪个句子是$s_{ctxt}$。实验设置候选句子集合大小为3，即$S_{cand}$包含1个上下文句子和两个无关句子。模型结构如下：\n模型有如下两个细节需要注意：\n 模型使用的分类器（得分函数）$c$非常简单，是两个向量内积，即$c(u, v)=u^Tv$，计算$s$的embedding与所有$S_{cand}$中的句子向量内积得分后，输入到softmax层进行分类。使用简单分类器是为了引导模型着重训练句子编码器，因为我们的目的是为了得到好的句子向量表示而不是好的分类器。 虽然某些监督任务模型如文本蕴含模型是参数共享的，$s$的编码器参数和候选句子编码器参数是不同的（不共享），因为句子表示学习往往是在大规模语料上进行训练，不必担心参数学习不充分的问题。测试时，给定待编码句子$s$，通过该模型得到的句子表示是两种编码器的连结 $[ f ( s ) ;g ( s ) ]$。  论文将上述模型命名为quick thoughts（QT），意味着该模型能够迅速有效地学习句子表示向量。模型使用GRU作为Encoder，为了和Skip-Tought模型进行比较，模型包含三种变体，使用单向GRU称为uni-QT，双向GRU称为bi-QT，将uni-QT和bi-QT生成的sentence embedding进行concat称为combine-QT。此外，论文将同时使用预训练词向量和随机初始化词向量的模型称为MultiChannel-QT（MC-QT）,这种设置是参照multi-channel CNN模型。\n论文通过多个句子分类任务证明QT模型了的优越性：\n 相较于其他无监督句子表示学习方法，QT在训练时间较少的情况下（相较于Skip-Thought、SDAE），能够达到非常不错的效果，在大多数数据集上的效果都是最好的。 与监督句子表示学习方法（如InferSent等）对比，QT（MC-QT）同样能够在大多数数据集上取得最优效果。 与专门用于句子分类任务模型（如CNN）对比，QT使用ensemble，考虑模型类型(单向/双向)，词向量（随机/预训练）以及数据集（BookCorpus/UMBC ）三个方面进行训练不同的模型进行集成，也取得了有竞争力的效果。  论文还通过image-sentence ranking和nearest neighbors两个实验来为QT有效性提供依据。\nTowards universal paraphrastic sentence embeddings pdf: 下载\n本文提出使用PPDB(the Paraphrase Database)来学习通用的sentence embeddings。论文模型的基本流程是输入mini-batch的释义对$\u0026lt;x_1, x_2\u0026gt;​$集合$X_b​$，并通过对$X_b​$中的句子进行采样得到$x_1,x_2​$对应的负样本$t_1, t_2​$，将这四个句子通过编码器（编码函数）$g​$得到句子编码，然后使用一种 margin-based loss进行优化，损失函数的基本思想是希望编码后的释义对$\u0026lt;x_1,x_2\u0026gt;​$能够非常相近而非释义对$\u0026lt;x_1,t_1\u0026gt;​$和$\u0026lt;x_2,t_2\u0026gt;​$能够有不小于$\\delta​$的间距。对于全体训练数据$X​$，目标函数如下，其中$\\lambda_c,\\lambda_w​$为正则化参数，$W_w​$为word embedding参数，$W_{w_{initial}}​![](https://latex.codecogs.com/svg.latex?为word embedding初始化矩阵，$W_c​$是除了$W_w​$后的其他参数。\n论文实现了6种类型的编码函数$g$，具体如下：\n 词向量平均； 词向量平均后通过一个线性层； DAN模型：词向量平均后通过多层带非线性函数的全连接层； Simple RNN，取最后一个隐状态向量； identity-RNN (iRNN)， 一种特殊的simple RNN，其weight矩阵初始化为单位矩阵，bias初始化为0向量，激活函数为恒等函数，最终的句子编码向量为最后一个隐状态向量除以句子中词的个数。当正则化程度很高时（模型参数几乎不更新），iRNN将变成模型1（词向量平均），不同的是iRNN能够考虑词序，有希望能够比模型1效果好； LSTM，取最后一个隐状态向量。  论文通过大量实验来对比上述6种编码器的优劣，得到如下结论：\n 对于无监督文本相似度任务，复杂的模型如LSTM在垂直领域数据集上表现更好，而对于开放域数据集，简单的模型如词向量平均比LSTM的效果更好； 对于句子相似度，句子蕴含以及情感分析这三种有监督任务，词向量平均模型在句子相似度和句子蕴含两个任务上表现比LSTM的效果更好，而情感分析任务LSTM表现非常不错。  Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks pdf: 下载\n之前往往是通过评测sentence embeddings在下游任务如句子分类的表现来反映该sentence embeddings的优劣。而本文设计了三种辅助预测任务来对sentence embeddings本身进行细粒度分析，包括句子长度，词内容（word content），词序三个方面。三种辅助预测任务如下：\n Length Task：该任务是来度量句子向量多大程度上编码了句子长度（词的个数）信息。该任务定义为多分类问题，将句子长度划分为8个等级，给定一个句子向量，分类器的目标是预测句子长度属于哪个等级。 Word-content Task: 该任务是来度量句子向量多大程度上编码了句子中是否包含某词的信息，该任务定义为二分类问题，给定一个句子向量和一个词向量，分类器的目标是判断这个词是否属于该句。 Word-order Task: 该任务是来度量句子向量多大程度编码了句子词序信息。该任务定义为二分类问题，给定一个句子向量和两个属于该句的词向量$w_1,w_2$，分类器的目标是判断$w_1$是否在$w_2$前面。  Supervised Learning of Universal Sentence Representations from Natural Language Inference Data pdf: 下载\n本文提出使用自然语言推理（natural language inference, NLI）数据集来学习通用的句子表示。选择NLI任务是因为NLI是一个high-level理解任务，涉及推理句子间的语义关系。模型整体架构如下：\n论文对比了7种不同的句子编码器，包括：\n  GRU，取最后一个隐状态\n  LSTM，取最后一个隐状态\n  BiGRU，前向GRU与反向GRU最后一个隐状态的连结\n  BiLSTM+mean pooling\n  BiLSTM+max pooling\n  Self-attentive network: bi-LSTM+inner Attention with multiple views，Inner Attention机制如下：\n$$\\overline { h } _ { i } = \\tanh \\left( W h _ { i } + b _ { w } \\right); \\alpha _ { i } = \\frac { e ^ { \\overline { h } _ { i } ^ { T } u _ { w } } } { \\sum _ { i } e ^ { \\overline { h } _ { i } ^ { T } u _ { w } } }; u = \\sum _ { t } \\alpha _ { i } h _ { i }$$\n其中${h_1,\u0026hellip;,h_T}$为BiLSTM的隐状态输出，将它们输入到tanh变换层产生keys集合$( \\overline { h } _ { 1 } , \\ldots , \\overline { h } _ { T } )$，然后与可学习（可训练）的query向量（上下文向量）计算得到${a_i}$，然后进行加权得到句子表示$u$，如下图所示：\n论文具体是采用4个上下文向量$u _ { w } ^ { 1 } , u _ { w } ^ { 2 } , u _ { w } ^ { 3 } , u _ { w } ^ { 4 }$（multiple views），对应产生4个表示后进行连结作为最终的句子表示。\n  Hierarchical ConvNet，多层卷积（4层），每层卷积的maxpooling输出进行连结得到最终句子表示，模型结构如下图：\n  论文实验表明：BiLSTM+maxpooling作为编码器，训练数据为SNLI，能够训练出比Skip-Toughts和FastSent等无监督方法更好的sentences embedding，达到state-of-the-art （2017年）。\nUniversal Sentence Encoder pdf: 下载\n本文在前人研究的基础上，综合利用无监督训练数据和有监督训练数据，进行多任务训练，从而学习一个通用的句子编码器。无监督训练数据包括问答(QA)型网页和论坛，Wikipedia, web news，有监督训练数据为SNLI。多任务模型设计如下图所示，其中灰色的encoder为共享参数的句子编码器。\n论文对比了DAN和Transfomer这两种编码器。得出如下结论：\n Transformer 模型在各种任务上的表现都优于简单的 DAN 模型，且在处理短句子时只稍慢一些。 DAN模型也能具有很不错的表现，并且相较于Transformer模型，训练时间和内存的开销都更小，尤其是当句子较长时。  更详细的介绍可以参考论文作者的博客Google AI Blog (中文版)。\n","description":"","id":86,"section":"posts","tags":["Sentence Embedding","句子向量","Sentence Representation"],"title":"转载-Sentence Representation","uri":"https://www.xunhs.cyou/posts/notes/%E8%BD%AC%E8%BD%BD-sentence-representation/"},{"content":" Linux基础及部分常用命令\n 目录结构 参考自知乎\n bin (binaries)存放二进制可执行文件 sbin (super user binaries)存放二进制可执行文件，只有root才能访问 etc (etcetera)存放系统配置文件 usr (unix shared resources)用于存放共享的系统资源 home 存放用户文件的根目录 root 超级用户目录 dev (devices)用于存放设备文件 lib (library)存放跟文件系统中的程序运行所需要的共享库及内核模块 mnt (mount)系统管理员安装临时文件系统的安装点 boot 存放用于系统引导时使用的各种文件 tmp (temporary)用于存放各种临时文件 var (variable)用于存放运行时需要改变数据的文件  Note:\nLinux 软件安装到 /usr，/usr/local/ 还是 /opt 目录？\nLinux 的软件安装目录是也是有讲究的，理解这一点，在对系统管理是有益的\n/usr：系统级的目录，可以理解为C:/Windows/，/usr/lib理解为C:/Windows/System32。\n/usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下。\n/opt：用户级的程序目录，可以理解为D:/Software，opt有可选的意思，这里可以用于放置第三方大型软件（或游戏），当你不需要时，直接rm -rf掉即可。在硬盘容量不够时，也可将/opt单独挂载到其他磁盘上使用。\n源码放哪里？\n/usr/src：系统级的源码目录。\n/usr/local/src：用户级的源码目录。\n文件权限操作  r 可读权限，w可写权限，x可执行权限（也可以用二进制表示 111 110 100 \u0026ndash;\u0026gt; 764） 第1位：文件类型（d 目录，- 普通文件，l 链接文件） 第2-4位：所属用户权限，用u（user）表示 第5-7位：所属组权限，用g（group）表示 第8-10位：其他用户权限，用o（other）表示 第2-10位：表示所有的权限，用a（all）表示  Linux系统常用快捷键及符号命令 搜索 find命令 参考自csdn\nfind \u0026lt; path \u0026gt; \u0026lt; expression \u0026gt; \u0026lt; cmd \u0026gt;\n path： 所要搜索的目录及其所有子目录。默认为当前目录。 expression： 所要搜索的文件的特征。 cmd： 对搜索结果进行特定的处理。  如果什么参数也不加，find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。\n -name 按照文件名查找文件  1 2 3  find /dir -name filename 在/dir目录及其子目录下面查找名字为filename的文件 find . -name \u0026#34;*.c\u0026#34; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 find / -name \u0026#34;航拍*\u0026#34; 在所有文件查找   运维   关机和重启\n 立刻关机: shutdown -h now 立刻重启: shutdown -r now    服务管理\n  service命令: sudo service [服务名] + start/restart/status/stop\n  systemd进程守护\n 配置文件目录\nsystemctl脚本目录：/usr/lib/systemd/\n系统服务目录：/usr/lib/systemd/system/\n用户服务目录：/usr/lib/systemd/user/ 在/usr/lib/systemd/system目录下新建cloudreve.service文件：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [Unit]Description=CloudreveDocumentation=https://docs.cloudreve.orgAfter=network.targetWants=network.target[Service]WorkingDirectory=/PATH_TO_CLOUDREVEExecStart=/PATH_TO_CLOUDREVE/cloudreveRestart=on-abnormalRestartSec=5sKillMode=mixedStandardOutput=nullStandardError=syslog[Install]WantedBy=multi-user.target   常用命令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # 更新配置 systemctl daemon-reload # 启动服务 systemctl start cloudreve # 设置开机启动 systemctl enable cloudreve # 启动服务 systemctl start cloudreve # 停止服务 systemctl stop cloudreve # 重启服务 systemctl restart cloudreve # 查看状态 systemctl status cloudreve       查看系统资源占用-htop工具\nhtop工具直观查看CPU使用信息\n1 2  sudo apt install htop htop      Ubuntu 查看磁盘空间及目录容量\n  df命令是linux系统以磁盘分区为单位查看文件系统，可以加上参数查看磁盘剩余空间： df -hl\n显示格式为：\n文件系统 容量 已用 可用 已用% 挂载点\n  查看端口占用/终止端口程序\n 查看8888端口: lsof -i:8888 或者 sudo netstat -ap | grep 8080    终止端口: kill +对应的pid\n    设置开机程序自启动\nsudo gnome-session-properties 添加启动项即可\n  环境变量   临时设置环境变量: export: 在 shell 中执行程序时，shell 会提供一组环境变量。export 可新增，修改或删除环境变量，供后续执行的程序使用。export 的效力仅限于该次登陆操作。\nexport MYENV=7 //定义环境变量并赋值\n  永久设置\n 方法一: 修改.bashrc文件（当前用户）  nano ~/.bashrc; 在bashrc文件末尾添加：export MYENV=7 使生效：source ~/.bashrc   方法二: 修改profile文件（对所有用户都是有效的）  nano /etc/profile 在profile文件末尾添加：export MYENV=7 使生效：source /etc/profile      查看环境变量\n echo $MYENV或者export $MYENV 显示所有环境变量：export -p    设置命令行别名\n 临时设置: 在当前窗口输入alias jb='jupyter notebook'即可 永久设置:  编辑bashrc: gedit ~/.bashrc; 添加alias: alias jb='jupyter notebook'      设置终端代理: 添加至~/.zshrc，并执行source ~/.zshrc :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  set-proxy () { # for terminal export proxyserveraddr=\u0026#34;192.168.123.155\u0026#34; export proxyserverport=\u0026#34;7890\u0026#34; export ALL_PROXY=\u0026#34;http://$proxyserveraddr:$proxyserverport\u0026#34; export all_proxy=\u0026#34;http://$proxyserveraddr:$proxyserverport\u0026#34; export http_proxy=\u0026#34;http://$proxyserveraddr:$proxyserverport\u0026#34; git config --global http.proxy \u0026#34;http://$proxyserveraddr:$proxyserverport\u0026#34; git config --global https.proxy \u0026#34;https://$proxyserveraddr:$proxyserverport\u0026#34; curl https://ip.gs } unset-proxy () { unset proxyserveraddr unset proxyserverport unset ALL_PROXY unset all_proxy unset http_proxy git config --global --unset http.proxy git config --global --unset https.proxy curl https://ip.gs }      文件  压缩与解压\nLinux下常见的压缩包格式有5种:zip tar.gz tar.bz2 tar.xz tar.Z 压缩\n压缩到指定目录(DirName): tar -zcvf FileName.tar.gz DirName  解压  zip解压: unzip FileName.zip tar.gz tar.bz2 tar.xz tar.Z解压: tar -xvf FileName.tar.gz  tar可以自动识别压缩的格式 x: extract解压; v:verbose详细信息; f:file文件        ","description":"","id":87,"section":"posts","tags":["Linux","Ubuntu","运维","代理"],"title":"Linux-基础及常用命令","uri":"https://www.xunhs.cyou/posts/notes/2020-02-17-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"content":" 转载-SCI常用经典词和常用句型：转载地址\n 经典替换词   individuals, characters, folks 替换 people , persons.\n  positive, favorable, rosy, promising, perfect, pleasurable, excellent, outstanding, superior 替换 good.\n  dreadful, unfavorable, poor, adverse, ill 替换 bad（如果bad做表语，可以有be less impressive替换。）\n  an army of, an ocean of, a sea of, a multitude of, a host of, if not most 替换 many.\n  a slice of, quiet a few 替换 some.\n  harbor the idea that, take the attitude that, hold the view that, it is widely shared that, it is universally acknowledged that 替换 think。\n  affair, business, matter 替换 thing.\n  shared 替换 common .\n  reap huge fruits 替换 get many benefits.\n  for my part ,from my own perspective 替换 in my opinion.\n  Increasing(ly), growing 替换 more and more（注意没有growingly这种形式。所以当修饰名词时用increasing/growing修饰形容词，副词用increasingly.）\n  little if anything或little or nothing 替换 hardly.\n  beneficial, rewarding 替换 helpful.\n  shopper, client, consumer, purchaser 替换 customer.\n  overwhelmingly, exceedingly, extremely, intensely 替换 very.\n  hardly necessary, hardly inevitable…替换 unnecessary, avoidable.\n  indispensable 替换 necessary.\n  sth appeals to sb, sth exerts a tremendous fascination on sb 替换sb take interest in / sb. be interested in.\n  capture one\u0026rsquo;s attention 替换 attract one\u0026rsquo;s attention.\n  facet, demension, sphere 替换 aspect.\n  be indicative of, be suggestive of, be fearful of 替换 indicate,suggest, fear.\n  give rise to, lead to, result in, trigger 替换 cause.\n  There are several reasons behind sth 替换…reasons for sth.\n  desire 替换 want.\n  pour attention into 替换 pay attention to.\n  bear in mind that 替换 remember.\n  enjoy, possess 替换 have（注意process是过程的意思）。\n  interaction 替换 communication.\n  frown on sth 替换 be against , disagree with sth .\n  as an example 替换 for example, for instance.\n  next to / virtually impossible 替换 nearly / almost impossible.\n  regarding / concerning 替换 about.\n  crucial /paramount 替换 important.\n  第一（in the first place/the first and foremost）；第二（there is one more point, I should touch on, that…）；第三（the last but not the least）。\n  assiduous 替换 hard-working.\n  arduous / formidable 替换 difficult.\n  underdeveloped / financially-challenged 替换poor（因为poor通常含有贬义）.\n  demonstrate / manifest 替换 show.\n  invariably 替换 always.\n  perilous / hazardous替换 dangerous.\n  quintessential 替换 typical（举例时常用，例如：a quintessential example should be cited that=for example; for instance）.\n  distinguished 替换 famous.\n  feasible 替换 possible.\n  consequently, accordingly替换 so.\n  通常，由数据推断出一定的结论，用Results indicate, infer, suggest, imply that……\n  最常见的引述别人观点的词汇  Much of the research in sexual selection in the last two decades has examined how a female’s preference that does not influence her immediate reproductive success can still evolve if it is genetically correlated with another character under direct selection.(不要每次写到研究时总用study，可以用些其它的词汇，比如examine，work。) Two hypotheses for female preference evolution—runaway sexual selection and good genes selection—state that preferences evolve indirectly because they are genetically correlated with male traits that are under direct selection; that is, the preferences themselves are not under direct selection.(在引述别人的观点时，如果不能完全同意，使用state 比show更加中立些。) Studies of receiver biases suggest that such analogies might not be broadly applicable(不能广泛被应用).(suggest,又一种较为客观的引述观点的表达方法。) Burley argued that the preference for red beaks is adaptive because it indicates male health, and this preference is then transferred to leg-band color.(argue,引用别人观点的又一表述。) According to the anti-monotony hypothesis, habituation plays an important role in the evolution of complex vocalizations in songbirds: Increased song complexity reduces habituation of neighboring males and courting females.(根据…) Previous studies of acoustic and bioluminescent interactions had emphasized potential advantages to group-signaling organization, such as minimizing predation, preserving species-specific signal characters, or increasing the attractiveness of the group.(带有小小的强调)  常见的连接词有 However, also, in addition, consequently, afterwards, moreover, Furthermore, further, although, unlike, in contrast, Similarly, Unfortunately, alternatively, parallel results, In order to, despite, For example, Compared with, other results, thus, therefore……\n用好连接词能使文章层次清楚，意思明确。比如，叙述有时间顺序的事件或文献，最早的文献可用AA advocated it for the first time.接下来可用Then BB further demonstrated that. 再接下来，可用Afterwards, CC……如果还有，可用More recent studies by DD……\n一些常用的短语及句式 “In order to prove…., we used…”；“We have set up….”；“To demonstrate…., we further…”；“Consistently/Consistent with…”；“Compared with….”；“Thus, at current time, we have evidence that…”；“We next characterized…”；“We found that…”；“We have noticed that….”；“It’s known that….”；“So we introduced….in our study”；“In contrast…”；“These data suggest that….”；“So we next explored….”；“Notably,\n….”；“Importantly, ….”；“Furthermore….”；“Moreover….”；“We have previously shown that….”；“As shown in Fig. 1,…..”；“Fig. 1 shows….”；“Overall,….”；“Taken together, these results suggest….”；“These data are consistent with the notion that\u0026hellip;..”；“Next, we examined the effect of….”；“We next set out to determine whether….”；“Lastly, we examined…..”；“In order to establish….”.\n常用句型 Beginning  In this paper, we focus on the need for This paper proceeds as follow. The structure of the paper is as follows. In this paper, we shall first briefly introduce fuzzy sets and related concepts To begin with we will provide a brief background on the  Introduction (介绍或总结后续内容)  This will be followed by a description of the fuzzy nature of the problem and a detailed presentation of how the required membership functions are defined. Details on xx and xx are discussed in later sections. In the next section, after a statement of the basic problem, various situations involving possibility knowledge are investigated: first, an entirely possibility model is proposed; then the cases of a fuzzy service time with stochastic arrivals and non fuzzy service rule is studied; lastly, fuzzy service rule are considered.  Review  This review is followed by an introduction. A brief summary of some of the relevant concepts in xxx and xxx is presented in Section 2. In the next section, a brief review of the \u0026hellip;. is given. In the next section, a short review of \u0026hellip; is given with special regard to \u0026hellip; Section 2 reviews relevant research related to xx. Section 1.1 briefly surveys the motivation for a methodology of action, while 1.2 looks at the difficulties posed by the complexity of systems and outlines the need for development of possibility methods.  Body   Section 1 defines the notion of robustness, and argues for its importance.\n  Section 1 devoted to the basic aspects of the FLC decision making logic.\n  Section 2 gives the background of the problem which includes xxx\n  Section 2 discusses some problems with and approaches to, natural language understanding.\n  Section 2 explains how flexibility which often \u0026hellip; can be expressed in terms of fuzzy time window\n  Section 3 discusses the aspects of fuzzy set theory that are used in the \u0026hellip;\n  Section 3 describes the system itself in a general way, including the ….. and also discusses how to evaluate system performance.\n  Section 3 describes a new measure of xx.\n  Section 3 demonstrates the use of fuzzy possibility theory in the analysis of xx.\n  Section 3 is a fine description of fuzzy formulation of human decision.\n  Section 3, is developed to the modeling and processing of fuzzy decision rules\n  The main idea of the FLC is described in Section 3 while Section 4 describes the xx strategies.\n  Section 3 and 4 show experimental studies for verifying the proposed model.\n  Section 4 discusses a previous fuzzy set based approach to cost variance investigation.\n  Section 4 gives a specific example of xxx.\n  Section 4 is the experimental study to make a fuzzy model of memory process.\n  Section 4 contains a discussion of the implication of the results of Section 2 and 3.\n  Section 4 applies this fuzzy measure to the analysis of xx and illustrate its use on experimental data.\n  Section 5 presents the primary results of the paper: a fuzzy set model ..\n  Section 5 contains some conclusions plus some ideas for further work.\n  Section 6 illustrates the model with an example.\n  Various ways of justification and the reasons for their choice are discussed very briefly in Section 2.\n  In Section 2 are presented the block diagram expression of a whole model of human DM system\n  In Section 2 we shall list a collection of basic assumptions which a \u0026hellip; scheme must satisfy.\n  In Section 2 of this paper, we present representation and uniqueness theorems for the fundamental measurement of fuzziness when the domain of discourse is order dense.\n  In Section 3, we describe the preliminary results of an empirical study currently in progress to verify the measurement model and to construct membership functions.\n  In Section 5 is analyzed the inference process through the two kinds of inference experiments\u0026hellip;\n  This Section  In this section, the characteristics and environment under which MRP is designed are described. We will provide in this section basic terminologies and notations which are necessary for the understanding of subsequent results.Next Section The next section describes the mathematics that goes into the computer implementation of such fuzzy logic statements. However, it is cumbersome for this purpose and in practical applications the formulae were rearranged and simplified as discussed in the next section. The three components will be described in the next two section, and an example of xx analysis of a computer information system will then illustrate their use. We can interpret the results of Experiments I and II as in the following sections. The next section summarizes the method in a from that is useful for arguments based on xx  Summary  This paper concludes with a discussion of future research consideration in section 5. Section 5 summarizes the results of this investigation. Section 5 gives the conclusions and future directions of research. Section 7 provides a summary and a discussion of some extensions of the paper. Finally, conclusions and future work are summarized The basic questions posed above are then discussed and conclusions are drawn. Section 7 is the conclusion of the paper.  Abstract  A basic problem in the design of xx is presented by the choice of a xx rate for the measurement of experimental variables. This paper examines a new measure of xx in xx based on fuzzy mathematics which overcomes the difficulties found in other xx measures. This paper describes a system for the analysis of the xx. The method involves the construction of xx from fuzzy relations. The procedure is useful in analyzing how groups reach a decision. The technique used is to employ a newly developed and versatile xx algorithm. The usefulness of xx is also considered. A brief methodology used in xx is discussed. The analysis is useful in xx and xx problem. A model is developed for a xx analysis using fuzzy matrices. Algorithms to combine these estimates and produce a xx are presented and justified. The use of the method is discussed and an example is given. Results of an experimental applications of this xx analysis procedure are given to illustrate the proposed technique. This paper analyses problems in This paper outlines the functions carried out by \u0026hellip; This paper includes an illustration of the \u0026hellip; This paper provides an overview and information useful for approaching Emphasis is placed on the construction of a criterion function by which the xx in achieving a hierarchical system of objectives are evaluated. The main emphasis is placed on the problem of xx Our proposed model is verified through experimental study. The experimental results reveal interesting examples of fuzzy phases of: xx, xx The compatibility of a project in terms of cost, and xx are likewise represented by linguistic variables. A didactic example is included to illustrate the computational procedure  Time  Over the course of the past 30 years, .. has emerged form intuitive Technological revolutions have recently hit the industrial world The advent of \u0026hellip; systems for has had a significant impact on the The development of \u0026hellip; is explored During the past decade, the theory of fuzzy sets has developed in a variety of directions The concept of xx was investigated quite intensively in recent years There has been a turning point in \u0026hellip; methodology in accordance with the advent of \u0026hellip; A major concern in \u0026hellip; today is to continue to improve\u0026hellip; A xx is a latecomer in the part representation arena. At the time of this writing, there is still no standard way of xx Although a lot of effort is being spent on improving these weaknesses, the efficient and effective method has yet to be developed. The pioneer work can be traced to xx [1965]. To date（到目前为止）, none of the methods developed is perfect and all are far from ready to be used in commercial systems.  Objective / Goal / Purpose   The purpose of the inference engine can be outlined as follows:\n  The ultimate goal of the xx system is to allow the non experts to utilize the existing knowledge in the area of manual handling of loads, and to provide intelligent, computer aided instruction for xxx.\n  The paper concerns the development of a xx\n  The scope of this research lies in\n  The main theme of the paper is the application of rule based decision making.\n  These objectives are to be met with such thoroughness and confidence as to permit \u0026hellip;\n  The objectives of the \u0026hellip; operations study are as follows:\n  The primary purpose/consideration/objective of\n  The ultimate goal of this concept is to provide\n  The main objective of such a \u0026hellip; system is to\n  The aim of this paper is to provide methods to construct such probability distribution.\n  In order to achieve these objectives, an xx must meet the following requirements:\n  In order to take advantage of their similarity\n  more research is still required before final goal of \u0026hellip; can be completed\n  In this trial, the objective is to generate\u0026hellip;\n  for the sake of concentrating on \u0026hellip; research issues\n  A major goal of this report is to extend the utilization of a recently developed procedure for the xx.\n  For an illustrative purpose, four well known OR problems are studied in presence of fuzzy data: xx.\n  A major thrust of the paper is to discuss approaches and strategies for structuring ..methods\n  This illustration points out the need to specify\n  The ultimate goal is both descriptive and prescriptive.\n  Chapter 2. Literature Review\n  A wealth of information is to be found in the statistics literature, for example, regarding xx\n  A considerable amount of research has been done .. during the last decade\n  A great number of studies report on the treatment of uncertainties associated with xx.\n  There is considerable amount of literature on planning\n  However, these studies do not provide much attention to uncertainty in xx.\n  Since then, the subject has been extensively explored and it is still under investigation as well in methodological aspects as in concrete applications.\n  Many research studies have been carried out on this topic.\n  Problem of xx draws recently more and more attention of system analysis.\n  Attempts to resolve this dilemma have resulted in the development of\n  Many complex processes unfortunately, do not yield to this design procedure and have, therefore, not yet been automated.\n  Most of the methods developed so far are deterministic and /or probabilistic in nature.\n  The central issue in all these studies is to\n  The problem of xx has been studied by other investigators, however, these studies have been based upon classical statistical approaches.\n  Applied \u0026hellip; techniques to\n  Characterized the \u0026hellip; system as\n  Developed an algorithm to\n  Developed a system called \u0026hellip; which\n  Uses an iterative algorithm to deduce\n  Emphasized the need to\n  Identifies six key issues surrounding high technology\n  A comprehensive study of the\u0026hellip; has been undertaken\n  Much work has been reported recently in these filed\n  Proposed/Presented/Statethat/Described/Illustrated/Indicated/Hasshown/showed/Address/Highlights\n  Point out that the problem of\n  A study on \u0026hellip;was done / developed by []\n  Previous work, such as [] and [], deal only with\n  The approach taken by [] is\n  The system developed by [] consists\n  A paper relevant to this research was published by []\n  []\u0026rsquo;s model requires consideration of\u0026hellip;\n  []' model draws attention to evolution in human development\n  []\u0026rsquo;s model focuses on\u0026hellip;\n  Little research has been conducted in applying \u0026hellip; to\n  The published information that is relevant to this research\u0026hellip;\n  This study further shows that\n  Their work is based on the principle of\n  More history of \u0026hellip; can be found in xx et al. [1979].\n  Studies have been completed to established\n  The \u0026hellip;studies indicated that\n  Though application of xx in the filed of xx has proliferated in recent years, effort in analyzing xx, especially xx, is lacking.\n  Problem / Issue / Question  Unfortunately, real-world engineering problems such as manufacturing planning do not fit well with this narrowly defined model. They tend to span broad activities and require consideration of multiple aspects. Remedy / solve / alleviate these problems \u0026hellip; is a difficult problem, yet to be adequately resolved Two major problems have yet to be addressed An unanswered question This problem in essence involves using x to obtain a solution.  ","description":"","id":88,"section":"posts","tags":["论文","写作"],"title":"转载-SCI论文写作常用经典词和常用句型","uri":"https://www.xunhs.cyou/posts/notes/83/"},{"content":"  \n 2020.2.1 静心。勿急躁。 2020.2.2 古语云：由俭入奢易，由奢入俭难。是否可以这样理解，古人因为害怕改变，就拒绝更好生活的可能？因为害怕失去，就拒绝所有的开始？ 2020.2.3 做一个简单单纯的人。 2020.2.4 沉稳一些。 2020.2.5 “凡有的，还要加倍给他叫他多余；没有的，连他所有的也要夺过来。” 2020.2.6 “巴巴地活着，每天打水，煮饭，按时吃药 阳光好的时候就把自己放进去，像放一块陈皮 茶叶轮换着喝：菊花，茉莉，玫瑰，柠檬 这些美好的事物仿佛把我往春天的路上带 所以我一次次按住内心的雪 它们过于洁白过于接近春天 在干净的院子里读你的诗歌。 这人间情事 恍惚如突然飞过的麻雀儿 而光阴皎洁。我不适宜肝肠寸断 如果给你寄一本书，我不会寄给你诗歌 我要给你一本关于植物，关于庄稼的 告诉你稻子和稗子的区别 告诉你一棵稗子提心吊胆的 春天” - 余秀华 《我爱你》 2020.2.7 霜叶红于二月花。 2020.2.8 日日重复同样的事，遵循着与昨日相同的惯例，若能避开猛烈的狂喜 ，自然也不会有悲痛的来袭。 2020.2.9 山川异域，风月同天。岂曰无衣，与子同裳。 2020.2.10 「你会自言自语吗？」「不然你以为我现在在跟谁说话？」 2020.2.11 1) 没有不停的雨，天一定会晴。互相争就不足，互相分就有馀。2) window10 上 pip安装的时候加上 \u0026ndash;user 会减少很多“拒绝访问”的问题。 pip install --user; 3) pip设置源：pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ 2020.2.12 青城山下白素贞~~ 2020.2.13 kepler.gl 可视化好用，而且可以到处高分辨率图集。但kepler.gl for Jupyter的版本较低 不好用。办法是在将kepler.gl在github的源码clone在本地，搭建好node, yarn 环境后， 设置mapbox的key ,就可以cpm start的了。非常方便~有服务器就可以直接部署在服务器上。 2020.2.14 文章还有一点就可以完成初稿了。 2020.2.15 造化到底为何物 2020.2.16 1) 不要把怀念搞得比经历还长。 2) 如果全世界都不要你了，记得要来找我，我认识好几个人贩子。 2020.2.17 自监督学习；图像表示学习。 2020.2.18 Skip-Thought Vectors; 从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史; 通用句子语义编码器; 2020.2.19 话都说不清楚 该怎么明了 2020.2.20 hexo的包太繁琐了，后续工具插件多了动不动就报错。思考了wordpress后，转到了typecho。记得最开始用的是typecho。 2020.2.21 终于把文档都迁移过来了。我真是闲的。不折腾了！音乐播放器和公式的插件搞不定、就这样了吧、 2020.2.22 把以前博客(WordPress)里面的文章，编辑了过来。那些周记和日记太繁琐了，就随它去吧。 2020.2.23 第二版修改稿完成😎 😎 憋了这么多天 我觉得我写东西严重靠感觉。 逼是逼不出什么墨水 2020.2.24 今天吃了螃蟹，很美味。但是晚上胃胀，感觉不消化，很不舒服。😵 2020.2.25 关于 House Prices 又有了新的提升点（0.12116），还是蛮开心的。不知怎么滴playground又是一天。 2020.2.26 轨迹表示学习 2020.2.27 1）自定义音乐引用:开启网站指定文件夹ftp功能（通过宝塔面板）；Python通过ftplib实现ftp上传音乐至custom文件夹；借助cplayer生成html；iframe指向html插入音乐；2）自定义图床（用公共图床总是有速度问题，想想就自己搭建图床）：使用PicGo + gitee 作为图床，参考; 3)QGIS挺好用的，而且反应速度也快，以后深入学一下。 2020.2.28 夜光遥感数据反映区域经济状况，同样也是网格状数据，同出租车数据联立一下。 2020.2.29 终于把Manuscript丢出去了。感觉放下了吧，又觉得沉了起来。我为啥给自己这么大压力呢。  ","description":"","id":89,"section":"posts","tags":["自定义音乐插件","自定义图床","博客迁移","出租车轨迹探索","kepler.gl","论文投稿","pip设置源"],"title":"2020-2","uri":"https://www.xunhs.cyou/posts/journals/98/"},{"content":" 用Python实现WGS84、火星坐标系、百度坐标系、web墨卡托四种坐标相互转换\n 简介 坐标系统：用于定位的系统，就跟二维笛卡尔坐标系统一样，一个点使用(x,y)，就能确定该点在笛卡尔坐标系统中的唯一位置。这里讲的坐标系统，相对于笛卡尔坐标系统，要复杂许多，但作用却都是一样，主要用于定位，也就是精确地定位地表上的一点。\n地理坐标系统：WGS84就是一种地理坐标系统。地理坐标坐标是对地球进行简单几何建模，比如将地球看成一个球体或者类球体，然后再将地表上点投影到该球面上形成的坐标就是地理坐标系统。WGS84就是定义了如何将地球抽象成球体或者类球体的规则。或者简单地来说，WGS84就是一堆参数，用于建立球体或者类球体，来近似地球。\n投影坐标系统：由于地球是一个球状，所以一般将其某个区域投影在平面上，形成的坐标系称为投影坐标系。\n国内各地图API坐标系统比较\n 地理坐标系：WGS84(Google, OSM)、火星坐标系/GCJ02(高德、腾讯地图)、百度坐标系(BD09)  WGS84 ：Google Earth和中Google Map使用，另外，目前基本上所有定位空间位置的设备都使用这种坐标系统，例如手机的GPS系统。 GCJ-02：也就是我们平常所说的火星坐标系，高德和腾讯使用，这个是中国自己在WGS84基础上加密而成。 BD09：百度地图使用，在GCJ-02基础上二次加密而成。   投影坐标系：web墨卡托  P.S. 关于经纬度十进制表示法   一度60分,一分60秒. 地球的子午线总长度大约40008km.平均： 纬度1度=大约111km 纬度1分=大约1.85km 纬度1秒=大约30.9m 单位经度的长度随着纬度的不同而变化：一个经度单位=（一个纬度单位的长度）乘以（该地区纬度的余弦值）.\n  对于两个点，在纬度相等的情况下：经度每隔0.00001度，距离相差约1米；每隔0.0001度，距离相差约10米；每隔0.001度，距离相差约100米；每隔0.01度，距离相差约1000米；每隔0.1度，距离相差约10000米。\n  对于两个点，在经度相等的情况下：纬度每隔0.00001度，距离相差约1.1米；每隔0.0001度，距离相差约11米；每隔0.001度，距离相差约111米；每隔0.01度，距离相差约1113米；每隔0.1度，距离相差约11132米。\n  P.P.S.\n Longitude (lon). 经度 Latitude (lat). 纬度  CoordinateTransctionTools.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184  import pandas as pd import math, uuid \u0026#34;\u0026#34;\u0026#34; GPS坐标转换： \u0026#34;\u0026#34;\u0026#34; def transformLat(x, y): ret = -100.0 + 2.0 * x + 3.0 * y + 0.2 * y * y + 0.1 * x * y + 0.2 * math.sqrt(abs(x)) ret += (20.0 * math.sin(6.0 * x * math.pi) + 20.0 * math.sin(2.0 * x * math.pi)) * 2.0 / 3.0 ret += (20.0 * math.sin(y * math.pi) + 40.0 * math.sin(y / 3.0 * math.pi)) * 2.0 / 3.0 ret += (160.0 * math.sin(y / 12.0 * math.pi) + 320 * math.sin(y * math.pi / 30.0)) * 2.0 / 3.0 return ret def transformLon(x, y): ret = 300.0 + x + 2.0 * y + 0.1 * x * x + 0.1 * x * y + 0.1 * math.sqrt(abs(x)) ret += (20.0 * math.sin(6.0 * x * math.pi) + 20.0 * math.sin(2.0 * x * math.pi)) * 2.0 / 3.0 ret += (20.0 * math.sin(x * math.pi) + 40.0 * math.sin(x / 3.0 * math.pi)) * 2.0 / 3.0 ret += (150.0 * math.sin(x / 12.0 * math.pi) + 300.0 * math.sin(x / 30.0 * math.pi)) * 2.0 / 3.0 return ret def delta(lat, lng): a = 6378245.0 # a: 卫星椭球坐标投影到平面地图坐标系的投影因子 ee = 0.00669342162296594323 # ee: 椭球的偏心率 dLat = transformLat(lng - 105.0, lat - 35.0) dLon = transformLon(lng - 105.0, lat - 35.0) radLat = lat / 180.0 * math.pi magic = math.sin(radLat) magic = 1 - ee * magic * magic sqrtMagic = math.sqrt(magic) dLat = (dLat * 180.0) / ((a * (1 - ee)) / (magic * sqrtMagic) * math.pi) dLon = (dLon * 180.0) / (a / sqrtMagic * math.cos(radLat) * math.pi) return dLat, dLon def wgs2gcj(wgsLat, wgsLng): \u0026#34;\u0026#34;\u0026#34; WGS-84转成GCJ-02 \u0026#34;\u0026#34;\u0026#34; if outOfChina(wgsLat, wgsLng): print(\u0026#34;The latitude or longitude is out of China!\u0026#34;) return wgsLat, wgsLng lat, lng = delta(wgsLat, wgsLng) return wgsLat + lat, wgsLng + lng def gcj2wgs_rough(gcjLat, gcjLon): \u0026#34;\u0026#34;\u0026#34; GCJ-02 转 WGS-84 粗略版 \u0026#34;\u0026#34;\u0026#34; if outOfChina(gcjLat, gcjLon): print(\u0026#34;The latitude or longitude is out of China!\u0026#34;) return gcjLat, gcjLon lat, lng = delta(gcjLat, gcjLon) return gcjLat - lat, gcjLon - lng def gcj2wgs_accurate(gcjLat, gcjLon): \u0026#34;\u0026#34;\u0026#34; GCJ-02 转 WGS-84 精确版 \u0026#34;\u0026#34;\u0026#34; initDelta = 0.01 threshold = 0.000000001 dLat = initDelta dLon = initDelta mLat = gcjLat - dLat mLon = gcjLon - dLon pLat = gcjLat + dLat pLon = gcjLon + dLon wgsLat = 0 wgsLon = 0 i = 0 while 1: wgsLat = (mLat + pLat) / 2 wgsLon = (mLon + pLon) / 2 lat, lon = gcj2wgs_rough(wgsLat, wgsLon) dLat = lat - gcjLat dLon = lon - gcjLon if (abs(dLat) \u0026lt; threshold) and (abs(dLon) \u0026lt; threshold): break if dLat \u0026gt; 0: pLat = wgsLat else: mLat = wgsLat if dLon \u0026gt; 0: pLon = wgsLon else: mLon = wgsLon if ++i \u0026gt; 10000: break return wgsLat, wgsLon def gcj2bd(gcjLat, gcjLon): \u0026#34;\u0026#34;\u0026#34; GCJ-02 转 BD-09 \u0026#34;\u0026#34;\u0026#34; x_pi = math.pi * 3000.0 / 180.0 x = gcjLon y = gcjLat z = math.sqrt(x * x + y * y) + 0.00002 * math.sin(y * x_pi) theta = math.atan2(y, x) + 0.000003 * math.cos(x * x_pi) bdLon = z * math.cos(theta) + 0.0065 bdLat = z * math.sin(theta) + 0.006 return bdLat, bdLon def bd2gcj(bdLat, bdLon): \u0026#34;\u0026#34;\u0026#34; BD-09 转 GCJ-02 \u0026#34;\u0026#34;\u0026#34; x_pi = math.pi * 3000.0 / 180.0 x = bdLon - 0.0065 y = bdLat - 0.006 z = math.sqrt(x * x + y * y) - 0.00002 * math.sin(y * x_pi) theta = math.atan2(y, x) - 0.000003 * math.cos(x * x_pi) gcjLon = z * math.cos(theta) gcjLat = z * math.sin(theta) return gcjLat, gcjLon def wgs2mercator(wgsLat, wgsLon): \u0026#34;\u0026#34;\u0026#34; WGS-84 to Web mercator mercatorLat -\u0026gt; y mercatorLon -\u0026gt; x \u0026#34;\u0026#34;\u0026#34; x = wgsLon * 20037508.34 / 180. y = math.log(math.tan((90. + wgsLat) * math.pi / 360)) / (math.pi / 180) y = y * 20037508.34 / 180. return y, x def mercator2wgs(mercatorLat, mercatorLon): \u0026#34;\u0026#34;\u0026#34; Web mercator to WGS-84 mercatorLat -\u0026gt; y mercatorLon -\u0026gt; x \u0026#34;\u0026#34;\u0026#34; x = mercatorLon / 20037508.34 * 180 y = mercatorLat / 20037508.34 * 180 y = 180 / math.pi * (2 * math.atan(math.exp(y * math.pi / 180.)) - math.pi / 2) return y, x def outOfChina(lat, lng): \u0026#34;\u0026#34;\u0026#34; 判断是否在中国范围外 \u0026#34;\u0026#34;\u0026#34; if lng \u0026lt; 72.004 or lng \u0026gt; 137.8347: return True if lat \u0026lt; 0.8293 or lat \u0026gt; 55.8271: return True return False def haversine(lat1, lon1, lat2, lon2): \u0026#34;\u0026#34;\u0026#34; :param: 纬度1，经度1，纬度2，经度2（十进制度数） :return: 二个坐标之间的距离（单位米） Calculate the great circle distance between two points on the earth (specified in decimal degrees) \u0026#34;\u0026#34;\u0026#34; # 将十进制度数转化为弧度 lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2]) # haversine公式 dlon = lon2 - lon1 dlat = lat2 - lat1 a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2 c = 2 * math.asin(math.sqrt(a)) r = 6371 # 地球平均半径，单位为公里 return c * r * 1000 if __name__ == \u0026#39;__main__\u0026#39;: //   case Ploygon Transfor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  import json from copy import deepcopy from CoordinateTransctionTools import * with open(\u0026#39;./layers/sz_block_mars.json\u0026#39;, \u0026#39;r\u0026#39;) as fp: blocks_json = json.load(fp) blocks_json_tran = deepcopy(blocks_json) def transfer(coordinates): new_coordinates = [] for coor in coordinates: try: (x, y) = coor except: print(_) print(\u0026#39;----\u0026#39;) _y, _x = gcj2wgs_rough(y, x) new_coordinates.append([_x, _y]) return [new_coordinates] for idx, blocks in enumerate(blocks_json[\u0026#39;features\u0026#39;]): _type = blocks[\u0026#39;geometry\u0026#39;][\u0026#39;type\u0026#39;] if _type == \u0026#34;Polygon\u0026#34;: coordinates = blocks[\u0026#39;geometry\u0026#39;][\u0026#39;coordinates\u0026#39;][0] blocks_json_tran[\u0026#39;features\u0026#39;][idx][\u0026#39;geometry\u0026#39;][\u0026#39;coordinates\u0026#39;] = transfer(coordinates) elif _type == \u0026#34;MultiPolygon\u0026#34;: coordinates = blocks[\u0026#39;geometry\u0026#39;][\u0026#39;coordinates\u0026#39;] new_coordinates_list = [] for _coor in coordinates: new_coordinates_list.append(transfer(_coor[0])) blocks_json_tran[\u0026#39;features\u0026#39;][idx][\u0026#39;geometry\u0026#39;][\u0026#39;coordinates\u0026#39;] = new_coordinates_list with open(\u0026#39;./layers/sz_street_blocks_wgs84.json\u0026#39;, \u0026#39;w+\u0026#39;) as fp: json.dump(blocks_json_tran, fp)   ","description":"","id":90,"section":"posts","tags":["Python","坐标转换"],"title":"Python-坐标系转换","uri":"https://www.xunhs.cyou/posts/notes/75/"},{"content":" 每一年的临近新年时期，总会感慨时间的匆匆。因为回想一年的工作和收获，总觉得少的可怜。2019年的年初给自己定下两个目标，在元旦到来之前也均有了结果。一次情感经历，一篇论文发表，一次雅思考试。总体上对今年的表现基本满意，会给自己制定计划，会依照计划行事，但是仍表现懒散，常有拖拉。然而，未来可期，对明年甚至接下来的几年，我都怀有期待，而且对自己充满自信。以下是我具体的总结以及相关规划。\n 吴老师您好，\n农历新年即将来临，首先祝您新年快乐！\n每一年的临近新年时期，总会感慨时间的匆匆。因为回想一年的工作和收获，总觉得少的可怜。2019年的年初给自己定下两个目标，在元旦到来之前也均有了结果。一次情感经历，一篇论文发表，一次雅思考试。总体上对今年的表现基本满意，会给自己制定计划，会依照计划行事，但是仍表现懒散，常有拖拉。然而，未来可期，对明年甚至接下来的几年，我都怀有期待，而且对自己充满自信。以下是我具体的总结以及相关规划：\n总结：\n 完成论文一篇，并发表在CEUS上。这是一篇探索城市功能结构的论文，主要基于POI数据，类比并改进词向量（表示学习）的方法，探索城市功能分区，旨在挖掘隐含在地理大数据中的与城市居民息息相关的信息。词向量或主题模型等自然语言处理的方法在城市功能研究中越来越受到学者的欢迎，本次研究仅在前人的基础上进行深化。论文最终能够发表并得到认可当然是非常开心的，但是我深知本篇文章还是存在很多不足的，有很多需要改进的地方，如数据源单一，导致特征表达有限，以及评阅人提及的土地利用复杂性等问题，为下一步研究提供更深层次的思考。同时，在文章撰写以及与评阅人辩论和交流的过程中，英语写作水平和思维逻辑能力有了较大的提升。特别是评阅过程中，遇到评审人特别刁钻的问题，首先要学会控制自己的负面情绪，考虑评阅人是如何看待这种问题，如若对于实验论证不足或缺乏对比等涉及实验相关的问题，能补就补，并强调讨论文章的侧重点。非OA期刊的评审时期有些长，要保持耐心，好的结果能经得起等待。 准备雅思考试，并在12月初考试。关于雅思考试或许已经“蓄谋已久”了吧。从读博士开始有“出去转转”的念头，到18年准备小段时间最终没报名考试，到2019年9月份来时的“精心”准备。三个半月的时间，有大半部分的时间是投入到复习中的，这对于很多“考鸭”来说已经很充足的时间了。但是对于我而言，仍没有做得很好。结果并不理想。考完之后有很长一段时间都在反思。我觉得是有多方面原因的：复习方法错误，对于自己能力的评估不到位以及情绪影响。英语更多的是长时间的积累，而不是短短三个月就可以突击完成的。通过此次考试，也对自己的语言水平有一个深刻的认知，关于写作，关于词汇量，关于听力，以及最让自己头疼的“儿童口语”。不要只是把英语学习挂在嘴边吧，不要等要用到在拼命的补吧，每天拿出半个小时甚至更多的时间去记单词做一些日常翻译、写作，养成英语学习的习惯，日积月累总会见到效果。欲速则不达。 地理大数据项目跟进。今年项目出差次数不算少，从年初在武大的课题总结报告，到年中5、6月份的中期检查，每次出差都使我印象深刻。项目方对于文档和各种报告（包括月报、进展报告等）的要求较严格，对于原型系统的设计和代码的编写要求也十分规范，以及各课题、子课题之间相互联系甚至制约、监督，部门和老师的分工，都使我颇有感触。以后真正走上教师的岗位的话，接触基金、课题甚至项目只会越来越多。越熟悉大项目的流程，理解从思路、到编写申请、再到项目管理和进展是多么不易。学会思考，从中获得经验。  规划：\n 完成至少两篇论文，其中至少一篇较高水平的文章。也许有了一篇论文为基础，我会更有自信。因此今年给自己两篇论文的目标。当然这个目标并不是空穴来风。这与目前的两个思路有关联。第一个是基于路网挖掘“社区”，并探索基于“社区”进行城市区域感知的可能性。第二个是基于词向量方法的多源数据融合，同样应用于城市区域感知。目前想法仍然不成熟，需要进一步的阅读论文进行理论验证，并实施相关实验。 日常英语学习。包括记单词，每日几句的翻译或写作。同样需保证论文阅读的数量，制定相关的学习计划。 CSC联培。熟知相关时间节点。指定联合培养学习计划。做好双方导师的沟通。以及，坚持！  停止抱怨，改掉拖延，罗列问题，逐一解决 \u0026mdash;- 对自己接下来工作的期许。感谢吴老师在关键时刻给与的指导和莫大的帮助。愿新的一年，可以不负韶华，砥砺前行。\n此致冬宁。\n","description":"","id":91,"section":"posts","tags":["邮件","学期总结","规划"],"title":"2020-1-总结与规划邮件","uri":"https://www.xunhs.cyou/posts/journals/2020-01-12-2020-1-%E6%80%BB%E7%BB%93%E4%B8%8E%E8%A7%84%E5%88%92%E9%82%AE%E4%BB%B6/"},{"content":" pathlib 是 python3 非常好用的文件/文件夹操作的库，总结常用用法，参考自jianshu\n 常用操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  from pathlib import Path p = Path() p = Path(r\u0026#39;d:\\test\\tt.txt.bk\u0026#39;) p.name # 获取文件名 # tt.txt.bk p.stem # 获取文件名除后缀的部分 # tt.txt p.suffix # 文件后缀 # .bk p.suffixs # 文件的后缀们... # [\u0026#39;.txt\u0026#39;, \u0026#39;.bk\u0026#39;] p.parent # 相当于dirnanme # WindowsPath(\u0026#39;d:/test\u0026#39;) p.parents # 返回一个iterable, 包含所有父目录 # \u0026lt;WindowsPath.parents\u0026gt; for i in p.parents: print(i) # d:\\test # d:\\ a.parts # 将路径通过分隔符分割成一个元祖 # (\u0026#39;d:\\\\\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;tt.txt.bk\u0026#39;) p = Path(p, \u0026#39;tt.txt\u0026#39;) # 字符串拼接 p.exists() # 判断文件是否存在 p.is_file() # 判断是否是文件 p.is_dir() # 判断是否是目录   遍历文件夹 1 2 3 4 5  p = Path(r\u0026#39;d:\\test\u0026#39;) # WindowsPath(\u0026#39;d:/test\u0026#39;) p.iterdir() # 相当于os.listdir p.glob(\u0026#39;*\u0026#39;) # 相当于os.listdir, 但是可以添加匹配条件 p.rglob(\u0026#39;*\u0026#39;) # 递归遍历   创建文件夹 1 2 3 4 5  p = Path(r\u0026#39;d:\\test\\tt\\dd\u0026#39;) p.mkdir(exist_ok=True) # 创建文件目录(前提是tt目录存在, 否则会报错) # 一般我会使用下面这种创建方法 p.mkdir((exist_ok=True, parents=True) # 递归创建文件目录   ","description":"","id":92,"section":"posts","tags":["Python","pathlib","文件/文件夹"],"title":"Python库：pathlib","uri":"https://www.xunhs.cyou/posts/notes/72/"},{"content":" 整理Python并行化常用技巧\n 利用joblib实现多进程/线程(参考1, 官网文档, 参考2) 与multiprocessing需要将执行运算的语句放置于含有if name == \u0026lsquo;main\u0026rsquo;：的脚本文件中下不同，joblib将多进程的实现方式大大简化，使得我们可以在IPython交互式环境下中灵活地使用它。\n入门实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  from joblib import Parallel, delayed, parallel_backend import numpy as np import time import datetime def job(i): start = datetime.datetime.now().strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) time.sleep(5) end = datetime.datetime.now().strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) return start, end if __name__ == \u0026#34;main\u0026#34;: with parallel_backend(\u0026#39;threading\u0026#39;, n_jobs=50): res = Parallel(verbose=1)(delayed(job)(j) for j in range(5))     结果\n  parallel_backend: threading为线程方式，multiprocessing为进程方式\n  n_jobs控制并行进程的数量，verbose参数控制是否打印进程运算过程\n  多参数方案 1 2 3 4 5 6 7 8 9 10 11 12  def my_fun_2p(i, j): \u0026#34;\u0026#34;\u0026#34; We define a simple function with two parameters. \u0026#34;\u0026#34;\u0026#34; time.sleep(1) return math.sqrt(i**j) start = time.time() # n_jobs is the number of parallel jobs Parallel(n_jobs=2)(delayed(my_fun_2p)(i, j) for i in range(num) for j in range(j_num)) end = time.time() print(\u0026#39;{:.4f}s\u0026#39;.format(end-start))   使用 joblib 对 Pandas 数据进行并行处理(参考1) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import pandas as pd from joblib import Parallel, delayed from tqdm import tqdm, tqdm_notebook tqdm_notebook().pandas() def double_func(data): return pow(data,2) def key_func(subset): subset[\u0026#34;double\u0026#34;] = subset[\u0026#34;source\u0026#34;].apply(double_func) data_grouped = data.groupby(data.index) results = Parallel(n_jobs=8)(delayed(key_func)(group) for name, group in tqdm(data_grouped)) data = pd.concat(results)    基本原理就是把整个 dataframe 根据 index，每行生成了一个子数据集，而把每个子数据集作为子任务使用多进程运行，最终生成 results 是多进程运行生成的结果的 list，使用 concat 重新组合就是我们最终想要的结果了。 我们生成的 data_grouped 是一个可迭代的对象，那么就可以使用 tqdm 来可视化进度条。 友情提示，在我自己使用的时候遇到 bug ，提示无法从 Pandas 导入 PanelGroupby 的错误。查了许久才发现，是新版 Pandas 删除了PanelGroupby 这个模块。解决办法其实就是……升级 tqdm，在最新版已经修复了这个 bug 了。  multiprocessing.map (参考1) 线程任务（IO 密集型任务） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [ \u0026#39;http://www.python.org\u0026#39;, \u0026#39;http://www.python.org/about/\u0026#39;, \u0026#39;http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html\u0026#39;, \u0026#39;http://www.python.org/doc/\u0026#39;, \u0026#39;http://www.python.org/download/\u0026#39;, \u0026#39;http://www.python.org/getit/\u0026#39;, \u0026#39;http://www.python.org/community/\u0026#39;, \u0026#39;https://wiki.python.org/moin/\u0026#39;, \u0026#39;http://planet.python.org/\u0026#39;, \u0026#39;https://wiki.python.org/moin/LocalUserGroups\u0026#39;, \u0026#39;http://www.python.org/psf/\u0026#39;, \u0026#39;http://docs.python.org/devguide/\u0026#39;, \u0026#39;http://www.python.org/community/awards/\u0026#39; # etc.. ] # Make the Pool of workers pool = ThreadPool(4) # Open the urls in their own threads # and return the results results = pool.map(urllib2.urlopen, urls) #close the pool and wait for the work to finish pool.close() pool.join()    多线程常应用在网络任务，如爬虫 ThreadPool.map 简化分组操作  进程任务（CPU 密集型任务） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  import os import PIL from multiprocessing import Pool from PIL import Image SIZE = (75,75) SAVE_DIRECTORY = \u0026#39;thumbs\u0026#39; def get_image_paths(folder): return (os.path.join(folder, f) for f in os.listdir(folder) if \u0026#39;jpeg\u0026#39; in f) def create_thumbnail(filename): im = Image.open(filename) im.thumbnail(SIZE, Image.ANTIALIAS) base, fname = os.path.split(filename) save_path = os.path.join(base, SAVE_DIRECTORY, fname) im.save(save_path) if __name__ == \u0026#39;__main__\u0026#39;: folder = os.path.abspath(\u0026#39;11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840\u0026#39;) os.mkdir(os.path.join(folder, SAVE_DIRECTORY)) images = get_image_paths(folder) pool = Pool() pool.map(creat_thumbnail, images) pool.close() pool.join()   ","description":"","id":93,"section":"posts","tags":["multiprocessing","joblib","并行","Pandas","Python"],"title":"Python多线程/进程技巧","uri":"https://www.xunhs.cyou/posts/notes/74/"},{"content":" 总结tqdm库，进度条显示。\n te quiero demasiado\n基本用法 1 2 3 4  from tqdm import tqdm for i in tqdm(range(10000)): ...   Manual 1 2 3 4 5 6  pbar = tqdm(total=100) for i in range(10): time.sleep(0.1) pbar.update(10) pbar.close()   Advanced 1 2 3 4 5 6 7 8 9 10 11 12  from tqdm import tqdm bar = tqdm(ncm_list) for ncm_item in bar: # print(ncm_item.stem) bar.set_description_str(desc=ncm_item.stem) dump(ncm_item) \u0026#39;\u0026#39;\u0026#39; 效果： 动态更新描述部分 \u0026#39;\u0026#39;\u0026#39;   Pandas Integrate df.progress_apply\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import pandas as pd import numpy as np from tqdm import tqdm df = pd.DataFrame(np.random.randint(0, 100, (100000, 6))) # Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm` # (can use `tqdm.gui.tqdm`, `tqdm.notebook.tqdm`, optional kwargs, etc.) tqdm.pandas(desc=\u0026#34;my bar!\u0026#34;) # Now you can use `progress_apply` instead of `apply` # and `progress_map` instead of `map` df.progress_apply(lambda x: x**2) # can also groupby: # df.groupby(0).progress_apply(lambda x: x**2)   Keras Integration 1 2 3 4 5 6  from tqdm.keras import TqdmCallback ... model.fit(..., verbose=0, callbacks=[TqdmCallback()])   IPython/Jupyter Integration 1 2 3 4 5 6 7 8  from tqdm.notebook import trange, tqdm from time import sleep for i in trange(3, desc=\u0026#39;1st loop\u0026#39;): for j in tqdm(range(100), desc=\u0026#39;2nd loop\u0026#39;, leave=False): sleep(0.01)   ","description":"","id":94,"section":"posts","tags":["progressbar","进度条","tqdm","Python"],"title":"Python库-tqdm-进度条","uri":"https://www.xunhs.cyou/posts/notes/73/"},{"content":" 总结个人使用中常用Pandas及扩展插件使用技巧\n I/O pandas可以直接读取压缩文件，同样写可以写入压缩文件 参考\nYou can read directly from a compressed file, Or write to a compressed file.\nAlso supported: .gz, .bz2, .xz\nHDFStore 尽可能的避免读取原始csv，使用hdf、feather或h5py格式文件加快文件读取 (参考1, 参考2)\nHDF5（Hierarchical Data Formal）是用于存储大规模数值数据的较为理想的存储格式，文件后缀名为h5，存储读取速度非常快，且可在文件内部按照明确的层次存储数据，同一个HDF5可以看做一个高度整合的文件夹，其内部可存放不同类型的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  import pandas as pd import numpy as np # 创建新的对象、读入已存在的对象 store = pd.HDFStore(\u0026#39;demo.h5\u0026#39;) # 导出到已存在的h5文件中，这里需要指定key df_.to_hdf(path_or_buf=\u0026#39;demo.h5\u0026#39;,key=\u0026#39;df_\u0026#39;) s = pd.Series(np.random.randn(5), index=[\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;]) df = pd.DataFrame(np.random.randn(8, 3), columns=[\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;]) # 将 Series 或 DataFrame 存入 store store[\u0026#34;s\u0026#34;], store[\u0026#34;df\u0026#34;] = s, df # 查看 store 中有哪些数据 store.keys() # out: [\u0026#39;/df\u0026#39;, \u0026#39;/s\u0026#39;] # 取出某一数据 df = store[\u0026#34;df\u0026#34;] # 删除store对象中指定数据 del store[\u0026#39;s\u0026#39;] # 将当前的store对象持久化到本地 store.close() # 查看连接状况 store.is_open   HDF5用时仅为csv的1/13，因此在涉及到数据存储特别是规模较大的数据时，HDF5是你不错的选择。\n读取csv 1  one_piece_df = pd.read_csv(csv_path, header = 0, encoding=\u0026#39;gbk\u0026#39;, engine=\u0026#39;python\u0026#39;, error_bad_lines=False)    encoding: 编码问题 engine: 报错- ParserError: Error tokenizing data. C error: EOF inside string starting at row 15946 error_bad_lines: 忽略有错误的行, 这个用处比较大，有很多类型的报错都可以解决，建议一般情况下加上: Skipping line 15513: ’ ’ expected after ‘\u0026quot;’; Skipping line 15546: unexpected end of data; ParserError: Expected 19 fields in line 212, saw 20field larger than field limit (131072)  保存为json 1 2 3 4  # 建议保存方法: parcels_info_df.to_json(\u0026#39;ParcelsInfo.json\u0026#39;, orient=\u0026#39;index’) # 同样读取方法： pd.read_json(\u0026#39;ParcelsInfo.json\u0026#39;, orient=\u0026#39;index’)   其他保存方法：\n1 2  with open(\u0026#39;./name.json\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as fp: json.dump(result_dict, fp, indent=4)   DataFrame and Dict: 1 2 3 4  # Dict 2 DataFrame: kmeans_result_df = pd.DataFrame.from_dict(kmeans_result_dict) # DataFrame 2 Dict: kmeans_result_dict = pd.DataFrame.to_dict(kmeans_result_df)   List of dict and DataFrame 1 2 3 4 5 6 7 8  # List of dict to DataFrame data_list = [{\u0026#39;points\u0026#39;: 50, \u0026#39;time\u0026#39;: \u0026#39;5:00\u0026#39;, \u0026#39;year\u0026#39;: 2010}, {\u0026#39;points\u0026#39;: 25, \u0026#39;time\u0026#39;: \u0026#39;6:00\u0026#39;, \u0026#39;month\u0026#39;: \u0026#34;february\u0026#34;}, {\u0026#39;points\u0026#39;:90, \u0026#39;time\u0026#39;: \u0026#39;9:00\u0026#39;, \u0026#39;month\u0026#39;: \u0026#39;january\u0026#39;}, {\u0026#39;points_h1\u0026#39;:20, \u0026#39;month\u0026#39;: \u0026#39;june\u0026#39;}] df = pd.DataFrame(data_list) # DataFrame to List of dict data_list = df.T.to_dict().values()   dict2nametuple 1 2 3 4 5 6 7 8 9 10 11 12 13  from collections import namedtuple args_dict = { \u0026#39;no_cuda\u0026#39;: False, \u0026#39;fastmode\u0026#39;: False, \u0026#39;seed\u0026#39;: 666, \u0026#39;epochs\u0026#39;: 500, \u0026#39;lr\u0026#39;: 0.01, \u0026#39;weight_decay\u0026#39;: 5e-4, \u0026#39;hidden\u0026#39;: 64, \u0026#39;dropout\u0026#39;: 0.5, } Args = namedtuple(\u0026#39;Args\u0026#39;, [_ for _ in args_dict.keys()]) args = Args(**(args_dict))   DataFrame导出Markdown 1 2 3 4 5 6 7 8 9 10  from tabulate import tabulate df = DataFrame({ \u0026#34;weekday\u0026#34;: [\u0026#34;monday\u0026#34;, \u0026#34;thursday\u0026#34;, \u0026#34;wednesday\u0026#34;], \u0026#34;temperature\u0026#34;: [20, 30, 25], \u0026#34;precipitation\u0026#34;: [100, 200, 150], }).set_index(\u0026#34;weekday\u0026#34;) md = tabulate(df, tablefmt=\u0026#34;pipe\u0026#34;, headers=\u0026#34;keys\u0026#34;) print(md)   joblib 1 2 3 4 5 6 7  # 保存变量 metrics_fp = Path(gensim_model_dir, \u0026#39;metrics.dat\u0026#39;) joblib.dump(value=metric_list, filename=str(metrics_fp)) # 载入变量 metrics_fp = Path(gensim_model_dir, \u0026#39;metrics.dat\u0026#39;) # metric_list = joblib.load(metrics_fp)   数据库交互 postgresql交互 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117  from sqlalchemy import create_engine from geoalchemy2 import Geometry, WKTElement import pandas as pd import geopandas as gpd \u0026#39;\u0026#39;\u0026#39; Geopanda, pandas 2 postgresql postgis操作在建立数据库后需添加postgis扩展，可在pgAdmin中新建数据库后添加 \u0026#39;\u0026#39;\u0026#39; class Transit(object): def __init__(self, engine_string, dbschema): self.engine_string = engine_string self.dbschema = dbschema self.engine = self.connect() def connect(self): engine = create_engine( self.engine_string, use_batch_mode=True, connect_args={\u0026#39;options\u0026#39;: \u0026#39;-csearch_path={}\u0026#39;.format(self.dbschema)}) return engine def list_tables(self, ): return self.engine.table_names() def to_dataframe(self, table_name): df = pd.read_sql_table(table_name, self.engine) return df def to_geodataframe_by_query(self, query_str, geom_col): gdf = gpd.read_postgis(sql=query_str, con=self.engine, geom_col=geom_col) return gdf def to_geodataframe(self, table_name, geom_col): sql_str = \u0026#34;select * from {}\u0026#34;.format(table_name) gdf = self.to_geodataframe_by_query(self, sql_str, geom_col) return gdf def write_dataframe(self, df, table_name): df.to_sql(table_name, self.engine) def write_geodataframe(self, gdf, table_name, if_exists=\u0026#39;replace\u0026#39;, geometry_str=\u0026#39;geometry\u0026#39;): \u0026#39;\u0026#39;\u0026#39; gdf: geopandas geodataframe table_name: if_exists: {‘fail’, ‘replace’, ‘append’} Geometry: See :class:`geoalchemy2.types._GISType` for the list of arguments that can be passed to the constructor \u0026#39;\u0026#39;\u0026#39; gdf.to_sql(name=table_name, con=self.engine, if_exists=if_exists, index=False, dtype={geometry_str: Geometry(\u0026#39;POINT\u0026#39;, srid=4326)}) if __name__ == \u0026#34;__main__\u0026#34;: # ----------------------- 定义数据库参数 -------------------------# # follows django database settings format, replace with your own settings DATABASES = { \u0026#39;db1\u0026#39;: { \u0026#39;NAME\u0026#39;: \u0026#39;postgis\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;123345678\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;localhost\u0026#39;, \u0026#39;PORT\u0026#39;: 5432, }, } # choose the database to use db = DATABASES[\u0026#39;db1\u0026#39;] # construct an engine connection string engine_string = \u0026#34;postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\u0026#34;.format( user=db[\u0026#39;USER\u0026#39;], password=db[\u0026#39;PASSWORD\u0026#39;], host=db[\u0026#39;HOST\u0026#39;], port=db[\u0026#39;PORT\u0026#39;], database=db[\u0026#39;NAME\u0026#39;], ) # 选择特定schema保存（默认保存在public）;public一定要加在尾部（不然geometry写入时会报错），逗号不能有空格 dbschema = \u0026#39;chongqing,public\u0026#39; # ----------------------- 定义数据库参数 -------------------------# # ----------------------- 列出表 -------------------------# transit = Transit(engine_string, dbschema) transit.list_tables() # [] # ----------------------- 列出表 -------------------------# # ----------------------- 写入数据至postgresql -------------------------# gdf = gpd.read_file(\u0026#39;./重庆市.geojson\u0026#39;) gdf[\u0026#39;wgs_geometry\u0026#39;] = gdf[\u0026#39;geometry\u0026#39;].apply(lambda x: WKTElement(x.wkt, srid=4326)) gdf.drop([\u0026#39;geometry\u0026#39;], axis=1, inplace=True) transit.write_geodataframe(gdf, table_name, \u0026#39;append\u0026#39;, geometry_str=\u0026#39;wgs_geometry\u0026#39;) #------ transit.write_dataframe(gdf[[\u0026#39;adcode\u0026#39;, \u0026#39;name\u0026#39;]], \u0026#39;chongqing_attr\u0026#39;) # ----------------------- 写入数据至postgresql -------------------------# # ----------------------- 从postgresql读出数据 -------------------------# table_name, geom_col = \u0026#39;chongqing\u0026#39;, \u0026#39;geometry\u0026#39; gdf = transit.to_geodataframe(table_name,geom_col) gdf.plot() table_name = \u0026#39;chongqing_attr\u0026#39; df = transit.to_dataframe(table_name) # ----------------------- 从postgresql读出数据 -------------------------#   mongodb交互 将 DataFrame 保存至 mongodb\n1  mongo.collection.insert(json.loads(df.T.to_json()).values())   to_sqlite 有时候大批量的df.query查询太耗时间了，没有sql查询速度快。因此想到的一个解决方案是把查询目标的DataFrame存储到sqlite数据库，然后使用sql进行查询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # pip install sqlalchemy from sqlalchemy import create_engine import os import geopandas as gpd import pandas from tqdm import tqdm data_root = \u0026#34;../data\u0026#34; nodes_fp = os.path.join(data_root, \u0026#34;wh/wh.shp/nodes.shp\u0026#34;) edges_fp = os.path.join(data_root, \u0026#34;wh/wh.shp/edges.shp\u0026#34;) edges_gdf = gpd.read_file(edges_fp) # Create an in-memory SQLite database. engine = create_engine(\u0026#39;sqlite://\u0026#39;, echo=False) edges_gdf[[\u0026#39;fid\u0026#39;, \u0026#39;from\u0026#39;, \u0026#39;to\u0026#39;]].to_sql(\u0026#39;edges\u0026#39;, con=engine, if_exists=\u0026#39;replace\u0026#39;) # 查询edges中fid为1，2的元素，并取值from和to engine.execute(\u0026#34;SELECT e.\u0026#39;from\u0026#39;, e.\u0026#39;to\u0026#39; FROM edges as e where e.\u0026#39;fid\u0026#39;in (1,2,3, \u0026#39;\u0026#39;)\u0026#34;).fetchall()    df.to_sql; create_engine:如果想保存到本地，sqlite://后填入地址即可，如engine = create_engine('sqlite:///C:\\\\sqlitedbs\\\\school.db', echo=True) 此处转换DataFrame为一个SQLite数据库，放在内存中 if_exists : {\u0026lsquo;fail\u0026rsquo;, \u0026lsquo;replace\u0026rsquo;, \u0026lsquo;append\u0026rsquo;}, default \u0026lsquo;fail\u0026rsquo;  fail: Raise a ValueError. replace: Drop the table before inserting new values. append: Insert new values to the existing table.   to_sql还可以通过dtype={\u0026quot;A\u0026quot;: Integer()}来定义数据类型，需先引入from sqlalchemy.types import Integer; sqlalchemy通用数据类型💨sqlalchemy.types   数据处理 基础操作 数据筛选（行操作） 在筛选数据的时候，我们一般用df[条件]的格式，其中的条件，是对data每一行数据的true和false布尔变量的Series\n 条件：例如，我们想得到车牌照为22271的所有数据。首先我们要获得一个布尔变量的Series，这个Series对应的是data的每一行，如果车牌照为\u0026quot;粤B4H2K8\u0026quot;则为true，不是则为false。这样子的Series很容易获得，只需要df['VehicleNum']==22271 筛选数据：  单一条件df[df['VehicleNum']==22271] 多条件：  并：df[(df['popularity'] \u0026gt; 3) \u0026amp; (df['popularity'] \u0026lt; 7)] 或：df[(df['popularity'] \u0026lt; 3) | (df['popularity'] \u0026gt; 7)]   返回满足条件的行号(索引)：np.where(df['VehicleNum']==22271) 提取某一行数据：df.iloc[32] 提取popularity列最大值所在行: df[df['popularity'] == df['popularity'].max()]   反向筛选：data[-(条件)]，例如: data[-(data['VehicleNum']==22271)] 添加一行数据: df = df.append({'grammer':'Perl','popularity':6.6},ignore_index=True) 去除重复行： df.drop_duplicates(subset=None, keep='first', inplace=False)  subset : column label or sequence of labels, optional 用来指定特定的列，默认所有列 keep : {‘first’, ‘last’, False}, default ‘first’ 删除重复项并保留第一次出现的项 inplace : boolean, default False 是直接在原来数据上修改还是保留一个副本 参考: drop_duplicates   将数据排序,并把排序后的数据赋值给原来的数据：  1 2  df = df.sort_values(by = [\u0026#39;VehicleNum\u0026#39;,\u0026#39;Stime\u0026#39;], ascending = True) #ascending: True 升序,False 降序    遍历行: 如果必须要要用iterrows，可以用itertuples来进行替换。在任何情况下itertuples都比iterrows快很多倍。 1 2  for row in df.itertuples(): print(getattr(row, \u0026#39;c1\u0026#39;), getattr(row, \u0026#39;c2\u0026#39;))     获取/删除/定义DataFrame的某一列（列操作）  获取列\u0026rsquo;Stime'：df['Stime']或df.loc[:,'Stime'] 删除列\u0026rsquo;Stime'：df.drop(['Stime'],axis=1) 获取某一列某一行的数据：df['Stime'].iloc[3] #获取Stime列的第4行数据 列（Columns）重命名：df.rename(columns={\u0026quot;x\u0026quot;: \u0026quot;pu_x\u0026quot;, \u0026quot;y\u0026quot;: \u0026quot;pu_y\u0026quot;}, inplace=True) 某一列类型转换：df['salary'].astype(np.float64) 索引： 重置行号：df.reset_index() 设置索引：df.set_index('car_id') 统计出现频率/次数：例如， 查看每种学历出现的次数：df.education.value_counts() 查看education列共有几种学历：df.education.nunique()  查看DataFrame基本信息  查看索引、数据类型和内存信息：df.info() 查看数值型列的汇总统计： df.describe() 查看df所有数据的最小值、25%分位数、中位数、75%分位数、最大值：np.percentile(df, q=[0, 25, 50, 75, 100]) EDA分析(数据可视化): sweetviz Init:    1 2 3 4  import sweetviz as sz import pandas as pd df = pd.read_csv(\u0026#39;train_set.csv\u0026#39;, header=0) df1 = pd.read_csv(\u0026#39;test_set.csv\u0026#39;, header=0)   - 综合报告:常见数据特征报告， [link](https://cdn.jsdelivr.net/gh/xunhs/image_host/assets/python/sweetviz/Advertising.html) ```python advert_report = sz.analyze(df) advert_report.show_html('Advertising.html') ``` - 对比报告:如训练集和测试集对比， [link](https://cdn.jsdelivr.net/gh/xunhs/image_host/assets/python/sweetviz/Comparing.html) ```python compare_report = sz.compare(df.drop('y', axis=1), df1) compare_report.show_html('Comparing.html') ```   Pandas基本数据类型dtype参考  缺失值  查看每列数据缺失值情况：df.isnull().sum() 提取日期列含有空值的行：df[df.datetime.isnull()] 删除存在缺失值的行：df.dropna(axis=0, how='any', inplace=True)  axis：0-行操作（默认），1-列操作 how：any-只要有空值就删除（默认），all-全部为空值才删除    关联和合并  合并concat（轴向连接）（无需键值，直接合并，A和B具有相同的结构）  1 2 3  # pd.concat([A, B]) # 有[] pd.concat([A, B], axis=1) # 列之间拼接 pd.concat([A, B], axis=0) # 行之间拼接    关联merge（数据库风格的合并）（需指定键值，依照键值匹配关系连接）  1 2  # pd.merge(A, B, left_on, right_on, how) # 无[] pd.merge(A, B, left_on=\u0026#39;airport_ref\u0026#39;, right_on=\u0026#39;id\u0026#39;, how=\u0026#39;inner\u0026#39;)   query() 参考基于query()的高效查询\n示例 找出类型为TV Show且国家不含美国的Kids' TV\n常用特性  直接解析字段名\n在使用query()时我们在不需要重复书写数据框名称[字段名]这样的内容，字段名也直接可以当作变量使用，而且不同条件之间不需要用括号隔开，在条件繁杂的时候简化代码的效果更为明显。 链式表达式 1 2 3 4 5 6  demo = pd.DataFrame({ \u0026#39;a\u0026#39;: [5, 4, 3, 2, 1], \u0026#39;b\u0026#39;: [1, 2, 3, 4, 5] }) demo.query(\u0026#34;a \u0026lt;= b != 4\u0026#34;)    支持in与not in判断: netflix.query(\u0026quot;release_year in [2018, 2019]\u0026quot;) 对外部变量的支持:query()表达式还支持使用外部变量，只需要在外部变量前加上@符号即可 1 2  years = [2018, 2019] netflix.query(\u0026#34;release_year in @years\u0026#34;)    对常规语句的支持: 可以直接解析Python语句，极大地自由度 1 2 3 4 5 6 7 8  def country_count(s): \u0026#39;\u0026#39;\u0026#39; 计算涉及国家数量 \u0026#39;\u0026#39;\u0026#39; return s.split(\u0026#39;,\u0026#39;).__len__() # 找出发行年份在2018或2019年且合作国家数量超过5个的剧集 netflix.query(\u0026#34;release_year.isin([2018, 2019]) and country.apply(@country_count) \u0026gt; 5\u0026#34;)    对Index与MultiIndex的支持  apply() apply + lambda 1 2  data.gender.apply(lambda x:\u0026#39;女性\u0026#39; if x is \u0026#39;F\u0026#39; else \u0026#39;男性\u0026#39;) # 等同于: data.gender.map({\u0026#39;F\u0026#39;: \u0026#39;女性\u0026#39;, \u0026#39;M\u0026#39;: \u0026#39;男性\u0026#39;})   apply输入多参 1 2 3 4 5  def _get_coordinates(row, points_df): return points_df[points_df.point_id.isin(row.traj_points)] .apply(lambda row: (row.x, row.y), axis=1).tolist() trajs_df[\u0026#39;coordinates\u0026#39;] = trajs_df.progress_apply(_get_coordinates, axis=1, args=(points_df,))    使用args输入多参数 函数参数列表中，row放在第一个，其他参数向后延续  apply 输入多列数据 1 2 3 4 5 6 7 8 9 10  def generate_descriptive_statement(year, name, gender, count): year, count = str(year), str(count) gender = \u0026#39;女性\u0026#39; if gender is \u0026#39;F\u0026#39; else \u0026#39;男性\u0026#39; return \u0026#39;在{}年，叫做{}性别为{}的新生儿有{}个。\u0026#39;.format(year, name, gender, count) data.apply(lambda row:generate_descriptive_statement(row[\u0026#39;year\u0026#39;], row[\u0026#39;name\u0026#39;], row[\u0026#39;gender\u0026#39;], row[\u0026#39;count\u0026#39;]), axis = 1)    axis=1 处理多个值时要给apply()添加参数axis=1 row['year'], row['gender'] 直接用列名即可（row.year, row.gender也是可以的）  apply 输出多列数据 1 2 3  # 提取name列中的首字母和剩余部分字母 _apply = data.apply(lambda row: (row[\u0026#39;name\u0026#39;][0], row[\u0026#39;name\u0026#39;][1:]), axis=1) a, b = zip(*list(_apply))    zip(*zipped)来解开元组序列;同样在函数传参的过程中，**args也可以解开args字典变换参数形式。  apply + swifter并行  2020.9.5 Note: swifter.apply加速效果很明显；读取大文件可以使用modin.pandas进行读取，apply等操作可以使用swifter进行加速。;另swifter.apply的函数中不可定义vectorized form（如if函数），否则可能导致加速效果不明显。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import pandas as pd import swifter df = pd.DataFrame({\u0026#39;x\u0026#39;: [1, 2, 3, 4], \u0026#39;y\u0026#39;: [5, 6, 7, 8]}) # runs on single core df[\u0026#39;x2\u0026#39;] = df[\u0026#39;x\u0026#39;].apply(lambda x: x**2) # runs on multiple cores df[\u0026#39;x2\u0026#39;] = df[\u0026#39;x\u0026#39;].swifter.apply(lambda x: x**2) # use swifter apply on whole dataframe df[\u0026#39;agg\u0026#39;] = df.swifter.apply(lambda x: x.sum() - x.min()) # use swifter apply on specific columns df[\u0026#39;outCol\u0026#39;] = df[[\u0026#39;inCol1\u0026#39;, \u0026#39;inCol2\u0026#39;]].swifter.apply(my_func)   时间处理 参考: pandas.pydata\n另见datetime时间处理\nparse_dates 在 read_csv() 方法中，通过 parse_dates 参数直接将某些列转换成 datetime64 类型, index_col设置索引\n1  df1 = pd.read_csv(\u0026#39;sample-salesv3.csv\u0026#39;, parse_dates=[\u0026#39;date\u0026#39;], index_col=\u0026#39;date\u0026#39;)   to_datetime Timestamp(时间点) 1 2 3 4 5 6 7 8 9  # unix time2datetime pd.to_datetime(1490195805, unit=\u0026#39;s\u0026#39;) # =\u0026gt; Timestamp(\u0026#39;2017-03-22 15:16:45\u0026#39;) # datetime str2Timestamp pd.to_datetime(\u0026#34;2017-11-01 12:24\u0026#34;) # or setting format pd.to_datetime(\u0026#34;2017年11月1日 12时24分\u0026#34;, format=\u0026#39;%Y年%m月%d日 %H时%M分\u0026#39;) #=\u0026gt; Timestamp(\u0026#39;2017-11-01 12:24:00\u0026#39;)    (Attributes)[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html]:  年月日（year, month, day） 時分秒（hour, minute, second）    DatetimeIndex(时间序列索引) 1 2  pd.to_datetime([1490195805.433, 1490195805.433502912], unit=\u0026#39;s\u0026#39;) #=\u0026gt;DatetimeIndex([\u0026#39;2017-03-22 15:16:45.433000088\u0026#39;, \u0026#39;2017-03-22 15:16:45.433502913\u0026#39;], dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=None)    (Attributes)[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html]:  年月日（year, month, day）, 時分秒（hour, minute, second）   unix time形式  1 2  pd.to_datetime([\u0026#39;2017-03-22 15:16:45.433000088\u0026#39;, \u0026#39;2017-03-22 15:16:45.433502913\u0026#39;]).astype(int) / 10**9 #=\u0026gt; Float64Index([1490195805.433, 1490195805.433503], dtype=\u0026#39;float64\u0026#39;)   参考: https://stackoverflow.com/questions/54313463/pandas-datetime-to-unix-timestamp-seconds\ndate_range Return a fixed frequency DatetimeIndex. 参考: pandas.date_range\n常用参数:  start: Left bound for generating dates. end: Right bound for generating dates. periods: Number of periods to generate. freq: Frequency strings can have multiples. 参考: timeseries-offset-aliases  D: calendar day frequency M: month end frequency Y: year end frequency H: hourly frequency T: minutely frequency S: secondly frequency Q: 季度    examples: 1 2 3 4 5 6 7 8 9 10 11  pd.date_range(start=\u0026#39;1/1/2018\u0026#39;, end=\u0026#39;1/08/2018\u0026#39;) #=\u0026gt; DatetimeIndex([\u0026#39;2018-01-01\u0026#39;, \u0026#39;2018-01-02\u0026#39;, \u0026#39;2018-01-03\u0026#39;, \u0026#39;2018-01-04\u0026#39;,\u0026#39;2018-01-05\u0026#39;, \u0026#39;2018-01-06\u0026#39;, \u0026#39;2018-01-07\u0026#39;, \u0026#39;2018-01-08\u0026#39;],dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=\u0026#39;D\u0026#39;) # 开始为2018.1.1, 取8个日期，默认间隔为天 pd.date_range(start=\u0026#39;1/1/2018\u0026#39;, periods=8) #=\u0026gt; DatetimeIndex([\u0026#39;2018-01-01\u0026#39;, \u0026#39;2018-01-02\u0026#39;, \u0026#39;2018-01-03\u0026#39;, \u0026#39;2018-01-04\u0026#39;,\u0026#39;2018-01-05\u0026#39;, \u0026#39;2018-01-06\u0026#39;, \u0026#39;2018-01-07\u0026#39;, \u0026#39;2018-01-08\u0026#39;],dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=\u0026#39;D\u0026#39;) # 三个月为间隔 pd.date_range(start=\u0026#39;1/1/2018\u0026#39;, periods=5, freq=\u0026#39;3M\u0026#39;) #=\u0026gt; DatetimeIndex([\u0026#39;2018-01-31\u0026#39;, \u0026#39;2018-04-30\u0026#39;, \u0026#39;2018-07-31\u0026#39;, \u0026#39;2018-10-31\u0026#39;, \u0026#39;2019-01-31\u0026#39;], dtype=\u0026#39;datetime64[ns]\u0026#39;, freq=\u0026#39;3M\u0026#39;)   日期检索 1 2 3 4 5 6 7 8 9 10 11 12 13 14  test_df = pd.DataFrame({\u0026#39;data\u0026#39;: range(1, 1000)}) test_df.index = pd.date_range(start=\u0026#39;2020-1-1\u0026#39;, end=\u0026#39;2020-6-1\u0026#39;, periods=test_df.shape[0]) # 获取2020年的数据 test_df[\u0026#39;2020\u0026#39;] # 获取2020年5月的数据 test_df[\u0026#39;2020-5\u0026#39;] # 获取2020年5月1号的数据 test_df[\u0026#39;2020-5-1\u0026#39;] # 获取2020年一季度(1,2,3月)的数据 test_df[\u0026#39;2020Q1\u0026#39;] # 获取2020年5月1号到2020年5月30号的数据 test_df[\u0026#39;2020-5-1\u0026#39;:\u0026#39;2020-5-30\u0026#39;]   聚合类方法 groupby() + agg() 参考：https://www.cnblogs.com/feffery/p/11468762.html\n要进行分组运算第一步当然就是分组，在pandas中对数据框进行分组使用到groupby()方法，其主要使用到的参数为by，这个参数用于传入分组依据的变量名称，当变量为1个时传入名称字符串即可，当为多个时传入这些变量名称列表，DataFrame对象通过groupby()之后返回一个生成器，需要将其列表化才能得到需要的分组后的子集\n1 2 3  group_df = trajs_with_id_df.groupby(by=[\u0026#39;car_id\u0026#39;])[[\u0026#39;traj_id\u0026#39;, \u0026#39;traj_points\u0026#39;]] groups = [group for group in group_df] groups[0]    output:\n 每一个结果都是一个二元组，元组的第一个元素是对应这个分组结果的分组组合方式，第二个元素是分组出的子集数据框  1  groups = data_df.groupby(by=[\u0026#39;assigned_c\u0026#39;, \u0026#39;osmid\u0026#39;])[[\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;]].max().reset_index(drop=False)    by=[\u0026lsquo;assigned_c\u0026rsquo;, \u0026lsquo;osmid\u0026rsquo;],分组的组合方式 [[\u0026lsquo;x\u0026rsquo;, \u0026lsquo;y\u0026rsquo;]]分组后取出x和y列进行后续操作 max() 根据分组对x和y列取最大值 reset_index(drop=False) 重置索引，便于显示和取值; drop: 是否丢掉原索引  1 2 3  agg_df = data_df.groupby(by=[\u0026#39;assigned_c\u0026#39;]).agg({\u0026#39;x\u0026#39;: [\u0026#39;mean\u0026#39;, \u0026#39;max\u0026#39;, \u0026#39;min\u0026#39;, \u0026#39;mean\u0026#39;, \u0026#39;std\u0026#39;]}) .reset_index(drop=False)    agg() 即aggregate，聚合；传入字典：操作列为key和相关操作为value  1 2 3 4 5  agg_df = data_df.groupby(by=[\u0026#39;assigned_c\u0026#39;]).agg(mean_x=pd.NamedAgg(column=\u0026#39;x\u0026#39;, aggfunc=\u0026#39;mean\u0026#39;), max_x=pd.NamedAgg(column=\u0026#39;x\u0026#39;, aggfunc=\u0026#39;max\u0026#39;), min_x=pd.NamedAgg(column=\u0026#39;x\u0026#39;, aggfunc=\u0026#39;min\u0026#39;),) .reset_index(drop=False)    使用pd.NamedAgg()来为聚合后的每一列赋予新的名字  异常调试 忽略warning全局设置 1 2  import warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;)   编码错误（illegal multibyte sequence） 1 2 3 4 5  def get_df(file_path): poi_df = None with open(file_path, encoding=\u0026#39;gb2312\u0026#39;, errors=\u0026#39;ignore\u0026#39;) as fp: poi_df = pd.read_csv(fp, header=0) return poi_df   显示设置  取消科学计数法显示\n参考：https://blog.csdn.net/chenpe32cp/article/details/87883420\n科学计数法的显示很难阅读。取消科学计数法显示，保留小数后两位。  1 2 3 4 5 6  # 全局设置 pd.set_option(\u0026#39;display.float_format\u0026#39;,lambda x : \u0026#39;%.2f\u0026#39; % x) # 或 # 单个DataFrame生效 df = pd.DataFrame(np.random.random(10)**10, columns=[\u0026#39;data\u0026#39;]) df.round(3)    显示所有列或所有行\n参考：https://blog.csdn.net/qq_42648305/article/details/89640714  1 2  pd.options.display.max_columns = None pd.options.display.max_rows = None   Geopandas I/O 参考：https://geopandas.org/io.html#writing-spatial-data\n 支持的格式：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  import fiona fiona.supported_drivers {\u0026#39;AeronavFAA\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;ARCGEN\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;BNA\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;DXF\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;CSV\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;OpenFileGDB\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;ESRIJSON\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;ESRI Shapefile\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;FlatGeobuf\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;GeoJSON\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;GeoJSONSeq\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;GPKG\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;GML\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;OGR_GMT\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;GPX\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;GPSTrackMaker\u0026#39;: \u0026#39;rw\u0026#39;, \u0026#39;Idrisi\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;MapInfo File\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;DGN\u0026#39;: \u0026#39;raw\u0026#39;, \u0026#39;OGR_PDS\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;S57\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;SEGY\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;SUA\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;TopoJSON\u0026#39;: \u0026#39;r\u0026#39;}    Read Data  read_file  1 2 3 4  geopandas.read_file(fp) # gdb or gpkg\u0026#39;s layer gdb_fp = \u0026#39;/workspace/UrbanFunctionalRegionalization/map_doc/regionalization.gdb\u0026#39; thiessen_gdf = gpd.geopandas.read_file(gdb_fp, layer=\u0026#39;thiessen_cliped\u0026#39;)    Write Data\nFor a full list of supported formats, type import fiona; fiona.supported_drivers  Writing to Shapefile  1  countries_gdf.to_file(\u0026#34;countries.shp\u0026#34;)    Writing to GeoJSON file  1  countries_gdf.to_file(\u0026#34;countries.geojson\u0026#34;, driver=\u0026#39;GeoJSON\u0026#39;)    Writing to GeoJSON string  1  countries_gdf.to_json()    Writing to GeoPackage 1 2  countries_gdf.to_file(\u0026#34;package.gpkg\u0026#34;, layer=\u0026#39;countries\u0026#39;, driver=\u0026#34;GPKG\u0026#34;) cities_gdf.to_file(\u0026#34;package.gpkg\u0026#34;, layer=\u0026#39;cities\u0026#39;, driver=\u0026#34;GPKG\u0026#34;)     DataFrame2GeoDataFrame set_geometry  set_geometry  1  trajs_gpd_df = trajs_df.set_geometry(\u0026#39;line_geo\u0026#39;)    在初始化GeoDataFrame时定义geometry  1 2 3  from shapely.geometry import Point, LineString geometry = [Point(), Point(), ...] or [LineString([p1, p2, ...]), ...] or ... gpd.GeoDataFrame(df, geometry=[])   空间连接/Spatial Join 参考：https://blog.csdn.net/qq_28360131/article/details/81165168\nshaply包的vectorized包含着一些对查询的优化，通过shaply和geopandas一起协作可以达到较好的优化效果。\n1 2 3 4 5 6 7  import shapely.vectorized as sv point_df = point_df[[\u0026#39;id\u0026#39;, \u0026#39;lon\u0026#39;, \u0026#39;lat\u0026#39;]] for row in ploy_gdf.itertuples(): geometry, area_id = getattr(row, \u0026#34;geometry\u0026#34;), getattr(row, \u0026#34;area_id\u0026#34;) point_df.loc[sv.contains(geometry, x=point_df.lon, y=point_df.lat), \u0026#34;AreaID\u0026#34;] = area_id    point_df      id lon lat datetime area_id     0 0 116.41 39.9084 2012-11-02 00:25:03 94   1 1 116.583 40.0793 2012-11-02 01:25:41 nan   2 2 116.34 39.9567 2012-11-02 02:06:14 145   3 3 116.343 39.9126 2012-11-02 02:19:51 86   4 4 116.334 39.906 2012-11-02 02:26:55 82    ","description":"","id":95,"section":"posts","tags":["Python","Pandas","GeoPandas","优化"],"title":"Pandas/Geopandas Tricks","uri":"https://www.xunhs.cyou/posts/notes/pandas-geopandas-tricks/"},{"content":" 利维亚的杰洛特。\n \n 2020.1.1 多喜乐，常安宁 2020.1.2 keras跑一个新闻主题分类（多分类）的问题，不能一上来就用复杂模型（TextCNN）。先从简单的模型（Embedding + 两层Dense 效果就很好）开始，复杂模型容易过拟合，且训练速度慢，有一个baseline后再去跑其他模型，像CNN啊，RNN之类的； 还有就是先把数据预处理好。 2020.1.3 每日一句想到词穷。 2020.1.4 奇了怪了奇，奇了怪了怪。 2020.1.5 止于唇齿，掩于岁月。 2020.1.6 正如夜空没有星星和月亮无法完整，没有你，我的生命也无法完整。 2020.1.7 欲速则不达。 2020.1.8 不是所有的事情都有意义的，能够做些无聊的事情有时候也是一种幸福。 2020.1.9 青青子衿，悠悠我心。 2020.1.10 真的要锻炼计划了。身体总觉得有不舒服的地方，而且精力也越来越差。 2020.1.11 晚上活动，游戏玩的很开心，脸皮都笑的疼了。 2020.1.12 在冬天遇见你，凛冬散尽，星河长明。 2020.1.13 沧海月明珠有泪，蓝田日暖玉生烟。 2020.1.14 此情可待成追忆，只是当时已惘然。 2020.1.15 终于这个冬天下了第一场雪。 2020.1.16 推荐icat.cc的代理，学校稳定、速度还可以。 2020.1.17 回家，假期开始。 2020.1.18 今天是催婚的（第）一天。 2020.1.19 The most difficult thing in life is to know yourself. 2020.1.20 时间没有等我，是你忘了带我走，我左手是过目不忘的萤火，右手是十年一个漫长的打坐。 2020.1.21 泱泱大国，巍巍华夏。 2020.1.22 愁肠试酒晚来迟。迢迢霄汉终无计。画楼云雨，良宵岑寂，一梦断尘泥。 2020.1.23 听闻远方有你，动身跋涉千里。我吹过你吹过的风，这算不算相拥。我踏过你走过的路，这算不算相逢。 2020.1.24 除夕。愿平安顺遂。 2020.1.25 利维亚的杰洛特。完成了巫师3的主线剧情。总觉得剧情结束的有些突然，可能也是因为想尽快结束主线的原因吧。感情方面选择了特莉丝，叶奈法去了北方。还是很喜欢这个游戏的。代入感很强。 2020.1.26 新型冠状病毒引起的肺炎太厉害了。得益于互联网、微博和微信等普及，信息的传播十分迅速，总觉得人们的恐慌远大于病情实际。希望病情能够尽快得到控制，大家都能够相安无事。 2020.1.27 被论文的方法部分难住了。想不通。 2020.1.28 研修计划。 2020.1.29 小事缺少坚持。 2020.1.30 世上没有繁琐的事，只有怕麻烦的人。 2020.1.31 研修计划初稿。   ","description":"","id":96,"section":"posts","tags":["新闻主题分类","锻炼","意义","联欢活动","代理","回家","春节","巫师3","思考","新冠肺炎","研修计划"],"title":"2020-1","uri":"https://www.xunhs.cyou/posts/journals/99/"},{"content":" 收集一百句诗词。\n  若似月轮终皎洁，不辞冰雪为卿热。 既见君子，云胡不喜？ 相思相见知何日？此时此夜难为情。 盈盈一水间，脉脉不得语。 愿君多采撷，此物最相思。 长相思兮长相忆，短相思兮无穷极。 只缘感君一回顾，使我思君朝与暮。 曾经沧海难为水，除却巫山不是云。 此心纵有千千结，还独系，一人意。 在天愿作比翼鸟，在地愿为连理枝。 玲珑骰子安红豆，入骨相思知不知。 取次丛中懒回顾，半缘修道半缘君。 言念君子，温其如玉。在其板屋，乱我心曲。 世间安得两全法，不负如来不负卿。 心乎爱矣，瑕不谓矣。中心藏之，何日忘之。 山有木兮木有枝，心悦君兮君不知。 赌书消得泼茶香，当时只道是寻常。 我住长江头，君住长江尾，日日思君不见君，共饮长江水。 相见亦无事，别后常忆君。 采莲南塘秋,莲花过人头。低头弄莲子,莲子清如水。 思君令人老，岁月忽已晚。 此情无计可消除，才下眉头，却上心头。 相逢情便深，恨不相逢早。 妆罢低声问夫婿，画眉深浅入时无。 月上柳梢头，人约黄昏后。 桃之夭夭，灼灼其华。之子于归，宜其室家。 何当共剪西窗烛，却话巴山夜雨时。 人非木石皆有情，不如不遇倾城色。 生当复来归，死当长相思。 去岁相思见在身，那年春，除却花开不是真。 郎骑竹马来，绕床弄青梅。 思君令人老，轩车何来迟。 但是相思莫相负，牡丹亭上三生路。 落花时节不逢君，空捻空枝空倚门。 此情可待成追忆？只是当时已惘然。 有一美人兮，见之不忘。一日不见兮，思之如狂。 君家何处住，妾住在横塘。停船暂借问，或恐是同乡。 春风十里扬州路，卷上珠帘总不如。 我欲与君相知，长命无绝衰。 枕前发尽千般愿，要休且待青山烂。 渺万里层云，千山暮雪，只影向谁去？ 一日不见，如三月兮。 逢郎欲语低头笑，碧玉搔头落水中。 宜言饮酒，与子偕老。琴瑟在御，莫不静好。 十年生死两茫茫，不思量，自难忘。 有美一人，清扬婉兮。邂逅相遇，适我愿兮。 十年青鸟音尘断，往事不胜思。 山有扶苏，隰有荷华。不见子都，乃见狂且。 翘翘错薪，言刈其楚；之子于归，言秣其马。 著以长相思，缘以结不解。 背灯和月就花阴，已是十年踪迹十年心。 采之欲遗谁？所思在远道。 南风知我意，吹梦到西洲。 人言人有愿，愿至天必成。愿作远方兽，步步比肩行。愿作深山木，枝枝连理生。 众里寻他千百度。蓦然回首，那人却在灯火阑珊处。 重愿郎为花底浪。无隔障。随风逐雨长往来。 只愿君心似我心，定不负相思意。 海棠开后，望到如今。 平生不会相思，才会相思，便害相思。 证候来时，正是何时？灯丰昏时，月伴明时。 溯洄从之，道阻且长。溯洄从之，宛在水中央。 沅有芷兮澧有兰,思公子兮未敢言。 美人赠我琴琅玕，何以报之双玉盘。 刘郎已恨蓬山远，更隔蓬山一万重！ 不堪盈手赠，还寝梦佳期。 春风正澹荡,暮雨来何迟。 夜夜相思更漏残，伤心明月凭阑干，想君思我锦裘寒。 半羞还半喜，欲去又依依。觉来之是梦，不胜悲。 红豆不堪看，满眼相思泪。 昨夜星辰昨夜风，画楼西畔桂堂东。 舞低杨柳楼心月，歌尽桃花扇底风。 望断云行无去处。梦回明月生春浦。 夜月一帘幽梦，春风十里柔情。 携手看花深径，扶肩待月斜廊。 金风玉露一相逢，便胜却、人间无数。 从别后，忆相逢。几回魂梦与君同。 软风吹遍窗纱，心期便隔天涯。从此伤春伤别，黄昏只对梨花。 花明月暗笼轻雾，今霄好向郎边去。 娇痴不怕人猜，和衣睡倒人怀。 易求无价宝，难得有心郎。 唯有潜离与暗别，彼此甘心无后期。 识尽千千万万人，终不似、伊家好。 若是前生未有缘，待重结、来生愿。 忆来何事最销魂，第一折枝花样画罗裙。 愿我如星君如月，夜夜流光星皎洁。 人如风后入江云，情似雨余黏地絮。 若问闲情都几许？一川烟草，满城风絮，梅子黄时雨。 多情只有春庭月，犹为离人照落花。 别来半岁音书绝，一寸离肠千万结。 明月不谙离恨苦，斜光到晓穿朱户。 鸿雁在云鱼在水，惆怅此情难寄。 恨君不似江楼月，南北东西，南北东西，只有相随无别离。 许是今生缘未了，还从梦里记明眸。 老来多健忘，唯不忘相思。 东边日出西边雨，道是无晴却有晴。 换我心为你心，始知相忆深。 相思树底说相思，思郎恨郎郎不知。 直道相思无益，未妨惆怅是清狂。 风月入我相思局，怎堪相思未相许。 春风宴，绿酒一杯歌一遍，再拜陈三愿：一愿郎君千岁，二愿妾身长健，三愿如同梁上燕，岁岁长相见。  ","description":"","id":98,"section":"posts","tags":["诗词"],"title":"100句情诗","uri":"https://www.xunhs.cyou/posts/journals/104/"},{"content":" 通过论文阅读，总结常用写作过程中的词语组合、句型句式等\n 单词/短语  据我所知  to the best of our knowledge   另外，另一方面  additionally   具体而言，更确切的说（讲）  Specifically to be more precise   简言之  in simple terms   重要的；显著的，有意义的  play an import role in Be of great importance in terms of sth Have a significant influence on sth pronounced   如图所示，表中显示  as depicted in Fig. 1, \u0026hellip; as illustrated/depicted in Figure 3, we find that ,,, Figure 4 shows that \u0026hellip; Figure 6 maps the clustering results \u0026hellip; In Figure 6, \u0026hellip;   能够\u0026hellip;; 使\u0026hellip;成为可能  be capable of doing sth enable. e.x., High spatial resolution (HSR) remote sensing images enable computation-based urban land use detection. (高分遥感影像使基于计算的城市土地利用监测成为可能。)   例如  for example for instance taking sth as an example   通常，在大多数情况下;直观上说；  in most cases Intuitively, 直观上说(是一种推断的说法，用的时候要虚拟语气，最后后面在举一个例子): Intuitively, the predictability of a place characteristic should be higher when choosing more appropriate connection measures. For example, the connection between places via taxi origin.   倾向于\u0026hellip;   be inclined to do sth  通过\u0026hellip;来实现   This was implemented by doing sth/ using \u0026hellip;  因此，从而，所以   accordingly: We have a different background, a different history. Accordingly, we have the right to different futures. hence: We suspect they are trying to hide something, hence the need for an independent inquiry. thus: We do not own the building. Thus, it would be impossible for us to make any major changes to it. Therefore  同样地；与此同时，在此期间   similarly meanwhile  换句话讲，也就是说，事实上   in other words indeed This is(也就是说): That is, if we consider the movement\u0026hellip; as a matter of fact  大量的，广泛的，众多的   a wide spectrum of （一系列的） a broad range of （大范围的） a variety of （各种各样的） extensive （广泛的，大量的）  更多的,此外, 另一方面; 相反   Furthermore/ further, on the contrary in contrast  利用，使用   employ a new time-series social media dataset utilize apply a \u0026hellip; based method to ..  随后，接下来；下一步   We subsequently apply a \u0026hellip;  传统的/常见的   conventional methods  开源的，可用的   available open source  最新的   state-of-the-art  在\u0026hellip;领域   in the field of \u0026hellip;  开创性（有创意的）的工作   seminal work  越\u0026hellip;, 越\u0026hellip;;比较级   A greater (lower) DTW distance suggests a more pronounced difference between two time series. A higher value of F indicates a larger number of POIs in the ith category at the location of building i. A greater positive value(正值) of s suggests a better assignment for the building object i.  特别的，尤其是   In particular  流程图   Workflow diagram  与\u0026hellip;一致，与\u0026hellip;对应; 引起共鸣   This corresponds to a high level of mixed land use. This resonates with (共鸣) the typical work/leisure activity patterns during the weekdays.  就这一点而言，在这一方面   in this regard  精细尺度；高分辨率   fine-grained (very) fine-scale  基于此   considering this fact following this idea on the basis of taxi-trip data from Shanghai (基于..数据，代替based on)  迄今为止   to date  为了明确/突出（强调）（这个）问题   To address this issue  (以往研究)广泛使用/常用/通用/流程的方法；   Calculating the proportions of POI types inside each area is a commonly used method to achieve this goal. We adopt the TF-IDF method, which has been widely used in information retrieval and text-based recommender systems. Among these methods, k-medoids with DTW distance has emerged as a popular method for time-series data clustering.  等等；等其他   Urban AOI can reveal useful information for city planners, transportation analysis, and location-based service providers to plan new business, extend existing infrastructure , and so forth.  可行性   The objective of this study was to investigate the feasibility of(调查/研究\u0026hellip;的可行性) incorporating place connections to predict place characteristics. To explore the utility of employing both remote and social sensing data in the estimation of population at fine scales  本身 per se   This work also relates to a different stream of research, which focuses not on data quality per se, but on an assessment of the similarity of POI obtained from different datasets for the purposes of conflation or data fusion.  真实场景   in real-world scenarios  Abstract Refer: Abstract Formula\n  General and Specific Background (~1 sentence each). Introduce the area of science that you will be speaking about and the state of knowledge in that area. Start broad in the general background, then narrow in on the relevant topic that will be pursued in the paper. If you use jargon, be sure to very briefly define it.\n  Knowledge Gap (~1 sentence). Now that you’ve stated what is already known, state what is not known. What specific question is your work attempting to answer?\n  “Here we show…” (~1 sentence). State your general experimental approach and the answer to the question which you just posed in the “Knowledge Gap” section.\n  Experimental Approach \u0026amp; Results (~1-3 sentences). Provide a high-level description of your most important methods and results. How did you get to the conclusion that you stated in the “Here we show…” section?\n  Implications (~1 sentence). Describe how your findings influence our understanding of the relevant field and/or their implications for future studies.\n  摘句 陈述研究点重要性/研究难点，被广泛研究，备受关注；数据描述  一直以来一个重要的研究问题, 持续被关注，一直以来都是一个有争议的话题，（因为\u0026hellip;在\u0026hellip;领域/研究中有重要意义）  Delineating urban functional areas is one of the long lasting questions in urban studies and planning. Land use and land cover classification through remote sensing imagery is a fundamental research topic in remote sensing community. Recently, numerous in-depth discussions have been conducted to classify urban land use via POIs. Over the past 50 years, there has been continued and sustained interest in developing \u0026hellip; for solving the \u0026hellip; problem, as this problem is applied in a wide variety of areas including .. and \u0026hellip; Therefore, the effective detection of urban land use patterns, which are significant for formulating effective urban planning policies, has been a controversial issue in recent studies. Many studies are in an effort to improve the pedestrian environment and pedestrian has become the subject of increasing attention among planners, engineers and public health officials. An understanding of what environment factors control or influence the value of D and its spatial variation is one of the central themes in geomorphology and hydrology. is of considerable conceptual and practical interests as the question is intimately related to the problem of assessing the risk of damage and degradation of landscape and the designing of measures to reduce such damage. In the last decade, the contradiction between (日益增长的矛盾) the housing demand from residents and high housing prices has become a top issue in the economy and livelihood of China, especially in metropolitan cities such as Beijing, Shanghai, and Shenzhen. [即使取的一些成就，但\u0026hellip;仍是一项艰难的任务] Although significant progress has been achieved, deriving high-resolution urban land use maps from satellite images is still a difficult task. [在这种新的背景下，\u0026hellip;问题变得越来越显著] In these newer contexts, then, the typical problem size for regionalization algorithms is increasing dramatically.   众源技术/基于个体的地理大数据带来的际遇;见证了\u0026hellip;的快速发展；。。。数据成为。。。研究的新的数据源； 。。为。。。的研究带来灵感；大数据；深度学习技术  Previous studies indicated that urban functional zones have a close relation to the regions formed by the city road network, and exploring this relation from the community perspective will undoubtedly bring new insights.(为。。。的研究带来灵感) (伴随着\u0026hellip;的势头) As the momentum to generate more geo-enriched movement data at large volumes, high frequencies and for longer durations continues, this is a timely and significant achievement towards movement data science The proliferation of crowdsourcing technology(众源技术) and the emergence of individual-level big geospatial data(个体等级的地理大数据) bring unprecedented opportunities for researchers to better understand the physical and socioeconomic environment of urban regions. In 2020, with the COVID-19 pandemic, we witness a change in the way large mobility data are shared and how access to geo-enriched mobility data is streamlined through data dashboards. (见证了大型移动数据共享方式的变化，以及如何通过数据仪表盘简化对地理丰富的移动数据的访问) Enabled by the ubiquitous generation of geo-referenced tracking data, there has been a recent surge in map construction algorithms coming from different computer science domains. The last five decades have witnessed the fast development of remote sensing techniques, of which a major objective is to reveal the physical characteristics of the Earth\u0026rsquo;s surface, such as land cover features. In recent years, the proliferation of crowdsourcing technology has enhanced the ability to collect a massive amount of images to represent the physical setting of place and to predict human perceptual responses of images. More recently, spatially referenced social media data emerged as a new data source for studying socioeconomic dynamics in the cities, such as human mobility, travel behaviors, and urban land use. These numerous street-level images (数据) not only scale up the size and scope of the related research but also provide new perspectives and dimensions for formalizing the concept of place. This data source lays the foundation (奠定了基础) of new approaches to observe, perceive and understand the urban environment. New sources of data such as \u0026lsquo;big data\u0026rsquo; and computational analytics have stimulated innovative pesestrian oriented research. Benefiting from the multi-level and multi-sourced big geospatial data, research efforts have been made to approximate spatio-temporal urban mobility patterns using Global Positioning System data , smart card records, mobile positioning data, etc. Over the years, the rapid development of map services and volunteered geographic information (VGI) has provided a massive amount of geo-tagged images. With wide applications of wireless communication, global position system (GPS), pervasive computing technology, and WEB 2.0, big data on (spatial behavior ) can reveal (human mobility patterns) at very refined temporal and spatial resolutions and thus sense the socioeconomic environments in an urban system. Recently, the development of network science (Cohen and Havlin 2010, Estrada 2012) and the creation of a large number of large-scale datasets have promoted research on road networks. 大数据及大数据技术在某些领域吸引力广泛，比如某些期刊开放专刊等等 Within the past decade, however, big data and big data analytics have begun to attract attention in the field of transport studies. Thus, for instance, several journals, such as Transportation Research Part C and Travel Behaviour and Society have devoted special issues to the topic. These recent studies have shown that big-data approaches make it possible to explore the spatial distribution of commuting burdens over a large geographical area.   具有重要意义, 具有重要作用，在。。。中起到重要作用  Sensing the spatial structures of urban land use quickly and identifying urban function structures accurately are of great significance in formulating effective policies and regulations for urban planning. Land use and land cover are extremely important geospatial features and play important roles in many fields such as environmental monitoring, urban planning and government management. Urban land use information plays an important role in urban management, government policy-making, and population activity monitoring. Extensive evidence has revealed that street greenery (sth), as a quality-of-life component, is important for oxygen production, pollutant absorption, and urban heat island effect mitigation. Measuring the human sense of place can potentially enrich place semantics(丰富场景语义), which will further help researchers understand the underlying urban heterogeneity patterns(理解潜在的城市异质性模式) and reveal the impacts of urban function(揭露城市功能的影响).   阐述该研究有众多应用领域，并举例  Regionalization is essentially a special form of clustering in geographic data analysis (Haining et al. 1994) that has a wide and diverse range of application domains, such as ecological patterns (Kupfer et al. 2012), medical regions (Harner and Slater 1980, Koylu et al. 2018), hydrology (Peterson et al. 2015) and city structure (Walsh and Pozdnoukhov 2011). Learning how to gather knowledge about physical settings and the visual information of a place that affects the experience of observers has long been of interest to a wide variety of fields, such as\u0026hellip; Understanding intra-urban human mobility patterns is crucial in addressing many real-world challenges, such as discovering functional urban zones that characterize the physical and social characters of a city (Austwick et al. 2013, Yuan et al. 2015, Liu et al. 2015, 2016), understanding road usage patterns for traffic prediction and congestion mitigation (Wang et al. 2012), modeling the spatial transmission of infectious diseases to improve epidemic control and intervention (Tizzoni et al. 2014), and assisting in the rapid evacuation of affected populations during calamitous events, such as earthquakes or terrorist attacks (Bengtsson et al. 2011). [from wenwen Li, https://www.tandfonline.com/doi/full/10.1080/13658816.2020.1712401] Urban AOI have great meanings in multiple application domains. For tourists, AOI highlight the interesting zones within a city, and can therefore be used to support trip planning of travelers. For city planners, AOI reveal the regions which receive high exposure among the general public. Accordingly, these regions could be assigned higher priorities when there are only limited resources for urban planning projects, such as city beautification (Espuche et al., 1991, Gandy, 2006). Since AOI are often visited by a large number of people, transportation analysts can examine these regions to understand traffic flows and human mobility patterns (Batty, 2007, Yuan and Raubal, 2012). In addition, information service providers can display targeted information based on AOI (e.g., highlighting the hotels within the AOI of a city)    现有研究者做了哪些事情；方法分类；方法描述；方法总结；方法比较  在。。。方面，现有研究者做了。。。的大量的努力/尝试/研究。  Research efforts have been made to formalize a place in terms of two aspects(在两个方面做出了工作): \u0026hellip; [当前\u0026hellip;的研究主要分为两个方面] Current trajectory privacy protection studies focus on two research streams. One is the differential privacy approach to grouping and mixing the trajectories from different users so that the identification of individual trajectory data is converted into a k-anonymity problem. For example, \u0026hellip; Another research stream is (另起一行) called geo-masking, which blurs the locations of original trajectory data by utilizing perturbation on the spatial dimension so that the original locations can be hidden or modified while spatial patterns may not be significantly affected. For example, \u0026hellip; Attempts have also been made to delineate urban functional areas using social media data. For instance \u0026hellip; Benefiting from the multi-level and multi-sourced big geospatial data, research efforts have been made to approximate spatio-temporal urban mobility patterns using Global Positioning System data , smart card records, mobile positioning data, etc. Researchers have employed street view images to reconstruct 3-dimensional urban models, to explore urban morphologies by mapping the distribution of image locations, and to analysze the visual elements of an urban space in terms of human perception, urban greenery, urban land use, and the sky view factor. Previous studies into the factors controlling the value of D have resulted in a large body of literature. The literature advanced by other urban planners and geographers has also demonstrated the importance of streets and the necessity of taking them as the elementary unit from various perspectives.(从多种视角而言\u0026hellip;之重要)   列举现有工作  Several stands of status quo work （工作现状）can be identified. At the \u0026hellip; level, \u0026hellip; At the \u0026hellip; level. Considerable research in recent years has demonstrated the advantages of this new data source in monitoring neighborhood changes, calculating the sky view factor, quantifying neighborhood types, discovering distinct place features, and measuring perceptions. On this basis, two major categories of methods were developed to quantify biophysical compositions in an urban area. The first category is machine learning methods, including A, B and C. With these machine learning methods, biophysical composition information is derived by establishing an empirical relationship with various spectral and spatial characteristics extracted from remote sensing imagery. The second category is spectral unmixing techniques. + spectral unmixing techniques的一句话介绍. (接下来就可以讲以上的不足了) A common thread that ties together previous works in modeling urban mobility is their focus on the driving force of mobility. (以往研究的关注点) Previous works \u0026hellip; (方法分类) From the trajectory**-based perspectives**, **there are three main approaches to** route planning **based on** big taxi trajectory path algorithm. The first approach is\u0026hellip; The second approach \u0026hellip; Drivers' experience is essential for finding satisfactoy routes for users of navigation systems, which need to take both real-time traffic conditions (e.g., consestion) and the driving preference of users into account. For the former, \u0026hellip; The latter \u0026hellip; [频繁应用，在\u0026hellip;中流行开来] Pixel-based image classification methods using spectral and/or textural properties are frequently applied to extract urban land use information. Recently, per-field and object-based classification methods have gained popularity in deriving land uses from the satellite images because per-field classification methods can better describe the function of urban areas and serve the needs of urban planning   \u0026hellip;方法取得巨大成功/很多研究验证了该方法的有效性/可靠性  In addition, great progress has been made on recent advance of computer vision technique for recognizing the image content by deep learning, which has attracted much attention and achieved great success in multiple fields due to its powerful ability in automatic image feature learning and representation. Due to its powerful ability in automatic image feature learning and representation, DCNN model has attracted much attention and achieved great success in multiple fields, including speech recognition, natural language processing, and visual object detection. Many in-depth discussions suggest that multi-social media data have great potential to reveal urban land use patterns. Previous studies indicated that mean filtering is an effective social media data preprocessing method to reduce the data size and computational demands without much information loss [套路很棒] The emergence of deep learning has advanced many research fields, including image recognition, time series classification, and etc. They have also greatly boosted the development of remote sensing. Significant improvements have been made in many tasks, such as hyperspectral image analysis, image scene classification, semantic labeling, object detection, and image retrieval. The major advantages of deep learning approaches are the powerful abilities to automatically learn high-level features from large amount of data, which are vital to bridge the gap between different data modalities at feature level. Therefore, deep learning-based fusion methods are very potential to integrate the multi-source and multimodal remote and social sensing data. (From https://doi.org/10.1016/j.isprsjprs.2020.02.014) [同样应用于其他领域] Despite the tremendous success in image recognition, convolutional neural networks have recently also been used in time series analysis and shown superior performances.   方法比较  The DTW distance is found to be more robust to time-series data clustering than other conventional measures such as the Euclidian distance. （方法比较， 。。。比。。。更稳健，更好） Clustering time-series data is more difficult than the clustering of non-sequential data, as (因为) the order of element in the time-series need to be considered when measuring the similarity between data samples.(方法比较.与\u0026hellip;相比，更加困难，难点) A comparison is further conducted between the proposed method and some state-of-the-art topic models 我们的方法优于基线标准 Our method outperformed baseline methods in a case study using Shanghai taxi trip data. (优于) We find that, regarding(就\u0026hellip;而言) understanding the urban physical environment, the visual features learned in our designed street classification task largely outperformed the visual feature learned in the ImageNet object detection task.   review总结，方法总结  As is evident from the above review, there is abundant research regarding the travel behaviors of public bicycle users, which provides the basis for research into free-float bicycle sharing. (从上面的评论可以明显看出，大量的研究。。。) Although both per-pixel and sub-pixel analyses have been employed for analyzing urban environments with different degrees of success. these methods are always considered as complicated(复杂难懂), computationally intensive(计算密集), and sometimes subjective(主观). especially when applied to a large geographic area (说别人的不足要加引用). + 接下来要举例说明人家的为啥不足 (这些方法通常被认为是复杂难懂的/计算复杂/带有主观色彩的。。。)    目前研究现状的不足点;难点；相比本文中方法的优势；亮点;受限，限制  (难点。。仍是待解决的问题); 陈述研究点的难点  仍是待解决的问题 However, it remains an unsolved problem despite numerous previous attempts to address it. 目前，对于研究者们而言，回答诸如\u0026hellip;的问题仍然是困难的 Correspondingly, for planners, it is also difficult to accurately answer questions such as ‘where the quality of the physical environment is the most dilapidated in the city that regeneration should be given first consideration’ and ‘in fast urbanising cities, how is the city appearance changing. 虽然\u0026hellip;已经有了一些研究，但仍是不足够的，其潜力有待被挖掘。 Although some researchers have focused on studying road network structure from community perspective, community studies in road networks are still insufficient, and their potential remains to be tapped. （仍）需要进一步/深入的研究。Accordingly (相应地), the application of spatial-pattern features for functional-zone segmentation needs further studies. 之前的方法不适用，因此需要进一步/深入的研究Accordingly (因此), neither method is applicable to the evaluation of functional-zone segmentations, thus a novel evaluation method should be further developed. While researchers have devoted considerable attention to spatial inequities in commuting burdens, this work has until recently been characterized by certain shortcomings.   研究主要集中在\u0026hellip;，关于\u0026hellip;的研究/证据是不足的  研究主要集中在\u0026hellip;，关于\u0026hellip;的证据是不足的 However, studies have focused mainly on cycling as a sole transportation mode, and evidence for bicycle-transit integration is scarce. although bicycle-transit integration has attracted some research attention in developed countries, evidence from developing countries remains scarce. 仍有提升的空间 Although many methods have been proposed for discovering urban functional zones, there is still space for improvement. \u0026hellip;关联的证据是不足的 The evidence for the association between urban greenness and cycling behaviors is inconclusive 很少有研究在\u0026hellip;开展, 很少有研究在国内开展 In addition, few studies have been conducted in developing countries, such as China, which enjoyed the reputation of cycling nation until the late 1990s and witness a big comeback of cycling in the last several years. \u0026hellip;的研究是不充足的 Although some researchers have focused on studying road network structure from the community perspective, community studies in road networks are still insufficient, and their potential remains to be tapped. 到目前为止，仅有少量文献支撑该论点 To date, the discussion regarding which urban design attributes lead to better cities or higher property values has largely been theoretical, supported quantitatively by only a few handful of studies. 虽然有强烈的联系，但是仍缺少研究、计算工具和数据能够\u0026hellip; Despite the strong link between urban design attributes and economic value, there is a clear lack of research, computational tools and data that can be used to discover these attributes and inform urban planning policies [在以往的研究中, \u0026hellip;没有被充分考虑，这可能会影响\u0026hellip;] In previous studies, the hierarchical correspondence and interaction between urban landscape and human activities have not been given full consideration in the cognition of urban functional zones, which would influence the accuracy and interpretability of the results. Therefore, a hierarchical fusion method considering urban landscape and human activity patterns based on multi‐source data is proposed in this article.   研究受限\u0026hellip;;不能够\u0026hellip;;没有考虑到  虽然进行过大量的研究，但是仍受限于数据的获取和工具的使用 Although several attempts have been made (引用) to analyze the physical appearance of an urban space by photos, the research scale and throughput have been limited by the accessibility of qualified data and the appropriate tools to process it. 以前的研究主要\u0026hellip;，因此造成了使人不信服的结论 However, previous studies mainly used overhead-view greenspace indicators such as park area or NDVI to assess greenspace exposure, thus leading to inconsistent findings. 比较委婉，通常研究人员并不能确信。。。是合适的 In most cases, however, the researcher cannot be certain that the connections used in the study are appropriate. 讲这个数据/工具没有能力\u0026hellip;(提取这类特征) Although remote sesing data can to a certain extent capture utban and suburban landscape and infrastructure(e.g., buildings and street networks), remote sensors have limited capability to extract socioeconomic attributes and human dynamics such as movements and daily activities. 因为要手工处理信息，因此受限与大规模的应用 Current stduies, however, are still limited and subjecetive with regard to the use of Google Street View and other sources for environment audits or pedestrian counts bacause of the manual information extraction and compilation, especially for large areas. \u0026hellip;的尝试也并不能充分的拟合复杂的本质 Attempts to simplify the knowledge of relevant contexts as predefined mathematical functions cannot adequately model its complex nature. 这个模型/方法是\u0026hellip;的经典模型/方法，但是仍然不能够\u0026hellip; This network abstraction model is the classic method of road network processing in traffic simulation and urban modeling, but it is incapable of revealing the latent network structure and mode. 以往研究趋向于\u0026hellip;，而没有充分考虑到\u0026hellip; Primarily based on node centrality analysis, these works tend to treat and evaluate the road nodes and segments independently, without considering the relationship between road segments. 忽略\u0026hellip;，使某些研究陷入瓶颈 The ignorance of spatial interaction information makes related research encounter a bottleneck on improving classification accuracy. 这些局限性致使人们呼吁——为研究和应用的生态区域的发展提供更有力的科学依据. These previously recognized limitations have led to calls for a stronger scientific basis for development of ecological regions for both research and application. 然而，关于解决这一问题的最佳方法的一致意见一直难以达成，现有的文献以传统的调查方法为主，这些方法容易因样本量小而受到批评，特别是在对大城市的研究中使用。Agreement on the best approach for addressing this problem has been elusive, however, and the existing literature is dominated by traditional survey approaches, which are liable to criticism for small sample sizes, especially when used in studies of megacities   传统方法费时费力  受限于金钱，时间，数据精度和主观能动性 The significant limitation of current pedestrian count method is mainly on cost, time, data accuracy, and subjectivity. Because of the limitations of data sources, analytic tools, and computation capabilities , these studies had limited development, with most studies relating to city structures focused on urban morphology. Travel-behavior studies experienced a low period during the 1990s for the same reason. 相比于传统研究 The rapid development of location-based services and technologies facilitates the attainment of big geospatial data and provides more accurate, plentiful and effective information of human interactions in places, compared with traditional survey data. Determining how green our streets are has always been difficult given the time and money consumed using conventional methods. 问卷调查，采访 Previous studies were conducted by the traditional data collection methods(传统的数据收集方法), such as interviews and questionnaires(问卷调查，采访), which are laborious, costly and time-consuming(费时费力). 传统方法费时费力，应当出现新的范式来指导 most studies rely on in-person assessments or field observations to collect data about built environment characteristics. Such conventional data collection approaches have several challenges, including high labour intensity, long update period, restriction to small-scale geographic areas, etc. (Golder and Macy 2011; Seresinhe, Preis, and Moat 2015; Lu 2019). New paradigms should be proposed to solve these problems and guide studies on sensing the urban physical environment (Rathore et al. 2016; Janowicz et al. 2019). 传统方法劣势详细描述 Traditional studies for environmental health research usually employ self-reports and questionnaires, field surveys, and secondary sources to characterize built environments at element level and at scene level, respectively. Questionnaires and self-reports are arguably the most commonly used sources. With these sources, investigators may ask respondents to evalu- ate different aspects of neighbourhood attributes . For field observations, researchers are asked to record and describe their urban environment audits by walking or driving around the study areas with pre-defined survey forms (Gullón et al. 2015; Lawlor et al. 2003; Takano, Nakamura, and Watanabe 2002). Secondary sources refer to those pre-defined environmental measures based on spatial analysis and modelling such as spatial accessibility measures (Pliakas et al. 2017; Leslie and Cerin 2008). All three approaches have their strengths and limitations. Questionnaires are the most commonly used method. It might be affected by people’s biases while field-audits are more objective. But both methods are costly, labour-intensive and time-consuming when conducting research with a large sample size or over large regions. Secondary sources might not characterize neighbourhoods in sufficient detail, and might be limited to specific types of environmental exposures (Pliakas et al. 2017). - [Yuhao Kang, A review of urban physical environment sensing using street view imagery in public health studies] 传统调查数据劣势：贵、短时效、不具代表性 Notwithstanding the fact that travel survey or diary data are often sufficient to create a detailed picture of travellers’ socioeconomic characteristics, the obvious disadvantages of such data include the expense involved in collection, the inability of such data to reveal real-time travel behaviour over a long period, and the small and therefore non-representative nature of the populations sampled in travel surveys—disadvantages that are particularly problematic for studies of megacities.   与现存研究相比\u0026hellip;， 我们的方法。。。具有的优势  Comparing with existing studies that delineate urban functional areas with social media data, our method has the following advantages. 与以往研究不同，我们的研究侧重。。。We differ from these previous approaches in multiple ways. First, \u0026hellip; Secondly, \u0026hellip; Third, \u0026hellip; 该方法能够\u0026hellip;,因此适合\u0026hellip;，一般用于介绍完方法做一句总结 This powerful technique is able to capture both the longrange and short-range relationships through its neural network weights. Clearly, it is suitable for modeling a graph of connected places. Building on recent studies with manual collection of pedestrian counts, our study contributes in three ways. Comparing with conventional types of social media data, the new dataset employed in this study offers a unique advantage (独特的优势)- the ability to capture the inherent heterogeneity even within the same urban function types. 计算更加高效 The DTW distance based k-medoid method in our study is computationally more efficient than previous methods used to delineate urban function areas, such as the family of probabilistic topic models.   这种方法可以通过。。。的方式提升  不需要人工干预，减少计算成本 This method can be implemented without much human intervention (e.g., input prior information or restructuring procedures), and has a much lower computational cost.    本文做了哪些事情；采用\u0026hellip;的方法；本文目的/目标在于\u0026hellip;；实验/算法/模型验证方法；详情请看\u0026hellip;;  本文关注点/目标/目的在于；侧重  本文关注点 Of particular interest in this article is the spatiotemporal modeling of local nonstationary process. Specifically, an extension of GWR, GWTR is developed in order to account for local effects in both space and time. 强调潜力 We focus on highlighting the potential role of computer vision in understanding urban systems related to the built environment. 汇总/规划研究问题：   本文强调以下几个问题 This article address the following three questions: (1)\u0026hellip; (2)\u0026hellip; (3)\u0026hellip; 本文关注问题 Two research questions (RQ) will be investigated in this work. RQ 1: \u0026hellip; RQ 2: \u0026hellip; 没有\u0026hellip;的深度研究，这些问题很难被解答 Comparing to these findings, how do the mobility patterns differ in bike-sharing trips from regular cycling activities? Will bike-sharing trips always follow shortest paths? How does road characteristics influence bike-sharing users’ route choice? Without the proper use and mining of bike-sharing trajectory data, these questions can hardly be thoroughly exploited.  归纳总结上述论文，本文的主要目的是\u0026hellip; Drawing upon (归纳总结) the review of place formalization and new methods in deep learning, the purpose of this study is to formalize the concept of place in terms of locale – the physical appearance of place. 本文目的\u0026hellip; Our goal in this paper is to explore this possibility in terms of the physical quality of the urban environment. 本文目的\u0026hellip; The aim of this study is to explore issues involved in the use of Google Street View (替换数据源) to examine outdoor food and beverage advertising (主题应用). 本文的目的是研究\u0026hellip;的可行性 The objective of this study was to investigate the feasibility of incorporating place connections to predict place characteristics.   这不是本文关注的重点  This work also relates to a different stream of research, which focuses not on data quality per se, but on an assessment of the similarity of POI obtained from different datasets for the purposes of conflation or data fusion. However, improving the accuracy on certain data set is not our focus.   延续/扩展研究  我们延续/扩展了\u0026hellip;的研究 We expand and complement a recent paper on such comparison by Dao and Thill (引用).   步骤描述  We started with going through Google Map, Google Street View, and APIs to develop an algorithm for downloading images and transforming images for the automatic detection. A Matlab toolkit was used to detect pedestrian in the second step and the last step validated the detection results. These steps were reported in three subsections below. The proposed framework for visualizing and exploring POI configurations of urban regions on POI-type semantic space is composed of three steps, as shown in Fig. 2. Step 1: \u0026hellip; Step 2: \u0026hellip; Step 3\u0026hellip; This study can be divided into the following steps: 1. Establish an urban road network model using the processed OSM roads. 2. 3. The flow chart of the study is shown in Figure 4. [常见用于Methodology第一段] The framework is composed of four stages, namely data collection, feature construction, model training, and mapping and analysis (Fig. X).   用于discussion部分第一段话（以下列举一些值得讨论的论点） Some meaningful points are summarized below. First, \u0026hellip; Second, \u0026hellip; Then, \u0026hellip; Finally, \u0026hellip; 模型的有效性和优势通过\u0026hellip;来验证  大规模的真实的出租车数据 The effectiveness and strength of our algorithms are validated by experiments on a very large volume of real taxi trajectories in an urban road network.   出于\u0026hellip;的目的,为了\u0026hellip;的目的;我们进行了\u0026hellip;实验或尝试\u0026hellip;  进行了一系列的尝试和努力 A few trials are performed to determine an appropriate value for the number of clusters (k) in our case study. 本文尝试进行\u0026hellip;的研究 this study attempts to combine NTL images, taxi trajectory data (a kind of popular social sensing data) and census data to spatialize population by using Shanghai as the study area. 我们设计了三组实验 \u0026hellip;Three scenarios were designed to consider different connection types. 对比实验 A series of comparative experiments revealed the influence of place connections on predicting place characteristics. 出于对比的目的 For comparison purpose, similar experiments are performed using \u0026hellip; method. 为了使读者更加清晰的了解本文中提及的方法 For a better understanding of our method, we illustrate the calculation of the DTW distance with an example that \u0026hellip;   (当参考别人使用过的方法时候\u0026hellip;) 相似的方法同样应用在。。。领域/研究  Similar averaging methods are frequently adopted in studies invloving time-series data with clear periodictiy. 详情请看/见 The similar taxi trip dateset and street view image dateset have been used in previous works; detailed descriptions can be found in XX. 与。。。研究类似  Our work is similar to that of Ewing and Handy in that we also aim to model the expert judgements on the qualities of urban environment based on very basic attributes. However（收）, the proposed big data-based machine learning method can be more automatic and labour saving.   To deal with the skewed distribution of the house prices, we discretize the house price values into 10 levels and formulate the training as a 10-category classification task. A similar strategy was adopted in Zhang et al. (2019). 基于同样的思想/想法 We embrace the idea of distributional semantics in geographic space and explore the similarity and relatedness of place types using different latent representations with augmented spatial contexts. As suggested by studies from urban planning and geography, we select 600m as the distance threshold for our distance analysis, which is suitable to represent the preferred coverage of human physical activity by walking.   详情请见/参考原著  Dollar (2015), Dollar et al. (2014) provide detailed information on the detection method and the toolkit. For further details regarding Neighborhoods for Active Kids methodology, please refer to Oliveret al. (2016). The details of how to train a GCNN model can be found in the Appendix detailed descriptions can be found in XX.   受。。。的启发，本文假设/工作。。。 Inspired by the evidence that the urban mobility is highly relevant to urban land use and urban physical environment, our method assumes that the streetscape depicted in street-level imagery reflects urban functions and that urban activities in streets of similar functions present similar temporal patterns. 从这种角度来讲 Compared to other data sources such as land use or land cover data, social sensing data has a great capability for delineating people’s movements（背景）. In this light, it is worthwhile using it to improve the accuracy of population estimation, given the fact that using NTL data alone may overestimate population in some specific areas due to excessive high light radiance. As suggested by Castells (1996), cities can be linked through many relations, such as politics, culture, economy, and technology. Inspired by these exploratory studies / prior studies, temporal activity variations have been widely used to infer land uses of places. To encourage spatial smoothness in the output image , we follow prior work on feature inversion [6,20] and super- resolution [48,49] and make use of total variation regularizer . 数据简介(用于图表的标题) Data schema of taxi GPS records 当多元数据时间/年份不一致时 Although the WorldView-3 images and the vector data were obtained at different times, there were few changes in land-use boundaries during these two years, and the potential influence of differences between these times is limited and can be ignored. 使用\u0026hellip;的概念来指代\u0026hellip; We adopt the notion semantic relatedness from the previous GIScience literature (Ballatore et al., 2014, Hecht and Raubal 2008, Hecht et al. 2012), and use it to refer to the city relatedness under different semantic topics. \u0026hellip;具有优势 There are several advantages in using news articles for extracting semantic relatedness between cities. 数据、代码开源、公开；方便获取  news articles are information sources that can be accessed relatively easily (Taylor 1997, Beaverstock et al. 2000). This feature can help remedy the data deficiency in city network research (Smith and Timberlake 1995, Short et al. 1996). [简单说一下应用 补刀] With a news article dataset, we can use the proposed computational framework to study the relatedness of a large number of cities in a timespan of multiple decades. Our R code is publicly available on GitHub for download and can be modified for individual research needs (github地址).    文章/实验表明，看图表明; 结论描述及分析  The results show that the proposed methods effectively\u0026hellip;（结果表明该方法能够有效的。。。）  The results support our hypothesis that \u0026hellip;(结果有效地支撑了我们的假设) they indicate that sth is appropriate for\u0026hellip;（结果表明该方法适合。。。） This method reveals (that)\u0026hellip;（该方法表明。。。） Fig. 2(b) shows (that)\u0026hellip; (图2，b显示。。。) The study/it observed that \u0026hellip; The study concludes that \u0026hellip; Experimental results evince that\u0026hellip;（实验结果表明） Experimental results evince that the proposed algorithm performs significantly better than the well-known A* algorithm. The reliability tests results based on pedestrian information collected from over 200 street segments in Buffalo, NY, Washington, D.C., and Boston, MA respectively suggested that the image detection method used in this study are capable of determining the presence of pedestrian with a reasonable level of accuracy. Computational results demonstrate that \u0026hellip;（计算结果表明） 实验结果如下 The results showed the following. (1)..(2).. 结果无法解释 The reason for this phenomenon still needs further research. 该结果将在后续\u0026hellip;详细讨论\u0026hellip;, which will be discussed in detail in Section 4.   参数设定  使用默认参数：Unless specified otherwise, we used default parameters in open source tools in baseline methods.   罗列术语 (terminology)   Throughout the paper, we use the vocabulary network or CNN to describe a network architecture, such as VGG; and use the vocabulary model to describe a trained network, or a fusion of many trained networks. One specific network may generate many models because it can be trained in different ways. We also use street view, ground view, and ground-level to describe terrestrial images that were taken from ground-level, and aerial view, overhead, and nadir view to describe remote sensing images acquired by airborne or spaceborne sensors.   神经网络模型框架介绍  [如图] The architecture of the proposed 1-d SPP-Net is presented in Fig. 2b. [由几部分组成] The network is composed of three major parts, i.e. five 1-d convolutional layers (each layer is closely followed by batch normalization and ReLU activation), one 1-d SPP layer, and two fully connected layers. [不同层的特点/参数] The convolutional layers use kernel size of 24, 24, 7, 7, and 3, with stride of 1, 24, 1, 7, and 1, and padding of 12, 12, 3, 3, and 1, respectively. The output of the convolutional layers is then fed into the 1-d SPP layer to obtain fixed-length representation, which is further processed by the fully connected layers. The final output 256-d features are exploited as extracted TS features. [不同层的作用] The convolutional layers can extract short-term time-series features, by stacking them, the patterns with long-term dependencies can be captured in higher layers. The 1-d SPP layer and fully connected layers can further aggregate and condense the convolutional features to higher level semantic features.   训练数据配置/ground-truth data  To train the proposed model, we utilize the continuously collected taxi trajectories in a Chinese city and calculate the congestion indices for all road intersections based on traffic speed and volume as the ground-truth data.    文章贡献；意义；文章总结，从结果/结论出发  提供新角度、视界\u0026hellip;  Via a series of basic statistic and correlation analyses, the street scene ontology and street visual descriptor can provide new perspectives for understanding the characteristics of an urban area. Section 4.3 presents a correlation analysis between scene content and space syntax indicators that offer insight into the potential relationship between street’s visual appearance and a road network structure.   本文所做工作所在，致力于；文章贡献  This study seeks to contribute to the literature in three ways. First, it models the relationship between A and B by C. Second, the study develops a systematical and integral route planning algorithm framework using big taxi trajectory data. The framework has two distinctive/significant features. (1)\u0026hellip;(2)\u0026hellip;Thrid, the study analyzes the contribution of A to representing taxi drivers' experience through numerical experiments. This work makes a contribution by enhancing the understanding of human perceptions of places in a large-scale urban environment in an automatic and efficient way by using machine learning and street-level imagery. This study enriches place-based GIS research and provides a human-centric perspective for urban planning and LBS applications. (强化了\u0026hellip;方法、技术在\u0026hellip;方面的应用)Our analysis advances the use of spatiotemporal clustering techniques in urban and geographical studies. （据我们所知）迈出第一步 This study explores their characteristics as cognitive places with human spatial cognition and perception on urban environments being considered, which to our knowledge, is the first attempt. （适用于，讲述本文提出的模型/方法的适用性）  The model and methods developed in the study are also applicable to other types of movement trajectories for extracting the experience of different types of drivers (e.g., private vehicles or truck drivers) and for understanding their driving behavior. The methods provided in this study are also suitable for analysis of other cities with similar data sources.   (提供一种开箱即用的工具)This work provides a ready-to-use computational tool for extracting visual concepts and high-level visual knowledge of a streetscape to facilitate studies using street-level imagery. (存在巨大的能力/潜力) A series of quantitative analyses demonstrates the ability and great potential of the framework for investigating the connections between place and other socioeconomic factors.   结论具有实用价值，十分重要  From this perspective, this result is of practical importance in identifying the real role and function of a street based on its visual appearance and in further informing traffic and transportation planning.   可复现性  This method allows large scale and consistent objective measures of visual enclosure that can be done reproducibly and universally applicable with readily available Google Street View imagery in many countries around the world to help test their association with walking behaviors.   为了满足\u0026hellip;的需求（一般前面会论述该need）  To help fill the need for adaptable and flexible methods for creating regions, we apply a newly published computer science clustering algorithm that creates customized ecological regions, test its use for macrosystems ecology research, and make it available in an online repository    提出倡议  To this end, what we suggest in this study is that urban planning practices should attach importance to \u0026ldquo;cognitive place\u0026rdquo; and \u0026ldquo;cognitive distance\u0026rdquo;, which load human experiences and perceptions toward the environments. This is also coincident with the ultimate goal of urban planning, urban design, and smart-city construction, i.e., making better human societies and improving human lives.  Remainder of this paper  The remainder of this paper is organized as follows. In Section 2, the literature on place formalization and those studies using street-level images are briefly reviewed. Section 3 introduces the proposed locale representation framework, including the street scene ontology and with a series of analyses using the street visual descriptor being conducted. The case study shows that the visual appearance of streets is highly correlated with the spatial structure of street network. In Section 5, we draw some conclusions and discuss future work.  Limitations/Future Works  The limitations of this work should also be discussed and paid more attention in future work. First\u0026hellip;Second\u0026hellip; The limitation and potential improvement of the proposed method is also discussed. Future works are anticipated to (预计今后的工作将重点关注) address regions with inconsistent physical environment conditions to traffic flows by focusing on the regions with a larger residual in the predictions. 没有验证（ground truth）The main limitation of this study may be that there is no ground truth to quantitatively verify the accuracy of our delineated cognitive boundaries, but we make efforts to guarantee the effectiveness of the derived results by assuring the quality of the data and rationality of the approach. Moreover, the analysis toward the characteristics of POI weights in Section 3.1 can also indirectly demonstrate the reasonability of the results. (虽然没有ground truth 但是我们确保数据和方法，并且3.1的结果也能够间接地表明方法的可靠性) However, further research is required to bridge the gap between CMA for human and animal movement towards an integrated science of movement. (需要进一步的研究，以弥合人类和动物运动的CMA之间的差距，实现运动的综合科学) In addition, visualization still remains a key challenge in the dissemination and communication of patterns and knowledge of movement, especially when dealing with large and long-term movement data sets. （被忽略）Data quality and privacy challenges as well as uncertainty in data, analytics, and modeling have been largely overlooked in the CMA literature so far.  (该研究仅仅作为\u0026hellip;的开始) Furthermore, we would like to regard this research as a beginning of detecting the spatial interaction communities based on mobile phone datasets. Further research is required to understand the causal relations and semantics of these communities if more detailed land-use or socio-economic data are available.    Acknowledgments  We thank the two anonymous reviewers for their critical and constructive reviews of the paper, which helped to improve its quality.  比较好的段落模板 Introduction  推荐Yang的Introduction写作，Refer: https://dx.doi.org/10.1080/13658816.2019.1700510 Introduction第一段(引入话题,你得说你做的研究有意义吧)  The mining of information hidden in urban and regional road networks has a longestablished history in the fields of traffic geography, land use planning, and economic geography (Porta et al. 2006). In an era of unprecedented global urbanization, the continuous improvement of the urban road system also sustains immense social mobility pressures (Batty 2008) and plays a vital role in urban development (Wang et al. 2012). As the artificial corridor in the urban landscape, the road network is the framework of urban development and an intrinsic factor of urban space expansion. Hence, the exploration of the road network structure not only helps to interpret the topology of the road network but also contributes to the understanding of the organization and spatial distribution of the urban system (Wang et al. 2011, Levinson and Moreno 2012). 解析：一段一句话，一句话至少一引用；研究话题历史悠久=\u0026gt;目前该话题也是热点=\u0026gt;(路网)的重要角色=\u0026gt;研究(路网)的意义(不但)(而且) (From Yao yao, https://doi.org/10.1080/13658816.2019.1584806) The rapid increase in private car ownership aggravates metropolitan traffic congestion, thereby causing a series of issues, such as air pollution, high energy consumption, and accidents (Ding, Wang, Liu, Zhang, \u0026amp; Jiawen Yang, 2017) [私家车保有量的快速增长加剧交通拥堵，同时造成了一系列的问题]. A possible countermeasure to alleviate the aforementioned negative impacts is to prioritize public transportation (Chakour \u0026amp; Eluru, 2016) [缓解以上问题一个比较好的策略是提高公共交通的地位。引出自己做的这样研究的意义]. Transit authorities aim to optimize public transportation planning and improve service quality to achieve the goal of promoting public transit systems, and ultimately, increase the attractiveness of public transit [提高公共交通地位的目的旨在\u0026hellip;就说它有什么好处嘛]. In particular, identifying the key determinants that affect transit ridership and analyzing the spatial and temporal evolution of influences is crucial (Taylor \u0026amp; Fink, 2003) [在这其中，识别关键因子尤为重要！引到自己的研究点]. A thorough understanding of the factors that influence transit ridership can enable transit authorities to efficiently allocate the limited resources for the deployment of transit service and to develop additional targeted policies for pricing and investments [继上一句补刀，我们做的这个研究点啊能干嘛。。能干嘛。。].   Introduction方法引入段（就是说你这篇论文引入了\u0026hellip;的方法，经典的三段论  Recently, there has been a surge of interest in graph convolutional neural networks (GCNNs) for learning graph-structured data where the range of connection varies (Bruna et al. 2014)该方法目前使用很广泛. To effectively process the connection information, GCNNs generally follow an aggregation scheme where each node aggregates characteristics of its neighbors to learn a deep representation of the contextual information (Defferrard, Bresson, and Vandergheynst 2016).一句话介绍该方法: 是什么、解决什么问题 This powerful technique is able to capture both the longrange and short-range relationships through its neural network weights. Clearly, it is suitable for modeling a graph of connected places.总之，该方法用在解决我们的问题上是适合的(From Di Zhu, https://www.tandfonline.com/doi/full/10.1080/24694452.2019.1694403)   Introduction讲数据  Crowdsourced data (such as POIs, check-in data, and taxi trajectory data) collected by various sensors have led the related studies into a new stage. These data sources contain abundant semantic information of human activity patterns and urban land use functions. Researchers have tried various data, such as POIs, mobile phone location records, GPS trajectories, and check-in data, to discover urban functional zones. Since different kinds of data can reflect different characteristics of urban functional zones, it is essential to integrate multi-source data to improve the accuracy of recognition of functional zones. In the literature, DRoF—proposed by Yuan, Zheng, and Xie (2012)—is one of the most representative methods. They used both POIs and GPS trajectories to discover the functions of each region with a topic-based inference model. Similarly, Wang, Gu, Dou, and Qiao (2018) used POIs and trajectory data to recognize urban functional zones based on spatial semantics and interactions between regions. Some researchers also tried to integrated remote sensing images and crowdsourced data (such as POIs and check-in data) to identify the land use functions of fine-grained zones using supervised classification. (From https://doi.org/10.1111/tgis.12642)   Introduction最后一段，概括总述  This research introduces the use of GCNNs to model connected places where each place is represented as a node, place haracteristics are the node features to be computed, and place connections are represented as the graph edges.本研究引入一种方法去\u0026hellip;,这里这个where用的很好 The graph convolution can effectively learn from the graph structures and node features to understand the place characteristics in a geographic context.这个方法好啊，能干啥干啥，其实就是上一句分开写，如果太长了看着难受 The objective of this study was to investigate the feasibility of incorporating place connections to predict place characteristics.本文的目标啊 In a case study of the Beijing metropolitan area, we took advantage of GCNNs in formalizing, reasoning, and understanding places.这里说case study在哪里 Three scenarios were designed to consider different connection types. A series of comparative experiments revealed the influence of place connections on predicting place characteristics.陈述对比实验的(From Di Zhu, https://www.tandfonline.com/doi/full/10.1080/24694452.2019.1694403) In this study, via identified communities in the city road network, we propose a novel way to link the urban roads with the urban space and urban functional zones先总的说一下，通过什么，这篇文章提出了什么去解决什么样的问题. Specifically, based on the urban road network model constructed with OpenStreetMap road data, the Infomap community detection method is employed to detect the hierarchical communities and analyze their spatial distribution at different levels. In addition, points-of-interest (POI) data and their indicators are used to reveal the land use and functional area density, the mixing degree and the enrichment status of the community-based network, exploring the relations between communities within road network and urban functional zone distributions从Specifically到结尾都是讲，你方法呀的步骤或者框架呀包含哪些部分.(From Yao yao, https://doi.org/10.1080/13658816.2019.1584806) In summary, the four technical issues referred to above are critical to extracting functional zones, but they have yet to be resolved未解决的问题. This study aims to determine the solutions to the four issues, and extract functional zones from VHR satellite images本文做了什么. Four contributions are made in this research总结贡献点: (1) spatial-pattern features characterizing local spatial patterns of objects are proposed and used for functional-zone segmentation; (2) a geoscene segmentation method is first proposed to delineate functional zones at multiple scales; (3) two parameters, i.e., scale and the weight of spatial-pattern features, as well as their impacts on segmentation results are evaluated and reviewed; and (4) the proposed methods are used to map functional zones for three cities and compare their functional structures. The four contributions are novel and crucial to urban functional-zone analysis这几个贡献对\u0026hellip;很重要. To the best of our knowledge, this study is the first work on automatic functional-zone segmentation就我们所知，我们是第一个. (From Zhang Xiuyuan, https://doi.org/10.3390/rs10020281)   讲研究的应用（对于各行各业的人都有用，其实比较套话，用的时候多举例子，写具体一点，太抽象了难让人信服）  Urban AOI have great meanings in multiple application domains. For tourists, AOI highlight the interesting zones within a city, and can therefore be used to support trip planning of travelers. For city planners, AOI reveal the regions which receive high exposure among the general public. Accordingly, these regions could be assigned higher priorities when there are only limited resources for urban planning projects, such as city beautification (Espuche et al., 1991, Gandy, 2006). Since AOI are often visited by a large number of people, transportation analysts can examine these regions to understand traffic flows and human mobility patterns (Batty, 2007, Yuan and Raubal, 2012). In addition, information service providers can display targeted information based on AOI (e.g., highlighting the hotels within the AOI of a city). (From Hu yingjie, https://www.sciencedirect.com/science/article/pii/S0198971515300120)   讲数据/方法的优势，适用于该研究  Among the many types of social media data, geotagged Flickr photos possess a high suitability for exploring urban AOI. One major advantage of Flickr data is that they reflect the interest of people towards locations. + (解释) In addition, the openness of the Flickr API allows the retrieval of publicly available data throughout the world and since the year of 2004. + (解释) Besides, existing research shows that a major proportion of Flickr photos were taken in urban areas, and this gives Flickr data one more advantage for studying urban AOI. + (解释) (From Hu yingjie, Introduction部分第5段， https://www.sciencedirect.com/science/article/pii/S0198971515300120) Finally, instead of focusing on one particular component (e.g., extracting textual tags), we propose a coherent framework which connects data processing, AOI generating, tag and photo summarizing, and knowledge discovery.    Study Area, Data Description, Method  数据描述  行政区划：The administrative boundary data used in this study was derived from the Database of Global Administrative Areas (GADM) (https://www.gadm.org/). After projection transformation and topology checking, the administrative division data of different scales are used in the preprocessing, calculation and analysis of other experimental data.(From Yao yao, https://doi.org/10.1080/13658816.2019.1584806) OSM： The primary dataset for this study is the road data obtained from OSM, which was acquired in January 2018 (https://www.openstreetmap.org). OSM is an open source map provider that aims to provide users with free and easily accessible digital map resources (Haklay 2010) and is considered to be the most successful and prevailing volunteered geographic information (VGI) at this stage (Fan et al. 2014). The accuracy of the positioning and the topological relationship of the OSM roads in the study area is exceptionally high (Yao et al. 2018). In addition to the fundamental spatial information such as latitude and longitude, the road data obtained from the OSM contains additional attribute information, including road type, maximum travel speed, and one-way streets, which contribute to preprocessing and establishing the road network. After preprocessing operations, such as simplification, merging, and topology inspection, 81,377 roads and 60,756 nodes were extracted (Figure 2).(From Yao yao, https://doi.org/10.1080/13658816.2019.1584806) 研究城市：Data used in this study have been retrieved using Flickr\u0026rsquo;s public API. Six cities from six different countries have been selected for this work, which are: New York City (NYC), London, Paris, Shanghai, Mumbai, and Dubai. The first three cities are generally recognized as well-developed cities, while the second three cities have experienced fast development in the past 10 years. We deliberately choose these two groups in order to examine the difference in the growth patterns of their AOI. The data retrieval was performed in July 2014, and we retrieved all publicly available and geotagged Flickr data from June 2004 to June 2014 in order to study the AOI growth patterns in the past 10 years. The data for each city were retrieved using a bounding box containing the city\u0026rsquo;s administrative boundary. trajectory：This dataset contains 102,361 trips made by 16,887 Mobike users on 79,062 bicycles in August 2016. Each trip consisted of data fields, including trip ID, bike ID, user ID, trip start time and end time, longitude and latitude for origin and destination, and GPS tracking along the trajectory. The spatial resolution of the GPS tracks is ~100 m and the temporal resolution is approximately 30 s. To discover the driving force behind different short-trip transportation patterns at both the individual and group level, land-use data and the locations of bus stops, road and bike lane networks, metro lines and stations were all collected for the study area. Road network data were acquired from OpenStreetMap, while the rest of the data were crawled automatically from Gaode Map, similar to Google Map, in China.   方法描述部分  Based on the theory and method of complex graph theory, this study aims to describe the structure of the road network in Guangzhou quantitatively. We explore the community formed by the urban roads at different levels and identify the functional areas from a community perspective. This study can be divided into the following steps: 1. Establish an urban road network model using the processed OSM roads. 2. Divide the road network model into multilevel communities based on the Infomap method. 3. Depict the functional density, mixed and enrichment degree of each community with Gaode POIs. The flow chart of the study is shown in Figure 4.(From Yao yao, https://doi.org/10.1080/13658816.2019.1584806)   结论描述/分析  (模型精度/预测结果)As we can see from the Fig. 6, high and reliable accuracy were achieved in predicting the six perceptual indicators.（全局总结） The accuracies of the different indicators varied. (不同指标的精度不同。表示差异的表述方式) For instance(举例说明), the accuracy of safe, beautiful, and wealth were slightly higher than that of depressing, boring and lively（举例结论一）. This result might be caused by variances in how people understand these concept（结论分析）; （进一步解释结论分析）their knowledge might tend to be relatively consistent with“what is the beautiful scene”but inconsistent with“what is the depressing scene”. Another reason might be insufficient data collection for the latter three dimensions（另一个结论分析）. In addition（此外）, the average accuracy decreased as the bandwidth of the sample gap narrowed (smallerδ)（举例结论二）, indicating that human preference was comparatively unstable for normal scenes.    ","description":"","id":99,"section":"posts","tags":["论文阅读","单词","短语","写作","思路","模板","总结"],"title":"论文写作摘抄-句型句式","uri":"https://www.xunhs.cyou/posts/notes/91/"},{"content":" 论文审阅过程中，与reviewers答辩常用句型句式整理。\n 审评中常出现的词组： state of art (SoA) 该课题的国内外研究现状\nrespecting the comments of the referee 作为对同审的回应\nIn response to the comment 作为对评审意见的响应\nTo the best of the authors' knowledge 据我们所知\n论辩意见： 学术论文的写作本身就是在批评与修改中提高，且这一过程并非一帆风顺，当有评审者对你的研究成果持怀疑甚至否定态度时，并不意味着该研究成果毫无价值。但是，我们需要正面且详细地回复这类评审意见。刻意回避负面的评审意见会使编辑认为论文确实有不足之处。\n答复信一般可由三部分组成：对编辑和评审者处理论文表示感谢；对答复和修改进行概要性的说明；针对每一位评审者进行一一对应的答复。\n功能句式整理 致谢   We (the authors) sincerely thank Referee 1 for the time and effort given to our manuscript and raising such a constructive suggestion.\n  We thank again the referee for raising such a constructive suggestion.\n  We thank again the referee for his/her frank recognition given to our manuscript, in addition to his/her time and effort spent in reviewing our manuscript.\n  We thank the referee for raising such a suggestion which improves further the presentation and quality of the manuscript.\n  We also thank the referee sincerely for the inspirations from the comment.\n  Thank the referee sincerely for the important discussions, which have greatly imporved the quality of our manuscript.\n  添加内容 Respecting the comments of the referee, the following Remark 1 has been added in the revised manuscript.\nRemark 1. \u0026ldquo;The general procedure of the discre\u0026hellip;\u0026rdquo;\nAs suggested, the formulations of such seven discrete-time models are listed in Table 3 of the Revision Information letter (i.e., Table 1 of the revised manuscript).\n删除 As suggested by referee, the revised manuscript has been shortened from 15 pages to 13 pages; specifically speaking, similar figures associated with Example 1 have been omitted, and some expressions or statements for constructing the discrete-time ZNN models and GNN model have been simplified.\n更新 更新内容 We have updated the literature survey in the new manuscript according to the suggestion of the editor. Specifically, nine recent related papers from ITS (i.e., references [4] through [6], [10] through [15] in the new manuscript) have been added in Introduction, and reference [6] in original manuscript has been removed (in the new manuscript).\n修改图片/图表: As suggested, the corresponding Fig.13 and 14 have been revised according to the format of Figs.1.\n列举修改 The formulations of other multiple-poiunt discrete-time ZNN-K nideks by exploiting diffenrent multiple-point numerical differentiation formulas, torgether with that of the ZNN-L model, are listed in Table 1 of the Revision Information letter (i.e., Table 4 in the revised manuscript) for readers' convenience. Note that \u0026hellip;\nIn response to the comment, some challenges of developing the discrete-time Zhang neural networks for the time-varying problems solving are listed as follows.\n  In the solving process of time-varying problems\u0026hellip;\n  In the solving process of time-varying problems\u0026hellip;\n  Two example of time-varying quadratic minimization in the original manuscript are investigated and illustrated, which substantiate well the effectiveness of the proposed methods/models.\n陈述观点   据我们所知，目前没有: To the best of the authors' knowledge, there is almost no literature dealing with time-varying quadratic minimization via discrete-time neural networks at present stage.\n  reviewer是不是误解我们的表述了: After reading the referee\u0026rsquo;s comments, we think that the referee may have misunderstood the essence of the time-varying problems solving, and we want to address the concern as follows.\n  简单明了是最好的: In the authors' opinion, simplicity is beauty. As Occam\u0026rsquo;s razor suggests, when we have two competing theories that achieve the same efficacy, the simpler one is the better. Therefore, being simple, direct and straightforward is actually the advantage of this work on the condition of achieving excellent results, and it is thus easy for readers to understand and use the discrete-time ZNN models proposed in the manuscript.\n  希望上述的解释能够让您满意: In summary, we sincerely hope that the above explanations can help the referee understand better the time-varying problems solving. We also thank the referee sincerely for the inspirations from the comment.\n  希望上述解释能够消除您的顾虑: Finally, we hope that our response can address the referee' concerns.\n  如果您能直接告诉我们，请您直说吧\n In addition, if he/she has other better specific discretization methods, please feel free to tell us to try. **This may be another good direction for us to extend the research. ** It will be much helpful if the referee can directly tell us the existing state of arts of conversion of a continuous-time system that he/she thinks. Respecting the comments of the referee, the multiple-point numerical differentiation formulas [40], [41] are investigated further to convert the continuous-time ZNN model to discrete-time ZNN models, which has been added in the revised manuscript, i.e., the Appendix.    答复模板 答复1:We/The authors thank the editor very much for giving us such inspiring advice. 【开头感谢】\nWe have updated the literature survey in the new manuscript according to the suggestion of the editor. 【我们做的修改】【引用方面的修改（添加，删除引用）】\nSpecifically, nine recent related papers from ITS (i.e., references [4] through [6], [10] through [15] in the new manuscript) have been added in Introduction, and reference [6] in original manuscript has been removed (in the new manuscript).【说明具体修改】\nFinally, the authors would like to say thanks again sincerely to the editor for his time and effort spent in reviewing the manuscript, as well as many constructive comments which have imporved much further the presentation and quality of this manuscript.【结尾感谢】\n答复2:First of all, we (the authors) would like to express our sincere gratitude to the editors and anonymous referees for their time, effort and recognition given to our manuscript ITS-0491. Specifically, \u0026ldquo;The problem studied in the paper is very interesting\u0026hellip; \u0026quot; (Referee 1); \u0026ldquo;*In my opinion, the work is ****good ****and the contribution of the paper is *significant\u0026rdquo; (Referee 2).\n【首先感谢review的评论，并列举评论的话】\nSecondly, we gratefully point out that the editors' and referees' comments and suggestions have really constructively helped us improve further the quality and presentation of this manuscript. In light of such inspiring comments and suggestions, we have revised the original manuscript duly and carefully, with main revisions listed as follows.\n  As the response to the comments of Referee 1, the multiple-point numerical differentiation formulas (given by newly-cited references [40], [41] in the revised manuscript) have been investigated to convert the continuous-time system to the discrete-time system (please see the Appendix in the revised manuscript). Moreover, a rebot-manipulator motion planning example (i.e., Example 3) has been added to Section VII for further verifying the effectiveness of the proposed methods/models.\n  As suggested by Referee 2, Remark 1 about the general differences between the continuous-time ZNN model and discrete-time ZNN models has been added to Section III. In addition, newly-cited references [40] through [42] in the revised manuscript are mentionede in Remark 1. Moreover, Remark 2 about the procedure of the combinede discrete-time ZNN-BFGS method/models for solving the time-varying quadratic-minimization problem has been added to S ection V.\n  As suggested by Referee 4, Figs.13 and 14 have been revised duly according to the format of Figs.1, 4, 5, 6 and 7. In addition, the formulations of the discrete-time ZNN, ZNN-BFGS and GNN models have been listed in Table 1 in Section VII.\n  Thirdly, with many thanks to the editors and referees, we would like to address their comments as follows. 【再次感谢，并分referee分别回答comments】\nResponse to Comment of (Assistant) Editor\nWe (the authors) sincerely thank the Assistant Editor for the constructive suggestions. As pointed out above, we have carefully addressed all comments of the referees and have imporved greatly the presentation and quality of the manuscript. So, also thank the referees for the comments. Moreover, we have read, checked and revised the whole manuscript carefully for many times.\nFinally, we would like to say thanks again sincerely to the editors and anonymous referees for their time and effort spent in handling our manuscrpt, as well as providing us many constructive comments for imporving very much the presentation and quality of this manuscript.\nAuthor\u0026rsquo;s ResponseDear Editor:\nWe would like to thank you and reviewers for providing valuable feedback on our paper. We have made all changes according to the comments and are resubmitting the attached revised manuscript, “Profitable Taxi Travel Route Recommendation based on Big Taxi Trajectory Data” (Ref. No.: T-ITS-18-04-0314) for consideration of publication in IEEE Transactions on Intelligent Transportation Systems.\nOur response letter is uploaded to the system, the attached letter presents our responses to the feedback and comments. The original comments are in italics, and our responses are in boldface following each comment. If you have any questions, please do not hesitate to contact us.\nSincerely,\nBoting Qu, Wenxin Yang, Ge Cui and Xin Wang\n","description":"","id":100,"section":"posts","tags":["review","论辩","论文"],"title":"论文审评论辩","uri":"https://www.xunhs.cyou/posts/notes/92/"},{"content":" 雅思考试。\n  2019.12.1 Threre are must somethings I can do for you. 2019.12.2 1) 下周一口语考试。 2) 有的时候总以为新的生活、新的环境、新的主题可以改变自己。其实不过是个借口。 2019.12.3 We don\u0026rsquo;t build the lives we want by saving time, we build the lives we want, and then time saves itself. 2019.12.4 MELANCHOLY 2019.12.5 I guess it\u0026rsquo;s ok. I mean, it\u0026rsquo;s not something I particularly enjoy doing it, but I also don\u0026rsquo;t mind doing that. 2019.12.6 Sadness is not a kind of good excuse. Be stronger! 2019.12.7 快乐的根本所在是保持欲望与能力的平衡。 2019.12.8 人生的每一次经历或许都是固定的，不然不会有之后发生的令人印象深刻的事情，不是么。 2019.12.9 口语考完了。虽然感觉结果没那么好，也没什么遗憾。我尽力了，而且我觉得水平之内，表现还好，希望考官给点表情分吧 2019.12.10 我可能是坏了眼睛，闭上眼仍常常看见你在这里打转，昨日重现。 2019.12.11 你的脖子好可爱，上面顶着一个猪脑袋。​​​ 2019.12.12 你的眼眸如星 回首是潇潇暮雨 2019.12.13 相见时难别亦难 东风无力百花残 2019.12.14 you have my word. 2019.12.15 总有些惊奇的际遇 比方说当我遇见你 2019.12.16 1)把我当做一棵树吧。2)美食与爱不可辜负。 2019.12.17 让你短暂快乐的东西通常会给你带来长期的痛苦。 2019.12.18 Mean Shift均值漂移 2019.12.19 误杀 2019.12.20 莫过于你不在我身边 我却感同身受 2019.12.21 记忆是相见的一种方式 2019.12.22 聚焦 2019.12.23 一直很安静 2019.12.24 Merry Christmas. 2019.12.25 1) 没有什么东西可以用来怀念你，怀念往日; 2) 虽然没过，总比缺席的好吧 2019.12.26 沉下心，慢慢来 2019.12.27 欢乐谷，过山车，跳楼机 2019.12.28 又做了一遍男爵的任务。最初是很抗拒做主线，把支线做完了，然后做主线，最后杀了树心，男爵没有死，安娜也没有死，男爵带着夫人去寻医。反反复复，想着随心在做一次任务吧，不想在纠结于谁该不该死的问题。二周目。遇到最纠结的任务\u0026mdash;-家家有本难念的经。 2019.12.29 你晓得的吧。有时候更多的是无话可说。 2019.12.30 二周目的巫师3，很多任务感觉做过，又感觉没做过。 2019.12.31 跨年，2019年结束了。   2019.12.31 跨年_校长讲话_弘雅堂\n","description":"","id":101,"section":"posts","tags":["口语考试","结束","巫师3","考试","欢乐谷","跨年"],"title":"2019-12","uri":"https://www.xunhs.cyou/posts/journals/100/"},{"content":" 雅思小作文，常用表述总结\n 开头描述 类型  chart/graph table  改写题目  the graph shows the changes in \u0026hellip; / the graph shows how \u0026hellip; changed/varied .  The charts shows the changes in the performance of boys and girls in different subjects in 1996 and 2002. The charts shows how the performance of boys and girls in different courses changed in 1996 and 2002. show的替换：the table shows/reveals/indicates/suggests sth.   The charts compare sb/ sth in terms of sth.   The chart compares five major cities in terms of the changes in the cost of an average house over a period of 13 years.   The chart presents/provides infromation/data about sth.  描述趋势 上升、增加 (increase/rise/climb)  sth (on average) increase twofold/threefold (in the past five years). , with the figure rising more than eight fold \u0026hellip; the percentage of sth more than double/tripe(d) (from 5% to 18% in 2002) The proportion increases sightly (稍微) to 25 units The amount of coal consumed climbs to 30% in 2030 Nuclear power consumption saw a steady increase to around 30% in 2005. the amount of sth increased significantly(明显增加) (from 20 to 36 in Australia).  下降、减少 (decrease/decline/drop)  the proportion of sth drop(ped) (from 40% to 34%) The proportion falls steeply (急剧) to 2 units there was a dramatic decline in the percentage of sth (from 28% to 5%). the figures for sth declined (in both countries to 2 units).  对比趋势/(两者)展现出的趋势  saw a different/same trend  (不同/相同的趋势)  The proportion of sth saw a different trend in these two countries, increasing sightly (稍微) to 25 units in France but falling steeply (急剧) to 2 units in Australia.   the gap between A and B widen/narrow   The gap between these two fuels is likely to widen. (差距逐渐扩大) The gap between these two proportions narrows as students get older. (差距逐渐缩小)    趋势稳定性  不稳定，波动  volatile (adj.)  The price was volatile, ranging from $20 to $40.   持平、不变，基本稳定  the percentage of sth did not change remarkably (16% in 2002 and 19% in 1982) remain stable at 30%  Other fuel sources are less significant.    描述数量 表述最值/重要性  adj.: important/primary/principal n. : consideration/cause/reason sth was the most important consideration (in both years) 最高 sth was the primary cause of sth. 最主要的因素 sth was the principal reason for sth in sw. 最主要的原因 sth had the largest proportion of sth (at 23%). (比例最大) sth had become the third most common reason for sth. 第三高 British\u0026rsquo;s crime rate peaked at 9% or so(左右) in 1999. The figure for women rose steadily and reached a peak of 53.3% for those aged 45-54, while the proportion of men fell to the lowest point at 39.5% for those aged 35-44.  比较、次级重要性  sth was much more/less important (in France)(比较重要、没那么重要)  描述占比  A and B were responsible for 30% and 28% of sth respectively, while the remaining 7% was attributed to sth. , with around 35% of sth, compared with 3.3% in Europe. , reaching 50% in 2030 (高达\u0026hellip;). the percentage of sth did not change remarkably (16% in 2002 and 19% in 1982) This age group will also make up with the largest proportion of Italy\u0026rsquo;s population in 2050. make up with a minor/major proportion of \u0026hellip;  只、仅仅、少量  sth were chosen by only 2% (and 3% respectively in this years)  常用总结  Overall, Australia and France relied on different fuel sources. While coal and hydro power were important in Australia, nuclear power dominated France\u0026rsquo;s energy sector. (总结两者重要性不同) Overall, sth was the main problem worldwide in terms of land degradation. Europe had a higher proportion of degraded land than other two areas.  基本句型 therebe  there was a dramatic decline in the percentage of sth (from 28% to 5%).  while  A and B were responsible for 30% and 28% of sth respectively, while the remaining 7% was attributed to sth.  比较级  Europe had a higher proportion of degraded land than other two areas.  一些名词 数据、数字  figure/data  the figures for sth declined (in both countries to 2 units). the figure for New York showed a similar pattern,\u0026hellip;    比例/百分比/占比  percentage  the percentage of sth more than double/tripe from 5% to 18% in 2002   proportion  The proportion (of sth) increases sightly to 25 units    时间表达  from 1990 to 2002 during a/the period of 13 years 一段时间 at the beginning of 前期 by the middle of 中期 by the end of 后期   年龄的表达  aged\u0026hellip;  people aged under 24 多少岁以下 people aged 30-39 / people aged between 30 and 39 多少岁之间 people aged over 50 多少岁以上   \u0026hellip;year-old  under-24-year-old people 30-39-year-old people over-50-year-old people   随着年龄的增长  with age(单数), \u0026hellip; as students get older    ","description":"","id":102,"section":"posts","tags":["雅思","作文"],"title":"图表类作文：描述性语句总结","uri":"https://www.xunhs.cyou/posts/notes/86/"},{"content":" 网上（知乎）摘录基础语法。\n   句子结构   学习词性/词类（英语单词根据在句中的功用，分为十大类）参考  名词 noun n. 形容词 adjective adj. 动词 verb v. 冠词 article art. 例如 a the 连词 conjunction conj. 例如 and  fanboys + and yet + and so 见下文从句.复合句部分 详解   代词 pronoun pron. 例如 you  人称代词：  主格：I我，you你，he他，she她，they他们， we我们 宾格：me我， you你， him他， her她， them他们， us我们    物主代词：   形容词性物主代词：my我的， his他的， your你的（your你们的）， their他们的， hers她的  名词词性物主代词：mine his yours hers theirs ours    指示代词： this这， that那， these这些， those 那些   反身代词：myself我自己， himself他自己， themselves他们自己， yourself你(们)自己，herself她自己    疑问代词：who谁， what什么， which哪个   不定代词：some一些， many许多， both两个、两个都， any许多   关系代词：which……的物， who……的人， that……的人或物， who谁， that引导定语从句  相互代词：each other 互相， one another互相  连接代词： who,whom,whose,what,which,whatever,whichever,whoever,whomever   替代词：one（单数），ones（复数）   副词 adverb adv. 数词 numeral num. 例如 three  基数词：基数词表示数量的多少。如 one,two,three,four…… 序数词：序数词表示排列的顺序。如 first---1st;second---2nd;　third-3rd; thirty-first---31st   介词 preposition prep. 例如 at 感叹词 interjection interj. 例如 oh   学习单句和从句  主/谓/宾  The emissions /from vehicles and planes /can cause /air pollution.   主/谓/宾/宾补  Modern technology /has allowed /rich people /to accumulate wealth more easily.   主/谓/间宾/直宾  Computer technology /gives /people /opportunities /to communicate with each other.   主/被动语态  Those serious offenders /should be sent to prison.   主/不及物动词  The tuition fee /has been rising.   主/系/表  Working long hours /has become /the norm in companies. She /is /lovely.   there be句型  There are /many job applicants /competing the limited positions. (\u0026lt;==Many job applicants are competing the limited positions)   it 充当形式主语或者宾语  It /would be /difficult /to create a happy, prosperous society.   状语从句  People in some countries /have to face /a long prison term /if they commit crimes.   名词性从句  Some people /argue /that harsh punishments can help deter crime.   定语从句 参考  在一个复合句中，跟在主句后修饰某一名词或代词（统称为先行词）的从句叫做定语从句(The Attributive Clause).被定语从句所修饰的词叫做先行词(Antecedent).定语从句通常跟在先行词之后,由关系词(Relatives)引出.因此,定语从句又可称为关系分句. 定语从句主要分为非限制性定语从句和限制性定语从句。 Tax reductions /are /beneficial to those /who live on a tight budget.        从句  问题澄清：何谓从句  从题⽬的正⽂可以看出来题主问的是名词性从句、形容词性从句（定语从句）、副词性从句（状语从句）三类复杂句从句，但是从句的概念不⽌如此。英语中的从句概念包括：  复合句（compound sentence），常称为并列句，指的是⽤连词连接多个简单句组成的句⼦。 复杂句（complex sentence），也称为从句、主从复合句，⽤代词、副词、连词把⼀个简单句作为另外⼀个简单句的从属成分的句⼦    两点说明  上⾯这两种是专业语法的说法，⽽⼀般我们说的复杂句其实指的是⽐较难⽐较复杂的句⼦，可能是简单句、复合句或者复合句。要学好语法，⾸先就要准确定义这些名词，不然会混，很多争论也是从此⽽来。  复合句和复杂句还可以融合为复合复杂句，也称为并列复杂句，不过理解了复合句和复杂句，就不⽤单独讨论.     总起：从句的⼀般结构  从上⾯的复合句和复杂句的定义就可以看出来，从句都是两个句⼦连接起来，代词、副词、连词，都笼统地称为引导词，所以从句的⼀般结构是：  简单句1 + 引导词 + 简单句2 关键点在引导词上，分述如下：  复合句的引导词：连词 复杂句的引导词：代词、副词、连词   根据引导词能够连接的句⼦的完整性（即完整句⼦与不完整句句⼦），引导词可以分为两类：  代词 + 不完整句⼦ 副词/连词 + 完整句⼦   从简单句2判断句子是否完整，从而判断引导词词性，通过引导词词性又可判断从句类型     复合句  复合句 = 简单句1 + 并列连词 + 简单句2 ⽽并列连词极其简单，即fanboys + and yet + and so，fanboys即下列连词的⾸字⺟缩写  for: I'd better take an umbrella, for it is going to rain. and: He is so handsome and the princess is willing to marry him. nor(也不): The city is not beautiful, nor is it clean. (这个城市不漂亮，也不干净) but: I like action movies but she doesnʼt like them. or: Take the chance, or you will regret. yet: She walked slowly into the hall and at once noticed that all the room doors were open, yet following her regular practice she had shut them before going out. (她慢慢地走进大厅，立刻注意到所有房间的门都打开了，但是在她经常练习之后，她在外出前关上了它们。) and yet: She walked slowly into the hall and at once noticed that all the room doors were open, and yet following her regular practice she had shut them before going out. so: It is hard for energetic, quick-minded people to waste time, so they are often tempted to finish a job before setting out to keep an appointment. (精力充沛，思维敏捷的人很难浪费时间，所以他们经常想在完成工作之前做好预约。) and so: It is hard for energetic, quick-minded people to waste time, and so they are often tempted to finish a job before setting out to keep an appointment.   三点说明：  and yet和and so是可以合并的两个连词，其他连词只能⽤⼀个（⽐如and or就不对，and but也不对，当然and/or另当别论。 and therefore、and thus等并不是连词合⽤，因为therefore/thus是副词，所以在and therefore+ 简单句2中，therefore只是副词做状语。 常⻅伪连词(副词)：  therefore however moreover/furthermore nonetheless/nevertheless (尽管如此)  Our defeat was expected but it is disappointing nevertheless. (我们的失败是意料中的事，尽管如此，还是令人失望。)   notwithstanding (虽然，尽管)  Notwithstanding some major financial problems, the school has had a successful year. (虽然有些重大的经费问题，这所学校一年来还是很成功。)   then   错误⽤法  句⼦1, however, 句⼦2. （注：你把副词放在中间，就分不清是修饰句子1还是句子2的了）    正确⽤法  句⼦1. However, 句⼦2. 句⼦1; however, 句⼦2. 句⼦1. 句⼦2第⼀部分, however, 句⼦2剩余部分. 句⼦1. 句⼦2, however.       复杂句  复杂句 = 主句 + 从句 = 简单句1 + 引导词 + 简单句2（划线部分即是从句） 复杂句分三类六种：  词性-从句(按词性)-典型成分-从句(按语法成分) 名词-名词性从句-主语-主语从句 名词-名词性从句-宾语-宾语从句 名词-名词性从句-表语-表语从句 名词-名词性从句-同位语-同位语从句 形容词-形容词性从句-定语-定语从句 副词-副词性从句-状语-状语从句   名词性从句  四类：  名词性从句-语法解释 主语从句-从句做主语 宾语从句/表语从句-从句做宾语/表语 同位语从句-跟在抽象名词后说明其具体内容   名词性从句的⼀般规律是分两类：  that/whether/if + 完整句⼦ 特殊疑问词的陈述语序   先讲主语/宾语/表语从句：  that/ whether/ if + 完整句⼦（注意这⾥的that是连词）  That you are right is a lie. I believe (that) you are right. It is not that you lied to me; it is that you do not regret it at all now. I donʼt know whether/ if he is trustworthy.   特殊疑问句的陈述语  what: What he wants to tell us is not clear. whatever: Whatever he does is not my concern. which: It is still unknown which team will win the match. whichever: I donʼt care whichever team will win the match. who: Who will win the match is still unknown. whoever: Whoever leaves the room last ought to turn off the lights. whom: I donʼt know whom he gave that ring to. whomever: I donʼt care whomever he gave that ring to.  where: Where the English evening will be held has not yet been announced. wherever: Wherever the English evening will be held is not my business. when: I hate it when they speak with their mouths full of food.（it是形式宾语) whenever: Whenever they speak with their mouths full of food is a pain for me. whose: Please tell me whose umbrella this is. whosever: Whosever umbrella this is is not my business.  how: It is known to us how he became a writer. however: However he became a writer is his own secret.  why: I still donʼt understand why he chose to betray me.     再讲同位语从句  同位语从句 = 抽象名词 + 主/宾/表从句 =抽象名词 + 引导词 + 同位句 抽象名词概括同位句，同位句解释抽象名词 抽象名词：fact/ idea/ news/ information/ order/ belief/ advice/ suggestion 引导词that（注意这⾥的that是连词）  The girls were surprised at the fact that ocean ships can sail up the Great Lakes. The idea that you can do this work well without thinking is quite wrong. There was a suggestion that Brown should be dropped from the team. He grabbed his suitcase and gave the impression that he was boarding the Tokyo plane.(他抓起他的手提箱，给人的印象是，他登上飞往东京的飞机。) The thought came to him that maybe the enemy had fled the city.   引导词whether  The question whether we should call in a specialist was answered by the family doctor.   特殊疑问词引导词what/ who/ whom/ whose/ when/ where/ how/ why  I have no idea what size she wears. The question who will take his place is still not clear. We havenʼt yet settled the question where we are going to spend our summer vacation.       形容词性从句  即定语从句，引导词在国内的语法教育中常称为关系词，分两类：关系代词和关系副词 关系代词that/ which/ who/ whom/ whose + 不完整句⼦  Itʼs the only one that Iʼve left. (这是我剩下的唯一一件东西) He is the man whom/that I saw yesterday. Is he the man who/that wants to see you? They rushed over to help the man whose car had broken down.    关系副词when/ where/ why + 完整句⼦  There are occasions when (on which) one must yield. Beijing is the place where (in which) I was born. Is this the reason why (for which) he refused our offer?   限定性与非限定性定语从句  限定性定语从句: 限定修饰，删除后意思变化较大； 非限定性定语从句：有逗号，补充说明 These courses are not approprite for children, who have learning difficulties. (非限定，意味着世界上的小孩都有学习困难。) These courses are not approprite for children who have learning difficulties.(这些课程不适合那些学习困难的小孩。)     副词性从句  即状语从句，状语从句的引导词只有副词和连词，所以只能引导完整句⼦，⼀般按意义分为9类  时间：When the dry desert ends, the green grass grows. (当干燥的沙漠结束时，绿草生长。) 地点：Where there is a will, there is a way. 原因：Collecting provides relaxation for leisure hours, as just looking at oneʼs treasures is always a joy. ⽬的：Such a plan should be carried out so that the goal of education could be better met.（注意这⾥的that是连词） 结果：Youth is so wonderful that it is a crime to waste it.（注意这⾥的that是连词）  条件: If the economy still develops at present way, the environment will be getting worse and worse. 让步：Although advertisements are never without disadvantages, their advantages carry more weight. ⽐较：The more we study, the better we understand life. (The + ⽐较级…, the + ⽐较级…)  ⽅式：If we cannot do as we would, we must do as we can.       结论  去除上⾯所有的例⼦，可以看得出来从句，不论是复合句还是复杂句都是极其简单的，不过本⼈也是在英语专业的三年级才完全理解透彻，之前总是被⽼师给讲晕了，所以⼀个好⽼师是多么重要啊，⽐如我（hahah）。结论如下：  从句 = 复合句/复杂句 主句 + 从句 = 简单句1做主句 + 引导词 + 简单句2（划线部分即从句） 复合句 = 简单句1 + 并列连词 + 简单句2  并列连词只有七个：fanboys，and yet、and so可以合⽤   复杂句 = 简单句1 + 引导词 + 简单句2  代词引导词 + 不完整句⼦ 副词/连词引导词 + 完整句⼦   名词性从句有两类：  that/whether/if + 完整句⼦ 特殊疑问词的陈述语⽓   形容词性从句有两类：  关系代词 + 不完整句⼦ 关系副词 + 完整句⼦   状语从句只有⼀类：副词/连词 + 完整句⼦      比较级   ","description":"","id":103,"section":"posts","tags":["语法"],"title":"Grammar Learning","uri":"https://www.xunhs.cyou/posts/notes/80/"},{"content":" 2019年，夏末秋初，写给天空\n献给怀抱梦想的我们\n ","description":"","id":104,"section":"posts","tags":["相册","天空"],"title":"写给天空的情书","uri":"https://www.xunhs.cyou/posts/journals/85/"},{"content":" 参考顾家北雅思作文写作，对大作文中常用表达进行整理。\n 骨架 论述类   discuss both views and give your own opinion\n  第一段：\n 第一句：改写题目 第二句：表明自己的观点：I would argue that it would have an adverse/desirable impact on sth.    第二段：\n 第一句：Some people are strong advocates of sth because sth. 第二句：解释 第三句：举例，for example    第三段：\n Opponents, however, argue that sth. 第二句：解释 第三句：举例，for example    第四段：\n In my view, sth. 第二句：解释 第三句：举例，for example    报告类   Why has this happened and how to address this issue?\n  第一段\n 第一句：改写题目 第二句：It is important to understand why this () has developed and how to reverse this trend.    第二段\n 第一句：第一个原因 解释 举例    第三段\n 第一句: Another reason is that (people lack environmental awareness)(人们缺乏**的意识)（想不出来可以作为原因） 解释 举例    第四段\n As + sth is pervasive (\u0026hellip;的问题是广泛的), it is important to take some measures to mitigate this problem. The first one is to raise environmental awareness, educating people to change the ways (\u0026hellip;)(增强意识，对应上文提到的意识问题). Governments can also enforce some laws to deter people from doing sth/encourage people to do sth(立法角度). + (最好举一个例子)    第五段\n To summarise，+ 问题 + 方法(两句话)    积极作用类 （Positive）   提高社会技能，以后有更多的人脉可用\n improve social skills, they also have more personal resources to draw up in the future    提高人际交往能力和工作能力\n improve their interpersonal skills and job skills    提高自己的素质\n develop some positive qualities    提高他们的信心和解决问题的能力\n boost their confidence and improve their problem-solving abilities    提高人们的工作前景\n improve people\u0026rsquo;s job prospects (通常用复数)    提高人们的生活水平（人们生活更好）\n improve people\u0026rsquo;s living standards    提高（增加）他们的收入（因此他们可以购买大量的产品/提高购买力）\n increase their income/wealth, and can afford many products    开拓人的思维，提高人的思辨能力\n broaden people\u0026rsquo;s minds and improve critical thinking skills    增加知识，开阔视野\n expand knowledge and broaden horizons (knowledge为单数，horizons为复数)    增加对不同国家的了解，获得更多就业机会\n have a better understanding of (these countries) and explore more career opportunities    人们可以更加健康，医疗系统的压力会减少\n improve the well-being of people and ease the pressure on the medical system    人们可以过更好的生活，也可以获得成就感\n improve their living standards and gain a sense of accomplishment    为家人提供一个相互交流、相互理解的机会\n provide family members with opportunities to communicate with each other and improve mutual understanding    有助于我们建立起一个关系紧密的社会\n it can help create a closely-knit community    创造一个大家可以和谐生活的社会\n create a society where people can live in harmony    有利于社会发展\n contribute to social progress    接触艺术让我们减少压力，也会让我们心情更好。\n Exposure to artworks can reduce our pressure and put us in a good mood.    减少（航空业的）环境影响\n can help reduce the environmental impact of (the airline industry)    噪声污染、环境破坏会得到改善\n problems (related to sth), including noise pollution and the environmental destruction (caused by sth), will also be mitigated.    减少（空航）产生的环境压力\n make effort to reduce the strain of (the whole industry) on the environment    让我们的生活方式更加环保\n make our lifestyles more sustainable    增加对不同科目的了解\n allow them to gain an insight into different subjects    成为某个行业的专业人士（精通/熟悉某个行业的专业知识）\n build expertise in their majors    摆脱贫困\n break the cycle of poverty    减少贫富差距，建立一个公平的社会\n close the gap between haves and have-nots and help build a fair society    负面作用类 （Negative）   约束个人自由\n restrict our freedom    限制（某人的）想象力\n stifle (/ˈstaɪfl/) one\u0026rsquo;s creativitiy and not able to solve problems in different ways    人们如果不遵守道德准则和社会规范，人和人之间就会缺乏尊重和信任\n If people do not follow moral principles and conform to social norms, they will not be able to develop a respectful and trusting relationship.    影响他们的学习（成绩），而不是提升他们的成绩\n have an adverse impact on their grades, rather than improve their academic performance    对于以后对家庭生活的态度有影响\n affect their attitude towards family life    不仅威胁人们的健康， 也会破坏饮食文化和社会关系\n not only pose a threat to people\u0026rsquo;s health but also to our cuisine culture and social relationships    社会将没有秩序，经济很难发展\n a country would be in chaos and the economy would collapse    交通事故就会增加，交通堵塞也会成为问题\n traffic accidents will increase and traffic congestion will become a problem    经济将会受到影响\n a country will suffer economically    社会将会缺乏凝聚力\n social cohesion ( /koʊˈhiːʒn/ ) will be under threat.    影响/减少生产力\n reduce productivity    （甚至）阻碍社会发展\n even hinder social progress    导致能源消耗，产生垃圾污染\n lead to energy consumption and cause waste as well as pollution    对环境会有很大的伤害\n have a destructive effect on the environment    影响公司的效率和盈利\n influence companies' productivity and profitability    影响经济\n have an adverse effect on the economic development    行为类 （Behaviour）  懂得尊重老师，和同学和睦相处  learn how to respect teachers and get along well with classmates   规范人们的行为  regulate people\u0026rsquo;s behaviour (一般用单数)   发现商机，赚取利润  discover business opportunities and earn profits   去城市上学和找工作  go to the cities in search of educational and employment opportunities   犯罪 v  commit crimes   缺少/提高环境意识  lack/raise environmental awareness   传播（关于\u0026hellip;的）知识  disseminate the knowledge of (how to \u0026hellip;)   颁布法律（去抑制\u0026hellip;的行为）  enforce some laws to deter (people) from \u0026hellip;   改变生活方式  change their lifestyles   表达想法，理解别人的话  express their views and understand the thoughts of other people   应对\u0026hellip;加以限制，而不是鼓励  should impose restriction on sth, rather than endorse this habit   被低估  undervalue   充分利用  make good use of sth   对他们的行为负责，从小塑造好的行为  hold sb. accountable for behaviour and help them develop good behaviour patterns   在职业生涯中获得成功  achieve success in their careers   保持良好的关系  maintain a good relationship with sb./governments   知道/了解家人的近况  keep up to date with family issues/news   与朋友合租（公寓）  share a flat with friends   很好的应对工作上的事情  can handle many matters easily in the workplace   将事情打理得井井有条  keep everything organized   入狱，出狱，再犯罪  sentence to prison, release, reoffend   提供教育和技能培训来提高犯罪人员的个人技能和工作能力  provide educational opportunities and vocational training for them, improving their interpersonal skills and job skills   一起做生意，讨论怎样开公司，怎样进口产品  conduct business together, discusss how to operate a company and import products   分享知识和想法，甚至一起合作去做（完成）项目  share knowledge and ideas or even cooperate to complete projects in different areas   用积极的眼光去看待  sth can be viewed in a postive light    现象类 （Phenomenon）  人们现在都很忙，压力很大，特别那些生活在大城市的打工族  Many people, especially working people living in large cities, lead a hectic life and feel stressed   城市人口比较密集，工作机会比较多，人们可以获得较高的收入  Cities are more densely populated and there are more job opportunities available, so people may earn more money.   这是一个令人担心的趋势 （可做从句来修饰）  This is a worrying trend.   了解这个问题为什么发生和如何解决这个问题是重要的。  It is important to understand why this issue (具体的问题) has developed and how to reverse this trend.   人数增加  the number of (senior workers) increases    常用关键词/短语 （Key Words）   技术革新/创新\n technological innovations    文化多样性\n cultural diversity(单数)    家用电器\n household/home appliances    （学科的）概念和原则\n concepts and principles    能力/技能\n abilities  吸收信息和处理工作的能力 the ability to absorb information and complete work 解决问题的能力 problem-solving abilities   skills  生活技能 (做家务，理财，与舍友相处) life skills (doing housekeeping, managing finances and getting along with flatmates) 交际能力和工作能力 interpersonal skills and job skills 思辨能力 critical thinking skills      面对（\u0026hellip;问题）\n in the face of (problems)    社会关系网\n social network (where we can receive information, share ideas and gain access to resources)    是至关重要的\n play a vital role in be vitally important (to sth)    各种活动 (去健身，听讲座，兼职)\n a great variety of activities (going to gym, attending lectures and doing part-time jobs)    罪犯\n offenders criminals those who commit crimes    熟练，精通\n master (通用，熟悉) build expertise in （专业精通）    常用连接词/短语 （Conjunction）   表引言\n in general (通常)(不要用generally speaking，非书面语表达) in most cases    表结果，因此\n , so + \u0026hellip; and therefore + \u0026hellip; , thereby + ing \u0026hellip; , and this is why + \u0026hellip;    引起并列的观点\n 此外  moreover, + \u0026hellip; (适合放在段落中间，连接两个例子) in addition, + \u0026hellip; (适合放在段落前表示“此外，另外”的意思)   同时  , while + \u0026hellip;      观点排列\n firstly/first of all secondly thirdly    转折\n however in/by contrast （相反的是） meanwhile (然而) 尽管 （语法糖）  although/even though + （a subject and a verb） despite/ in spite of + (a noun, gerund (-ing form of a verb) or a pronoun)      举例\n for example for instance    形容人 （All kinds of folks）  有野心的、精力充沛的、勤奋的和有创造力的年轻人  young people who are ambitious, energetic, hardworking and creative   一个乐观、勤奋、积极、善于与人交往的人  an optimistic, hardworking and sociable person   患有肥胖症的人  people who suffer from obesity   理智的人  a rational person   犯轻微罪行的人  those who commit minor crimes   遵纪守法的公民  law-abiding citizens    替换词   bad\n dreadful adverse    people\n folks individuals    many\n a host of    some\n quite a few    in my view\n from my own perspective    more and more\n increasing(ly)    helpful\n beneficial rewarding    necessary\n indispensable    important\n crucial    cause\n give rise to lead to result in    pay attention to\n pour attention into    poor\n underdeveloped    show\n demonstrate manifest    dangerous\n hazardous    difficult\n formidable    ","description":"","id":105,"section":"posts","tags":["作文","雅思"],"title":"English Writing 常用表达整理","uri":"https://www.xunhs.cyou/posts/notes/81/"},{"content":" Better than nothing.\n  2019.11.1 不是所有的鱼都会生活在同一片海里。 2019.11.2 知耻而后勇。 2019.11.3 万事开头难。 2019.11.4 1）口腔溃疡，张口就疼。2）“我感觉没有以前快乐了。” 2019.11.5 1）今天终于把二修提交了。希望论文接下来可以顺利一些。2）有的人开心，有的人会失落。但是当知道身边的人有开心的事情时，我也会有些欣慰。证明开心是会传染的。 2019.11.6 1）你喜欢的，和大多数人喜欢的，还是有很多差距的。这可能是很多人收敛的原因吧。毕竟不表露，就不会展现差距，也就少有矛盾、不解和反驳。2）看作文解析，他（顾家北）讲的一些思路着实很有启发性。 原文：解决（文章跳跃）问题的两个方法：多想原因，培养批判性思维；多思考结果，思考某件事对我们有什么影响。 看暴力电影=\u0026gt;年轻人会模仿，会便暴力。那么，为什么年轻人会模仿？（Why）是不是大多数人都会模仿？（Who）年轻人如何模仿？（How） 年轻人模仿的原因可能是电影里面的暴力往往是一些明星角色实施的，所以年轻人可能觉得暴力是魅力的表现，而电影里面的暴力也是解决问题的一种手段，年轻人以为通过暴力也可以解决生活中的问题。3）I heard,I study,I know,I come,I explore,I see,I think, I understand, I love. 2019.11.7 夜曲。 2019.11.8 但行好事，莫问前程。 2019.11.9 期刊中了，开心的不得了。 2019.11.10 成熟不就是学会成全。 2019.11.11 磨刀不误砍柴工。 2019.11.12 大家都在努力，而你却总是比别人先感觉累。还是基础不好啊。 2019.11.13 总之，你努力就好啦，剩下的交给时间，原来有很多人在帮你。 2019.11.14 我喜欢夏天的雨，雨后的光，和任何时候的你。 2019.11.15 1) 没有人送可以用来装点; 2) 好久没有听后摇了。听听后摇给自己镇定剂。 2019.11.16 做不到全力以赴。 2019.11.17 妖风啊 真是妖风 2019.11.18 满怀期待，却又怯步不前 2019.11.19 相逢何必曾相识。 2019.11.20 我野蛮生长没能成为自己的月亮 能遇见你 是银河赠我的糖 天上有行云 人在芸阁里 欸乃一声山水绿 他们说 青山是否妩媚 还需看青山是谁 可我摇头 我见众生皆草木 唯你灼灼是青山 2019.11.21 简单点 2019.11.22 1) 你必须为你的懒惰负责。 2) 留学最大的意义，不是看千帆览万物，而是在路上发现事事未必如你意，人人未必如你想，于是开始学会接受和享受挫折及不确定性。心境于是豁然，心胸于是开阔，于是开始放下纠结与偏执，找到一个随遇而安的自己，然后带着一个崭新的自己回到那个熟悉的家。 2019.11.23 1) 幻听。 2) Better than nothing~ 2019.11.24 1）解决问题，最重要的是要去思考布局，如何改变现在和未来。过去式无法改变的，无论你乐观也好，悲观也好，愤怒也好，小陈也好，无论你做或者不做任何事情，过去都是无法改变的。2）妖风又来了，而且越演越烈了。3）越想越急，越急越消极。这些都没有，每天进步一些，坚持住，会好的。 2019.11.25 昨天因为还有几天就要口语测试而焦虑的睡不着觉。今天又听section2听力错误率飙升而感到无药可救。我觉得我可以放弃雅思了。不好意思，我刚才想打IELTS的，但是我忘记怎么拼写了。 2019.11.26 成熟的人一个标志就是放弃改变别人，转而改变自己，这个改变不是让自己变得没有原则，不是让自己谁都喜欢，更不是让自己成为一个人云亦云的人。而是要放弃改变别人的幻想，专注于自己的进步，专注于自己的学业或事业，当你自己更强大的时候，你会吸引到更优秀的人，别人为了和你在一起会自己改变自己，不用你再去改变了 2019.11.27 不要焦虑啊，不管时间有多紧急。就算是明天考试，做好今天就好了。每天都有一点进步，过得充实即可。 2019.11.28 休对故人思故国，且将新火试新茶。诗酒趁年华。——苏轼 2019.11.29 今天真的是百般不想看英语。 2019.11.30 海底捞。闹肚子。卡宾+中国航天联名羽绒服  ","description":"","id":106,"section":"posts","tags":["过程","IELTS"],"title":"2019-11","uri":"https://www.xunhs.cyou/posts/journals/101/"},{"content":" 摘抄自-热带汽水·新浪微博\n   天空不再落下雨水，眼泪通过空气传播，无论爱不爱惜羽毛，鸟儿都飞不出包围圈。我想你我想见你，但我力不能及。我可以为你攻占一个无线电台，我可以为你捏造明日的天晴，但我没法停止你的哭泣。天空不再落下雨水，地面只被泪水打湿。听说明天会更好，我听到有人哭着这么播报。 ​​​ ​​​​ 以为人类孜孜不倦钻研科技，延展手臂，是用来探索未知的星球。偶然又会惊醒，觉得这只不过是用来克服自己的不完美。 ​​​​ 我们搁浅在旋转木马的台阶上，夜游场的霓虹下，欢快而不知所谓的广播里，苏打水甜甜的气泡拥簇我们上天，威士忌的木桶香流连在你的唇边，愚蠢的酒鬼通过酒精暂时回魂人间。 从来没有喜欢过你，从未执迷于你的手心，没有要同你数尽星星的决心，更不提那种要和你共一场台风的迷情。没有幻想过和你锅碗瓢盆的声音，没有期待过你赖床不起的风情。没有你的时候，我充沛鲜艳，从未因你枯萎，从未梦念你名字，时至今日，我从未爱你。 -至愚人节 天空不再落下雨水，眼泪通过空气传播，无论爱不爱惜羽毛，鸟儿都飞不出包围圈。我想你我想见你，但我力不能及。我可以为你攻占一个无线电台，我可以为你捏造明日的天晴，但我没法停止你的哭泣。天空不再落下雨水，地面只被泪水打湿。听说明天会更好，我听到有人哭着这么播报。 ​ 其实我是个反圣诞情结的人，圣诞帽或者圣诞树，我全都没拥有过，只有门店里“全场五折全场五折”的喇叭声音，配上一首Jingle bells 向我兜售廉价的节日气息。我的朋友猴哥燕姐无疑加重了我这种情结，如果圣诞是一场电影，他们就是根本不关心电影内容的观影情侣，我则扮演在他们中间，阻碍他们接吻的爆米花，但他们偏偏要点我，次次都点我。以至于常去的酒吧的老板，都管我们这个团体叫做“一家三口”。“现在你们都已经长大了”我呷了一口酒“圣诞节能不能放你们爸爸一天假”。听到这种话，别的朋友又起哄，说明明我才是儿子，但他俩这对狗男女就只顾着笑，往杯里注酒。于是我决定今天还是再留一下，留给这些纵容我的兄弟朋友们。毕竟圣诞对我意义实在寡淡，我没有在槲寄生下接过吻，没有去过捷克，没见过女孩把鞋子抛到空中，期待嫁给谁。我没有满心期待地拆过圣诞礼物，也没有心仪的苹果在这天打来电话，说要陪我过。无人与共的圣诞，我也决定再留大家一下。我突然想起圣诞陪大家的最后一支烟，那个和大家挤在屋檐下，分着抽的最后一支烟。烟头复暗复亮，好像一颗特别的红星星，然后我们一齐抬头看，发现得天上的星星分开得太寂寞，甚至不如我们手中的这一颗。我也打算再等你一下，我会多劝劝这些节日，让凝结的圣诞等你一下，绽放的新年等你一下，早开的春等你一下，让我有机会同你一起看花，狂热的夏等你一下，我才能去超市陪挑一只西瓜。寡情的歌休唱，期望2019的圣诞能晚点打烊，给我你的暗号，让我可以和你一起参与圣诞后夜场。其实，我最后明白了，我没那么讨厌节日，我只是讨厌没有你。 巧克力会变甜，啤酒也会变得清爽起来。潮汐不会，潮汐不在乎你，它是反复着，掳走一部分你又还给你。没谁是无情的动物，我们都是感性的多米诺牌，跌倒了自己爬不起来。浪花笑浪子多情，每每撞死在岸，学不懂大海。 回忆是一种主观的呈现。当然，我不是说真实存在的楼宇，街道，或是你常去的那家便利店会在回忆里消失，我是说，在回忆中的评价都充满偏见，好吵的街道也会因为身边的人变得具有烟火味，难饮的酒水，现在想起来竟然会想再饮一遍。我不认为这是一种欺骗，反而会觉得这是人类仅有的，可作用于自己回忆的魔法。『我觉得这段记忆值得一片镀金的晚霞』。于是，即便是星星满落的午夜，太阳也重新上班，洒落金光。我没有更多的奢侈念头，只是想让你在想起我的时候，觉得记忆里寡情的云朵也和棉花糖一般很美味。 是你把色彩打在了我的眼眸，也是你把飓风种在了我的心腔，是你定义了我仲夏夜的味道，让它永远附着上你的香。也是你，只有你能消祛我的心慌，这就像我家楼下的便利店招牌灯，胜过了东升西沉的日月，二十四小时，你都在我的世界里发亮。 侥幸获得一个午夜，才发现窗外有红色的光，时间变安静，只剩下空调叹息和月亮穿过云朵的声音。没有信仰的人；忘记理想的人；忘点香烟的人和失去酒量的人，在这个场景下，被揉成一个人，一个突然想起你的人。 我想你，想和你赤裸的拥抱在一起，感受彼此心率和呼吸，飞向黑夜边际。我想缠绕着你蔓生于你，不留下一丝毫的空隙，和你一起翱翔从山巅到谷底，探索那些不为人知的秘密，像正要开花的枝桠和初生的羽翼。残烛解衣，浅迎深递，巫山云雨，在你的身体里撞击出无数个自己，然后一起面红耳赤的娇喘呼吸。 衰老有一种终极意义上的好处，我不必再『什么都要了』。卸下长高的使命，不再逼自己喝什么牛奶，而有关宇航员的梦，和MJ的月球漫步，我可以选择性地留给不近视的孩子以及四肢协调的朋友。同时我也不必那么想你了，虽然仍寄送出了大量的爱，但不再那么强求它们回来，我仍旧每天搜查邮箱，但那只是习惯，我开始把风归还给风，把大海归还给大海，把自己归还给空无一人的山峦。 不要慌，我们有很多应对方法。如果打碎玻璃杯，放心，橱柜里有备用的很多只。如果弄糟一场考试，我们可以少睡一些，然后等待下次。就算是感冒发烧心情多云，别急，医院有药，人间有酒。搭配出组合拳一套，这是很多事的解决之道。但如果突然想你，这件事，我暂时还没有找到办法。 今天下班，不想那么快回家，办公室窗口点根烟看楼下的行车道。大批量的轮胎碾过水泥路，不知道他们要去哪里。理论上，这条路的尽头是大海，可大海的尽头是哪里呢？尽头的尽头又是哪里呢？如果这只是一场折返的行程，我们最后又会去哪里呢。可能我哪里都没有去，我只是在油表告警之前等待下一个加油站。早晚高峰将人类包围，谷中的居民不知四季，不晓得世上有海，没有望见过山下的灌木草皮，因此也算不得登过山。 吃了凉风，感冒三日。躺在床上噩梦接踵造访。我再次想起那个金色的午后，短暂地休憩，梅子的汁水滴在我的脸上，树叶把风拦停，鸽子在我胸口打转，一千万只羽毛喷射而出，又全悬停在我心上。来不及开口，有关你的念头，被修饰了成了浅睡的梦呓，喝多的絮语，放空时的眉角。我全然已把时间忘记，但回头，又好似它从来没走。 总有一天飞船会登陆火星，电磁波能运输思念，爱可以被观测被斗量，变成医生手中的处方药。在这一天来临之前，科学的信徒永远都没法证明人类已经在错误的方向进化得太久。只是任手中的小玫瑰反复枯萎，寄情下一个宇宙。 最近发现我的记忆力开始显著消退。消退得幅度之大，一度让我以为我以前的记忆力是一种超能力。我开始只能过一些概括性的生活，过去的几个月变得像老旧的胶片，充斥着光影，迷离以及不确定性，翻动他们的时候，像是在拧一只罐头。我开始写一些日记，照着卡夫卡那个套路写，结果现在看来，更像是失去语言能力的菲茨杰拉德，只剩酒精。可怜的是，即便是酒精，我也记不太清了，医院倒是给了我一份脂肪肝报告，证明我的肝脏甚至比我记得更清。喝多了，喝多的次数太多了，喝多了总觉得不是我自己失忆，是我在搞一个自我的定期记忆清除，免得对未来失去兴趣。 我把家搬到了滨海大道，阳光过剩，不得不沿途派发。有次我出门没帽子，一下午给我烫得脸红，像是为我的大意轻敌而羞愧。海风也很皮，不带来降温也不带来风情，只是一个劲呼呼呼呼。我每次抽烟要屏息听风，发现它有些力竭的时候，趁它不注意，猛火烧烟。除此之外，唯一的困扰是分不清椰子和棕榈树。 假如照相这件事，没有存在过世界上。景点附近都是20一张的现场速写画家。Ins风变成一种花体的手写信件，投递所有订阅你的观众。你失恋后，不再会有翻看相册突然难过的时候，除非你把你的一生临摹，做成画廊供游人徜徉。但若是有天你不小心忘了，也不再会有一张照片停留在故事发生的那天不肯走，替你一直记得。 湿垃圾箱里躺着一束鲜花，真情卡片被丢在了可回收物里，一同被谢绝的心算是什么垃圾，算了，朋友，投递不至的爱我们都有毒有害，咱们走吧，谁会为垃圾分类伤心。 终日与你伴游，折返在门口小公园，后山乱径，冷气不足的电影院之间。那时候不晓得冰岛除了冰块还有耐寒松柏，不知道夏季的烟火大会的存在，世界被我看得很小，你说你想去卡萨布兰卡，我说请带我走，那时我开始相信人会失去旅行的概念，置万物于不顾，只想始终伴在你的身边，把这当作唯一宇宙。 ​​​​ 有时候我还是愿意相信人类头顶上是有神的，横亘着带有恶意的神，这样想的话，难熬的分分秒秒和突如其来的破事我都可以怪罪给命运的捉弄与玩笑。最怕的是这一切都是随机，混沌，无序的，没有神惩罚你，没有人在乎你，人只是本能地坠落。 ​​​​ 你听好了，从今天起，我俩要做绝命的偷猎者，不稀罕冰川企鹅，瞧不起沙漠骆驼；拳打奥特曼，脚踢小怪兽，点燃仅有的夜色，照亮你我一无所有，除了你的温柔。让我们勾肩搭背，在午夜空旷的泳池啤酒烧烤，称王称霸。夏风吹来，你的发梢在我心波回转，打结。此时，地球空有五亿平方千米，不如你我此时一隅一步。 期待衰老，期待自我接受，期待荷尔蒙下降，期待不用再讲我怎么梦见谁，期待远山星辰和宇宙，我啥都尝试过不少，掐指一算我命中犯年少，现在一心寄情万能的时间，期待它骟了我，赤条条应该会自在不少。 ​​​ 假如、如果、会不会，这样的虚拟语气永远让人想掉头发。考虑了一下，假如世界上酒精都被禁止，如果月光和你都不再救我，我仍会留在这里。就算明天你要早起离去，我也会留在这里。就算戒断反应情不自禁，我也会留在这里。即使没有酒精和月亮，我也可以万丈霞光地留在这里，清醒地留在这里。 ​​​​ 世间万般美好予我皆不配。我不配出现在易于保留的影像里，不配被归纳到他人口中的未来里。我是前奏里的一个音，渡口上的一段木，送你一程送你一程，我永远在你不回头的景色里，永远不等你。 ​ 睡了一天被雨声挠醒，忘关的音响还在绵绵唱一支情歌，欢迎来到一个四下无人的周天夜晚，没有恼人的嘈杂，也没有冰块在杯中碎裂的声音，反倒清醒，反倒专情。世界是很吵没错，可但凡有一个这样无人打搅的夜晚，就能轻易地发现，你始终被我挂在心头。 ​​​​ 越是乱了方寸越是要不动声色。 ​​​​ 春有狂花秋有月，冷风几度入冬雪，只有夏天，夏天是爱人的庆典，夏天是少女的祭祀，夏天从你裸露的锁骨和洁白的脚踝入场。我没有花月风雪，唯有让棕榈阳伞为你暂借荫凉，睡莲臂弯伴你一夜好眠，我一介凡人庸人无用之人，为了你，三两杯浊酒下肚，也想试试那些所谓的不可能，不二不重来的夏天。 有没有可能每个人都是一家餐厅，从前有个不长眼的客人是在晚上七点一刻推门进来，坐在左手第一桌，点一杯大都会，她昨天来今天来天天来。你就在心里帮她把这个位置留出来，音响被她中意的歌慢慢填满，灯光和眼光都偏心地打向她，整晚整晚。直到有天她不再来了，但你的餐厅还是要开，也会歌舞升平，也会有了更多新的夜晚，新的客人。但这并不妨碍你永远把那张桌子空出来，也并不妨碍你在打烊的时候，在擦拭音响的时候，期待背后忽然传来声音，喊你点一杯大都会配她最爱的老歌。 如果躺在床上却不睡，那这段时间会像是从谁手里抢过来的似的。白天的正事和楼下汽车鸣笛声一齐渐变渐灭，夜晚像个今朝有酒今朝醉的酗酒者，鼓吹末世理论，『假如太阳不再升起』『假如今晚会无限延长』。我开始一场不作期限的漂浮，不带期许的被碰撞，飞进异国他乡的地窖里，或是被锁回十七岁的某个教室里，壁橱里爬满被倾空的酒瓶，一些字句从我心里跑出来，现在又躺在地上，鲜有问津。如果今晚就是最后一晚，我会把这些东西一一赎回，然后做一只粒子，一只不晓得自己会飞向何处的微小粒子，不再留下口讯，不再等谁。 白天落了一场雨，不知道深圳湾公园是否仍旧挤满了人，斯里兰卡前些日子爆炸，他们是否仍旧有悲歌啜泣。世界怎么与我无关，我怎么只想驾驶一颗流星，来换你惊呼一下，那你现在在哪里？怎么我还留在这空无一人的房间抽烟。 夏天难免让人想逃。趁着夏风北上，夜晚会变短浅，如你淡淡的眉梢，仲夏夜删去溽热，删去虫鸣，留下飞鸟扑棱翅膀后丰满的羽毛，轻拿轻放。但这也没有什么两样，盛夏永远在我脑内礼花齐放，喷泉沾染霓虹，人影憧憧，我反复背诵第一见你时的对白，时间嗡嗡作响，酒瓶哐哐哐哐。 ​ 溽暑难消，太阳百无聊赖被人吊死在天空，等待一个月亮来救。医生说我没有病，只是不该一个人呆太久，我对症服下一些酒精，打开手机，夜晚童叟无欺，将在19:47降临，可我晓得那不是我的月亮，今天的我仍旧被悬在天上，双脚悬空，枯等一个你月光返照。 ​​​ 人类每时每刻都在老去，而迟钝的城市相对于我们几乎是静止的。穿过不老的街区，去到异国永恒的喷泉，绕了一大圈，回到十七岁的那条街，现在还是叫做台北路。后来我也去到一些陌生的城市，每每想到你也曾在这条路上走过，忽然就对这条道路亲切起来，不知道你能不能明白，这种感觉就像一只猫，当我想念你的时候，就把被你抚摸过的毛，细吻一遍。 其实也没有那么喜欢酒，我是不成瘾的体质。我只是爱好虚幻，沉湎于不真实，太空漂浮的爱好者，地球母亲重力的弃儿。酒精给我的，像是无情无尽的暗淡宇宙，漫无目的的漂流，直到你是唯一的飞船。 过了很久后，我才后知后觉，记忆中淡金色的旧日子是不是不会再来了。而我喜欢上你的那天，空中出现了绯红色的晚霞。晚霞太多了，但这种程度红，我再也没有见过。没有什么东西可以用来怀念你，怀念往日，把你供上神龛，献上专属的色度。我可能是坏了眼睛，闭上眼仍常常看见你在这里打转，昨日重现。 ​​​ ​​​​  ","description":"","id":107,"section":"posts","tags":["摘抄","热带汽水"],"title":"热带汽水","uri":"https://www.xunhs.cyou/posts/journals/88/"},{"content":" 本来无一物，何处惹尘埃。\n   2019.10.22 想想两个人都变了，大概也是件难过的事，之后吃顿饭看个笑话就忘了对方。 2019.10.23 如果快乐太难，那么祝你平安。 2019.10.24 我知道，那些夏天，就像你一样回不来，我已不会再对谁满怀期待。我知道，这个世界，每天都有太多遗憾，所以，你好，再见。 -安河桥·宋冬野 2019.10.25 菩提本无树，明镜亦非台。本来无一物，何处惹尘埃。 2019.10.26 曾经沧海难为水，除却巫山不是云。取次丛中懒回顾，半缘修道半缘君。 2019.10.27 不要因为走太远而忘记为什么出发。 2019.10.28 人心不会太差，但也不会像你想象的那么美好。做一个性情凉薄之人。 2019.10.29 开心一天也是过，失落一天也是过。为什么不开心一些呢。 2019.10.30 白牙 2019.10.31 爱太满 遗憾太长  ","description":"","id":108,"section":"posts","tags":["开始","每日一句","改变"],"title":"2019-10","uri":"https://www.xunhs.cyou/posts/journals/102/"},{"content":" 雅思复习过程中（大/小）作文练习\n Rural-to-urban Shift  2019.10.3 Many people are moving from rural areas to big cities. Why has this happened? To what extent do you think it is a good trend?  These days many people choice to migrate to big cities from rural areas. They may believe that they can find a more satisfied employment and enjoy a better quality of life in urban areas. However, this trend can lead to a lot of problems.\nThere are two main reasons why people tend to move to cities. First, cities own dense population and there are more working chances available in cities, so people can make more money. This also means that they can imporve their life standards and afford more consumer goods ever before. In comparsion, in rural areas, there are less employment opportunities since many industries are lack of development and many dwellers' buy power is limited. Another reason is that urban residents are more accessible to public services, such as education and healthcare, and enjoy better standards of living. Young couples intend to bring their children to cities to accept better educations, so as to get rid of poverty.\nHowever, the increasing number of population in cities many put great pressure on cities' infrastructures and lead to serious housing problem. The lands in some cities are limited, so difficult to absorb in too many people. For example, many migrants live in slums and have to endure poor living conditions because they cannot afford a house in cities. Moreover, people are prone to sickeness because of the undevelopment of urban infrastructures. People cannot use enough clean water and household garbages as well as waste water are fail to be disposed.\nAnother main question associated with rural-to-urban shift is the increasing gap between urban and rural incomes. Ambitious, energetic, industrial and creative people tend to move to cities in serarch of educational and employment opportunities, causing the lack of working force in rural areas and it becoming more difficult to develop rural economics. Moreover, some young people will commit crimes because of increasing gap between rich and poor in cities.\nIn conclusion, poor employment prospects and undeveloped economics in rural areas lead to people moving to cities. I claim that this is a worrying trend.\nLow-cost Air Travel  2019.10.7  Cheap air travel enable us to travel acorss border with low expenditure. In my view, cheap air service can benefit ordinary people, although unnecessary travels are not suggested.\nPeople are able to go to different countries by air flights, increasing (enriching) their knowledge of these countries and acquiring more employment opportunities. For example, some people who has gone to other countries may find better jobs and earn more money (earn higher salaries). Some small business owners, for another instance, may find (discover) some business opportunities during traveling (their trips), and they can get more money (earn profits) by importing or exporting products. However, the high-cost air flight would make them lose (miss) these opportunies.\nOn the other hand, many individuals argue that raising the price of air travel can reduce the environmental effects (impact) of air flight. High-cost price of air ticket will make people give up their travel plans. As results, the greenhouse gases generated (produced) by planes can seriouly reduce (decrease). Moreover, other air related issues, such as noise pollution and environmental demages for building airports or related infrastructures, can be greatly improved (mitigated).\nIn my personal point, I don\u0026rsquo;t think it is necessary to raise the price of air tickets, since ordinary people can have opportunies to travel to some beautiful spots for relaxation. Many people, especially those who live in big cities, are busy in their works and widely under great pleasure. With low-cost air travel, they can go to somewhere distant on holidays. For example, many Chinese travellers are likely to go to some tropical countries and take a taste on local foods, instead of staying at home.\nIn conclusion, my argument is that restriction on air flights is not rational, since air travel with low-cost price is benefical to most ordinary people. What\u0026rsquo;s more, air companies may take some measures to reduce the environmental pressure by technology innovation.\nLaw and Sociaty  2019.10.9  Law refer to the rules implied on people in society. Although legislation is of great importance to (play a important role in) rule people\u0026rsquo;s behaviors, I think it limits the freedom of individuals.\nIf social individuals do not obey laws, the society would lost its principles and economics would be difficult to develop. For example, people disobey traffic rules, resulting in soaring traffic events and further traffic jam. Moreover, if the people who sell fake medications are not been hardly punished, customs would not dare to buy anything and the economic development would be hindered accordingly.\nThere would be a serious lack of respect and trust between people if they do not follow ethical principles and social behaviors. Since people sometimes would do somethings which harm others driving by their benefits. For instance, if people always betray their friends, they would not have any cooperations, resulting the lack of social cohesion. What\u0026rsquo;s more, assuming that more and more people tend to be dishonest, they would feel difficult to do bussiness together and frequent controveries between them also would pose a threat to productivity and creativity.\nSometimes, however (on the other hand), laws or rules will limit people\u0026rsquo;s freedom inevitably, even hindering the social development. For example, if the country make varieties of rules on commerce, the commercial behaviors would be difficult to be active. Moreover, assuming that people with high incomes have to (are subject to) commit high taxes high tax rates, they may have no ambitions (motivation) to make effort to eran more money (increase their income). In this issue, governments should give off up (relax) some limitations properly and encouage creativity to benefit social development.\nIn my view, the standpoint that without laws or rules the socity would be diffcult to function (operate) well is rational. Although laws do not allow people to do whatever they want, the main target (purpose) of legislation is to create a harmonious sociaty which we both accept.\nDistance Education  2019.10.16 Nowadays, distance-learning programs are commonplace, but some people argue that they are not as good as those attending in a college or university in person. To what extent do you agree or disagree?  The coming (advent) of Internet has changed the ways people live their lives or work. A growing number of people are now looking forward to (considering) distance education, which allows them to complete a degree at home. Although distance-learning is different from traditional education of college or university, distance-learning has some advantages in some situations (aspects).\nCompared with traditional education, distance-learning is more flexible and easily access people to accept a education by this way. The students can read related meterials and have a lesson by watching vedios. When they have any questions, they could suspend that vedio or replay other vedios until they fully understand the puzzling issues. This distanced courses are opened for students every time of every day. Therefore, it is a very desired way for the completely busy individuals to abtain knowledge.\nThe development of distance education also creates great opportunities for students to ask questions to distanced teachers. Students can ack questions by communicating tools in virtual courses and emailing to their teachers. As a result, they can easily obtain the guidances of the teachers and finish their courses in a better way. Even distance education allows them to communicate with scholars of famous colleges, who actually live in different countries.\nHowever, a significant downside of distance education is that the students' communicating skill is difficult to enhance, since this education generally has no group works. The students fininsh their homeworks by themselves and are unable to meet other students. As a result, they have no chance to expend their relationships and their vocational prospect would be potentially impacted.\nIn my view, distance education provides more and more individuals with great accessibility to the college education because of its flexibility. However, downsides, such as lack of communications, also exist. Therefore, it can\u0026rsquo;t achieve equal effects like traditional college education.\nGovernment Tax  2019.10.24 Some people believe that they should be able to keep all the money they earn and should no pay any tax to the state. To what extent do you agree or disagree?  Many people may complain that tax is a heavy burden to them because tax decreases their incomes. I claim that paying tax to the state is greatly necessary. If we pay no tax, the society we depend will be difficult to run.\nWith taxes, governments can fund variety of public service projects, such as road facilities, educational services and public healthcare. Firstly if we don\u0026rsquo;t have a good public transportation system, people commuting will be diffcult and traffic jams seriously influence people\u0026rsquo;s working efficience. Secondly public schools provide children with opportunities to access to education and acquire knowledge, which benefits the development of economy. However, the above pulice service projects generally are not funded by private companies because these projects always have low profits. Moreover, we could also realise that the government can redivide the social fortunes by tax. For instance, in many countries, high-income individuals always pay higher taxes than low-income, people who even be supplied by governments.\nGovernments can also behave people\u0026rsquo;s behaviors by taxes. For example, some people may feel difficult to give up bad habits such as drinking and smoking. However, governments levying heavy taxes on cigarettes and alcohols enable people to decrease the consumption of these items. Therefore, people have to gradually give up these habits. People tend to be less ill and the public healthcare seems to under less pressures.\nHowever, heavy tax can limits the development of the economy. If the government always leavy heavy tax on people, they will be under great burdens for making livings and have no time and passion to achieve their dreams. As a result, the society might face the danger of declination.\nI am convinced that the tax always has great priority of the development of our society and economy, although heavy tax poses negative impacts to some extent.\nVolunteer Works  2019.11.5  Volunteer work has been extensively promoted by many schools, and even in some schools, it become a definate requirement for graduation. On my personal sense, although volunteer work has some negative impact, it can exert postive influence on volunteers as well as the whole society.\nOn one side, by taking part in volunteer work, young students can develop some postive qualities. To be more specific, young individuals may be confronted with varieties of problems and challenges, which are rare at school, when they are involved in these voluntary services. For example, when rasing funds for charities, they need to learn how to communicate with benefactors, organise an acitivity and cooperate with all kinds of folks. As a result, these activites can directly boost their confidence and improve their abilities of solving problems.\nOn another, young people can also/meanwhile improve their sense of responsibility and find enjoyment in serving the community. In other words, only if they realize that their volunteer works can greatly be fovorable for other members in society, they would recognize the sense of community. For example, helping disadvantaged students to receive a good education is a kind of social responsibilities, in which voluntary students would be fulfilled with achievement since their volunteer works can make a fair and happy society. Consequently, it help create a close-knit community.\nHowever, we shouldn\u0026rsquo;t ignore the fact that voluntary services may waste lots of volunteers' times and energies, if not well-organized. This kind of volunteer work is tedious and strenuous, instead of funny and significannt. Consequently, they would be not willing to devote their times and energies to voluntary services because they can\u0026rsquo;t realize the value of what they do. Moreover, students might argue that volunteer work is hard and time consuming, and interferes their studies.\nOverall, in my eyes, it is important for students to take part in volunteer work for their improvement of abilities and their employment prospects. However, schools should ensure that volunteer work suit students' needs.\nPrison Term  2019.11.6  Imposing sentences is considered as a way to punish those who commit serious crimes and sometimes as a correctional method. Although this method may be effective to some extent, other approaches are suggested to reform offenders.\nSupporters with stiff sentences maintain that serious punishment exert deterrent impact (震慑力) on potiential criminals or habitual offenders. Imposing sentences means those who violate laws will lose freedom, a result that no rational person is willing to take. The criminal record can also negatively influence their lives including their career. Consequently, they will not commit crimes because they fear of the long prison term.\nAlthough prison term sometimes help us fight crime, we can consider community service (service不可数) as an alternative. By taking part in community service, many offenders, especially who commit minor crimes, have chance to become law-abiding citizens (守法的市民). In contrast, if they are sentenced to prison, they might reoffend (重蹈覆辙) after being released, which can pose a threat to other members of society.\nMeanwhile we can provide educational opportunities and vocational training for them, improving their interpersonal skills and job skills. It is worth noting that many young offenders or first-time criminals break the law because of their lack of social experience (experience不可数) or their low socio-economic status. However, if they able to find a job or understand legal responsibilities, crime is no longer an option. In contrast, prison term isolates offenders from society, and preventing them from acquiring employability.\nOverall, my view is that a longer prison term can deter crime, but it is not the best approach. Through other correctional programs like community service, we can build a happy and stable society.\nLiving Away From Parents  2019.11.8  Many university students today have either chosen university accommondation or shared a flat with their friends. I think it is a rite of passage although young individual is difficult to maintain frequent contact with their parents.\nLiving away from parents means that young individuals are supported to learn how to live an independent life. They have to develop some basic living skills, such as doing houseworks, making financial budgets and getting along with flatmates. With these skills, they can also deal well with problems once they enter the workforce. For instance, those who used to clean their bedrooms are more likely to keep everything organised.\nIn addition, college students can enjoy their freedom in social lives and make new friends. Since they needn\u0026rsquo;t to go back home every day, they have time to take part in more activities with their friends, including going to gym, attending lectures, going to the library and even doing a part-time job. Consequently, not only can they improve their social skills, but they have many personal resources to draw upon in the future.\nHowever, the choice that students living away from home might cause some adverse impact. Because they do not live with parents, young individuals have less and less contacts with parents, resulting vulnerable relationship between them and their parents. Sepecifically, children rarely have meals with their parents and cannot keep up to date with the news about the family. As a result, young individuals may feel helpless when they cannot work out some problems, which affects their attitude towards family.\nOverall, I am convinced that college students living away from home is a good decision, although it may have a damaging effect on their family relationships.\nFast Food  2019.11.9  People today are more likely to eat at fast food restaurants because of fast life pace and irregular working hours. In my view, fast food has posed negative threat to traditional food in many countries, which should be greatly concerned.\nFast food has been a kind of severe healthy issues in many countries like America, where the number of overweight individuals has been increasing uncontrolledly. Because fast food, which is served in large protions, is high in sugar, fat, salt and calories. In general, those who suffer from obesity are more likely to contract heart diseases than normal-weight people. This means that governments are suggested to pay much funds in health care, which may influence the development of enconomy.\nAnother problem is that fast food can change people\u0026rsquo;s lifestyle including dietary habits. Traditional foods pay more attentions to materials, cooking styles and varieties of taste, suggesting the evolution of cuisine in different countries. However, the majority of fast food restaurants provide American or Eureapon foods, such as humberger, fried chicken an pizza. Consequently, people\u0026rsquo;s diet is increasingly monotonous, which some traditional recipes may vanish.\nFast food also exert adverse impact on family relationship since family members do not have frequent meals together like before. Family meals provide family members with opportunity to communicate with each other and imporve mutual understanding. If people always eat outside, they cannot keep up to date with family issues and response to emotion needs of other family members. Consequently, people may feel helpless when they involved in troubles but obtain no help from family members.\nTherefore, I am convinced that the popularity of fast food is a kind of serious problems, which should be noticed by contemporary individuals. Fast food is damaging not only to people\u0026rsquo;s health, but also to cooking cultures and social relationships.\nUniversity Education And Success  2019.11.11  People always have diverse views about the contributions of theoretical knowledge to their employments. It is reasonable that there are many individuals who succeed in their careers actually do not complete their university education. Howecer, I am convinced that the knowledge we obtained at university is vitally important to a fulfilling career.\nVia theoretical knowledge, people can acquire the concepts and principles of subjects, which allow them to built expertise in their majors. For example, if a psychologist do not master the theories about psychological diseases, he or she can not make effective therapies. It means that the majority of theories are developed based on practical experiments and experiences, therefore they are significant and count much for humans. Besides, those who are familiar with these theories can improve their job prospects and even get a fortun because of the innovations they have advanced.\nLearning knowledge from theories allows people to enhance their problem-solving abilities. For instance, college students can gather information on different subject matters and consequently improve their research skills. Morevoer, theories can extend students' horizons and improve their thinking skills, which encourages them to push forward the boundaries of knowledge. In contrast, those who did not go to university may deal with some ordinary problems by receiving some pratical training, but they would have no ideas when in the face of irregular issues.\nHowever, we should recognise the fact that theoretical knowledge is not the only key of success. It is interesting to note that many successful folks seem to have some similiar characters. For example, a person who is positive, industrial, active and good at communication generally do better in overcoming all kinds of troubles and cooperating with others to achieve their success. Another important factor may be the social network, by which people can acquire a great variety of information, thoughts and resources. It means that some businesspeople tell them how to maintain a good relationship with governments, but books can not.\nOverall, university education seems to be undervalued and people can work out many problems in more efficient and creative approach. what we should be considered is that people\u0026rsquo;s characters and social relationships are also important factors to achieve success.\nEducation Tuition Fees  2019.11.16  Receiving an university education is important to many people, because they can find empolyment easily in the fature. People who support government spending on university education may contend that some students cannot go to a college because they are not able to afford tuition fees. In my view, students are supposed to pay tuition fees themselves, while those from disadvantaged backgrounds can receive financial assistance from the government.\nIf higher education is not free of charge, students will feel precious about this educational opportunity and study much hard. In general, students aware that going to a college is costly, and therefore they will try their best to study tesks and pass all exams in order to gain the qualification on time. In contrast, students whose tuition fees paid by the government would take it for granted and may frequently fail exams.\nMoreover, another benefit of self-funding is that it can ease the burden on the government. The government can put more investment into secondary and primary education, which can reduce the number of illiterate folks, and allow elders to go to a college. Also the government can provide postgraduate students with more funds and promote the technological innovation.\nHowever, the government can bear the cost of education for the disadvantaged students. Young students are encouraged to go to a college to acquire knowledge and improve sociable skills, which can boost their career prospects. Moreover, this can close the gap between haves and have-nots and help build a fair society. In contrast, if these students give up their university education just because of higher tuition fees, they would be difficult to discovery their potential abilities.\nOverall, the government should provide students with financial support according to their needs and backgrounds to ensure that they have fair access to university education.\nChildren\u0026rsquo;s Advertisements  2019.11.17  Nowadays most of children are exposed to a variety of commercial advertisements, which encourage them to buy snacks, toys and computer games. My view is that advertisements aimed at kids should be seriously limited or even banned.\nIf children\u0026rsquo;s advertisements are not widely allowed, kids would not ask their parents to buy some kinds of things with less value. Many children actually are not sensitive to prices while parents are more likely to meet their needs. For example, many children prefer to expensive toys and girls like to buy fashionable clothes. These behaviours can bring a heavier burden on disadvantaged families. However, this issue could be avoided if kids have less access to advertisements.\nAlso advertisements are responsible for many behaviours problems and lifestyle issues among children. Kids prefer to fast food since they are always attracted by snack advertisements. Moreover, many kids become easy to get angry because they play violent computer games which promoted by advertising firms. These issues can pose a negative impact on children\u0026rsquo;s health.\nThere are, without any doubts, some advertisements which can benefit kids. For instance, some advertisements encourage nourishing foods, such as milk and vegetable foods. Other advertisements promote books, computer games and toys of educational value. As a result, parents can purchase some valuable products even though they are not familiar with those products.\nOverall, I contend that advertisements aimed at children, especially those which are harmful to kids, should be not allowed. However, the government can encourage some educational advertisements.\nImport Products  2019.11.19  Our world is becoming more and more globalised and the exchange of commodities across the borader is processing at an astounding rate. In my view, this trend can help imporve living standards of customers.\nCustomers can be benefited from import products in many aspects. The first one is that the price of these products is competitive. These countries who export products generally reduce the cost of goods by improving technologies to ensure a cheaper price. For example, Chinese textile products, in many other countries, usually have a cheaper price than the local ones because China specialises in textile. Moreover, import products can challenge the dominant status of domestic firms and cause competition, which enforce manufactures to cut price. This can be great beneficial to domestic customers because of decling living costs. It is worth noting that customers have more choices when they go shopping. Import foods, for instance, can mitigate the shortage of foods when they suffer from abnormal climates in some regions.\nHowever, the downside of import goods is serious and can not be neglected. The country who heavily relies on import goods may suffer from underdevelopment of some industries in home. If customers prefer to buy import comupters, the local manufactures may be bankrupted. This pose a severe threat on domestic self-funded enconomy. Moreover, the air transportation of import goods can cause considerable contamination to the environment.\nTherefore, it is reasonable to think that importing products from other countries has a postive influence on customers. Some local firms may be in danger of bankruptcy, but domestic customers can buy products with much cheaper prices.\nThe Spread of English  2019.11.26  English has developed into a global language, which has been used as a vehicle for cross-cultural communication all over the world. For my part, the spread of English can be viewed in a positive light, althought it might have it negative effect.\nThe wide use of English broosts the global cooperation, as it can help people overcome the obstcles under the international environment. Folks from different countries can conduct business and discuss how to operate a company and import products, regardless of their native languages. Moreover, English has been identified as the main language by many international conferences and research groups. This means that scholars are able to share knowledge and ideas or even cooperate to complete projects in different areas.\nIn addition, the spread of English can help people expand knowledge and broaden horizons. About 80% of world\u0026rsquo;s websits are post in English, so folks who master English can read newspapers, magazines and books on the Internet and keep up to date with our world. They can travel in different parts of the world and deepen their understanding of customs of these places.\nAlthough the English language has vast contribution to globalisation, sometimes it\u0026rsquo;s considered as the main reason of the reduction of cultural diversity. This idea lies in the fact that increasing young people make an effort to study English instead of their native languages. As the dominant language of international medium, English language has been bringing the lifestyle, sense of value and belief of English countries to the every corner of the world, which might have a negative impact on cultural diversity. For example, many native therapies, recipes, religious practices and ceremonies have been vanishing because of the spread of English language, so our knowledge about the world will be limited if these cultures graduately disappear.\nOverall, English plays an important role in communication and cooperation among people from different countries, although some people suspect that English will endanger some native languages.\nAustralian People\u0026rsquo;s Physical Activity  2019.12.4  The chart compares Australian men and women in terms of the percentage of doing exercise in 2010.\nOver 52.8% of 15-24-year-old men were involved into regular physical activity in this country, compared with 47.7% of women in the same age group, but they saw a different trend with age. The percentage of women increased steadily and peaked (53.3%) for those aged 45-54, while the figure for men dropped significantly and fell to the lowest point at 39.5% for those aged 35-44.\nAfter the men reached the age of 45, the percentage of those who did regular physical activity increased gradually from 39.5% to 46.7%, but the proportion of women decreased to 47.1%.\nOverall, women in different age group were more active than men, with exception of the 15-24 age group. As people got older, the gap between men and women gradually narrowed.\nPopulations Of Yemen And Italy  2019.12.4  The charts compare Yemen and Italy in terms of the ages of the populations in 2002 and 2050.\nIn Yemen, the figure of the people aged 15-59 is expected to increase from 46.3% to 57.3%. This age group will also make up with the largest proportion of Italy\u0026rsquo;s population (46.2%) in 2050, despite a significantly drop from 61.6% in 2002. These figures for these aged 0-14 seem to decrease in both countries. The proportion of this age group in Yemen is predicted to drop from 50.1% to 37.0%, while in Italy the percentage drop slightly from 14.3% to 11.5%.\nThere are likely to see increases in the proportion of over-60-year-old people. In Yemen, the figure of this age group is predicted to increase to 5.7%, although they make up with the smallest proportion of population. The figure in this age group in Italy seem to rise nearly twofold, with around 42.3% in 2050.\nOverall, the population of both countries is predicted to become older. Italy had older population than Yemen in 2002, and the same is predicted in 2050.\n","description":"","id":109,"section":"posts","tags":["写作","雅思"],"title":"雅思英语写作练习","uri":"https://www.xunhs.cyou/posts/notes/133/"},{"content":" 民国时期婚书上的题字。十分喜欢。\n 其一  两姓联姻，一堂缔约，良缘永结，匹配同称，看此日桃花灼灼，宜室宜家，卜他年瓜瓞绵绵，尔昌尔炽，谨以白头之约，书向红笺，好将红叶之盟，载明鸳谱。此证。\n 不同姓氏的两家联姻，在一起缔结婚约，结成良缘，是得称的匹配。桃花盛开之际，正宜婚嫁(引自诗经)，预料将来一定子孙像瓜蔓绵延，子子孙孙世代昌盛(引自诗经)。将白头到老的约定书写在纸上，像红叶题诗一样的天赐良缘，记载于鸳鸯谱上。以此证明。\n其二  喜今日嘉礼初成，良缘遂缔。诗咏关雎，雅歌麟趾。瑞叶五世其昌，祥开二南之化。同心同德，宜室宜家。相敬如宾，永谐鱼水之欢。互助精诚，共盟鸳鸯之誓。此证。\n 在这喜庆的日子里，祝贺两位新人喜结良缘。用诗歌来赞美《关雎》、《麟之趾》中所描写的爱情。这婚姻的结合，祥瑞绵泽五代子孙，使其家族昌盛，并开创圣贤似的教化。希望他们日后能够同心同德，夫妻一体，相敬如宾，永远甜蜜，携手共进，共赴鸳鸯一般的婚誓。以此证明。\n其三  从兹缔结良缘，订成佳偶，赤绳早系，白首永偕，花好月圆，欣燕尔之，将泳海枯石烂，指鸳侣而先盟，谨订此约。\n 从现在缔结美好的姻缘，订婚成为优秀的伴侣，（千里姻缘）一条红线早已牵系，永远结伴同行直到满头白发。正是花儿怒放月儿圆满的时候，摆宴饮酒大家快乐极了，愿将此美好一直到大海枯干石头腐烂，面对着一对鸳鸯来盟誓，郑重地签下合约。\n其四  礼同掌判，合二姓以嘉姻，诗咏宜家，敦百年之静好，此证！\n 其五  喜今日赤绳系定，珠联璧合。卜他年白头永偕，桂馥兰馨。\n 离婚  凡为夫妇之因，前世三生结缘，始配今生之夫妇。若结缘不合，比是冤家，故来相对。既以二心不同，难归一意，快会及诸亲，各还本道。愿娘子相离之后，重梳婵鬓，美扫蛾眉，巧呈窈窕之姿，选聘高官之主。解怨释结，更莫相憎。一别两宽，各生欢喜。\n ","description":"","id":110,"section":"posts","tags":["婚书","文言文"],"title":"民国结婚证书","uri":"https://www.xunhs.cyou/posts/notes/90/"},{"content":" 2019年7月中，生日旅行。在苏州。\n \n","description":"","id":111,"section":"posts","tags":["旅游","苏州","相册"],"title":"2019.7-苏州游记","uri":"https://www.xunhs.cyou/posts/journals/103/"},{"content":" 间隔好久没有写日志。\n 原因是每天的“日记”写的很无味。虽然最初的想法只是为了养成一种记录日记的习惯，但是越发的感觉这种记录是多余的、无趣的。而且日常偷懒还是有的。早上记录计划。第二天早上总结前一日的工作后再做计划。很多计划都不能完成。也就失去了所谓做计划的意义吧。还有就是，周末时长偷懒，不去做日记。仿佛周末的时光从博客里剔除了一般，记录在虚拟世界的时间比现实生活少了许多。这也是对记录这种行为、对日记这种产出的物品的一种不公吧。\n以上并非我对偷懒的借口。\n时至六月，暑期快要来到了。亦或是，暑期已经到来。\n给自己制定一个周计划怎样。\n想的是。\n每周可以做一些阅读。\n每周可以完成一些编程的工作。\n既不会在阅读上生疏。\n也不会在代码上时常忘记。\n可是，要设定多少才是合适呢。\n先来个初始值吧，怎样。\n阅读论文三篇。\n代码项目怎样量化呢。\n先去了解，去做就是了。\n思路写到一半，然后去打了游戏，写的都忘记了。\n再谈谈遗忘的感情吧。\n成熟的路上对于来讲还真是很漫长呢。\n我想重新树立价值观了吧。\n希望自己可以变得安静一些。\n少些玩笑。\n少些无聊的谈话。\n不想向别人表露自己。\n希望自己可以做一个安静的男生。\n也不是封闭自己。\n只是有些累了向别人介绍自己。\n只是看不过他人的离去。\n你说这样好不好呀。\n今天上午（准确的说是晚上一个半小时+上午睡醒后半个小时）补了一下《哥斯拉》第一部。看完后还是觉得蛮好看的。买了个下午哥斯拉的第二部。还是蛮好看的。是我喜欢的科幻类型。很炫酷、很宏大的场面和特效。故事线还是那么尴尬。。。反正我也是奔着特效去看的。其实自己看电影，自己逛街也没有什么不好的。没有感受到孤独。没有感受到无趣。也没有必要依赖别人吧。买一杯圣代。走在路上感受初夏。用手机在北街捕捉到夏日的阳光。还是想去海边。想去追逐海风。想去抓起沙滩。更或许静静坐在水边就好。\n","description":"","id":112,"section":"posts","tags":null,"title":"2019.6.2 随笔","uri":"https://www.xunhs.cyou/posts/journals/131/"},{"content":" 纪念第一篇一作吧。\n 论文总结  简介：基于POI数据，将城市区块类比为自然语言处理中的文档，进一步借鉴自然语言处理的方法（如LDA模型和Word2vec模型）提取城市功能区域，已经得到了广泛的研究。在自然语言文档中，同一单词在不同文档中存在多义性以及歧义性等特性，衍生至城市功能区域挖掘，同样存在此类问题。本文引入了一种topic word embedding的方法，结合文档主题模型和词向量技术，基于城市海量POI数据，致力于解决城市功能的“多义性”问题，使得自然语言处理的模型更好的服务于城市功能区域挖掘。 论文基本结构  Introduction (完成，待整理) Study Area and data (未写) Methodology (部分完成) Implementation and results (部分完成) Discussion (未写) Conclusion (未写)     近期写作计划  论文基本结构整理  Abstract (未写) Introduction (完成，待整理) Study Area and data (未写) Methodology (部分完成)  Building of urban functions corpus (完成，待整理) Word embeddings representation model (完成，待整理) Similarity measurement and clustering method (未写)   Implementation and results (部分完成)  Implementation of study (未写) Topic modeling analysis (完成，待整理) POI categories correlation analysis (完成，待整理) Clustering results (未写)   Discussion (未写)  关于聚类方法的讨论 (未写) Word2vec和TWE向量应用在hdbscan的聚类效果对比 (未写) 关于LDA参数的确定 (未写)   Conclusion (未写)   写作计划（两星期计划）  Clustering results - 3天 Discussion + Conclusion - 3 天 Implementation of study - 1 天 Similarity measurement and clustering method - 1 天 Study Area and data - 1 天 Abstract - 1 天 全文、图表、格式等相关整理 - 4 天    ","description":"","id":113,"section":"posts","tags":["论文","写作计划"],"title":"论文写作总结及近期写作计划","uri":"https://www.xunhs.cyou/posts/notes/128/"},{"content":" 整理博客学习过程中一些笔记。\n 文本挖掘的分词原理  分词的基本原理：利用语料库建立的统计概率，对于一个新的句子，我们就可以通过计算各种分词方法对应的联合分布概率，找到最大概率对应的分词方法，即为最优分词。 N元模型 维特比算法与分词：维特比算法可以大大简化求出最优分词的时间 常用分词工具：英文分词推荐使用nltk。对于中文分词，则推荐用结巴分词（jieba）  分词是文本挖掘的预处理的重要的一步，分词完成后，我们可以继续做一些其他的特征工程，比如向量化（vectorize），TF-IDF以及Hash trick，这些我们后面再讲。\n向量化与Hash Trick  词袋模型(Bag of Words), 词集模型(Set of Words) 词袋模型的三部曲：  分词（tokenizing） TF-IDF统计修订词特征值（counting） 标准化（normalizing）    这里我们对向量化与它的特例Hash Trick做一个总结。在特征预处理的时候，我们什么时候用一般意义的向量化，什么时候用Hash Trick呢？标准也很简单。\n一般来说，只要词汇表的特征不至于太大，大到内存不够用，肯定是使用一般意义的向量化比较好。因为向量化的方法解释性很强，我们知道每一维特征对应哪一个词，进而我们还可以使用TF-IDF对各个词特征的权重修改，进一步完善特征的表示。\n而Hash Trick用大规模机器学习上，此时我们的词汇量极大，使用向量化方法内存不够用，而使用Hash Trick降维速度很快，降维后的特征仍然可以帮我们完成后续的分类和聚类工作。当然由于分布式计算框架的存在，其实一般我们不会出现内存不够的情况。因此，实际工作中我使用的都是特征向量化。\n向量化与Hash Trick就介绍到这里，下一篇我们讨论TF-IDF。分词是文本挖掘的预处理的重要的一步，分词完成后，我们可以继续做一些其他的特征工程，比如向量化（vectorize），TF-IDF以及Hash trick，这些我们后面再讲。\nTF-IDF 如果我们直接将统计词频后的19维特征做为文本分类的输入，会发现有一些问题。比如第一个文本，我们发现”come”,”China”和“Travel”各出现1次，而“to“出现了两次。似乎看起来这个文本与”to“这个特征更关系紧密。但是实际上”to“是一个非常普遍的词，几乎所有的文本都会用到，因此虽然它的词频为2，但是重要性却比词频为1的”China”和“Travel”要低的多。如果我们的向量化特征仅仅用词频表示就无法反应这一点。因此我们需要进一步的预处理来反应文本的这个特征，而这个预处理就是TF-IDF。IDF就是来帮助我们来反应这个词的重要性的，进而修正仅仅用词频表示的词特征值。\nTF-IDF是非常常用的文本挖掘预处理基本步骤，但是如果预处理中使用了Hash Trick，则一般就无法使用TF-IDF了，因为Hash Trick后我们已经无法得到哈希后的各特征的IDF的值。使用了IF-IDF并标准化以后，我们就可以使用各个文本的词特征向量作为文本的特征，进行分类或者聚类分析。\n当然TF-IDF不光可以用于文本挖掘，在信息检索等很多领域都有使用。因此值得好好的理解这个方法的思想。\n中文文本挖掘预处理流程总结  中文文本挖掘预处理特点 数据收集：主题爬虫—-ache，ache允许我们用关键字或者一个分类算法来过滤出我们需要的主题语料，比较强大。 除去数据中非文本部分 处理中文编码问题 中文分词：可以帮jieba加入词汇 引入停用词 特征处理 建立分析模型  潜在语义索引（LSI） LSI是最早出现的主题模型了，它的算法原理很简单，一次奇异值分解就可以得到主题模型，同时解决词义的问题，非常漂亮。但是LSI有很多不足，导致它在当前实际的主题模型中已基本不再使用。\n通过一次SVD，就可以得到文档和主题的相关度，词和词义的相关度以及词义和主题的相关度。\nk是我们假设的主题数，一般要比文本数少。\n主要的问题有：\n SVD计算非常的耗时，尤其是我们的文本处理，词和文本数都是非常大的，对于这样的高维度矩阵做奇异值分解是非常难的。 主题值的选取对结果的影响非常大，很难选择合适的k值。 LSI得到的不是一个概率模型，缺乏统计基础，结果难以直观的解释。  对于问题1），主题模型非负矩阵分解（NMF）可以解决矩阵分解的速度问题。对于问题2），这是老大难了，大部分主题模型的主题的个数选取一般都是凭经验的，较新的层次狄利克雷过程（HDP）可以自动选择主题个数。对于问题3），牛人们整出了pLSI(也叫pLSA)和隐含狄利克雷分布(LDA)这类基于概率分布的主题模型来替代基于矩阵分解的主题模型。\n回到LSI本身，对于一些规模较小的问题，如果想快速粗粒度的找出一些主题分布的关系，则LSI是比较好的一个选择，其他时候，如果你需要使用主题模型，推荐使用LDA和HDP。\nGensim LSI实现：\n 中文：https://blog.csdn.net/ld326/article/details/78508162 英文：https://www.52nlp.cn/tag/lsi；官网：https://radimrehurek.com/gensim/wiki.html#id6  非负矩阵分解（NMF） NMF作为一个漂亮的矩阵分解方法，它可以很好的用于主题模型，并且使主题的结果有基于概率分布的解释性。但是NMF以及它的变种pLSA虽然可以从概率的角度解释了主题模型，却都只能对训练样本中的文本进行主题识别，而对不在样本中的文本是无法识别其主题的。根本原因在于NMF与pLSA这类主题模型方法没有考虑主题概率分布的先验知识，比如文本中出现体育主题的概率肯定比哲学主题的概率要高，这点来源于我们的先验知识，但是无法告诉NMF主题模型。而LDA主题模型则考虑到了这一问题，目前来说，绝大多数的文本主题模型都是使用LDA以及其变体。下一篇我们就来讨论LDA主题模型。\n","description":"","id":114,"section":"posts","tags":["阅读笔记","NLP","刘建平"],"title":"刘建平博客NLP-阅读笔记","uri":"https://www.xunhs.cyou/posts/notes/93/"},{"content":" 这篇文章是应该是昨天开始写的。但是没有头绪（lan），拖到今天动笔。不知道写什么，不想回忆什么，这几天的心情也是糟糕透了。刚刚看过《写在2018年的第一天》，不自觉的就笑了。看着最后罗列的新年心愿简直可笑。第一，没有完成。第二，关于最后一项，遇到心爱之人。是的，只是遇到了，也怪我没有争取吧。\n 这次从年末开始倒叙吧。\n2018年的年末简直是狼狈。没有比这个词更好的说明吧。非常高兴能够认识她，也觉得和她在一起非常开心，她是一个可爱、开朗的女孩子，同时也非常不舍不能和她在一起。我深陷其中，每日胡思乱想，不愿等待消息的过程，十分煎熬，最后约她也被她理由回绝了。我有预兆她不喜欢我，因此我最后的“表白”也只是为了得到一个肯定的答案吧。满打满算是一个星期时间吧。相识，却不能相知，爱而不得，我告诉朋友我不再相信爱情了。\n12月比较重要的事情就是去美国的一个星期了。以AGU会议为名，实则各种娱乐。真的不喜欢那边的生活，吃饭不合胃口，游玩也不是很开心，甚至有些孤独。来回飞机上难受的24+小时。还有回国的倒了好久的时差。你说，那些一个人旅行的人们啊，你们是怎样拒绝孤独的呢？\n11月，有什么好回忆的呢。中期考核和去北京出差吧。中期考核，说是形式上的走过程，但是导师的要求还是蛮苛刻的。也是第一次与吴老师改了这么多次ppt且不满意吧。对之前的工作研究做了一个总结，同时也初步确定了城市功能区域划分这个研究方向。月末是地理大数据的项目，和何老师、谢老师去北京感受了三天的寒冷。那些天还好，北京的风没有那么矫情，记忆比较深的是吃的那次老北京涮羊肉~在寒冷的冬天，暖阳和火锅相得益彰。\n10月初去了广州。办签证。三天住宅毛毛的公寓里。玩的比较开心。毛子很真诚。签证办理的很顺利，一下子拿下了十年签。广州这座城市留下的印象也非常深刻。清淡的饮食。直到中午下午的早茶。清爽的天气。非常宜居的一座城市。如果没有房价的烦恼。希望以后也不会被此所烦恼。\n发生在十月底的就是春儿的婚礼了。去年第二次去宜昌。同样非常喜欢宜昌这座城市。他有攀比武汉的繁荣，却没有武汉那么喧嚣，没有那么拥挤。有江水为伴，环境十分舒适。婚礼办得十分隆重，盛典、豪车、美食，这次宜昌之行没错了。\n九月份是立flag的最多的日子。健身flag，雅思flag，日志flag。雅思flag目前没有进行，与其说是没时间，其实还是没坚持。健身flag和日志flag断断续续的在坚持。也算是一种进步了。很开心可以把之前所有的东西记录下来。先不考虑其是否有逻辑，比较吃惊的是自己竟然可以写这么多文字。虽然有时不想回首，但总是一种经历吧。哦对了，九月初又去了一趟北京，去了一趟圆明园，清华大学。那时候的天空，真美。\n七八月份最为浮躁。每天都会来公司（八月份还是满勤，难得），每天貌似都很忙的样子，却不知道自己在忙什么。也没有任何成果。有时候会傻傻的开心，有时候突然的失落。还是那种不成熟的样子。期间回家了一次，因为大姐带着晨露晨曦来朱河看爸妈。\n七月底以过生日为由，去了一趟上海。那时候燕还在上海实习。和她度过了三天时间。也算走遍了上海大部分地方，吃过了比较出名和好吃的美食。最终她还是留在西安。我们也没有继续。\n六月份又到了毕业季。又送走一批人。今年这个时候没有往年那么伤感了。毕竟学校里面也就只有自己了。六月初去仙桃参加龚希的婚礼，玩的很愉快。哦，对了，忘记了公司组织的宜昌出游。\n五月份是春天要走，夏天要来的时候，以朋友为名去了西安，找燕玩。你说，我和其他女生为什么会有“尬聊”呢。但是和她没有尬聊。我觉得与自己有很大的原因。是失忆了么，还是不想回忆了。西安是座美好的城市。但是近些年却不想靠近了。\n四月份以及之前，回忆不起来了。照片也没有。或许没什么大事吧。\n二姐带着沐沐来武汉，然后我带着她俩回家。\n既然2018已经过去了，那就让她过去吧。时间是个温柔的姑娘，她会无时无刻一直陪伴你左右。时间又是一个残酷的女人，她会在你开心的时候悄悄的溜走，在你难过的时候让眼泪无法凝结。我无法断言2018年过的好不好，我也不知道罗列了这么多我该怎样形容过去的这一年。一年的时间很长，长的你去看过江河，游历大山。可她又偏偏很短，短的像一天的下午茶，稍微打一个盹就没了踪影。\n人情冷暖，真心就好。\n新年愿景：\n 成熟 学会释怀 习惯孤独 专心 不再等待 没心没肺 孝敬父母 去看一场演唱会 玩吉他 雅思 至少熬出一篇paper 坚持写日志  回忆就继续在这卷磁带中吧。\nPhoto by Stas Knop from Pexels\n  ","description":"","id":115,"section":"posts","tags":["随记"],"title":"写在2019年的第一天","uri":"https://www.xunhs.cyou/posts/journals/2019-01-02-%E5%86%99%E5%9C%A82019%E5%B9%B4%E7%9A%84%E7%AC%AC%E4%B8%80%E5%A4%A9/"},{"content":" 这是第二次来宜昌了。也是今年第二次来宜昌。目的是参加春的婚礼~\n 我和权大周六早上早早出发，昨天晚上回到武汉。短短两天的“旅行”，感触很大。\n第一天上午到的，先到了春的新房，稍微安顿了一下然后去CBD附近，给伴郎试衣服。可以说伴郎的衣服真的很像服务生。也是，伴郎本来就是衬新郎的嘛。中午去了一家餐厅吃饭，真的味道挺不错的。都是家常菜，不过做的很有味道。春说常吃这家的菜，有时候经常点这家的外卖。吃完饭后来到新房，我们几个和伴郎一起布置新房。新房的位置非常好，在阳台上一眼望去就是长江和宜昌的大桥。吹气球，贴墙纸，大家边聊边忙着。我能看出虽然不是他们自己的婚礼，但是他们布置新房的时候还是很讲究的。对于我来说可能很随意，都可以的事情，他们会很认真，并校正多次。比如说，贴墙纸的时候他们会共同谋策怎么更好看一些，是不是歪了等等。可能如果我一个人做这种事情的话，觉得怎样都好吧。他们这种认真，不知是出自自己本身认真的态度，还是出于对春的友谊。两方面都有吧。然后忙到六点多左右我们来到酒店吃饭。酒店里很豪华，第二天感触更加深切。见到了春的父母等亲朋。吃的饭菜也都十分可口。吃过之后就去酒店房间了。终于躺在床上好好休息了~中间还有一件事情就是陶老师分配的申请省科技专项的任务。晚饭之前改了初稿，然后晚上又改了一稿。把之前的idea写了进去，画了一个流程图。\n第二天早早的起来，等待着接亲的队伍。伴郎早早的随新郎取化妆了并做准备，我和春的一些其他的朋友同行。感觉没有什么话聊。他们都是老同学，所以聊得很开心，而我不知道怎么和他们同聊。有一个家伙觉得性格挺好的，平常有的没有和他聊一两句，但是他也不是健谈的类型。早上一起吃的小面，早就听说宜昌的小面好吃。虽然是随意就近的一家路边面馆，但是还是很好吃。我没有加辣椒，味道很不错。早上看到婚车的时候是十分诧异的。接亲的车是劳斯莱斯幻影系列，后面的车清一色的黑色奔驰。我的天！这是我目前见我最高配了吧。我还特意手机查了一下劳斯莱斯。等了不久之后见到了新郎和伴郎队伍，然后就是出发前往新娘的酒店。新娘很漂亮。接新娘的时候玩了几个挺有意思的游戏，整的伴郎和新郎。这比一味的要红包也许好多了吧。之后接新娘来新房。他们这边的习俗有一个不太一样的地方。在新娘接亲的地方给女方父母敬茶，在新房给男方父母敬茶。我见过之前的都是在酒店典礼的时候敬茶。然后就是到达桃花岭酒店，听说是习大大来宜昌的时候住的酒店。确实很豪华。典礼大厅，真的很大，装饰很美。很排场。不久之后开始了典礼，内容非常丰富。有他们的VCR，有灯光秀，伴娘伴郎伴舞等等。中间春说到自己的爷爷给自己留的戒指的时候，止不住的哭了。当时也确实为他感动。很真挚。我给春微信发了500的红包，由衷的发了祝福。不久婚礼饭席结束了。我和权收拾收拾也离开了酒店。因为是晚上6点的高铁。还有两个多小时没什么做的。我就提议去洗脚休息一下。权大也同意了。之后就是坐高铁回武汉了。\n婚礼给我最大的感受就是盛大，豪华，真挚。这是我见过，目前最盛大的婚礼吧。不禁让我与半个月前表哥的婚礼进行比较，觉得表哥的婚礼较随意一些吧。心中也有想法，希望自己以后的婚礼可以盛大一些，可以气派一些，可以非常真挚。现在还是好好赚钱吧。为了以后盛大的婚礼，哈哈。\n虽然宜昌是第二次来了，还是非常喜欢这座城市的，而且是越发的喜欢。第一次来记得是六月初中地平台组织的出游游玩。也是两天的时间，全程参团跟导游妹子走。虽然住在市里一个酒店，但是大部分时间也都是在山水风景之地。这次两天的时间好好的感受了市里的“气息”。喜欢这座城市，道路非常宽阔，路上车不多，不堵。城区新旧建筑泾渭分明。新楼高耸，旧区破旧许多。在宜昌的几顿饭都吃的非常舒服。对比在岳阳吃的不习惯而言，不懂得照顾一些人的饮食。延边的长江，江边的公园，总能给行人一些惬意。也许喜欢一个地方有时候就相当简单吧。不缺少城市的繁荣，却有乡间的安逸。有城市的发展，不缺少乡间的自由。\n","description":"","id":118,"section":"posts","tags":["旅行","宜昌"],"title":"宜昌婚礼之行","uri":"https://www.xunhs.cyou/posts/journals/2018-10-29-%E5%AE%9C%E6%98%8C%E5%A9%9A%E7%A4%BC%E4%B9%8B%E8%A1%8C/"},{"content":" 参考了这里，这里，主要是整理复制的这里\n 目录\n[TOC]\nIntroduction to Graph What is a Graph?  Graphs can be used to represent:  social networks web pages biological networks …   What can we do on a graph?  study topology and connectivity community detection identification of central nodes …    pre-built graph-karate What does this graph represent? “A social network of a karate club was studied by Wayne W. Zachary for a period of three years from 1970 to 1972. The network captures 34 members of a karate club, documenting links between pairs of members who interacted outside the club. During the study, a conflict arose between the administrator “John A” and instructor “Mr. Hi” (pseudonyms), which led to the split of the club into two. Half of the members formed a new club around Mr. Hi; members from the other part found a new instructor or gave up karate. Based on collected data Zachary correctly assigned all but one member of the club to the groups they joined after the split.”\n1 2 3 4 5 6 7 8 9 10 11 12 13  import numpy as np import random import networkx as nx from IPython.display import Image import matplotlib.pyplot as plt import warnings warnings.filterwarnings(\u0026#39;ignore\u0026#39;) G_karate = nx.karate_club_graph() pos = nx.spring_layout(G_karate); nx.draw(G_karate, cmap = plt.get_cmap(\u0026#39;rainbow\u0026#39;), with_labels=True, pos=pos)   retrieve the basic information from this graph  On average, each person in the graph is connected to 4.6 persons.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  degree_sequence = list(G_karate.degree()) nb_nodes = len(G_karate.nodes()) nb_arr = len(G_karate.edges()) avg_degree = np.mean(np.array(degree_sequence)[:,1]) med_degree = np.median(np.array(degree_sequence)[:,1]) max_degree = max(np.array(degree_sequence)[:,1]) min_degree = np.min(np.array(degree_sequence)[:,1]) print(\u0026#34;Number of nodes : \u0026#34; + str(nb_nodes)) print(\u0026#34;Number of edges : \u0026#34; + str(nb_arr)) print(\u0026#34;Maximum degree : \u0026#34; + str(max_degree)) print(\u0026#34;Minimum degree : \u0026#34; + str(min_degree)) print(\u0026#34;Average degree : \u0026#34; + str(avg_degree)) print(\u0026#34;Median degree : \u0026#34; + str(med_degree))     out:\nNumber of nodes : 34 Number of edges : 78 Maximum degree : 17 Minimum degree : 1 Average degree : 4.588235294117647 Median degree : 3.0    plot the histogram of the degrees the histograms of degrees are quite important to determine the kind of graph we are looking at\n1 2 3 4 5 6 7 8  degree_freq = np.array(nx.degree_histogram(G_karate)).astype(\u0026#39;float\u0026#39;) plt.figure(figsize=(12, 8)) plt.stem(degree_freq) plt.ylabel(\u0026#34;Frequence\u0026#34;) plt.xlabel(\u0026#34;Degree\u0026#34;) plt.show()   Graph Analysis   2020.3.10 不知道作者为啥这里突然讲到随机图，这个有蛮难的。Tutorial跳过。\n  We can analyze a graph at different scales:\n using the global properties of the network using communities and clusters or by looking at individual nodes    The main descriptive measures we’ll explore will be:\n the degree distribution the clustering coefficient the “small world” phenomena the centrality of a node the diameter of the graph …    Erdos-Rényi model(ER随机网络模型) Defination In an Erdos-Rényi model, we build a random graph model with n nodes. The graph is generated by drawing an edge between a pair of nodes (i,j) independently with probability p. We, therefore, have 2 parameters: n the number of nodes and p\nG(n, p)模型的两个主要假设（连边独立，每条连边可能性相同）可能不适合为某些现实生活中的现象建模。尤其是ER图的度分布没有厚尾，而许多实际网络的分布是厚尾的。此外，与许多社交网络不同，ER图集聚系数较低。其他较好的替代模型可见BA网络模型（Barabási–Albert model）和WS小世界网络模型（Watts and Strogatz model）\n1 2 3 4 5 6 7 8  n = 150 p = 0.1 G_erdos = nx.erdos_renyi_graph(n,p, seed =100) # Plot the graph plt.figure(figsize=(12,8)) nx.draw(G_erdos, node_size=10)   Degree distribution Let pk the probability that a randomly selected node has a degree k. Due to the random way the graphs are built, the distribution of the degrees of the graph is binomial. The distribution of the number of degrees per node should be close to the mean. The probability of high nodes decreases exponentially.\n1 2 3 4 5 6 7 8  degree_freq = np.array(nx.degree_histogram(G_erdos)).astype(\u0026#39;float\u0026#39;) plt.figure(figsize=(12, 8)) plt.stem(degree_freq) plt.ylabel(\u0026#34;Frequence\u0026#34;) plt.xlabel(\u0026#34;Degree\u0026#34;) plt.show()   Descriptive statistics  The average degree is given by n×p. The degree expectation is given by (n−1)×p The maximum degree is concentrated around the average  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # Get the list of the degrees degree_sequence_erdos = list(G_erdos.degree()) nb_nodes = len(G_erdos.nodes()) nb_arr = len(G_erdos.edges()) avg_degree = np.mean(np.array(degree_sequence_erdos)[:,1]) med_degree = np.median(np.array(degree_sequence_erdos)[:,1]) max_degree = max(np.array(degree_sequence_erdos)[:,1]) min_degree = np.min(np.array(degree_sequence_erdos)[:,1]) esp_degree = (nb_nodes-1)*p print(\u0026#34;Number of nodes : \u0026#34; + str(nb_nodes)) print(\u0026#34;Number of edges : \u0026#34; + str(nb_arr)) print(\u0026#34;Maximum degree : \u0026#34; + str(max_degree)) print(\u0026#34;Minimum degree : \u0026#34; + str(min_degree)) print(\u0026#34;Average degree : \u0026#34; + str(avg_degree)) print(\u0026#34;Expected degree : \u0026#34; + str(esp_degree)) print(\u0026#34;Median degree : \u0026#34; + str(med_degree))    out:\nNumber of nodes : 150\nNumber of edges : 1135\nMaximum degree : 25\nMinimum degree : 8\nAverage degree : 15.133333333333333\nExpected degree : 14.9\nMedian degree : 15.0  Barabasi-Albert model (无标度网络) Definition 这个图的目标是建模优先连接（preferential attachment），真实世界网络中常会观察到这一点。（注：优先连接是指根据各个个体或对象已有的量来分配某个量，这通常会进一步加大优势个体的优势。）\n无标度网络(scale-free network)是一种度分布（即对复杂网络中节点度数的总体描述）服从或者接近幂律分布的复杂网络。\n 无标度网络的特性是普遍存在度远高于平均值的节点。度最高的节点通常称为枢纽（hub），被认为在网络中起到特殊作用 无标度网络的另一个重要特性是随节点度数升高而降低的聚集系数(clustering coefficient)分布。这个分布也服从幂律分布。 许多真实世界的网络被认为是无标度的  1 2 3 4 5 6 7 8 9 10  # Generate the graph n = 150 m = 3 G_barabasi = nx.barabasi_albert_graph(n,m) # Plot the graph plt.figure(figsize=(12,8)) nx.draw(G_barabasi, node_size=10)   Degree distribution  The distribution is now heavy-tailed. There is a large number of nodes that have a small degree, but a significant number of nodes have a high degree. The distribution is said to be scale-free, in the sense that the average degree is not informative.  1 2 3 4 5 6 7  degree_freq = np.array(nx.degree_histogram(G_barabasi)).astype(\u0026#39;float\u0026#39;) plt.figure(figsize=(12, 8)) plt.stem(degree_freq) plt.ylabel(\u0026#34;Frequence\u0026#34;) plt.xlabel(\u0026#34;Degree\u0026#34;) plt.show()   Descriptive statistics 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85  # Get the list of the degrees degree_sequence_erdos = list(G_erdos.degree()) nb_nodes = len(G_erdos.nodes()) nb_arr = len(G_erdos.edges()) avg_degree = np.mean(np.array(degree_sequence_erdos)[:,1]) med_degree = np.median(np.array(degree_sequence_erdos)[:,1]) max_degree = max(np.array(degree_sequence_erdos)[:,1]) min_degree = np.min(np.array(degree_sequence_erdos)[:,1]) esp_degree = (nb_nodes-1)*p print(\u0026#34;Number of nodes : \u0026#34; + str(nb_nodes)) print(\u0026#34;Number of edges : \u0026#34; + str(nb_arr)) print(\u0026#34;Maximum degree : \u0026#34; + str(max_degree)) print(\u0026#34;Minimum degree : \u0026#34; + str(min_degree)) print(\u0026#34;Average degree : \u0026#34; + str(avg_degree)) print(\u0026#34;Expected degree : \u0026#34; + str(esp_degree)) print(\u0026#34;Median degree : \u0026#34; + str(med_degree))``` - out: Number of nodes : 150 Number of edges : 1135 Maximum degree : 25 Minimum degree : 8 Average degree : 15.133333333333333 Expected degree : 14.9 Median degree : 15.0 ## Graph Algorithms explore the main graph algorithms and several use cases in a visual way with direct examples in Python. - To understand the context, here are some use cases for graph algorithms : - real-time fraud detection - real-time recommendations - streamline regulatory compliance - management and monitoring of complex networks - identity and access management - social applications/features - … - 3 main categories of graph algorithms are currently supported in most frameworks (networkx in Python, or Neo4J for example) : - pathfinding: identify the optimal path, evaluate route availability and quality. This can be used to identify the quickest route or traffic routing for example. - **centrality**: determine the importance of the nodes in the network. This can be used to identify influencers in social media for example or identify potential attack targets in a network. - **community detection**: evaluate how a group is clustered or partitioned. This can be used to segment customers and detect fraud for example. ### Pathfinding and Graph Search Algorithms - Pathfinding algorithms try to find the shortest path between two nodes by minimizing the number of hops. - Search Algorithms does not give the shortest path. Instead, they explore graphs considering neighbors or depths of a graph. #### Search Algorithms - Breadth-First Search (BFS) that explore each node’s neighbor first, then neighbors or the neighbors… - Depth-First Search (DFS) which try to go down a path as much as possible, and visit new neighbors if possible 根据可用性和质量等条件确定最优路径。我们也将搜索算法包含在这一类别中。这可用于确定最快路由或流量路由。 - 寻路算法是通过最小化跳（hop）的数量来**寻找两个节点之间的最短路径**。 - 最短路径： 最短路径计算的是一对节点之间的最短的加权（如果图有加权的话）路径。这可用于确定最优的驾驶方向或社交网络上两个人之间的分离程度。 - 搜索算法不是给出最短路径，而是根据图的相邻情况或深度来探索图。这可用于信息检索。 - 宽度优先搜索（BFS）：首先探索每个节点的相邻节点，然后探索相邻节点的相邻节点 - 深度优先搜索（DFS）：会尝试尽可能地深入一条路径，如有可能便访问新的相邻节点 ![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309084645.png) #### Pathfinding algorithms - Shortest Path calculates the shortest weighted (if the graph is weighted) path between a pair of nodes. It is used to identify optimal driving directions or degree of separation between two people on a social network for example. - Single-Source Shortest Path The Single Source Shortest Path (SSSP) computes the shortest path from a given node to all other nodes in the graph. It is often used for routing protocol for IP networks for example. - All Pairs Shortest Path The All Pairs Shortest Path (APSP) algorithm computes the shortest path length between all pairs of nodes. It is quicker than calling the Single Source Shortest Path for every pair of nodes. ```python # Returns the shortest path between each node nx.shortest_path(G_karate) # Returns shortest path length between each node list(nx.all_pairs_shortest_path_length(G_karate))   Minimum Weight Spanning Tree (最小生成树)   关于图的几个概念定义：\n连通图：在无向图中，若任意两个顶点$$v_i$$与$$v_j$$都有路径相通，则称该无向图为连通图。\n强连通图：在有向图中，若任意两个顶点$$v_i$$与$$v_j$$都有路径相通，则称该有向图为强连通图。\n连通网：在连通图中，若图的边具有一定的意义，每一条边都对应着一个数，称为权；权代表着连接连个顶点的代价，称这种连通图叫做连通网。\n生成树：一个连通图的生成树是指一个连通子图，**它含有图中全部$$n$$个顶点，但只有足以构成一棵树的$$n-1$$条边。**一颗有$$n$$个顶点的生成树有且仅有$$n-1$$条边，如果生成树中再添加一条边，则必定成环。\n最小生成树：在连通网的所有生成树中，所有边的代价和最小的生成树，称为最小生成树。\n  两种算法\n Kruskal算法 Prim算法    意义（案例）\n 网络G表示n各城市之间的通信线路网线路（其中顶点表示城市，边表示两个城市之间的通信线路，边上的权值表示线路的长度或造价。可通过求该网络的最小生成树达到求解通信线路或总代价最小的最佳方案(参考)。 走遍全部城市的车费或者路程最小。    1 2 3  from networkx.algorithms import tree mst = tree.minimum_spanning_edges(G_karate, algorithm=\u0026#39;prim\u0026#39;, data=False) edgelist = list(mst);edgelist   Community detection(社区发现/检测)  2020.3.10 从具体的任务来看我们不妨把社区发现分成以下四类：  图分割\n图分割的相关工作认为社区的成因是因为网络连边之间存在“强弱连边关系”，主要有两点：“三元闭包”关系下演化出来的、节点之间相互博弈生成的。因此在图分割视角下的科学问题就是“如何识别强弱连边关系”，代表的方法有betweenness、min-cut和优化Modularity的方法、CPM等。其中对Modulairty的优化可以更好的解释什么是好的社区，以后的很多方法包括基于统计模型的block model都可以最终归结为是优化Modularity的目标函数。Louvain则是将Modularity的优化进行了scalable，可以快速的应用在大规模的网络上。Modularity的缺点也很明显就是存在识别极限的问题。 图聚类 图聚类的相关工作大致的思路是embedding+聚类。代表的方法是谱聚类。它关注的科学问题是“节点的空间映射问题”。其实Newman自己也证明了Modularity其实是对模块度矩阵进行一个谱分析。这也体现了Modularity方法的普适性和良好的可解释性。\n 节点表达 然而，上述的方法都是从建模网络连边密度入手的，没有实际建模网络连边的生成过程。而且上述方法认为每个节点仅仅属于一个社区，忽略了社区中存在的重叠现象，因此，节点表达的思路就是认为每个节点都是一个k个社区的assignment的表达。这里的科学问题就是“如何通过观测网络学习得到这种节点的隐式表达”，借鉴LDA的思想Blei等人提出了Mixture membership block model（MMSB），这种基于概率统计方法的生成式模型更好的解释了节点之间的边是如何生成的以及整个网络是如何生成的，通过机器学习来学到隐变量。我们就得到了网络的重叠划分。这种方法对网络的解释性更好，唯一的缺点就是优化速度慢，可能会优化到局部最优。2013年Gopalan等人已经将该模型进行了加速可以处理百万规模的网络。除此之外的生成模型还有利用poisson分布建模multigraph的一些工作，这样的模型相对简单而且假设限制比MMSB要小一些，比如Brain Ball 2011 PRE的工作和Brain Karrer 的Degree corrected的相关工作。\n 广义社区发现 除此之外，网络中可能共存除社区结构之外的其他聚团结构，比如二部结构、中心-边缘结构等，因此，广义社区发现的任务就是发现网络中所有的连边模式。比如经典的Mixture model以及Newman等人2015年的相关工作。\n    Defination Community detection is a process by which we partition the nodes into a set of groups/clusters according to a certain quality criterion. It is typically used to identify social communities, customers behaviors or web pages topics.\nThe process to identify communities is the following:\n define a quality criterion design an algorithm to optimize this criterion  Quality criteria Quality criteria might be based on :\n internal connections  Internal density of edges Average internal degree   external connections  Expansion Ratio Cut   both  Conductance Normalized cut Modularity    Girvan Newman algorithm A common algorithm to find communities is the Girvan Newman algorithm. It identifies communities by progressively removing edges within the network. We’ll refer to betweenness as the “edge betweenness”. It is a score proportional to the number of shortest paths between pairs of nodes that go through this edge.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  from networkx.algorithms import community import itertools communities_generator = community.girvan_newman(G_karate) top_level_communities = next(communities_generator) next_level_communities = next(communities_generator) third_level_communities = next(communities_generator) # ... more level communities partition = {} for no_com, com in enumerate(top_level_communities): for c in com: partition[c]= no_com pos = nx.spring_layout(G_karate) plt.figure(figsize=(8, 8)) plt.axis(\u0026#39;off\u0026#39;) nx.draw_networkx_nodes(G_karate, pos, node_size=600, cmap=plt.cm.RdYlBu, node_color=list(partition.values())) nx.draw_networkx_edges(G_karate, pos, alpha=0.3) plt.show(G_karate)   Louvain Modularity Modularity is a measure of how well groups have been partitioned into clusters. The only thing we’re doing is to group the closest nodes so that we optimize the modularity criteria.\n1 2 3 4 5 6 7 8 9 10  import community partition = community.best_partition(G_karate) pos = nx.spring_layout(G_karate) plt.figure(figsize=(8, 8)) plt.axis(\u0026#39;off\u0026#39;) nx.draw_networkx_nodes(G_karate, pos, node_size=600, cmap=plt.cm.RdYlBu, node_color=list(partition.values())) nx.draw_networkx_edges(G_karate, pos, alpha=0.3) plt.show(G_karate)   Hierarchical Clustering The idea is to analyze community structures at different scales. We build the dendrogram bottom-up. We start with a cluster at each node and merge the two “closest” nodes.\n define the matrix of distances between each node identify hierarchical clustering  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  n = len(G_karate.nodes()) pcc_longueurs = list(nx.all_pairs_shortest_path_length(G_karate)) distances = np.zeros((n, n)) # distances[i, j] is the length of the shortest path between i and j for i in range(n): for j in range(n): distances[i, j] = pcc_longueurs[i][1][j] # --------- # from sklearn.cluster import AgglomerativeClustering clustering = AgglomerativeClustering( n_clusters=4, linkage=\u0026#39;average\u0026#39;, affinity=\u0026#39;precomputed\u0026#39;).fit_predict(distances) partition = {} for clu, node in zip(clustering, G_karate.nodes()): partition[node] = clu pos = nx.spring_layout(G_karate) plt.figure(figsize=(8, 8)) plt.axis(\u0026#39;off\u0026#39;) nx.draw_networkx_nodes(G_karate, pos, node_size=600, cmap=plt.cm.RdYlBu, node_color=list(partition.values())) nx.draw_networkx_edges(G_karate, pos, alpha=0.3) plt.show(G_karate) # nx.draw(G_karate, node_color = clustering)   Clustering Coefficient The clustering coefficient measures how well two nodes tend to cluster together.\n A local clustering coefficient\nThe local clustering coefficient is a ratio of the number of triangles centered at node i over the number of triples centered at node i. A global coefficient measures\nthe density of triangles (local clusters) in the graph  1 2 3 4 5  # List of local clustering coefficients list(nx.clustering(G_karate).values()) # Global clustering coefficient nx.average_clustering(G_karate)   Centrality algorithms ( SNA社会关系网络分析) Centrality measures how important a node is. This is not a clear definition, but it’s useful when we want to identify important web pages, bottlenecks in transportation networks…\nDegree Centrality (度中心度) Degree Centrality counts the number of walks of length 1 ending at node $$i$$ (直接相连). It measures incoming and outgoing relationship.Degree Centrality is used to identify the most influential persons on a social network for example\n例子：\n设想一下，你在微信上有个账号，那么是不是意味着微信好友数量越多，那么你的社交圈子越广？（假设都是真实好友，不考虑微商神马的奇葩情况）比如我有20个好友，那么意味着20个结点与我相连。如果你有50个好友，那么意味着你的点度中心度比我高，社交圈子比我广。这个就是点度中心性的概念。当然，刚才这个情况是无向图的情形，如果是有向图，需要考虑的出度和入度的问题。在刚才的基础上拓展一下，假如我们要比较你在微博和微信上的点度中心度，刚才的方法是否适用？如果说使用微信与微博的人数差不多，那么的确可以。但是如果说用户数量不一样呢？那么我们需要考虑到去规模化的问题，这就是标准化的点度中心性的理念。\n1 2  c_degree = nx.degree_centrality(G_karate) c_degree = list(c_degree.values())   PageRank Algorithm PageRank estimates a current node’s importance from its linked neighbors and then again from their respective neighbors.\nPageRank is** usually computed on directed graphs**. However, it will also execute on undirected graphs by converting each edge in the directed graph to two edges.\n你可以很轻易地找到最受欢迎的网页。但是，PageRank的思想认为，指标最好还需要考虑到指向你的那些网页。也就是说，**来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转。**这就是PageRank思想的精华，Google就是利用这一思想来给网站排名的。这里的思想依据和特征向量中心性其实是一致的(参考)。\n参考\n1 2 3 4 5 6 7 8 9 10  pr = nx.pagerank(G_karate, alpha=0.9) pr = list(pr.values()) pos = nx.spring_layout(G_karate) nx.draw(G_karate, cmap=plt.get_cmap(\u0026#39;inferno\u0026#39;), node_color=pr, node_size=600, pos=pos, with_labels=True)   Eigenvector Centrality (特征向量中心度) 特征向量得分较高意味着该节点与许多自身得分较高的节点相连接。\nEigenvector centrality is a measure of the influence of a node in a network. It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. Google\u0026rsquo;s PageRank is a variant of the Eigenvector centrality measure. Another closely related centrality measure is Katz centrality.\n1 2  c_eigenvector = nx.eigenvector_centrality(G_karate) c_eigenvector = list(c_eigenvector.values())   Closeness Centrality (接近度中心度) Closeness Centrality detects nodes that are can spread information efficiently through a graph.It can be used to identify fake news accounts or in terrorist cells to isolate the individuals that can spread information to the rest of the graph.\n例子：\n对于了解图论的朋友而言，最短路这个概念一定不陌生。我们设想一个实际生活中的场景，比如你要建一个大型的娱乐商场，你可能会希望周围的顾客到达这个商场的距离都可以尽可能地短。这个就涉及到接近中心性的概念，接近中心性的值为路径长度的倒数。接近中心性需要考量每个结点到其它结点的最短路的平均长度。也就是说，对于一个结点而言，它距离其它结点越近，那么它的中心度越高。一般来说，那种需要让尽可能多的人使用的设施，它的接近中心度一般是比较高的。\n1 2  c_closeness = nx.closeness_centrality(G_karate) list(c_closeness.values())   Betweenness Centrality (居间性中心度/中介中心性) Betweenness Centrality detects the amount of influence a node has over the flow of information in a graph. It is often used to find nodes that serve as a bridge from one part of a graph to another, for example in the package delivery processor in a telecommunication network, or in the propagation of fake news. The betweenness centrality measures the number of times a node acts as a bridge between two nodes\n例子:\n这个度量很有意思。这个有点像是我们身边那种社交达人，我们认识的不少朋友可能都是通过他/她认识的，这个人起到了中介的作用。中介中心性指的是一个结点担任其它两个结点之间最短路的桥梁的次数。一个结点充当“中介”的次数越高，它的中介中心度就越大。如果要考虑标准化的问题，可以用一个结点承担最短路桥梁的次数除以所有的路径数量。\n1 2  c_betweenness = nx.betweenness_centrality(G_karate) list(c_betweenness.values())   来源\ngraph learning There are two main tasks in graph learning :\n Link prediction Node labeling  Linke prediction (链路预测) Predictions are useful to predict future relations or missing edges when the graph is not fully observed for example.\ndifferent similarity scores\n Jaccard Coefficient\nCommon Neighbors =\u0026gt; a normalized common neighbors version Adamic-Adar index\ncommon elements with very large neighborhoods are less significant when predicting a connection between two nodes compared to elements shared between a small number of nodes Preferential attachement  How do we evaluate the link prediction? We must hide a subset of node pairs, and predict their links based on the rules defined above. We then evaluate the proportion of correct predictions for dense graphs, or use Area under the Curve criteria for Sparse graphs.\n1 2 3 4 5 6 7 8 9 10 11  from sklearn.metrics import roc_curve, roc_auc_score import matplotlib.pyplot as plt n = G_karate.number_of_nodes() m = G_karate.number_of_edges() print(\u0026#34;Number of nodes : %d\u0026#34; % n) print(\u0026#34;Number of edges : %d\u0026#34; % m) # 连通分量 ??? print(\u0026#34;Number of connected components : %d\u0026#34; % nx.number_connected_components(G_karate))    out:\nNumber of nodes : 34\nNumber of edges : 78\nNumber of connected components : 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14  # Remove 20% of the edges proportion_edges = 0.2 edge_subset = random.sample(G_karate.edges(), int(proportion_edges * G_karate.number_of_edges())) # Create a copy of the graph and remove the edges G_karate_train = G_karate.copy() G_karate_train.remove_edges_from(edge_subset) plt.figure(figsize=(12,8)) nx.draw(G_karate_train) edge_subset_size = len(list(edge_subset)) print(\u0026#34;Number of edges deleted : %d\u0026#34; % edge_subset_size) print(\u0026#34;Number of edges remaining : %d\u0026#34; % (m - edge_subset_size))    out:\nNumber of edges deleted : 15\nNumber of edges remaining : 63  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  # Make prediction using Jaccard Coefficient pred_jaccard = list(nx.jaccard_coefficient(G_karate_train)) \u0026#39;\u0026#39;\u0026#39; pred_jaccard: a first node, a second node and a jaccard score [ (0, 32, 0.15), (0, 33, 0.125), ... ] \u0026#39;\u0026#39;\u0026#39; # label_jaccard: whether the node tuple(n,v) is in edge_subset score_jaccard, label_jaccard = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_jaccard]) \u0026#39;\u0026#39;\u0026#39; Compute the ROC AUC Score fpr: False positive rate, tpr: True postive rate, auc: the area under the ROC curve \u0026#39;\u0026#39;\u0026#39; fpr_jaccard, tpr_jaccard, _ = roc_curve(label_jaccard, score_jaccard) auc_jaccard = roc_auc_score(label_jaccard, score_jaccard) # Prediction using Adamic Adar  pred_adamic = list(nx.adamic_adar_index(G_karate_train)) score_adamic, label_adamic = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_adamic]) # Compute the ROC AUC Score fpr_adamic, tpr_adamic, _ = roc_curve(label_adamic, score_adamic) auc_adamic = roc_auc_score(label_adamic, score_adamic) # Compute the Preferential Attachment pred_pref = list(nx.preferential_attachment(G_karate_train)) score_pref, label_pref = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_pref]) fpr_pref, tpr_pref, _ = roc_curve(label_pref, score_pref) auc_pref = roc_auc_score(label_pref, score_pref) plt.figure(figsize=(10,8)) plt.plot([0, 1], [0, 1], \u0026#39;k--\u0026#39;) plt.plot(fpr_jaccard, tpr_jaccard, label=\u0026#39;jaccard(auc: {:.3})\u0026#39;.format(auc_jaccard)) plt.plot(fpr_adamic, tpr_adamic, label=\u0026#39;adamic(auc: {:.3})\u0026#39;.format(auc_adamic)) plt.plot(fpr_pref, tpr_pref, label=\u0026#39;pref(auc: {:.3})\u0026#39;.format(auc_pref)) plt.xlabel(\u0026#39;False positive rate\u0026#39;) plt.ylabel(\u0026#39;True positive rate\u0026#39;) plt.title(\u0026#39;ROC curve\u0026#39;) plt.legend(loc=\u0026#39;best\u0026#39;) plt.show()   参考: 1, 2\nNode Labeling Given a graph where some nodes are not labeled, we want to predict their labels. This is in some sense a semi-supervised learning problem.\nOne common way to deal with such problems is to assume that there is a certain smoothness on the graph. The Smoothness assumption states that points connected via a path through high-density regions on the data are likely to have similar labels. This is the main hypothesis behind the Label Propagation Algorithm(LPA). LPA is a fast algorithm for finding communities in a graph using network structure alone as its guide, without any predefined objective function or prior information about the communities.\ngraph embedding we saw ways to learn in graphs, i.e. make node labeling and edge prediction. One of the limitations of graphs remains the absence of vector features. Just like in NLP, we face structured data. But just like in NLP, we can learn an embedding of the graph! There are several levels of embedding in a graph:\n Embedding graph components (nodes, edges, features…) (Node2Vec) Embedding sub-parts of a graph or a whole graph (Graph2Vec)  After learning an embedding, it can be used as features for several tasks :\n classification recommender systems  Embedding process Node Embedding According to the authors: “node2vec is an algorithmic framework for representational learning on graphs. Given any graph, it can learn continuous feature representations for the nodes, which can then be used for various downstream machine learning tasks.” How does Node2Vec work? The model learns low-dimensional representations for nodes by optimizing a neighborhood preserving objective, using random walks.\n1 2 3 4 5 6 7 8 9 10  from node2vec import Node2Vec node2vec = Node2Vec(G_karate, dimensions=64, walk_length=30, num_walks=200, workers=4) model = node2vec.fit(window=10, min_count=1, batch_words=4) # get the vector of a node model.wv.get_vector(\u0026#39;2\u0026#39;) # identify the most similar node model.wv.most_similar(\u0026#39;2\u0026#39;)   Edge Embedding 1 2 3 4 5 6 7 8 9 10  from node2vec.edges import HadamardEmbedder edges_embs = HadamardEmbedder(keyed_vectors=model.wv) # get the vector of an edge edges_embs[(\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;)] # identify the most similar edges edges_kv = edges_embs.as_keyed_vectors() edges_kv.most_similar(str((\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;)))   Graph Embedding There are also ways to embed a graph or a sub-graph directly. Graph embedding techniques take graphs and embed them in a lower-dimensional continuous latent space before passing that representation through a machine learning model.\nAn approach has been developed in the Graph2Vec paper and is useful to represent graphs or sub-graphs as vectors, thus allowing graph classification or graph similarity measures for example.\n","description":"","id":119,"section":"posts","tags":["学习笔记","图论","graph","complex network"],"title":"学习笔记-Graph Learning(图论) Tutorial","uri":"https://www.xunhs.cyou/posts/notes/124/"},{"content":" 12月份要去美国华盛顿特区参加AGU Fall Meeting，十一收到邀请函，之后就开始紧张的准备美签材料。在准备一星期之后，申请了10.15的签证面试。想着没去过广州，然后毛毛在那边，就想趁着周末早两天过去浪一圈~\n 12号深夜坐火车出发，13号上午10点半左右到的广州站，毛毛已经到出站口等我了。感觉有些意外，也有些感动的。因为她早上去上班了，穿着一身正装就过来了。她穿正装挺好看的，也显成熟，但是我总是看不习惯，可能是因为她在我心中一直都是小妹妹的缘故吧。到了她宿舍大约11点半左右了吧。跟她在附近买了一些菜，然后下厨给我炒了三个菜，味道非常棒~\n坐火车睡得不好，吃完饭后就去睡了一觉。稍微休息了一会就打算出去走走了。因为时间比较短，也没有计划走太远，就在附近的暨南大学的一个二级学院随便转了转。随便聊了聊，感觉也就没那么拘束了。之后到了接近午饭的时间，我们去的一家潮汕牛肉火锅。味道确实不错。因为中午吃的比较饱的缘故，火锅没有吃太多。吃完火锅后，毛子提议去看电影，她说她在这边工作这么久，一直都是一个人看电影，一个人吃饭，一个人上班，想让我陪她看电影。我说好呀。我们就在火锅店附近的一个电影院看的。期间我们去了一家宠物店，因为我说你可以买一只宠物陪着你呀。但是她因为每个月都要去几天杭州的缘故，那段时间不能陪它。看她的样子还是蛮喜欢宠物的。之后我们去看了电影，嗝嗝老师。印度电影，讲师生关系，教育方式的，整个电影院里大多数都是家长带着孩子来的，就我和毛毛两个人不是。。。哈哈。看完感觉还是挺不错的，笑点充足，剧情有些老套 。看完电影之后就回到宿舍休息了，碰到了她们同住的舍友。虽然都有独自的房间，但是感觉男女同住一个套间还是蛮尴尬的。晚上睡觉有些不自在。晚上2点多被蚊子叮起来了。忍了一会受不了了就起来开灯打蚊子。看自己身上被咬了红一片红一片的。反正睡不着，玩了会手机。听听歌，玩累了没一会就睡着了。\n第二天毛子请假了。带我玩了一整天。早上我早早的起床了。在客厅玩手机。看了看知乎上面签的一些分享。整理了一些常问问题和答案。地理大数据的双月报也整理好了发给陶老师。大约10点钟左右，毛子起来了，收拾一会就出发吃“早茶”啦。去的附近一个饭店，里面做了好多人。大多都是老头老太太，围在一桌聊天。偶尔有一桌是年轻人。毛子说这边吃早点的很多老人。从早上点单可以一直做到下午。嗯，这边老年人的生活方式确实悠闲。上的“早点”都很精致，口味偏清淡，味道很不错（我喜欢吃清淡）。这边的肠粉味道很好，刚开始我以为肠粉是加大肠的细粉或者宽粉，看到之后就知道理解错了。原来是类似于“肠”的。还有一个芋头蒸排骨。味道也不错。凤爪我没吃，她全包了。\n吃饭后大约中午了。我们做在附近坐公交转地铁，然后到了中山大学的一个小门，顺着人流就溜进去了（之后走大门不让进）。里面环境挺不错的。非常幽雅情景，绿化做的非常好，数目都很挺直，粗大，看着非常悠久的样子。建筑非常古典，与现代建筑样式不同，没有那种呆板的教学楼的样子。外表的红色墙体给人一种心旷神怡的感觉。像是一位坐在长椅上的老师，是让人肃然起敬的样子。“公园”里的雕塑都很有神韵，没有特别大的体积，却给人一种深深的自豪感。\n在学校的咖啡店坐了坐。点了一些水果和茶点。环境挺不错的，可能是中午的缘故，人不是很多。等了一段时间茶点还没有上，我们就取消然后离开了。从另一门出来就能看到中山大学的牌坊，立在大学门口和珠江之间。之后我们骑着摩拜单车，沿着珠江边向广州塔方向前行。一路海风相伴，非常舒适。第二天重温此路线依旧如此。\n没有多久到了广州塔。白天的广州塔，俨然是一座高耸的雕像。别致的曲线。细腻的建筑。没有灯光变化的修饰，也别无他色。我们坐着有轨电车沿着风景线坐到了终点站，然后又坐了回来。之后到了一个小吃街。我忘记是什么名字，具体的位置了。不过好吃的很多，煎饼果子。可口的甜点，好吃的披萨。走了一天真的好累，之后我们就回到了宿舍。晚上在宿舍毛毛就直接去睡觉了。我却精神了起来。看了一晚上的电视。看的《斗破苍穹》。电视剧翻拍的小说。我可以说不好看么。但是觉得电视剧能拍成这个样子其实也挺好的了，打发时间可以。还记得那句经典的台词：三十年河东，三十年河西，莫欺少年穷。\n第二天早上起来吃了肠粉，哦之前那个好像叫“粉肠”。又一个“人间美食”。没多久崔姐和文佳先后到了这边，我们稍微整理了一下，收拾下东西就出发前往大使馆附近了。当天的温度尚可，有点毛毛细雨。时而下，时而几滴划过。大使馆附近还是很繁华的。高耸的建筑插入云霄。拍不出那种感觉。不过现场看着实是美妙。我们找了一下粤菜馆吃饭。好像叫“点都德”，网上评论很高。但是菜单里面也都是“茶点”。已经好久没吃米饭和“菜”了。。。为了满足她俩，我们点了一桌“茶点”，可能是第二次吃的缘故，感觉这里的茶点没有昨天的好吃。不过味道还是不错的。\n吃饭后就就直接来到美国大使馆这边排队了。我们是预约的是三点半左右的，所以我们等到了两点多才排队。然后又是排队。里面的人更多。审查很严格。查基本证件、过安检、录指纹，然后才到了室内。最后又排很长的对准备最后的面试。我们三个是一起面试的，是一个很严肃的外国人给我们面的，不过面试我们的时候，感觉他并不是很严肃。而且说话挺温柔的。非常白净。简单问了我们三个几个问题，我们三个也几乎都是同时回答的，很有默契的样子。没有两分钟，面试官递过来一张黄色纸条，告诉我们通过了。哇，当时真的，非常开心。\n面试结束后非常开心、放松了。应她俩强烈要求，带着他们两个又去了中山大学，然后是广州塔的重复路线。不过这次看到的夜景也非常美妙。然后我们去了北京路步行街。熙熙攘攘的人群和灯火通明的闹市，走在路上非常开心。由于11点左右的火车，没有多停留便去赶火车了。和表妹简单告别，拖着疲惫的身体，来到广州东站真的吓一跳，这是我见过“人最多”的火车站候车厅了。我们没有等直接上火车了。\n第二天大约上午十点半左右到的武昌。我和崔到学校有11点半左右了，简单吃过饭就去午睡了。因为今天下午还有关老师的科技论文写作课。。上完课后去健身房转了转。拉伸了一下身体。还是器械。下拉器和pickup。2.5km跑步。一个小时下来很是舒服。回到宿舍之后整理了一下衣服，洗了一晚上的衣服。\n健身时长： 17/85\n","description":"","id":120,"section":"posts","tags":["签证","旅行","广州"],"title":"广州面签之行","uri":"https://www.xunhs.cyou/posts/journals/2018-10-17-%E5%B9%BF%E5%B7%9E%E9%9D%A2%E7%AD%BE%E4%B9%8B%E8%A1%8C/"},{"content":"过完十一长假，今天中午回学校。\n记得是9.30号中午去航海汽车站坐的车，因为堵车，晚上6、7点才到家，回到家爸妈正在吃饭，也就跟着简简单单吃了便饭。刚回到家是不习惯早睡的。翻来覆去睡不着觉。感觉这几天一直睡不好。最不好的就是4号晚上在大舅妈家，几个舅舅舅妈吵成一团，根本没法睡觉。\n这个长假过的非常自由、舒适了，除了AGU会议和基金评审的事，真的没做别的事情。饮食上，基本是饭来张口，想吃什么跟老妈说就好，老妈做的也都是平时喜欢吃的菜。不过不知道是菜中辣椒太多还是家里太干燥的缘故，这几天一直在上火，鼻子（鼻腔）非常干。其次是帮家里干活，出锅、拌高粱等零零散散的体力活做了很多，基本上老妈做的体力活我都代劳了。发现这段时间健身还是有效果的，没有之前做一点体力活就酸痛了。论文上真的不想说啥，本来打算每天都写一点，争取过完节写完，我就呵呵了。自己放假一个字都没有动。以后还是不要太自信为好。当然，你会问我，你这，啥也没做，那你在家平时干啥\u0026mdash;-玩游戏。王者荣耀和海岛奇兵。这要是这两个。王者荣耀自己连胜到钻石，在钻石发现输一把赢一把非常没劲，这个时候真的就需要队友一起上分了。自己打也没劲，之后的几天就没有玩。海岛奇兵每天基本刷刷任务，抢夺图上的几个资源岛。。。所以说，这几天是，真的，自由、舒适。。。。\n其实，这种自由和舒适总是感觉非常空虚的。并没有觉得劳累之后的舒适，并没有觉得被困了好久的舒适，而是一种放纵、放肆，而并没有无忧无虑的那种。有时候，真的想像劝说别人那样的自由和洒脱。不用考虑年纪，不用考虑学历，不用考虑时间成本，不用考虑。。。每天总觉得自己时间不多了。好比一个将死之人。每天工作的时候明明有计划，却总是完不成，飘飘忽忽。无所忌惮。。。好比一个植物人。。麻木。\n我是很想改变这种状态。\n啊，中午就到学校了，去食堂吃了个饭，洗完衣服，睡了午觉，然后就去图书馆了。逼自己写论文。发现真的真的憋不出来。。写不出社会意义之类的话。。看了一篇中文摘要，龙瀛的什么“大模式”框架？讲大数据在城市科学中的应用的一些综述，感觉还是蛮好的，可以作为框架和找研究点来看。已经收率在zotero中了。\n晚上坚持去健身房了。为自己又坚持一天做出的努力打call。我知道坚持做一件事情非常困难，但是只要是在改变，就算是进步。相比复杂的心理活动，可能简简单单的坚持一件事情更加困难得多。今天健身房人炒鸡少，各种器械随便用。今天做的项目有：2.5km、下拉器，上推器，还有一个什么chin up的器械，也是练习背部肌肉的。\n晚上回宿舍，接着看完了《刺客伍六七》，这部国漫真的很不错，搞笑，各种梗，广东话，很有意思的。第一季加上番外有14，每集10分钟左右的样子。坐等第二季更新啦。后来捣鼓了一下wordpress博客，以后打算就用wordpress啦，虽然后台卡顿了一些，但是毕竟用的人多，出问题也好解决啦。\n 健身时长：15/85\n","description":"","id":121,"section":"posts","tags":["总结","假期"],"title":"十一长假总结","uri":"https://www.xunhs.cyou/posts/journals/2018-10-06-%E5%8D%81%E4%B8%80%E9%95%BF%E5%81%87%E6%80%BB%E7%BB%93/"},{"content":" 记事。\n 做了什么事情   搭建Typecho博客，并坚持每天写日报（计划、工作、健身）两个星期；博客备份。\n  完善博客框架，包括博客主题、插件等。主题偏文艺风，插件不多，日常插件，每篇日常配图；完善博客内容，除日报外，还包括一些资料，一些随笔，随笔偏摘抄，记录个人比较喜欢的东西（Personal Preferences），资料是自己在查找文献、知乎等资料的时候做的相关整理，方便日后查看。\n  熟悉雅思考试，确定雅思考试时间，制定全局学习计划。\n  在全局计划的控制范围内，制定了听力和写作的具体到天的学习计划。\n  熟悉地理探测器，阅读相关文献，了解地理探测器都是怎么用的。\n  坚持健身，总健身时长7小时。\n  确定论文写作完成之间，并制定写作的计划。\n  非计划中任务：\n W老师基金预算整理，和M师兄一起。 W老师寨卡病毒相关论文审阅。 折腾黑苹果。dell机没成功。在小米Pro上成功了。苹果系统真的很好看，不过用起来还是要习惯一段时间。    完成情况总结 总体感觉完成情况中等偏好，前几天和后几天完成情况不好，中期比较好。前几天没计划好日工作量，后几天有些偷懒了。其实算算这14天自己还是做了蛮多事情的，当然就很充实，很有意义啦。。。下个半月着重完成论文写作、还有英语学习上。还有就是每天早上去公司不想做事情，比较浮躁，借了一本曼昆的经济学基础，可以在早上的时间看一看，权当打发时间了~单词要坚持背啊，你的单词量和错误率真的是奇差了。。抽时间一定要感受一下真题带来的痛苦。。。\n这两天开学，来了很多新学生。原本安静的校园突然熙熙攘攘的都是人。。虽然每天跑公司，但是还是能明显感觉到学校的变化。想起自己大学入学的时候的场景，但是忘记了当时是怎样的心情。或平淡、或无所谓。又想起了自己研究生入学的时候的场景，心中踌躇满志，想学业有成，想收获感情。说实话其实自己研究生这两年读的是有些痛苦的，但是着实在这两年里自己学会了很多东西，感情上，生活上，种种。心性也发生变化了。大学的时候庸庸碌碌，各种事都抱着无所谓的态度。读研之后，浮躁了很多，想什么都比别人好，能力上却比别人差很多，知道自己差却不去行动。就这样自不量力、浮躁了两三年。为什么是三年呢，因为博一很长一段时间也是这种状态，只是转换来转换去，心里确实有些累了。放心吧，不是你读不懂，我也不知道我在说什么。感情上始终都是一个人，没有确定那种关系的，匆匆碌碌身边路过几个女孩子，有停留的、有问候的、有吻你的、你却始终不为所动。再也没有研究生入学时的那种向往，那种愿为之疯狂的力量。始终一个人，始终觉得自己孤独，却不知道只是自己闲的蛋疼而已。你TM忙起来哪有功夫像这个。得，说好的半月报，都快成研究生生活总结大会了。碎觉吧，说好写15分钟的，硬生生写了45分钟了。撤了撤了。\n","description":"","id":122,"section":"posts","tags":["计划"],"title":"2018.8.20 - 2018.9.2 / 1st-half-month Report","uri":"https://www.xunhs.cyou/posts/journals/2018-09-02-2018-8-20-2018-9-2___1st-half-month_report/"},{"content":"W老师，您好。\n转眼2018年又过去了接近大半，而我目前却没有长远的目标，没有较明确的方向，说起来实属不应该。周五在您办公室，听您一席话之后，确实感触颇多，自己的状态、认知也认的更清一些。周末这两天去长江大桥转了转，在江边坐了好久，一直在思考人生的意义，虽然目前对我而言还是很抽象的概念，如果一时之间能够想明白也不至于迷茫这么久吧；周天也跟父亲、母亲聊了很久，关于以后的打算等等。想着以后的事情想不明白的话，就等有时间了在想，现在的话先把到年底的计划做一下。我是一个非常懒散的人，所以您提的定制计划表的这个方法可谓是非常适用的。我算了一下，现在是2018年8月19日，到2018年12月31日还有四个半月左右，准确来讲是135天，所以我为这135天做了一个计划及实现方法（过程）：\n 计划一： 8月20日-9月16日（28天），完成有关共享单车的实验及文章初稿，准备润色及投稿。 计划二： 9月17日-10月31日（44天），完成AGU会议的初稿或海报，以及出国准备的资料、签证办理等。 计划三：健身计划。我前年的时候跟同学一起办过一次健身卡，当时连续去过两个月左右，虽然没能坚持下来，但是我觉得收获还是蛮大的，尤其是心理调节方面，当时开朗了许多；因此我这次又办理一个健身卡，为了能够坚持下去，我同时制定了这样的计划：从8月20日至12月31日的135天内，锻炼时长最低标准不少于100个小时， 一次锻炼时间在一个小时（最少）到两个小时左右。同样我希望这个健身计划更多的是可以开阔我的心性（不要那么浮躁）以及培养一种坚持的精神，同时可以锻炼身体（有点驼背，同时有点发胖了）。 计划四：英语学习。记得去年在您车上，您当时就提到过关于出国联合培养的想法。现在想来，不管之前的打算如何，至少在往后的三年内至少拼一把，争取一下出国联合培养的机会。因此，这就涉及到英语学习（托福考试等）。其实这次在写草稿的时候就觉得吃力很多，半天憋不出一句话来，发现只是看英文文献真的是不管用的。由于之前没有准备过类似考试，因此我打算给自己留多一些备考时间。今年下半年准备备考，明天五月份或六月份进行第一次考试，完整备考期大约10个月左右。今年下半年先从听力（听力最差）和写作（因为要写文章，可以同步进行）开始，后期口语与阅读同时跟进。关于各科目的详细学习希望在在10月初（大约国庆节的时候）作更加细致的计划表。 计划五：11月1日-12月31日。专业知识学习。关于机器学习的内容（理论和编程实践）要更加精通，可以通过以往的面试题来测试；了解城市科学(Urban Science)的基础、研究方向、研究现状，可以通过文献综述来测试；掌握遥感基础。我记得最初接触遥感是在大三上的一节课《遥感导论》，当时觉得遥感都是纯理论的东西，所以并不喜欢，直到现在仍然是不懂（虽然师兄师姐都做这个）。还有就是作为一个GISer不懂遥感真的感觉有些羞愧。因此需要好好补充这方面的基础。  这五个计划仍然是比较抽象的计划，很多其他事情和时间点（比如 12月初去参加AGU等）都没有列入，中间也会穿插很多事情等。因此我打算一天一小计划，一周一总结，一月一报的形式来总结自己小阶段的成果（结果），每次的月报都会发至您的邮箱，并且开一个博客记录这些内容，以后看这些东西应该也会很有感触吧。\nW老师，非常感谢您在百忙之中仍然对我十分的用心，关心我的生活和学习情况，这对于我来说是莫大的感激。我是您最笨的学生，虽然做不到成为您最用功的学生，但是我会努力做好，不辜负与您师生的时光。\nHS，敬上。\n2018.8.19\n","description":"","id":123,"section":"posts","tags":["信件","计划"],"title":"2018年下半年计划表----至W老师邮件","uri":"https://www.xunhs.cyou/posts/journals/2018-08-22-2018%E5%B9%B4%E4%B8%8B%E5%8D%8A%E5%B9%B4%E8%AE%A1%E5%88%92%E8%A1%A8-%E8%87%B3w%E8%80%81%E5%B8%88%E9%82%AE%E4%BB%B6/"},{"content":"去年（2017）的最后几天里，我选择逃离到其他地方。\n第一天去了表妹XX家里。有人说，做事都是有目的的，但是这次去XX家，我说不出来我的目的，后来我甚至怀疑、抱怨此行。是的，我丝毫没有精神，不在状态。遇见CYM，礼貌性微笑打招呼，甚至没说半句话，我不知道应该对她有什么样的状态，什么样的表情。跟着XX出来，在街上、在商场、在星巴克，丝毫不知道我在做什么，她在说什么。晚上，我在她上班的地方等她开完会，坐在沙发上昏昏郁郁两个小时过去了。她挺忙的，我挺闲的。\n不过有一件事情非常开心，我碰到吉他了。她简单的教我玩了两下吉他。非常的开心。我喜欢听琴弦的声音，特别是2和1的声音。我有学吉他的打算，至少在我写这篇的时候还很强烈。\n第二天我逃到了家里。妈妈因为我的到来很意外，因为平时回家我都会事先通知她们，然后妈妈做好中午饭等我回家。我没有和爸妈亲口说过想念之类的词，我只是对着妈妈笑，听着她说着什么，我只是笑。\n时间过得很快，在家呆坐了两天，做了点体力活，今天回到学校。他没在，宿舍依旧冰冰冷冷。中午有些饿，买的零食没吃两口，躺下睡午觉，但好像没睡着。\n晚上饭后把衣服洗净，坐在电脑前把hexo在新电脑上重新搭建起来。起先仅仅想写一下新年愿望的（找不到了），写着写着就絮叨到现在了。隔壁不知道哪个宿舍传来男男女女“鱼龙混杂”的笑声。\n回首一下2017年吧。先罗列自认为比较重要的事情：\n 2月， 新年 3月， 写毕设，事业单位初试（后来没进面试），结识表妹XX 4月， 考博初试， 去成都找小志玩 5月， 考博复试， 毕设答辩 6月， 硕士毕业了，YW 7月， 去上海三天（以开会学习为由） 8月， ZMY 9月， 博士开学 11月， 去北京两天，去长沙三天  这样想想其实也做了挺多事情嘛。。。还有很多不太起眼的细节事件吧，现在没有太想起。\n最后的两个月有点消极，特别是12月，很消极。同时，在公司和她开始聊天了。每天都能遇到她，心里还是会荡起涟漪。都这么久了，自己竟然还会这个样子。\n好啦好啦，2017年过的还算圆满了。本命年过去了，2018-1993=25，我也25了。前两天还在朋友圈流行18岁照片，是的，最后一批90后也18岁成年了。\n2018年伊始，说点好听的吧。\n 愿你有酒有肉有姑娘，能贫能笑能干架，此生纵情豁达\n愿贪吃不胖，愿长生不老，愿美梦不空，愿深情不负\n所有快乐，无需假装\n此生尽兴，赤诚善良\n 新年心愿：\n 一篇paper\n玩会神经网络，入门深度学习\n玩会吉他\n戒掉一直以来的坏毛病\n学会释怀\n托福（Orz,这个好难）\n遇到心爱之人（同样难，）\n","description":"","id":124,"section":"posts","tags":null,"title":"写在2018年的第一天","uri":"https://www.xunhs.cyou/posts/journals/2018-01-01-%E5%86%99%E5%9C%A82018%E5%B9%B4%E7%9A%84%E7%AC%AC%E4%B8%80%E5%A4%A9/"}]