---
layout: post
cid: 124
title: 学习笔记-Graph Learning(图论) Tutorial
slug: 124
date: 2018-10-22T08:53:13+00:00
status: publish
author: Ethan
categories:
  - 收藏
tags:
  - 学习笔记
  - 图论
  - graph
  - complex network
abbrlink: 2ff0e437
---


> 参考了[这里](https://www.jiqizhixin.com/articles/2019-08-03-3)，[这里](https://networkx.github.io/documentation/stable/index.html)，主要是整理复制的[这里](https://maelfabien.github.io/machinelearning/graph_3/#)

<!--more-->

目录  

[TOC]


## Introduction to Graph

### What is a Graph?


- Graphs can be used to represent:
	- social networks
	- web pages
	- biological networks
	- …
- What can we do on a graph?
	- study topology and connectivity
	- community detection
	- identification of central nodes
	- …


### pre-built graph-karate 

What does this graph represent? “A social network of a karate club was studied by Wayne W. Zachary for a period of three years from 1970 to 1972. The network captures 34 members of a karate club, documenting links between pairs of members who interacted outside the club. During the study, a conflict arose between the administrator “John A” and instructor “Mr. Hi” (pseudonyms), which led to the split of the club into two. Half of the members formed a new club around Mr. Hi; members from the other part found a new instructor or gave up karate. Based on collected data Zachary correctly assigned all but one member of the club to the groups they joined after the split.”


```python
import numpy as np
import random
import networkx as nx
from IPython.display import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


G_karate = nx.karate_club_graph()
pos = nx.spring_layout(G_karate);
nx.draw(G_karate, cmap = plt.get_cmap('rainbow'), with_labels=True, pos=pos)

```

### retrieve the basic information from this graph
- On average, each person in the graph is connected to 4.6 persons.

```python
degree_sequence = list(G_karate.degree())
nb_nodes = len(G_karate.nodes())
nb_arr = len(G_karate.edges())

avg_degree = np.mean(np.array(degree_sequence)[:,1])
med_degree = np.median(np.array(degree_sequence)[:,1])

max_degree = max(np.array(degree_sequence)[:,1])
min_degree = np.min(np.array(degree_sequence)[:,1])

print("Number of nodes : " + str(nb_nodes))
print("Number of edges : " + str(nb_arr))

print("Maximum degree : " + str(max_degree))
print("Minimum degree : " + str(min_degree))

print("Average degree : " + str(avg_degree))
print("Median degree : " + str(med_degree))

```

- out:
	```
	Number of nodes : 34
	Number of edges : 78
	Maximum degree : 17
	Minimum degree : 1
	Average degree : 4.588235294117647
	Median degree : 3.0

	```

### plot the histogram of the degrees

the histograms of degrees are quite important to determine the kind of graph we are looking at

```python
degree_freq = np.array(nx.degree_histogram(G_karate)).astype('float')

plt.figure(figsize=(12, 8))
plt.stem(degree_freq)
plt.ylabel("Frequence")
plt.xlabel("Degree")
plt.show()

```
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309174203.png)

## Graph Analysis

- 2020.3.10 **不知道作者为啥这里突然讲到随机图，这个有蛮难的。Tutorial跳过。**
- We can analyze a graph at different scales:
    - using the global properties of the network
    - using communities and clusters
    - or by looking at individual nodes

- The main descriptive measures we’ll explore will be:
    - the degree distribution
    - the clustering coefficient
    - the “small world” phenomena
    - the centrality of a node
    - the diameter of the graph …


### Erdos-Rényi model([ER随机网络模型](https://wiki.swarma.net/index.php/ER%E9%9A%8F%E6%9C%BA%E5%9B%BE%E6%A8%A1%E5%9E%8B))
#### Defination
In an Erdos-Rényi model, we build a random graph model with n nodes. The graph is generated by drawing an edge between a pair of nodes (i,j) independently with probability p. We, therefore, have 2 parameters: n the number of nodes and p
G(n, p)模型的两个主要假设（连边独立，每条连边可能性相同）可能不适合为某些现实生活中的现象建模。尤其是ER图的度分布没有厚尾，而许多实际网络的分布是厚尾的。此外，与许多社交网络不同，ER图集聚系数较低。其他较好的替代模型可见BA网络模型（Barabási–Albert model）和WS小世界网络模型（Watts and Strogatz model）

```python
n = 150
p = 0.1
G_erdos = nx.erdos_renyi_graph(n,p, seed =100)

# Plot the graph
plt.figure(figsize=(12,8))
nx.draw(G_erdos, node_size=10)

```

#### Degree distribution
Let pk the probability that a randomly selected node has a degree k. Due to the random way the graphs are built, the distribution of the degrees of the graph is binomial. The distribution of the number of degrees per node should be close to the mean. The probability of high nodes decreases exponentially.


```python
degree_freq = np.array(nx.degree_histogram(G_erdos)).astype('float')

plt.figure(figsize=(12, 8))
plt.stem(degree_freq)
plt.ylabel("Frequence")
plt.xlabel("Degree")
plt.show()

```
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309174335.png)

#### Descriptive statistics
- The average degree is given by n×p. 
- The degree expectation is given by (n−1)×p
- The maximum degree is concentrated around the average


```python
# Get the list of the degrees
degree_sequence_erdos = list(G_erdos.degree())

nb_nodes = len(G_erdos.nodes())
nb_arr = len(G_erdos.edges())

avg_degree = np.mean(np.array(degree_sequence_erdos)[:,1])
med_degree = np.median(np.array(degree_sequence_erdos)[:,1])

max_degree = max(np.array(degree_sequence_erdos)[:,1])
min_degree = np.min(np.array(degree_sequence_erdos)[:,1])

esp_degree = (nb_nodes-1)*p

print("Number of nodes : " + str(nb_nodes))
print("Number of edges : " + str(nb_arr))

print("Maximum degree : " + str(max_degree))
print("Minimum degree : " + str(min_degree))

print("Average degree : " + str(avg_degree))
print("Expected degree : " + str(esp_degree))
print("Median degree : " + str(med_degree))
```
- out:
	Number of nodes : 150
	Number of edges : 1135
	Maximum degree : 25
	Minimum degree : 8
	Average degree : 15.133333333333333
	Expected degree : 14.9
	Median degree : 15.0

### Barabasi-Albert model (无标度网络)
#### Definition
这个图的目标是建模优先连接（preferential attachment），真实世界网络中常会观察到这一点。（注：优先连接是指根据各个个体或对象已有的量来分配某个量，这通常会进一步加大优势个体的优势。）

无标度网络(scale-free network)是一种度分布（即对复杂网络中节点度数的总体描述）服从或者接近幂律分布的复杂网络。
- 无标度网络的特性是普遍存在度远高于平均值的节点。度最高的节点通常称为枢纽（hub），被认为在网络中起到特殊作用
- 无标度网络的另一个重要特性是随节点度数升高而降低的聚集系数(clustering coefficient)分布。这个分布也服从幂律分布。
- 许多真实世界的网络被认为是无标度的

```python
# Generate the graph
n = 150
m = 3
G_barabasi = nx.barabasi_albert_graph(n,m)

# Plot the graph
plt.figure(figsize=(12,8))
nx.draw(G_barabasi, node_size=10)


```

#### Degree distribution
- The distribution is now heavy-tailed. There is a large number of nodes that have a small degree, but a significant number of nodes have a high degree.
- The distribution is said to be scale-free, in the sense that the average degree is not informative.

```python
degree_freq = np.array(nx.degree_histogram(G_barabasi)).astype('float')

plt.figure(figsize=(12, 8))
plt.stem(degree_freq)
plt.ylabel("Frequence")
plt.xlabel("Degree")
plt.show()
```

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309174521.png)

#### Descriptive statistics
```python
# Get the list of the degrees
degree_sequence_erdos = list(G_erdos.degree())

nb_nodes = len(G_erdos.nodes())
nb_arr = len(G_erdos.edges())

avg_degree = np.mean(np.array(degree_sequence_erdos)[:,1])
med_degree = np.median(np.array(degree_sequence_erdos)[:,1])

max_degree = max(np.array(degree_sequence_erdos)[:,1])
min_degree = np.min(np.array(degree_sequence_erdos)[:,1])

esp_degree = (nb_nodes-1)*p

print("Number of nodes : " + str(nb_nodes))
print("Number of edges : " + str(nb_arr))

print("Maximum degree : " + str(max_degree))
print("Minimum degree : " + str(min_degree))

print("Average degree : " + str(avg_degree))
print("Expected degree : " + str(esp_degree))
print("Median degree : " + str(med_degree))```

- out:
	Number of nodes : 150
	Number of edges : 1135
	Maximum degree : 25
	Minimum degree : 8
	Average degree : 15.133333333333333
	Expected degree : 14.9
	Median degree : 15.0

## Graph Algorithms
explore the main graph algorithms and several use cases in a visual way with direct examples in Python.

- To understand the context, here are some use cases for graph algorithms :
    - real-time fraud detection
    - real-time recommendations
    - streamline regulatory compliance
    - management and monitoring of complex networks
    - identity and access management
    - social applications/features
    - …

- 3 main categories of graph algorithms are currently supported in most frameworks (networkx in Python, or Neo4J for example) :
    - pathfinding: identify the optimal path, evaluate route availability and quality. This can be used to identify the quickest route or traffic routing for example.
    - **centrality**: determine the importance of the nodes in the network. This can be used to identify influencers in social media for example or identify potential attack targets in a network.
    - **community detection**: evaluate how a group is clustered or partitioned. This can be used to segment customers and detect fraud for example.


### Pathfinding and Graph Search Algorithms

- Pathfinding algorithms try to find the shortest path between two nodes by minimizing the number of hops.
- Search Algorithms does not give the shortest path. Instead, they explore graphs considering neighbors or depths of a graph.

#### Search Algorithms

- Breadth-First Search (BFS) that explore each node’s neighbor first, then neighbors or the neighbors…
- Depth-First Search (DFS) which try to go down a path as much as possible, and visit new neighbors if possible

根据可用性和质量等条件确定最优路径。我们也将搜索算法包含在这一类别中。这可用于确定最快路由或流量路由。
- 寻路算法是通过最小化跳（hop）的数量来**寻找两个节点之间的最短路径**。
	- 最短路径： 最短路径计算的是一对节点之间的最短的加权（如果图有加权的话）路径。这可用于确定最优的驾驶方向或社交网络上两个人之间的分离程度。
- 搜索算法不是给出最短路径，而是根据图的相邻情况或深度来探索图。这可用于信息检索。
	- 宽度优先搜索（BFS）：首先探索每个节点的相邻节点，然后探索相邻节点的相邻节点
	- 深度优先搜索（DFS）：会尝试尽可能地深入一条路径，如有可能便访问新的相邻节点
	
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309084645.png)


#### Pathfinding algorithms
- Shortest Path
calculates the shortest weighted (if the graph is weighted) path between a pair of nodes. It is used to identify optimal driving directions or degree of separation between two people on a social network for example.
- Single-Source Shortest Path  
The Single Source Shortest Path (SSSP) computes the shortest path from a given node to all other nodes in the graph. It is often used for routing protocol for IP networks for example.
- All Pairs Shortest Path  
The All Pairs Shortest Path (APSP) algorithm computes the shortest path length between all pairs of nodes. It is quicker than calling the Single Source Shortest Path for every pair of nodes.


```python
# Returns the shortest path between each node
nx.shortest_path(G_karate)
# Returns shortest path length between each node
list(nx.all_pairs_shortest_path_length(G_karate))
```

#### Minimum Weight Spanning Tree (最小生成树)
- [关于图的几个概念定义：](https://blog.csdn.net/luoshixian099/article/details/51908175?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)
连通图：在无向图中，若任意两个顶点$$v_i$$与$$v_j$$都有路径相通，则称该无向图为连通图。  
强连通图：在有向图中，若任意两个顶点$$v_i$$与$$v_j$$都有路径相通，则称该有向图为强连通图。  
连通网：在连通图中，若图的边具有一定的意义，每一条边都对应着一个数，称为权；权代表着连接连个顶点的代价，称这种连通图叫做连通网。  
生成树：一个连通图的生成树是指一个连通子图，**它含有图中全部$$n$$个顶点，但只有足以构成一棵树的$$n-1$$条边。**一颗有$$n$$个顶点的生成树有且仅有$$n-1$$条边，如果生成树中再添加一条边，则必定成环。  
最小生成树：在连通网的所有生成树中，**所有边的代价和最小**的生成树，称为最小生成树。  

- 两种算法
	- Kruskal算法
	- Prim算法
- 意义（案例）
	- 网络G表示n各城市之间的通信线路网线路（其中顶点表示城市，边表示两个城市之间的通信线路，边上的权值表示线路的长度或造价。可通过求该网络的最小生成树达到求解通信线路或总代价最小的最佳方案([参考](https://www.zhihu.com/question/41970266))。
	- 走遍全部城市的车费或者路程最小。


![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310162514.png)

```python
from networkx.algorithms import tree
mst = tree.minimum_spanning_edges(G_karate, algorithm='prim', data=False)
edgelist = list(mst);edgelist
```

### Community detection(社区发现/检测)

- 2020.3.10 [从具体的任务来看我们不妨把社区发现分成以下四类](https://www.zhihu.com/question/29042018)：
	- 图分割
		图分割的相关工作认为社区的成因是因为网络连边之间存在“强弱连边关系”，主要有两点：“三元闭包”关系下演化出来的、节点之间相互博弈生成的。因此在图分割视角下的科学问题就是“如何识别强弱连边关系”，代表的方法有betweenness、min-cut和优化Modularity的方法、CPM等。其中对Modulairty的优化可以更好的解释什么是好的社区，以后的很多方法包括基于统计模型的block model都可以最终归结为是优化Modularity的目标函数。Louvain则是将Modularity的优化进行了scalable，可以快速的应用在大规模的网络上。Modularity的缺点也很明显就是存在识别极限的问题。
	- 图聚类
		<p>图聚类的相关工作大致的思路是embedding+聚类。代表的方法是<b>谱聚类</b>。它关注的科学问题是“节点的空间映射问题”。其实Newman自己也证明了Modularity其实是对模块度矩阵进行一个谱分析。这也体现了Modularity方法的普适性和良好的可解释性。</p>
	- 节点表达
		<p>然而，上述的方法都是从建模网络连边密度入手的，没有实际建模网络连边的生成过程。而且上述方法认为每个节点仅仅属于一个社区，忽略了社区中存在的重叠现象，因此，节点表达的思路就是认为每个节点都是一个k个社区的assignment的表达。这里的科学问题就是“如何通过观测网络学习得到这种节点的隐式表达”，借鉴LDA的思想Blei等人提出了Mixture membership block model（<b>MMSB</b>），这种基于概率统计方法的生成式模型更好的解释了节点之间的边是如何生成的以及整个网络是如何生成的，通过机器学习来学到隐变量。我们就得到了网络的重叠划分。这种方法对网络的解释性更好，唯一的缺点就是优化速度慢，可能会优化到局部最优。2013年Gopalan等人已经将该模型进行了加速可以处理百万规模的网络。除此之外的生成模型还有利用poisson分布建模multigraph的一些工作，这样的模型相对简单而且假设限制比MMSB要小一些，比如<b>Brain Ball 2011 PRE的工作</b>和<b>Brain Karrer 的Degree corrected</b>的相关工作。</p>
	- 广义社区发现
		<p>除此之外，网络中可能共存除社区结构之外的其他聚团结构，比如二部结构、中心-边缘结构等，因此，广义社区发现的任务就是发现网络中所有的连边模式。比如经典的<b>Mixture mode</b>l以及Newman等人2015年的相关工作。</p>



#### Defination  
Community detection is a process by which we partition the nodes into a set of groups/clusters according to a certain quality criterion. It is typically used to identify social communities, customers behaviors or web pages topics.
The process to identify communities is the following:

- define a quality criterion
- design an algorithm to optimize this criterion

#### Quality criteria 
Quality criteria might be based on :
- internal connections
    - Internal density of edges
    - Average internal degree
- external connections
    - Expansion 
    - Ratio Cut
- both
    - Conductance 
    - Normalized cut
    - Modularity 

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310174402.png)
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310174450.png)




#### Girvan Newman algorithm
A common algorithm to find communities is the Girvan Newman algorithm. It identifies communities by progressively removing edges within the network. We’ll refer to **betweenness** as the “edge betweenness”. It is **a score proportional to the number of shortest paths between pairs of nodes that go through this edge**.


```python

from networkx.algorithms import community 
import itertools

communities_generator = community.girvan_newman(G_karate)

top_level_communities = next(communities_generator) 
next_level_communities = next(communities_generator)
third_level_communities = next(communities_generator)
# ... more level communities

partition = {}
for no_com, com in enumerate(top_level_communities):
    for c in com:
        partition[c]= no_com

pos = nx.spring_layout(G_karate)
plt.figure(figsize=(8, 8))
plt.axis('off')
nx.draw_networkx_nodes(G_karate, pos,   
node_size=600, cmap=plt.cm.RdYlBu,   
node_color=list(partition.values()))
nx.draw_networkx_edges(G_karate, pos, alpha=0.3)
plt.show(G_karate)

```
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309174923.png)

#### Louvain Modularity
Modularity is a measure of how well groups have been partitioned into clusters. The only thing we’re doing is to group the closest nodes so that we optimize the modularity criteria.

```python

import community
partition = community.best_partition(G_karate)

pos = nx.spring_layout(G_karate)
plt.figure(figsize=(8, 8))
plt.axis('off')
nx.draw_networkx_nodes(G_karate, pos, node_size=600, cmap=plt.cm.RdYlBu, node_color=list(partition.values()))
nx.draw_networkx_edges(G_karate, pos, alpha=0.3)
plt.show(G_karate)
```

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309175013.png)

#### Hierarchical Clustering
The idea is to analyze community structures at different scales. We build the dendrogram bottom-up. We start with a cluster at each node and merge the two “closest” nodes.

- define the matrix of distances between each node
- identify hierarchical clustering

```python
n = len(G_karate.nodes())
pcc_longueurs = list(nx.all_pairs_shortest_path_length(G_karate))
distances = np.zeros((n, n))

# distances[i, j] is the length of the shortest path between i and j
for i in range(n):
    for j in range(n):
        distances[i, j] = pcc_longueurs[i][1][j]

# --------- #
from sklearn.cluster import AgglomerativeClustering
clustering = AgglomerativeClustering(
    n_clusters=4, linkage='average',
    affinity='precomputed').fit_predict(distances)

partition = {}
for clu, node in zip(clustering, G_karate.nodes()):
    partition[node] = clu

pos = nx.spring_layout(G_karate)
plt.figure(figsize=(8, 8))
plt.axis('off')
nx.draw_networkx_nodes(G_karate,
                       pos,
                       node_size=600,
                       cmap=plt.cm.RdYlBu,
                       node_color=list(partition.values()))
nx.draw_networkx_edges(G_karate, pos, alpha=0.3)
plt.show(G_karate)

# nx.draw(G_karate,  node_color = clustering)
```

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309175100.png)

#### Clustering Coefficient
The clustering coefficient measures how well two nodes tend to cluster together.
- A local clustering coefficient  
The local clustering coefficient is a ratio of the number of triangles centered at node i over the number of triples centered at node i.
- A global coefficient measures  
the density of triangles (local clusters) in the graph


```python
# List of local clustering coefficients
list(nx.clustering(G_karate).values())
# Global clustering coefficient
nx.average_clustering(G_karate)

```

### Centrality algorithms ( SNA社会关系网络分析)
Centrality measures how important a node is. This is not a clear definition, but it’s useful when we want to identify important web pages, bottlenecks in transportation networks…






#### Degree Centrality (度中心度)   
Degree Centrality counts the number of walks of length 1 ending at node $$i$$ (直接相连). It measures incoming and outgoing relationship.Degree Centrality is used to identify the most influential persons on a social network for example

[例子](https://www.zhihu.com/question/22610633/answer/143644471)：
设想一下，你在微信上有个账号，那么是不是意味着微信好友数量越多，那么你的社交圈子越广？（假设都是真实好友，不考虑微商神马的奇葩情况）比如我有20个好友，那么意味着20个结点与我相连。如果你有50个好友，那么意味着你的点度中心度比我高，**社交圈子比我广**。这个就是点度中心性的概念。当然，刚才这个情况是无向图的情形，如果是有向图，需要考虑的出度和入度的问题。在刚才的基础上拓展一下，假如我们要比较你在微博和微信上的点度中心度，刚才的方法是否适用？如果说使用微信与微博的人数差不多，那么的确可以。但是如果说用户数量不一样呢？那么我们需要考虑到去规模化的问题，这就是**标准化的点度中心性**的理念。


```python
c_degree = nx.degree_centrality(G_karate)
c_degree = list(c_degree.values())
```

#### PageRank Algorithm  
PageRank estimates a current node’s importance from **its linked neighbors and then again from their respective neighbors**.  
PageRank is** usually computed on directed graphs**. However, it will also execute on undirected graphs by converting each edge in the directed graph to two edges.

你可以很轻易地找到最受欢迎的网页。但是，PageRank的思想认为，指标最好还需要考虑到指向你的那些网页。也就是说，**来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转。**这就是PageRank思想的精华，Google就是利用这一思想来给网站排名的。这里的思想依据和特征向量中心性其实是一致的([参考](https://zhuanlan.zhihu.com/p/31198752))。

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310193038.jpg)
[参考](https://maelfabien.github.io/machinelearning/graph_3/#pagerank-algorithm)


```python
pr = nx.pagerank(G_karate, alpha=0.9)
pr = list(pr.values())

pos = nx.spring_layout(G_karate)
nx.draw(G_karate,
        cmap=plt.get_cmap('inferno'),
        node_color=pr,
        node_size=600,
        pos=pos,
        with_labels=True)
```

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309175156.png)



#### Eigenvector Centrality (特征向量中心度)  

特征向量得分较高意味着该节点与许多自身得分较高的节点相连接。

Eigenvector centrality is a measure of the influence of a node in a network. It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. Google's PageRank is a variant of the Eigenvector centrality measure. Another closely related centrality measure is Katz centrality.


```python
c_eigenvector = nx.eigenvector_centrality(G_karate)
c_eigenvector = list(c_eigenvector.values())
```

#### Closeness Centrality (接近度中心度) 
Closeness Centrality detects nodes that are can spread information efficiently through a graph.It can be used to identify fake news accounts or in terrorist cells to isolate the individuals that can spread information to the rest of the graph.

例子：
对于了解图论的朋友而言，最短路这个概念一定不陌生。我们设想一个实际生活中的场景，比如你要建一个大型的娱乐商场，你可能会**希望周围的顾客到达这个商场的距离都可以尽可能地短**。这个就涉及到接近中心性的概念，接近中心性的值为路径长度的倒数。**接近中心性需要考量每个结点到其它结点的最短路的平均长度**。也就是说，对于一个结点而言，它距离其它结点越近，那么它的中心度越高。一般来说，那种需要让尽可能多的人使用的设施，它的接近中心度一般是比较高的。



```python
c_closeness = nx.closeness_centrality(G_karate)
list(c_closeness.values())
```

#### Betweenness Centrality (居间性中心度/中介中心性)  
Betweenness Centrality detects the amount of influence a node has over the flow of information in a graph. It is often used to find nodes that **serve as a bridge** from one part of a graph to another, for example in the package delivery processor in a telecommunication network, or in the propagation of fake news. The betweenness centrality measures the number of times a node acts as a bridge between two nodes

例子:
这个度量很有意思。这个有点像是我们身边那种社交达人，我们**认识的不少朋友可能都是通过他/她认识的**，这个人起到了**中介的作用**。中介中心性指的是**一个结点担任其它两个结点之间最短路的桥梁的次数**。一个结点充当“中介”的次数越高，它的中介中心度就越大。如果要考虑标准化的问题，可以用一个结点承担最短路桥梁的次数除以所有的路径数量。



```python
c_betweenness = nx.betweenness_centrality(G_karate)
list(c_betweenness.values())
```

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310185726.png)
[来源](https://cloud.tencent.com/developer/article/1436714)



## graph learning
There are two main tasks in graph learning :
- Link prediction
- Node labeling

### Linke prediction (链路预测)
Predictions are useful to predict future relations or missing edges when the graph is not fully observed for example.
different similarity scores  
- Jaccard Coefficient  
Common Neighbors => a normalized common neighbors version
- Adamic-Adar index  
common elements with very large neighborhoods are less significant when predicting a connection between two nodes compared to elements shared between a small number of nodes
- Preferential attachement  

How do we evaluate the link prediction? We must hide a subset of node pairs, and predict their links based on the rules defined above. We then evaluate the proportion of correct predictions for dense graphs, or use Area under the Curve criteria for Sparse graphs.


```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt


n = G_karate.number_of_nodes()
m = G_karate.number_of_edges()
print("Number of nodes : %d" % n)
print("Number of edges : %d" % m)
# 连通分量 ???
print("Number of connected components : %d" % nx.number_connected_components(G_karate))

```

- out:
	Number of nodes : 34
	Number of edges : 78
	Number of connected components : 1


```python
# Remove 20% of the edges
proportion_edges = 0.2
edge_subset = random.sample(G_karate.edges(), int(proportion_edges * G_karate.number_of_edges()))

# Create a copy of the graph and remove the edges
G_karate_train = G_karate.copy()
G_karate_train.remove_edges_from(edge_subset)

plt.figure(figsize=(12,8))
nx.draw(G_karate_train)

edge_subset_size = len(list(edge_subset))
print("Number of edges deleted : %d" % edge_subset_size)
print("Number of edges remaining : %d" % (m - edge_subset_size))
```
- out:
	Number of edges deleted : 15
	Number of edges remaining : 63


```python
# Make prediction using Jaccard Coefficient
pred_jaccard = list(nx.jaccard_coefficient(G_karate_train))
'''
pred_jaccard: a first node, a second node and a jaccard score
[   
    (0, 32, 0.15),
    (0, 33, 0.125),
    ...
]

'''
# label_jaccard: whether the node tuple(n,v) is in edge_subset
score_jaccard, label_jaccard = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_jaccard])


'''
Compute the ROC AUC Score
fpr: False positive rate, 
tpr: True postive rate, 
auc: the area under the ROC curve
'''
fpr_jaccard, tpr_jaccard, _ = roc_curve(label_jaccard, score_jaccard)
auc_jaccard = roc_auc_score(label_jaccard, score_jaccard)



# Prediction using Adamic Adar 
pred_adamic = list(nx.adamic_adar_index(G_karate_train))
score_adamic, label_adamic = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_adamic])

# Compute the ROC AUC Score
fpr_adamic, tpr_adamic, _ = roc_curve(label_adamic, score_adamic)
auc_adamic = roc_auc_score(label_adamic, score_adamic)



# Compute the Preferential Attachment
pred_pref = list(nx.preferential_attachment(G_karate_train))
score_pref, label_pref = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_pref])

fpr_pref, tpr_pref, _ = roc_curve(label_pref, score_pref)
auc_pref = roc_auc_score(label_pref, score_pref)



plt.figure(figsize=(10,8))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr_jaccard, tpr_jaccard, label='jaccard(auc: {:.3})'.format(auc_jaccard))
plt.plot(fpr_adamic, tpr_adamic, label='adamic(auc: {:.3})'.format(auc_adamic))
plt.plot(fpr_pref, tpr_pref, label='pref(auc: {:.3})'.format(auc_pref))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
```
参考: [1](https://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py), [2](https://blog.csdn.net/xyz1584172808/article/details/81839230?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310212348.png)


### Node Labeling  
Given a graph where some nodes are not labeled, we want to predict their labels. This is in some sense a semi-supervised learning problem.
One common way to deal with such problems is to assume that there is a certain smoothness on the graph. The Smoothness assumption states that points connected via a path through high-density regions on the data are likely to have similar labels. This is the main hypothesis behind the Label Propagation Algorithm(LPA). LPA is a fast algorithm for finding communities in a graph using network structure alone as its guide, without any predefined objective function or prior information about the communities.


## [graph embedding](https://maelfabien.github.io/machinelearning/graph_5/#)
we saw ways to learn in graphs, i.e. make node labeling and edge prediction. One of the limitations of graphs remains the absence of vector features. Just like in NLP, we face structured data. But just like in NLP, we can learn an embedding of the graph! There are several levels of embedding in a graph:
- Embedding graph components (nodes, edges, features…) ([Node2Vec](https://snap.stanford.edu/node2vec/))
- Embedding sub-parts of a graph or a whole graph ([Graph2Vec](https://arxiv.org/abs/1707.05005))

After learning an embedding, it can be used as features for several tasks :
- classification
- recommender systems


### Embedding process  
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200310214132.png)


### Node Embedding
According to the [authors](https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef): “node2vec is an algorithmic framework for representational learning on graphs. Given any graph, it can learn continuous feature representations for the nodes, which can then be used for various downstream machine learning tasks.” How does Node2Vec work? The model learns low-dimensional representations for nodes by optimizing a neighborhood preserving objective, using random walks.

```python
from node2vec import Node2Vec
node2vec = Node2Vec(G_karate, dimensions=64, walk_length=30, num_walks=200, workers=4)
model = node2vec.fit(window=10, min_count=1, batch_words=4)

# get the vector of a node
model.wv.get_vector('2')

# identify the most similar node
model.wv.most_similar('2')

```

### Edge Embedding

```python
from node2vec.edges import HadamardEmbedder
edges_embs = HadamardEmbedder(keyed_vectors=model.wv)

# get the vector of an edge
edges_embs[('1', '2')]

# identify the most similar edges
edges_kv = edges_embs.as_keyed_vectors()
edges_kv.most_similar(str(('1', '2')))

```

### Graph Embedding
There are also ways to embed a graph or a sub-graph directly. Graph embedding techniques take graphs and embed them in a lower-dimensional continuous latent space before passing that representation through a machine learning model.

An approach has been developed in the [Graph2Vec](https://github.com/benedekrozemberczki/graph2vec) paper and is useful to represent graphs or sub-graphs as vectors, thus allowing graph classification or graph similarity measures for example. 

***

![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/spring/20200309175413.webp)





