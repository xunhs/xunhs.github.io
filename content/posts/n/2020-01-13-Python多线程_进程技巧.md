---
layout: post
cid: 74
title: Python多线程/进程技巧
slug: 74
date: 2020-01-17T09:02:53+00:00
updated: '2020/02/21 14:40:46'
status: publish
author: Ethan
categories:
  - 收藏
tags:
  - multiprocessing
  - joblib
  - 并行
  - Pandas
  - Python
abbrlink: 7e2aa896
---



<!-- Abstract -->
> 整理Python并行化常用技巧

<!-- Abstract -->

<!--more-->

<!-- 正文内容 -->
### 利用joblib实现多进程/线程([参考1](https://www.cnblogs.com/feffery/p/11621076.html), [官网文档](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html), [参考2](https://www.cnblogs.com/massquantity/p/10357898.html))
~~与multiprocessing需要将执行运算的语句放置于含有if name == 'main'：的脚本文件中下不同，joblib将多进程的实现方式大大简化，使得我们可以在IPython交互式环境下中灵活地使用它。~~

#### 入门实例
```Python
from joblib import Parallel, delayed, parallel_backend
import numpy as np
import time
import datetime

def job(i):
    start = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    time.sleep(5)
    end = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    return start, end

if __name__ == "main":
    with parallel_backend('threading', n_jobs=50):
        res = Parallel(verbose=1)(delayed(job)(j) for j in range(5))
```

- 结果
![](https://i.postimg.cc/ZY22qHSn/1344061-20191108173936696-1411162155.png)

- parallel_backend: threading为线程方式，multiprocessing为进程方式
- n_jobs控制并行进程的数量，verbose参数控制是否打印进程运算过程


#### 多参数方案

```Python
def my_fun_2p(i, j):
    """ We define a simple function with two parameters.
    """
    time.sleep(1)
    return math.sqrt(i**j)


start = time.time()
# n_jobs is the number of parallel jobs
Parallel(n_jobs=2)(delayed(my_fun_2p)(i, j) for i in range(num) for j in range(j_num))
end = time.time()
print('{:.4f} s'.format(end-start))
```

#### 使用 joblib 对 Pandas 数据进行并行处理([参考1](https://www.cnblogs.com/IvyWong/p/11889926.html))

```Python
import pandas as pd
from joblib import Parallel, delayed
from tqdm import tqdm, tqdm_notebook

tqdm_notebook().pandas()

def double_func(data):
    return pow(data,2)

def key_func(subset):
    subset["double"] = subset["source"].apply(double_func)

data_grouped = data.groupby(data.index)
results = Parallel(n_jobs=8)(delayed(key_func)(group) for name, group in tqdm(data_grouped))
data = pd.concat(results)
```
- 基本原理就是把整个 dataframe 根据 index，每行生成了一个子数据集，而把每个子数据集作为子任务使用多进程运行，最终生成 results 是多进程运行生成的结果的 list，使用 concat 重新组合就是我们最终想要的结果了。
- 我们生成的 data_grouped 是一个可迭代的对象，那么就可以使用 tqdm 来可视化进度条。
- 友情提示，在我自己使用的时候遇到 bug ，提示无法从 Pandas 导入 PanelGroupby 的错误。查了许久才发现，是新版 Pandas 删除了PanelGroupby 这个模块。解决办法其实就是……升级 tqdm，在最新版已经修复了这个 bug 了。

### multiprocessing.map ([参考1](https://segmentfault.com/a/1190000000414339#fnref-2))
#### 线程任务（IO 密集型任务）
```Python
import urllib2
from multiprocessing.dummy import Pool as ThreadPool

urls = [
'http://www.python.org',
'http://www.python.org/about/',
'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html',
'http://www.python.org/doc/',
'http://www.python.org/download/',
'http://www.python.org/getit/',
'http://www.python.org/community/',
'https://wiki.python.org/moin/',
'http://planet.python.org/',
'https://wiki.python.org/moin/LocalUserGroups',
'http://www.python.org/psf/',
'http://docs.python.org/devguide/',
'http://www.python.org/community/awards/'
# etc..
]

# Make the Pool of workers
pool = ThreadPool(4)
# Open the urls in their own threads
# and return the results
results = pool.map(urllib2.urlopen, urls)
#close the pool and wait for the work to finish
pool.close()
pool.join()
```
- 多线程常应用在网络任务，如爬虫
- ThreadPool.map 简化分组操作

#### 进程任务（CPU 密集型任务）
```Python

import os
import PIL

from multiprocessing import Pool
from PIL import Image

SIZE = (75,75)
SAVE_DIRECTORY = 'thumbs'

def get_image_paths(folder):
    return (os.path.join(folder, f)
    for f in os.listdir(folder)
        if 'jpeg' in f)

def create_thumbnail(filename):
    im = Image.open(filename)
    im.thumbnail(SIZE, Image.ANTIALIAS)
    base, fname = os.path.split(filename)
    save_path = os.path.join(base, SAVE_DIRECTORY, fname)
    im.save(save_path)

if __name__ == '__main__':
    folder = os.path.abspath('11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840')
    os.mkdir(os.path.join(folder, SAVE_DIRECTORY))

    images = get_image_paths(folder)

    pool = Pool()
    pool.map(creat_thumbnail, images)
    pool.close()
    pool.join()

```

<!-- 正文内容 -->
***

<!-- 图片位置 -->

<!-- 图片位置 -->