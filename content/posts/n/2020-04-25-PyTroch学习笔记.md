---
layout: post
cid: 328
title: PyTrochå­¦ä¹ ç¬”è®°
slug: 328
date: 2020-04-25T09:22:21+00:00
status: publish
author: Ethan
toc: true
categories:
  - æ”¶è—
tags:
  - æ·±åº¦å­¦ä¹ 
  - PyTorch
  - Python
  - ç¥ç»ç½‘ç»œ
  - é¢„è®­ç»ƒæ¨¡å‹
---


> Refer: [deep_learning_60min_blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)

<!--more-->

### Getting Started
```python
import torch
```
- [PYTORCH CHEAT SHEET](https://pytorch.org/tutorials/beginner/ptcheat.html)
- [PYTORCH TUTORIALS](https://pytorch.org/tutorials/index.html)
- [PyTorch 1.4 ä¸­æ–‡æ–‡æ¡£](https://pytorch.apachecn.org/docs/1.4/)

#### Tensors
- Construct a randomly initialized matrix: `x = torch.rand(5, 3)`
- Construct a matrix filled zeros and of dtype long: `x = torch.zeros(5, 3, dtype=torch.long)`
- Construct a tensor directly from data: `x = torch.tensor([5.5, 3])`
- or create a tensor based on an existing tensor. These methods will **reuse** properties of the input tensor, e.g. dtype, unless new values are provided by user: 
    - `x = x.new_ones(5, 3, dtype=torch.double)`
    - `x = torch.randn_like(x, dtype=torch.float)`
- Get its size (shape in numpy/pandas): `x.size()` [Note: `torch.Size` is in fact a tuple]

#### Operations
- use standard NumPy-like indexing: `x[:, 1]`
- resize/reshape tensor, you can use `torch.view`:
```python 
x = torch.randn(4, 4)
y = x.view(16)
z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
print(x.size(), y.size(), z.size())
```
#### NumPy Bridge
Torch Tensor <=> a NumPy
- Converting a Torch Tensor to a NumPy Array: `tensor.numpy()`
```python
a = torch.ones(5)
b = a.numpy()
```
- Converting NumPy Array to Torch Tensor: `torch.from_numpy(array)`
```python
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
```

#### CUDA Tensors

```python
# let us run this cell only if CUDA is available
# We will use ``torch.device`` objects to move tensors in and out of GPU
if torch.cuda.is_available():
    device = torch.device("cuda")          # a CUDA device object
    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU
    x = x.to(device)                       # or just use strings ``.to("cuda")``
    z = x + y
    print(z)
    print(z.to("cpu", torch.double))       # ``.to`` can also change dtype together!
```

### AUTOGRAD: AUTOMATIC DIFFERENTIATION
To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`. This can be particularly helpful when **evaluating a model** because the model may have trainable parameters with `requires_grad=True`, but for which we donâ€™t need the gradients.

### NEURAL NETWORKS
Neural networks can be constructed using the torch.nn package.<br />
Now that you had a glimpse of autograd, nn depends on autograd to define models and differentiate them. An nn.Module contains layers, and a method forward(input)that returns the output.<br />
A typical training procedure for a neural network is as follows:
1. Define the neural network that has some learnable parameters (or weights)
2. Iterate over a dataset of inputs
3. Process input through the network
4. Compute the loss (how far is the output from being correct)
5. Propagate gradients back into the networkâ€™s parameters
6. Update the weights of the network, typically using a simple update rule: `weight = weight - learning_rate * gradient`

#### Define the network
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/summer/20200425094243.png)
```python
import torch
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        # 1 input image channel, 6 output channels, 3x3 square convolution
        # kernel
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        # an affine operation: y = Wx + b
        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # Max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        # If the size is a square you can only specify a single number
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


net = Net()
print(net)

'''
Out:
Net(
  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=576, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
'''
```
- You just have to **define the forward function**, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function.
- The learnable parameters of a model are returned by `net.parameters()`:
```python
params = list(net.parameters())
print(len(params)) # å“ªåå±‚çš„å‚æ•°å‘¢ï¼Ÿ
print(params[0].size())  # conv1's .weight
'''
10: 
torch.Size([6])
'''
```
Note: åå±‚å‚æ•°(->): input -> conv2d -> relu -> conv2d -> relu -> view -> linear -> relu -> linear -> relu -> linear
- **try a random 32x32 input**. Note: expected input size of this net (LeNet) is 32x32. To use this net on the MNIST dataset, please resize the images from the dataset to 32x32.
```python
input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)
```
- Zero the gradient buffers of all parameters and backprops with random gradients:
```python
net.zero_grad()
out.backward(torch.randn(1, 10))
```
#### Loss Function
A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.<br />
There are several different loss functions under the nn package. A simple loss is: `nn.MSELoss` which computes the mean-squared error between the input and the target.
```python
input = torch.randn(1, 1, 32, 32)
output = net(input)
target = torch.randn(10)  # a dummy target, for example
target = target.view(1, -1)  # make it the same shape as output
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)

'''
out:
tensor(0.9145, grad_fn=<MseLossBackward>)
'''

```

#### Backprop
```python
net.zero_grad()     # zeroes the gradient buffers of all parameters

print('conv1.bias.grad before backward')
print(net.conv1.bias.grad)

loss.backward()

print('conv1.bias.grad after backward')
print(net.conv1.bias.grad)
'''
out:
conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
conv1.bias.grad after backward
tensor([ 1.2122e-03, -9.3038e-04, -3.8394e-04,  2.5266e-03, -1.4529e-03,
         9.5785e-05])
'''
```

#### Update the weights
The simplest update rule used in practice is the Stochastic Gradient Descent (SGD): `weight = weight - learning_rate * gradient`
As you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: `torch.optim` that implements all these methods. Using it is very simple:
```python
import torch.optim as optim
# create your optimizer
optimizer = optim.SGD(net.parameters(), lr=0.01)
# in your training loop:
optimizer.zero_grad()   # zero the gradient buffers
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()    # Does the update
```
### TRAINING A CLASSIFIER
#### What about data?
Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a `torch.*Tensor`.

- For images, packages such as Pillow, OpenCV are useful
- For audio, packages such as scipy and librosa
- For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful

For this tutorial, we will use the CIFAR10 dataset. It has the classes: â€˜airplaneâ€™, â€˜automobileâ€™, â€˜birdâ€™, â€˜catâ€™, â€˜deerâ€™, â€˜dogâ€™, â€˜frogâ€™, â€˜horseâ€™, â€˜shipâ€™, â€˜truckâ€™. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/summer/20200425094540.png)

#### Training an image classifier
We will do the following steps in order:
1. Load and normalizing the CIFAR10 training and test datasets using torchvision
2. Define a Convolutional Neural Network
```python
import torch.nn as nn
import torch.nn.functional as F
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
net = Net()
```
3. Define a loss function
```python
import torch.optim as optim
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```
4. Train the network on the training data
```python
for epoch in range(10):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
print('Finished Training')
'''
out:
[1,  2000] loss: 2.151
[1,  4000] loss: 1.804
[1,  6000] loss: 1.634
[1,  8000] loss: 1.591
[1, 10000] loss: 1.499
[1, 12000] loss: 1.469
[2,  2000] loss: 1.389
[2,  4000] loss: 1.378
[2,  6000] loss: 1.362
[2,  8000] loss: 1.307
[2, 10000] loss: 1.302
[2, 12000] loss: 1.272
Finished Training
'''
```
- [save model](https://pytorch.org/docs/stable/notes/serialization.html):
```python
PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)
```
- load model:
```python
the_model = TheModelClass(*args, **kwargs)
the_model.load_state_dict(torch.load(PATH))
```
5. Test the network on the test data
- simple test:
```python
dataiter = iter(testloader)
images, labels = dataiter.next() # 4 images, (4,3,32,32)
outputs = net(images) # outputs: (4, 10)
_, predicted = torch.max(outputs, 1) 
print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                              for j in range(4)))
'''
Predicted:    cat  ship  ship plane
'''
```
Note:
torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)
æŒ‰ç»´åº¦dim è¿”å›æœ€å¤§å€¼, ä¸”è¿”å›ç´¢å¼•. **dim:(0: åˆ—ï¼Œ1: è¡Œ)**
- performs on the whole dataset:
```python
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
'''
Accuracy of the network on the 10000 test images: 55 %
'''
```
- Hmmm, what are the classes that performed well, and the classes that did not perform well
```python
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1
for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
'''
Accuracy of plane : 55 %
Accuracy of   car : 63 %
Accuracy of  bird : 25 %
Accuracy of   cat : 45 %
Accuracy of  deer : 41 %
Accuracy of   dog : 52 %
Accuracy of  frog : 66 %
Accuracy of horse : 63 %
Accuracy of  ship : 72 %
Accuracy of truck : 70 %
'''
```
#### Training on GPU
```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# Assuming that we are on a CUDA machine, this should print a CUDA device:
print(device)
'''
cuda:0
'''
# convert their parameters and buffers to CUDA tensors
net.to(device)
# send the inputs and targets at every step to the GPU too:
inputs, labels = data[0].to(device), data[1].to(device)
```

### Learning PyTorch with Examples
#### two-layer network(torch.nn.Sequential)
```python
# -*- coding: utf-8 -*-
import torch

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

# Use the nn package to define our model and loss function.
model = torch.nn.Sequential(
    torch.nn.Linear(D_in, H),
    torch.nn.ReLU(),
    torch.nn.Linear(H, D_out),
)
loss_fn = torch.nn.MSELoss(reduction='sum')

# Use the optim package to define an Optimizer that will update the weights of
# the model for us. Here we will use Adam; the optim package contains many other
# optimization algoriths. The first argument to the Adam constructor tells the
# optimizer which Tensors it should update.
learning_rate = 1e-4
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
for t in range(500):
    # Forward pass: compute predicted y by passing x to the model.
    y_pred = model(x)

    # Compute and print loss.
    loss = loss_fn(y_pred, y)
    if t % 100 == 99:
        print(t, loss.item())

    # Before the backward pass, use the optimizer object to zero all of the
    # gradients for the variables it will update (which are the learnable
    # weights of the model). This is because by default, gradients are
    # accumulated in buffers( i.e, not overwritten) whenever .backward()
    # is called. Checkout docs of torch.autograd.backward for more details.
    optimizer.zero_grad()

    # Backward pass: compute gradient of the loss with respect to model
    # parameters
    loss.backward()

    # Calling the step function on an Optimizer makes an update to its
    # parameters
    optimizer.step()
```
#### Custom nn Modules
Sometimes you will want to specify models that are more complex than a sequence of existing Modules; for these cases you can define your own Modules by subclassing nn.Module and defining a forward which receives input Tensors and produces output Tensors using other modules or other autograd operations on Tensors.
```python
# -*- coding: utf-8 -*-
import torch


class TwoLayerNet(torch.nn.Module):
    def __init__(self, D_in, H, D_out):
        """
        In the constructor we instantiate two nn.Linear modules and assign them as member variables.
        """
        super(TwoLayerNet, self).__init__()
        self.linear1 = torch.nn.Linear(D_in, H)
        self.linear2 = torch.nn.Linear(H, D_out)

    def forward(self, x):
        """
        In the forward function we accept a Tensor of input data and we must return a Tensor of output data. We can use Modules defined in the constructor as well as arbitrary operators on Tensors.
        """
        h_relu = self.linear1(x).clamp(min=0)
        y_pred = self.linear2(h_relu)
        return y_pred


# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

# Construct our model by instantiating the class defined above
model = TwoLayerNet(D_in, H, D_out)

# Construct our loss function and an Optimizer. The call to model.parameters()
# in the SGD constructor will contain the learnable parameters of the two
# nn.Linear modules which are members of the model.
criterion = torch.nn.MSELoss(reduction='sum')
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)
for t in range(500):
    # Forward pass: Compute predicted y by passing x to the model
    y_pred = model(x)

    # Compute and print loss
    loss = criterion(y_pred, y)
    if t % 100 == 99:
        print(t, loss.item())

    # Zero gradients, perform a backward pass, and update the weights.
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```
### Visualizing Models, Data, and Training with TensorBoard
https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html#tracking-model-training-with-tensorboard


### Pretained models
#### torchvision.models
å‚è€ƒ:
- [torchvision.models](https://ptorch.com/docs/1/models)
- [pytorchä¸­çš„pre-trainå‡½æ•°æ¨¡å‹å¼•ç”¨åŠä¿®æ”¹](https://blog.csdn.net/whut_ldz/article/details/78845947)
- [Pytorchï¼šåˆ©ç”¨é¢„è®­ç»ƒå¥½çš„VGG16ç½‘ç»œæå–å›¾ç‰‡ç‰¹å¾](https://blog.csdn.net/Geek_of_CSDN/article/details/84343971)



#### pretrainedmodels
å‚è€ƒ:
- [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch)

***
![](https://gitee.com/xunhs/xunhs/raw/master/pics/2020/summer/20200425114411.jpg)




### Other tricks
#### æ¸…é™¤GPUå­˜å‚¨
å‚è€ƒ:[çŸ¥ä¹](https://www.zhihu.com/collection/334915478)
æœ‰æ—¶Control-Cä¸­æ­¢è¿è¡ŒåGPUå­˜å‚¨æ²¡æœ‰åŠæ—¶é‡Šæ”¾ï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç©ºã€‚åœ¨PyTorchå†…éƒ¨å¯ä»¥`torch.cuda.empty_cache()`, æˆ–åœ¨å‘½ä»¤è¡Œå¯ä»¥å…ˆä½¿ç”¨psæ‰¾åˆ°ç¨‹åºçš„PIDï¼Œå†ä½¿ç”¨killç»“æŸè¯¥è¿›ç¨‹:
```bash 
ps aux | grep python
kill -9 [pid]
```
æˆ–è€…ç›´æ¥é‡ç½®æ²¡æœ‰è¢«æ¸…ç©ºçš„GPU`nvidia-smi --gpu-reset -i [gpu_id]`

#### å¸¸ç”¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é¢„å¤„ç†
å…¶ä¸­ToTensoræ“ä½œä¼šå°†PIL.Imageæˆ–å½¢çŠ¶ä¸ºHÃ—WÃ—Dï¼Œæ•°å€¼èŒƒå›´ä¸º[0, 255]çš„np.ndarrayè½¬æ¢ä¸ºå½¢çŠ¶ä¸ºDÃ—HÃ—Wï¼Œæ•°å€¼èŒƒå›´ä¸º[0.0, 1.0]çš„torch.Tensorã€‚
```python
train_transform = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(size=224,
                                             scale=(0.08, 1.0)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
 ])
 val_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
])
```



### pytorch-lighting

#### hello world-mnist

A more complete MNIST Lightning Module Example

1. [prepare_data()](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.prepare_data) ğŸ’¾

â€‹    \- This is where we can download the dataset. We point to our desired dataset and ask torchvision's `MNIST` dataset class to download if the dataset isn't found there.

2. [setup(stage)](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning-module.html#setup) âš™ï¸

â€‹    \- Loads in data from file and prepares PyTorch tensor datasets for each split (train, val, test). 

â€‹    \- Setup expects a 'stage' arg which is used to separate logic for 'fit' and 'test'.

â€‹    \- If you don't mind loading all your datasets at once, you can set up a condition to allow for both 'fit' related setup and 'test' related setup to run whenever `None` is passed to `stage` (or ignore it altogether and exclude any conditionals).

3. [x_dataloader()](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning-module.html#data-hooks) â™»ï¸

â€‹    \- `train_dataloader()`, `val_dataloader()`, and `test_dataloader()` all return PyTorch `DataLoader` instances that are created by wrapping their respective datasets that we prepared in `setup()`

```python
import os
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import MNIST
from torchvision import transforms
import pytorch_lightning as pl
from pytorch_lightning.metrics.functional import accuracy


class LitMNIST(pl.LightningModule):

    def __init__(self, data_dir='./', hidden_size=64, learning_rate=2e-4):
        super().__init__()
        # Set our init args as class attributes
        self.data_dir = data_dir
        self.hidden_size = hidden_size
        self.learning_rate = learning_rate

        # Hardcode some dataset specific attributes
        self.num_classes = 10
        self.dims = (1, 28, 28)
        channels, width, height = self.dims
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])

        # Define PyTorch model
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(channels * width * height, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, self.num_classes)
        )

    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        acc = accuracy(preds, y)

        # Calling self.log will surface up scalars for you in TensorBoard
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss

    def test_step(self, batch, batch_idx):
        # Here we just reuse the validation_step for testing
        return self.validation_step(batch, batch_idx)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer

    ####################
    # DATA RELATED HOOKS
    ####################

    def prepare_data(self):
        # download
        MNIST(self.data_dir, train=True, download=True)
        MNIST(self.data_dir, train=False, download=True)

    def setup(self, stage=None):

        # Assign train/val datasets for use in dataloaders
        if stage == 'fit' or stage is None:
            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)
            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])

        # Assign test dataset for use in dataloader(s)
        if stage == 'test' or stage is None:
            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)

    def train_dataloader(self):
        return DataLoader(self.mnist_train, batch_size=32)

    def val_dataloader(self):
        return DataLoader(self.mnist_val, batch_size=32)

    def test_dataloader(self):
        return DataLoader(self.mnist_test, batch_size=32)
```

